<html><head>
      <meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
   <title>10.&nbsp;Streams</title><link rel="stylesheet" type="text/css" href="css/manual-multipage.css"><meta name="generator" content="DocBook XSL Stylesheets V1.78.1"><link rel="home" href="index.html" title="Spring Cloud Data Flow for Apache YARN"><link rel="up" href="architecture.html" title="Part&nbsp;III.&nbsp;Architecture"><link rel="prev" href="arch-streaming-apps.html" title="9.&nbsp;Streaming Applications"><link rel="next" href="arch-analytics.html" title="11.&nbsp;Analytics"></head><body bgcolor="white" text="black" link="#0000FF" vlink="#840084" alink="#0000FF"><div class="navheader"><table width="100%" summary="Navigation header"><tr><th colspan="3" align="center">10.&nbsp;Streams</th></tr><tr><td width="20%" align="left"><a accesskey="p" href="arch-streaming-apps.html">Prev</a>&nbsp;</td><th width="60%" align="center">Part&nbsp;III.&nbsp;Architecture</th><td width="20%" align="right">&nbsp;<a accesskey="n" href="arch-analytics.html">Next</a></td></tr></table><hr></div><div class="chapter"><div class="titlepage"><div><div><h2 class="title"><a name="arch-streams" href="#arch-streams"></a>10.&nbsp;Streams</h2></div></div></div><div class="section"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="arch-streams-topologies" href="#arch-streams-topologies"></a>10.1&nbsp;Topologies</h2></div></div></div><p>The Stream DSL describes linear sequences of data flowing through the system.  For example, in the stream definition <code class="literal">http | transformer | cassandra</code>, each pipe symbol connects the application on the left to the one on the right.  Named channels can be used for routing and to fan out data to multiple messaging destinations.</p><p>Taps can be used to &#8216;listen in&#8217; to the data that if flowing across any of the pipe symbols.  Taps can be used as sources for new streams with an in independent life cycle.</p></div><div class="section"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="arch-streams-concurrency" href="#arch-streams-concurrency"></a>10.2&nbsp;Concurrency</h2></div></div></div><p>For an application that will consume events, Spring Cloud stream exposes a concurrency setting that controls the size of a thread pool used for dispatching incoming messages.  See the 1.2.2.RELEASE#_consumer_properties[Consumer properties] documentation for more information.</p></div><div class="section"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="arch-streams-partitioning" href="#arch-streams-partitioning"></a>10.3&nbsp;Partitioning</h2></div></div></div><p>A common pattern in stream processing is to partition the data as it moves from one application to the next.  Partitioning is a critical concept in stateful processing, for either performance or consistency reasons, to ensure that all related data is processed together. For example, in a time-windowed average calculation example, it is important that all measurements from any given sensor are processed by the same application instance.  Alternatively, you may want to cache some data related to the incoming events so that it can be enriched without making a remote procedure call to retrieve the related data.</p><p>Spring Cloud Data Flow supports partitioning by configuring Spring Cloud Stream&#8217;s output and input bindings.  Spring Cloud Stream provides a common abstraction for implementing partitioned processing use cases in a uniform fashion across different types of middleware.  Partitioning can thus be used whether the broker itself is naturally partitioned (e.g., Kafka topics) or not (e.g., RabbitMQ).  The following image shows how data could be partitioned into two buckets, such that each instance of the average processor application consumes a unique set of data.</p><div class="figure"><a name="d0e341" href="#d0e341"></a><p class="title"><b>Figure&nbsp;10.1.&nbsp;Spring Cloud Stream Partitioning</b></p><div class="figure-contents"><div class="mediaobject"><img src="https://raw.githubusercontent.com/spring-cloud/spring-cloud-dataflow/v1.2.2.RELEASE/spring-cloud-dataflow-docs/src/main/asciidoc/images/stream-partitioning.png" alt="Stream Partitioning Architecture"></div></div></div><br class="figure-break"><p>To use a simple partitioning strategy in Spring Cloud Data Flow, you only need set the instance count for each application in the stream and a <code class="literal">partitionKeyExpression</code> producer property when deploying the stream.  The <code class="literal">partitionKeyExpression</code> identifies what part of the message will be used as the key to partition data in the underlying middleware.  An <code class="literal">ingest</code> stream can be defined as <code class="literal">http | averageprocessor | cassandra</code>  (Note that the Cassandra sink isn&#8217;t shown in the diagram above).  Suppose the payload being sent to the http source was in JSON format and had a field called <code class="literal">sensorId</code>.  Deploying the stream with the shell command <code class="literal">stream deploy ingest --propertiesFile ingestStream.properties</code> where the contents of the file <code class="literal">ingestStream.properties</code> are</p><pre class="programlisting">deployer.http.count=<span class="hl-number">3</span>
deployer.averageprocessor.count=<span class="hl-number">2</span>
app.http.producer.partitionKeyExpression=payload.sensorId</pre><p>will deploy the stream such that all the input and output destinations are configured for data to flow through the applications but also ensure that a unique set of data is always delivered to each averageprocessor instance.  In this case the default algorithm is to evaluate <code class="literal">payload.sensorId % partitionCount</code> where the <code class="literal">partitionCount</code> is the application count in the case of RabbitMQ and the partition count of the topic in the case of Kafka.</p><p>Please refer to <a class="xref" href="spring-cloud-dataflow-create-stream.html#passing_stream_partition_properties" title="25.2.7&nbsp;Passing stream partition properties during stream deployment">Section&nbsp;25.2.7, &#8220;Passing stream partition properties during stream deployment&#8221;</a> for additional strategies to partition streams during deployment and how they map onto the underlying 1.2.2.RELEASE#_partitioning[Spring Cloud Stream Partitioning properties].</p><p>Also note, that you can&#8217;t currently scale partitioned streams.  Read the section <a class="xref" href="arch-runtime.html#arch-runtime-scaling" title="14.3&nbsp;Scaling at runtime">Section&nbsp;14.3, &#8220;Scaling at runtime&#8221;</a> for more information.</p></div><div class="section"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="arch-streams-delivery" href="#arch-streams-delivery"></a>10.4&nbsp;Message Delivery Guarantees</h2></div></div></div><p>Streams are composed of applications that use the Spring Cloud Stream library as the basis for communicating with the underlying messaging middleware product.  Spring Cloud Stream also provides an opinionated configuration of middleware from several vendors, in particular providing 1.2.2.RELEASE#_persistent_publish_subscribe_support[persistent publish-subscribe semantics].</p><p>The 1.2.2.RELEASE#_binders[Binder abstraction] in Spring Cloud Stream is what connects the application to the middleware.  There are several configuration properties of the binder that are portable across all binder implementations and some that are specific to the middleware.</p><p>For consumer applications there is a retry policy for exceptions generated during message handling.  The retry policy is configured using the 1.2.2.RELEASE#_consumer_properties[common consumer properties] <code class="literal">maxAttempts</code>, <code class="literal">backOffInitialInterval</code>, <code class="literal">backOffMaxInterval</code>, and <code class="literal">backOffMultiplier</code>.  The default values of these properties will retry the callback method invocation 3 times and wait one second for the first retry.  A backoff multiplier of 2 is used for the second and third attempts.</p><p>When the number of retry attempts has exceeded the <code class="literal">maxAttempts</code> value, the exception and the failed message will become the payload of a message and be sent to the application&#8217;s error channel.  By default, the default message handler for this error channel logs the message.  You can change the default behavior in your application by creating your own message handler that subscribes to the error channel.</p><p>Spring Cloud Stream also supports a configuration option for both Kafka and RabbitMQ binder implementations that will send the failed message and stack trace to a dead letter queue.  The dead letter queue is a destination and its nature depends on the messaging middleware (e.g in the case of Kafka it is a dedicated topic).  To enable this for RabbitMQ set the 1.2.2.RELEASE#_rabbitmq_consumer_properties[consumer properties] <code class="literal">republishtoDlq</code> and <code class="literal">autoBindDlq</code> and the 1.2.2.RELEASE#_rabbit_producer_properties[producer property] <code class="literal">autoBindDlq</code> to true when deploying the stream.  To always apply these producer and consumer properties when deploying streams, configure them as <a class="link" href="spring-cloud-dataflow-create-stream.html#spring-cloud-dataflow-global-properties" title="25.3&nbsp;Common application properties">common application properties</a> when starting the Data Flow server.</p><p>Additional messaging delivery guarantees are those provided by the underlying messaging middleware that is chosen for the application for both producing and consuming applications.  Refer to the Kafka 1.2.2.RELEASE#_kafka_consumer_properties[Consumer] and 1.2.2.RELEASE#_kafka_producer_properties[Producer] and Rabbit 1.2.2.RELEASE#_rabbitmq_consumer_properties[Consumer] and 1.2.2.RELEASE#_rabbit_producer_properties[Producer] documentation for more details.  You will find extensive declarative support for all the native QOS options.</p></div></div><div class="navfooter"><hr><table width="100%" summary="Navigation footer"><tr><td width="40%" align="left"><a accesskey="p" href="arch-streaming-apps.html">Prev</a>&nbsp;</td><td width="20%" align="center"><a accesskey="u" href="architecture.html">Up</a></td><td width="40%" align="right">&nbsp;<a accesskey="n" href="arch-analytics.html">Next</a></td></tr><tr><td width="40%" align="left" valign="top">9.&nbsp;Streaming Applications&nbsp;</td><td width="20%" align="center"><a accesskey="h" href="index.html">Home</a></td><td width="40%" align="right" valign="top">&nbsp;11.&nbsp;Analytics</td></tr></table></div></body></html>