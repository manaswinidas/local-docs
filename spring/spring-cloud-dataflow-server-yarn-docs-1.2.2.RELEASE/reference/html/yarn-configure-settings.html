<html><head>
      <meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
   <title>17.&nbsp;Configuring Runtime Settings and Environment</title><link rel="stylesheet" type="text/css" href="css/manual-multipage.css"><meta name="generator" content="DocBook XSL Stylesheets V1.78.1"><link rel="home" href="index.html" title="Spring Cloud Data Flow for Apache YARN"><link rel="up" href="_spring_cloud_data_flow_runtime.html" title="Part&nbsp;IV.&nbsp;Spring Cloud Data Flow Runtime"><link rel="prev" href="yarn-deploying-on-ambari.html" title="16.&nbsp;Deploying on AMBARI"><link rel="next" href="yarn-how-it-works.html" title="18.&nbsp;How YARN Deployment Works"></head><body bgcolor="white" text="black" link="#0000FF" vlink="#840084" alink="#0000FF"><div class="navheader"><table width="100%" summary="Navigation header"><tr><th colspan="3" align="center">17.&nbsp;Configuring Runtime Settings and Environment</th></tr><tr><td width="20%" align="left"><a accesskey="p" href="yarn-deploying-on-ambari.html">Prev</a>&nbsp;</td><th width="60%" align="center">Part&nbsp;IV.&nbsp;Spring Cloud Data Flow Runtime</th><td width="20%" align="right">&nbsp;<a accesskey="n" href="yarn-how-it-works.html">Next</a></td></tr></table><hr></div><div class="chapter"><div class="titlepage"><div><div><h2 class="title"><a name="yarn-configure-settings" href="#yarn-configure-settings"></a>17.&nbsp;Configuring Runtime Settings and Environment</h2></div></div></div><p>This section describes how settings related to running YARN
application can be modified.</p><div class="section"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="_generic_app_settings" href="#_generic_app_settings"></a>17.1&nbsp;Generic App Settings</h2></div></div></div><p>All applications whether those are stream apps or task apps can be
centrally configured with <code class="literal">servers.yml</code> as that file is passed to apps
using <code class="literal">--spring.config.location='servers.yml'</code>.</p></div><div class="section"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="_configuring_application_resources" href="#_configuring_application_resources"></a>17.2&nbsp;Configuring Application Resources</h2></div></div></div><p>Stream and task processes for application master and containers can be
further tuned by setting memory and cpu settings. Also java options
allow to define actual jvm options.</p><pre class="programlisting">spring:
  cloud:
    deployer:
      yarn:
        app:
          streamappmaster:
            memory: 512m
            virtualCores: 1
            javaOpts: "-Xms512m -Xmx512m"
          streamcontainer:
            priority: 5
            memory: 256m
            virtualCores: 1
            javaOpts: "-Xms64m -Xmx256m"
          taskappmaster:
            memory: 512m
            virtualCores: 1
            javaOpts: "-Xms512m -Xmx512m"
          taskcontainer:
            priority: 10
            memory: 256m
            virtualCores: 1
            javaOpts: "-Xms64m -Xmx256m"</pre></div><div class="section"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="_configure_base_directory" href="#_configure_base_directory"></a>17.3&nbsp;Configure Base Directory</h2></div></div></div><p>Base directory where all needed files are kept defaults to <code class="literal">/dataflow</code>
and can be changed using <code class="literal">baseDir</code> property.</p><pre class="programlisting">spring:
  cloud:
    deployer:
      yarn:
        app:
          baseDir: /dataflow</pre></div><div class="section"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="yarn-pre-populate" href="#yarn-pre-populate"></a>17.4&nbsp;Pre-populate Applications</h2></div></div></div><p>Spring Cloud Data Flow app registration is based on URI&#8217;s with various
different endpoints. As mentioned in section <a class="xref" href="yarn-how-it-works.html" title="18.&nbsp;How YARN Deployment Works">Chapter&nbsp;18, <i>How YARN Deployment Works</i></a> all
applications are first stored into hdfs before application container
is launched. Server can use <code class="literal">http</code>, <code class="literal">file</code>, <code class="literal">http</code> and <code class="literal">maven</code> based
uris as well direct <code class="literal">hdfs</code> uris.</p><p>It is possible to place these applications directly into HDFS and
register application based on that URI.</p></div><div class="section"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="_configure_logging" href="#_configure_logging"></a>17.5&nbsp;Configure Logging</h2></div></div></div><p>Logging for all components is done centrally via <code class="literal">servers.yml</code> file
using normal Spring Boot properties.</p><pre class="programlisting">logging:
  level:
    org.apache.hadoop: INFO
    org.springframework.yarn: INFO</pre></div><div class="section"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="_configure_metrics" href="#_configure_metrics"></a>17.6&nbsp;Configure Metrics</h2></div></div></div><p>If metrics are enabled, needed settings are written into <code class="literal">servers.yml</code>
files used by applications. Also specific settings are written into
<code class="literal">collectors.yml</code> used by <span class="emphasis"><em>SCDF Metrics Collector</em></span> service. You need to
choose a correct collector type, its service port and output channel
name.</p><div class="figure"><a name="d0e1095" href="#d0e1095"></a><p class="title"><b>Figure&nbsp;17.1.&nbsp;Metrics Config</b></p><div class="figure-contents"><div class="mediaobject"><img src="images/ambari-metrics-config.png" alt="Metrics Config"></div></div></div><br class="figure-break"></div><div class="section"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="_global_yarn_memory_settings" href="#_global_yarn_memory_settings"></a>17.7&nbsp;Global YARN Memory Settings</h2></div></div></div><p>YARN Nodemanager is continously tracking how much memory is used by
individual YARN containers. If containers are using more memory than
what the configuration allows, containers are simply killed by a
Nodemanager. Application master controlling the app lifecycle is given
a little more freedom meaning that Nodemanager is not that aggressive
when making a desicion when a container should be killed.</p><div class="important" style="margin-left: 0.5in; margin-right: 0.5in;"><table border="0" summary="Important"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Important]" src="images/important.png"></td><th align="left">Important</th></tr><tr><td align="left" valign="top"><p>These are global cluster settings and cannot be changed during an
application deployment.</p></td></tr></table></div><p>Lets take a quick look of memory related settings in YARN cluster and
in YARN applications. Below xml config is what a default vanilla
Apache
Hadoop uses for memory related settings. Other distributions may have
different defaults.</p><div class="variablelist"><dl class="variablelist"><dt><span class="term"><span class="strong"><strong>yarn.nodemanager.pmem-check-enabled</strong></span></span></dt><dd>Enables a check for physical memory of a process. This check if
enabled is directly tracking amount of memory requested for a YARN
container.</dd><dt><span class="term"><span class="strong"><strong>yarn.nodemanager.vmem-check-enabled</strong></span></span></dt><dd>Enables a check for virtual memory of a process. This setting is one
which is usually causing containers of a custom YARN applications to
get killed by a node manager. Usually the actual ratio between
physical and virtual memory is higher than a default <code class="literal">2.1</code> or bugs in
a OS is causing wrong calculation of a used virtual memory.</dd><dt><span class="term"><span class="strong"><strong>yarn.nodemanager.vmem-pmem-ratio</strong></span></span></dt><dd>Defines a ratio of allowed virtual memory compared to physical memory.
This ratio simply defines how much virtual memory a process can use
but the actual tracked size is always calculated from a physical
memory limit.</dd><dt><span class="term"><span class="strong"><strong>yarn.scheduler.minimum-allocation-mb</strong></span></span></dt><dd><p class="simpara">Defines a minimum allocated memory for container.</p><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><table border="0" summary="Note"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Note]" src="images/note.png"></td><th align="left">Note</th></tr><tr><td align="left" valign="top"><p>This setting also indirectly defines what is the actual physical
memory limit requested during a container allocation. Actual physical
memory limit is always going to be multiple of this setting rounded to
upper bound. For example if this setting is left to default <code class="literal">1024</code> and
container is requested with <code class="literal">512M</code>, <code class="literal">1024M</code> is going to be used.
However if requested size is <code class="literal">1100M</code>, actual size is set to <code class="literal">2048M</code>.</p></td></tr></table></div></dd><dt><span class="term"><span class="strong"><strong>yarn.scheduler.maximum-allocation-mb</strong></span></span></dt><dd>Defines a maximum allocated memory for container.</dd><dt><span class="term"><span class="strong"><strong>yarn.nodemanager.resource.memory-mb</strong></span></span></dt><dd>Defines how much memory a node controlled by a node manager is allowed
to allocate. This setting should be set to amount of which OS is able
give to YARN managed processes in a way which doesn&#8217;t cause OS to
swap, etc.</dd></dl></div></div><div class="section"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="_configure_kerberos" href="#_configure_kerberos"></a>17.8&nbsp;Configure Kerberos</h2></div></div></div><p>Enabling kerberos is relatively easy when existing kerberized
cluster exists. Just like with every other hadoop related service,
use a specific user and a keytab.</p><pre class="programlisting">spring:
  hadoop:
    security:
      userPrincipal: scdf/_HOST@HORTONWORKS.COM
      userKeytab: /etc/security/keytabs/scdf.service.keytab
      authMethod: kerberos
      namenodePrincipal: nn/_HOST@HORTONWORKS.COM
      rmManagerPrincipal: rm/_HOST@HORTONWORKS.COM
      jobHistoryPrincipal: jhs/_HOST@HORTONWORKS.COM</pre><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><table border="0" summary="Note"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Note]" src="images/note.png"></td><th align="left">Note</th></tr><tr><td align="left" valign="top"><p>When using ambari, configuration and keytab generation are
fully automated.</p></td></tr></table></div><div class="section"><div class="titlepage"><div><div><h3 class="title"><a name="_working_with_kerberized_kafka" href="#_working_with_kerberized_kafka"></a>17.8.1&nbsp;Working with Kerberized Kafka</h3></div></div></div><div class="important" style="margin-left: 0.5in; margin-right: 0.5in;"><table border="0" summary="Important"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Important]" src="images/important.png"></td><th align="left">Important</th></tr><tr><td align="left" valign="top"><p>Currently released kafka based apps doesn&#8217;t work with cluster
where zookeeper and kafka itself are configured to for kerberos
authentication. Workaround is to use rabbit based apps or
build stream apps based on new kafka binder having support
for kerberized kafka.</p></td></tr></table></div><p>After a kafka based stream app has a kerberos support, some settings
in ambari&#8217;s kafka configuration needs to be changed. Effectively
<code class="literal">listeners</code> and <code class="literal">security.inter.broker.protocol</code> needs to use
<span class="emphasis"><em>SASL_PLAINTEXT</em></span>. Also binder needs to be able to create topics, thus
<code class="literal">scdf</code> user needs to be added to a kafka&#8217;s super users.</p><pre class="programlisting">listeners=SASL_PLAINTEXT://localhost:6667
security.inter.broker.protocol=SASL_PLAINTEXT
super.users=user:kafka;user:scdf</pre><p>Additional configs are needed for binder and sasl config.</p><pre class="programlisting">spring:
  cloud:
    stream:
      kafka:
        binder:
          configuration:
            security:
              protocol: SASL_PLAINTEXT
spring:
  cloud:
    deployer:
      yarn:
        app:
          streamcontainer:
            saslConfig: "-Djava.security.auth.login.config=/etc/scdf/conf/scdf_kafka_jaas.conf"</pre><p>Where <code class="literal">scdf_kafka_jaas.conf</code> looks something like shown below.</p><pre class="programlisting">KafkaClient {
   com.sun.security.auth.module.Krb5LoginModule required
   useKeyTab=true
   keyTab="/etc/security/keytabs/scdf.service.keytab"
   storeKey=true
   useTicketCache=false
   serviceName="kafka"
   principal="scdf/sandbox.hortonworks.com@HORTONWORKS.COM";
};</pre><div class="important" style="margin-left: 0.5in; margin-right: 0.5in;"><table border="0" summary="Important"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Important]" src="images/important.png"></td><th align="left">Important</th></tr><tr><td align="left" valign="top"><p>When ambari is kerberized via its wizard, everything else is
automatically configured except kafka settings for a <code class="literal">super.users</code>,
<code class="literal">listeners</code> and <code class="literal">security.inter.broker.protocol</code>.</p></td></tr></table></div></div></div><div class="section"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="_configure_hdfs_ha" href="#_configure_hdfs_ha"></a>17.9&nbsp;Configure Hdfs HA</h2></div></div></div><p>Generic settings for dataflow components to work with
HA setup can be seen below where id is set to <code class="literal">mycluster</code>.</p><pre class="programlisting">spring:
  hadoop:
    fsUri: hdfs://mycluster:8020
    config:
      dfs.ha.automatic-failover.enabled=True
      dfs.nameservices=mycluster
      dfs.client.failover.proxy.provider.mycluster=org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider
      dfs.ha.namenodes.mycluster=nn1,nn2
      dfs.namenode.rpc-address.mycluster.nn2=ambari-3.localdomain:8020
      dfs.namenode.rpc-address.mycluster.nn1=ambari-2.localdomain:8020</pre><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><table border="0" summary="Note"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Note]" src="images/note.png"></td><th align="left">Note</th></tr><tr><td align="left" valign="top"><p>When using ambari and Hdfs HA setup, configuration is fully automated.</p></td></tr></table></div></div><div class="section"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="_configure_database" href="#_configure_database"></a>17.10&nbsp;Configure Database</h2></div></div></div><p>On default a dataflow server will start embedded H2 database
using in-memory storage and effectively using configuration.</p><pre class="programlisting">spring:
  datasource:
    url: jdbc:h2:tcp://localhost:19092/mem:dataflow
    username: sa
    password:
    driverClassName: org.h2.Driver</pre><p>Distribution package contains a bundled self-contained
H2 executable which can be used instead. This allows
to persist data throughout server restarts and is not
limited to single host.</p><pre class="programlisting">./bin/dataflow-server-yarn-h2 --dataflow.database.h2.directory=/var/run/scdf/data</pre><pre class="programlisting">spring:
  datasource:
    url: jdbc:h2:tcp://neo:19092/dataflow
    username: sa
    password:
    driverClassName: org.h2.Driver</pre><div class="important" style="margin-left: 0.5in; margin-right: 0.5in;"><table border="0" summary="Important"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Important]" src="images/important.png"></td><th align="left">Important</th></tr><tr><td align="left" valign="top"><p>With external H2 instance you cannot use <code class="literal">localhost</code>, instead
use a real hostname.</p></td></tr></table></div><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><table border="0" summary="Note"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Note]" src="images/note.png"></td><th align="left">Note</th></tr><tr><td align="left" valign="top"><p>Port can be changed using property <code class="literal">dataflow.database.h2.port</code>.</p></td></tr></table></div><p>This bundled H2 database is also used in ambari to have a default
out of a box functionality. Any database supported by a dataflow
itself can be used by changing <code class="literal">datasource</code> settings.</p></div><div class="section"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="_configure_network_discovery" href="#_configure_network_discovery"></a>17.11&nbsp;Configure Network Discovery</h2></div></div></div><p><span class="emphasis"><em>YARN Deployer</em></span> has to be able to talk with <span class="emphasis"><em>Application Master</em></span>
which then is responsible controlling containers running stream and
task applications. The way this work is that <span class="emphasis"><em>Application Master</em></span>
tries to discover its own address which <span class="emphasis"><em>YARN Deployer</em></span> is then able
to use. If <span class="emphasis"><em>YARN</em></span> cluster nodes have multiple <span class="emphasis"><em>NICs</em></span> or for some other
reason address is discovered wrongly, some settings can be changed to
alter default discovery logic.</p><p>Below is a generic settings what can be changed.</p><pre class="programlisting">spring
  yarn:
    hostdiscovery:
      pointToPoint: false
      loopback: false
      preferInterface: ['eth', 'en']
      matchIpv4: 192.168.0.0/24
      matchInterface: eth\\d*</pre><div class="itemizedlist"><ul class="itemizedlist" style="list-style-type: disc; "><li class="listitem"><span class="strong"><strong>pointToPoint</strong></span> - Skips all interfaces which are most likely i.e.
VPNs. Defaults to <span class="emphasis"><em>false</em></span>.</li><li class="listitem"><span class="strong"><strong>loopback</strong></span> - Don&#8217;t take loopback interface. Defaults to <span class="emphasis"><em>false</em></span>.</li><li class="listitem"><span class="strong"><strong>preferInterface</strong></span> - In case multiple interface names exist, setup
preference order for discovery. Format is interface name without
number qualifier so with <span class="emphasis"><em>eth0</em></span>, use <span class="emphasis"><em>eth</em></span>. There&#8217;s no defaults.</li><li class="listitem"><span class="strong"><strong>matchIpv4</strong></span> - Interface can be matched using its existing ip address
which is given as <span class="emphasis"><em>CIDR</em></span> format. There&#8217;s no defaults.</li><li class="listitem"><span class="strong"><strong>matchInterface</strong></span> - Interface can also matched using a simple regex
pattern which gives even better control if complex interface combinations
exist in a cluster. There&#8217;s no defaults.</li></ul></div></div></div><div class="navfooter"><hr><table width="100%" summary="Navigation footer"><tr><td width="40%" align="left"><a accesskey="p" href="yarn-deploying-on-ambari.html">Prev</a>&nbsp;</td><td width="20%" align="center"><a accesskey="u" href="_spring_cloud_data_flow_runtime.html">Up</a></td><td width="40%" align="right">&nbsp;<a accesskey="n" href="yarn-how-it-works.html">Next</a></td></tr><tr><td width="40%" align="left" valign="top">16.&nbsp;Deploying on AMBARI&nbsp;</td><td width="20%" align="center"><a accesskey="h" href="index.html">Home</a></td><td width="40%" align="right" valign="top">&nbsp;18.&nbsp;How YARN Deployment Works</td></tr></table></div></body></html>