<html><head>
      <meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
   <title>8.&nbsp;Streams</title><link rel="stylesheet" type="text/css" href="css/manual-multipage.css"><meta name="generator" content="DocBook XSL Stylesheets V1.78.1"><link rel="home" href="index.html" title="Spring Cloud Data Flow Server for Apache Mesos"><link rel="up" href="architecture.html" title="Part&nbsp;II.&nbsp;Architecture"><link rel="prev" href="arch-streaming-apps.html" title="7.&nbsp;Streaming Applications"><link rel="next" href="arch-analytics.html" title="9.&nbsp;Analytics"></head><body bgcolor="white" text="black" link="#0000FF" vlink="#840084" alink="#0000FF"><div class="navheader"><table width="100%" summary="Navigation header"><tr><th colspan="3" align="center">8.&nbsp;Streams</th></tr><tr><td width="20%" align="left"><a accesskey="p" href="arch-streaming-apps.html">Prev</a>&nbsp;</td><th width="60%" align="center">Part&nbsp;II.&nbsp;Architecture</th><td width="20%" align="right">&nbsp;<a accesskey="n" href="arch-analytics.html">Next</a></td></tr></table><hr></div><div class="chapter"><div class="titlepage"><div><div><h2 class="title"><a name="arch-streams" href="#arch-streams"></a>8.&nbsp;Streams</h2></div></div></div><div class="section"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="arch-streams-topologies" href="#arch-streams-topologies"></a>8.1&nbsp;Topologies</h2></div></div></div><p>The Stream DSL describes linear sequences of data flowing through the system.  For example, in the stream definition <code class="literal">http | transformer | cassandra</code>, each pipe symbol connects the application on the left to the one on the right.  Named channels can be used for routing and to fan out data to multiple messaging destinations.</p><p>Taps can be used to &#8216;listen in&#8217; to the data that if flowing across any of the pipe symbols.  Taps can be used as sources for new streams with an in independent life cycle.</p></div><div class="section"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="arch-streams-concurrency" href="#arch-streams-concurrency"></a>8.2&nbsp;Concurrency</h2></div></div></div><p>For an application that will consume events, Spring Cloud stream exposes a concurrency setting that controls the size of a thread pool used for dispatching incoming messages.  See the <a class="link" href="http://docs.spring.io/spring-cloud-stream/docs/1.0.2.RELEASE/reference/htmlsingle/index.html#_consumer_properties" target="_top">Consumer properties</a> documentation for more information.</p></div><div class="section"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="arch-streams-partitioning" href="#arch-streams-partitioning"></a>8.3&nbsp;Partitioning</h2></div></div></div><p>A common pattern in stream processing is to partition the data as it moves from one application to the next.  Partitioning is a critical concept in stateful processing, for either performance or consistency reasons, to ensure that all related data is processed together. For example, in a time-windowed average calculation example, it is important that all measurements from any given sensor are processed by the same application instance.  Alternatively, you may want to cache some data related to the incoming events so that it can be enriched without making a remote procedure call to retrieve the related data.</p><p>Spring Cloud Data Flow supports partitioning by configuring Spring Cloud Stream&#8217;s output and input bindings.  Spring Cloud Stream provides a common abstraction for implementing partitioned processing use cases in a uniform fashion across different types of middleware.  Partitioning can thus be used whether the broker itself is naturally partitioned (e.g., Kafka topics) or not (e.g., RabbitMQ).  The following image shows how data could be partitioned into two buckets, such that each instance of the average processor application consumes a unique set of data.</p><div class="figure"><a name="d0e291" href="#d0e291"></a><p class="title"><b>Figure&nbsp;8.1.&nbsp;Spring Cloud Stream Partitioning</b></p><div class="figure-contents"><div class="mediaobject"><img src="https://raw.githubusercontent.com/spring-cloud/spring-cloud-dataflow/v1.0.1.RELEASE/spring-cloud-dataflow-docs/src/main/asciidoc/images/stream-partitioning.png" alt="Stream Partitioning Architecture"></div></div></div><br class="figure-break"><p>To use a simple partitioning strategy in Spring Cloud Data Flow, you only need set the instance count for each application in the stream and a <code class="literal">partitionKeyExpression</code> producer property when deploying the stream.  The <code class="literal">partitionKeyExpression</code> identifies what part of the message will be used as the key to partition data in the underlying middleware.  An <code class="literal">ingest</code> stream can be defined as <code class="literal">http | averageprocessor | cassandra</code>  (Note that the Cassandra sink isn&#8217;t shown in the diagram above).  Suppose the payload being sent to the http source was in JSON format and had a field called <code class="literal">sensorId</code>.  Deploying the stream with the shell command <code class="literal">stream deploy ingest --propertiesFile ingestStream.properties</code> where the contents of the file <code class="literal">ingestStream.properties</code> are</p><pre class="programlisting">app.http.count=<span class="hl-number">3</span>
app.averageprocessor.count=<span class="hl-number">2</span>
app.http.producer.partitionKeyExpression=payload.sensorId</pre><p>will deploy the stream such that all the input and output destinations are configured for data to flow through the applications but also ensure that a unique set of data is always delivered to each averageprocessor instance.  In this case the default algorithm is to evaluate <code class="literal">payload.sensorId % partitionCount</code> where the <code class="literal">partitionCount</code> is the application count in the case of RabbitMQ and the partition count of the topic in the case of Kafka.</p><p>Please refer to <a class="xref" href="spring-cloud-dataflow-create-stream.html#passing_stream_partition_properties" title="17.1.3&nbsp;Passing stream partition properties during stream deployment">Section&nbsp;17.1.3, &#8220;Passing stream partition properties during stream deployment&#8221;</a> for additional strategies to partition streams during deployment and how they map onto the underlying <a class="link" href="http://docs.spring.io/spring-cloud-stream/docs/1.0.2.RELEASE/reference/htmlsingle/index.html#_partitioning" target="_top">Spring Cloud Stream Partitioning properties</a>.</p><p>Also note, that you can&#8217;t currently scale partitioned streams.  Read the section <a class="xref" href="arch-runtime.html#arch-runtime-scaling" title="12.3&nbsp;Scaling at runtime">Section&nbsp;12.3, &#8220;Scaling at runtime&#8221;</a> for more information.</p></div><div class="section"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="arch-streams-delivery" href="#arch-streams-delivery"></a>8.4&nbsp;Message Delivery Guarantees</h2></div></div></div><p>For consumer applications, there is a retry policy for exceptions generated during message handling.  The default is to retry the callback method invocation 3 times and wait one second for the first retry.  A backoff multiplier of 2 is used for the second and third attempts.  All of these retry properties are configurable.</p><p>If there is still an exception on the last retry attempt, and dead letter queues are enabled, the message and exception message are published to the dead letter queue.  The dead letter queue is a destination and its nature depends on the messaging middleware (e.g in the case of Kafka it is a dedicated topic).  If dead letter functionality is not enabled, the message and exception is sent to the error channel, which by default logs the message and exception.</p><p>Additional messaging delivery guarantees are those provided by the underlying messaging middleware that is chosen for the application for both producing and consuming applications.  Refer to the Kafka <a class="link" href="http://docs.spring.io/spring-cloud-stream/docs/1.0.2.RELEASE/reference/htmlsingle/index.html#_kafka_consumer_properties" target="_top">Consumer</a> and <a class="link" href="http://docs.spring.io/spring-cloud-stream/docs/1.0.2.RELEASE/reference/htmlsingle/index.html#_kafka_producer_properties" target="_top">Producer</a> and Rabbit <a class="link" href="http://docs.spring.io/spring-cloud-stream/docs/1.0.3.BUILD-SNAPSHOT/reference/htmlsingle/index.html#_rabbitmq_consumer_properties" target="_top">Consumer</a> and <a class="link" href="http://docs.spring.io/spring-cloud-stream/docs/1.0.3.BUILD-SNAPSHOT/reference/htmlsingle/index.html#_rabbit_producer_properties" target="_top">Producer</a> documentation for more details.  You will find there to be extensive declarative support for all the native QOS options.</p></div></div><div class="navfooter"><hr><table width="100%" summary="Navigation footer"><tr><td width="40%" align="left"><a accesskey="p" href="arch-streaming-apps.html">Prev</a>&nbsp;</td><td width="20%" align="center"><a accesskey="u" href="architecture.html">Up</a></td><td width="40%" align="right">&nbsp;<a accesskey="n" href="arch-analytics.html">Next</a></td></tr><tr><td width="40%" align="left" valign="top">7.&nbsp;Streaming Applications&nbsp;</td><td width="20%" align="center"><a accesskey="h" href="index.html">Home</a></td><td width="40%" align="right" valign="top">&nbsp;9.&nbsp;Analytics</td></tr></table></div></body></html>