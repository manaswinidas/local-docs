<html lang="zh-Hans" ><head></head><body class="book toc2 toc-left" >﻿
<meta charset="UTF-8">
<!--[if IE]><meta http-equiv="X-UA-Compatible" content="IE=edge"><![endif]-->
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="Asciidoctor 1.5.3">
<meta name="author" content="Apache HBase Team">
<title>Apache HBase™参考指南</title>
<link rel="stylesheet" href="./hbase.css">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.4.0/css/font-awesome.min.css">
<link rel="stylesheet" href="./coderay-asciidoctor.css">


<div id="header">
<h1>Apache HBase™参考指南</h1>
<div class="details">
<span id="author" class="author">Apache HBase团队</span><br>
<span id="email" class="email">< <a href="mailto:hbase-dev@lists.apache.org">hbase-dev@lists.apache.org</a> ></span><br>
<span id="revnumber">版本1.5.0</span>
</div>
<div id="toc" class="toc2">
<div id="toctitle">内容</div>
<ul class="sectlevel1">
<li><a href="#_preface">前言</a></li>
<li><a href="#getting_started">入门</a>
<ul class="sectlevel1">
<li><a href="#_introduction">1。介绍</a></li>
<li><a href="#quickstart">2。快速入门-独立HBase</a></li>
</ul>
</li>
<li><a href="#configuration">Apache HBase配置</a>
<ul class="sectlevel1">
<li><a href="#_configuration_files">3。配置文件</a></li>
<li><a href="#basic.prerequisites">4。基本先决条件</a></li>
<li><a href="#standalone_dist">5，HBase运行模式：独立和分布式</a></li>
<li><a href="#confirm">6。运行并确认安装</a></li>
<li><a href="#config.files">7。默认配置</a></li>
<li><a href="#example_config">8。示例配置</a></li>
<li><a href="#important_configurations">9。重要配置</a></li>
<li><a href="#dyn_config">10。动态配置</a></li>
</ul>
</li>
<li><a href="#upgrading">升级中</a>
<ul class="sectlevel1">
<li><a href="#hbase.versioning">11。HBase版本号和兼容性</a></li>
<li><a href="#_upgrade_paths">12升级路径</a></li>
</ul>
</li>
<li><a href="#shell">Apache HBase Shell</a>
<ul class="sectlevel1">
<li><a href="#scripting">13用Ruby编写脚本</a></li>
<li><a href="#_running_the_shell_in_non_interactive_mode">14。在非交互模式下运行命令行管理程序</a></li>
<li><a href="#hbase.shell.noninteractive">15OS脚本中的HBase Shell</a></li>
<li><a href="#_read_hbase_shell_commands_from_a_command_file">16。从命令文件中读取HBase Shell命令</a></li>
<li><a href="#_passing_vm_options_to_the_shell">17。将VM选项传递到命令行管理程序</a></li>
<li><a href="#_overriding_configuration_starting_the_hbase_shell">18岁覆盖启动HBase Shell的配置</a></li>
<li><a href="#_shell_tricks">19贝壳技巧</a></li>
</ul>
</li>
<li><a href="#datamodel">资料模型</a>
<ul class="sectlevel1">
<li><a href="#conceptual.view">20概念观点</a></li>
<li><a href="#physical.view">21物理视图</a></li>
<li><a href="#_namespace">22命名空间</a></li>
<li><a href="#_table">23。表</a></li>
<li><a href="#_row">24行</a></li>
<li><a href="#columnfamily">25岁列族</a></li>
<li><a href="#_cells">26细胞</a></li>
<li><a href="#_data_model_operations">27。数据模型操作</a></li>
<li><a href="#versions">28岁版本号</a></li>
<li><a href="#dm.sort">29。排序</a></li>
<li><a href="#dm.column.metadata">30岁列元数据</a></li>
<li><a href="#_joins">31。加入</a></li>
<li><a href="#_acid">32。酸</a></li>
</ul>
</li>
<li><a href="#schema">HBase和架构设计</a>
<ul class="sectlevel1">
<li><a href="#schema.creation">33。模式创建</a></li>
<li><a href="#number.of.cfs">34。关于列族的数量</a></li>
<li><a href="#rowkey.design">35岁行键设计</a></li>
<li><a href="#schema.versions">36。版本数</a></li>
<li><a href="#supported.datatypes">37。支持的数据类型</a></li>
<li><a href="#schema.joins">38。加入</a></li>
<li><a href="#ttl">39。生存时间（TTL）</a></li>
<li><a href="#cf.keep.deleted">40保留删除的单元格</a></li>
<li><a href="#secondary.indexes">41。二级索引和备用查询路径</a></li>
<li><a href="#_constraints">42。约束条件</a></li>
<li><a href="#schema.casestudies">43。模式设计案例研究</a></li>
<li><a href="#schema.ops">44。操作和性能配置选项</a></li>
</ul>
</li>
<li><a href="#mapreduce">HBase和MapReduce</a>
<ul class="sectlevel1">
<li><a href="#hbase.mapreduce.classpath">45。HBase，MapReduce和CLASSPATH</a></li>
<li><a href="#_mapreduce_scan_caching">46。MapReduce扫描缓存</a></li>
<li><a href="#_bundled_hbase_mapreduce_jobs">47。捆绑的HBase MapReduce作业</a></li>
<li><a href="#_hbase_as_a_mapreduce_job_data_source_and_data_sink">48。HBase作为MapReduce作业数据源和数据接收器</a></li>
<li><a href="#_writing_hfiles_directly_during_bulk_import">49。批量导入期间直接写入HFile</a></li>
<li><a href="#_rowcounter_example">50RowCounter示例</a></li>
<li><a href="#splitter">51。映射任务拆分</a></li>
<li><a href="#mapreduce.example">52。HBase MapReduce示例</a></li>
<li><a href="#mapreduce.htable.access">53。在MapReduce作业中访问其他HBase表</a></li>
<li><a href="#mapreduce.specex">54。投机执行</a></li>
</ul>
</li>
<li><a href="#security">保护Apache HBase</a>
<ul class="sectlevel1">
<li><a href="#_using_secure_http_https_for_the_web_ui">55。将安全HTTP（HTTPS）用于Web UI</a></li>
<li><a href="#hbase.secure.spnego.ui">56。使用SPNEGO通过Web UI进行Kerberos身份验证</a></li>
<li><a href="#hbase.secure.configuration">57。安全的客户端访问Apache HBase</a></li>
<li><a href="#hbase.secure.simpleconfiguration">58。简单的用户访问Apache HBase</a></li>
<li><a href="#_securing_access_to_hdfs_and_zookeeper">59。确保对HDFS和ZooKeeper的访问</a></li>
<li><a href="#_securing_access_to_your_data">60保护对您数据的访问</a></li>
<li><a href="#security.example.config">61。安全配置示例</a></li>
</ul>
</li>
<li><a href="#_architecture">建筑</a>
<ul class="sectlevel1">
<li><a href="#arch.overview">62。总览</a></li>
<li><a href="#arch.catalog">63。目录表</a></li>
<li><a href="#architecture.client">64。客户</a></li>
<li><a href="#client.filter">65。客户请求过滤器</a></li>
<li><a href="#_master">66。主</a></li>
<li><a href="#regionserver.arch">67。区域服务器</a></li>
<li><a href="#regions.arch">68。地区</a></li>
<li><a href="#arch.bulk.load">69。批量装载</a></li>
<li><a href="#arch.hdfs">70HDFS</a></li>
<li><a href="#arch.timelineconsistent.reads">71。时间轴一致的高可用读取</a></li>
</ul>
</li>
<li><a href="#hbase_apis">Apache HBase API</a>
<ul class="sectlevel1">
<li><a href="#_examples">72。例子</a></li>
</ul>
</li>
<li><a href="#external_apis">Apache HBase外部API</a>
<ul class="sectlevel1">
<li><a href="#nonjava.jvm">73。非Java语言与JVM对话</a></li>
<li><a href="#_rest">74。休息</a></li>
<li><a href="#_thrift">75。节约</a></li>
<li><a href="#c">76。C / C ++ Apache HBase客户端</a></li>
</ul>
</li>
<li><a href="#thrift">节俭API和过滤器语言</a>
<ul class="sectlevel1">
<li><a href="#thrift.filter_language">77。筛选语言</a></li>
</ul>
</li>
<li><a href="#cp">Apache HBase协处理器</a>
<ul class="sectlevel1">
<li><a href="#_coprocessor_framework">78。协处理器框架</a></li>
<li><a href="#_examples_2">79。例子</a></li>
<li><a href="#_building_a_coprocessor">80。构建协处理器</a></li>
<li><a href="#_check_the_status_of_a_coprocessor">81。检查协处理器的状态</a></li>
<li><a href="#_monitor_time_spent_in_coprocessors">82。监视协处理器中花费的时间</a></li>
</ul>
</li>
<li><a href="#performance">Apache HBase性能调优</a>
<ul class="sectlevel1">
<li><a href="#perf.os">83。操作系统</a></li>
<li><a href="#perf.network">84。网络</a></li>
<li><a href="#jvm">85。爪哇</a></li>
<li><a href="#perf.configurations">86。HBase配置</a></li>
<li><a href="#perf.zookeeper">87。动物园管理员</a></li>
<li><a href="#perf.schema">88。模式设计</a></li>
<li><a href="#perf.general">89。HBase通用模式</a></li>
<li><a href="#perf.writing">90写入HBase</a></li>
<li><a href="#perf.reading">91。从HBase读取</a></li>
<li><a href="#perf.deleting">92。从HBase删除</a></li>
<li><a href="#perf.hdfs">93。HDFS</a></li>
<li><a href="#perf.ec2">94。亚马逊EC2</a></li>
<li><a href="#perf.hbase.mr.cluster">95。并置HBase和MapReduce</a></li>
<li><a href="#perf.casestudy">96。实例探究</a></li>
</ul>
</li>
<li><a href="#profiler">探查器Servlet</a>
<ul class="sectlevel1">
<li><a href="#_background">97。背景</a></li>
<li><a href="#_prerequisites_2">98。先决条件</a></li>
<li><a href="#_usage">99。用法</a></li>
<li><a href="#_ui">100用户界面</a></li>
<li><a href="#_notes">101。笔记</a></li>
</ul>
</li>
<li><a href="#trouble">故障排除和调试Apache HBase</a>
<ul class="sectlevel1">
<li><a href="#trouble.general">102。一般准则</a></li>
<li><a href="#trouble.log">103。日志</a></li>
<li><a href="#trouble.resources">104。资源资源</a></li>
<li><a href="#trouble.tools">105。工具类</a></li>
<li><a href="#trouble.client">106。客户</a></li>
<li><a href="#trouble.mapreduce">107。MapReduce</a></li>
<li><a href="#trouble.namenode">108。名称节点</a></li>
<li><a href="#trouble.network">109。网络</a></li>
<li><a href="#trouble.rs">110。区域服务器</a></li>
<li><a href="#trouble.master">111。主</a></li>
<li><a href="#trouble.zookeeper">112。动物园管理员</a></li>
<li><a href="#trouble.ec2">113。亚马逊EC2</a></li>
<li><a href="#trouble.versions">114。HBase和Hadoop版本问题</a></li>
<li><a href="#_hbase_and_hdfs">115。HBase和HDFS</a></li>
<li><a href="#trouble.tests">116。运行单元或集成测试</a></li>
<li><a href="#trouble.casestudy">117。实例探究</a></li>
<li><a href="#trouble.crypto">118。加密功能</a></li>
<li><a href="#_operating_system_specific_issues">119。操作系统特定问题</a></li>
<li><a href="#_jdk_issues">120。JDK问题</a></li>
</ul>
</li>
<li><a href="#casestudies">Apache HBase案例研究</a>
<ul class="sectlevel1">
<li><a href="#casestudies.overview">121。总览</a></li>
<li><a href="#casestudies.schema">122。模式设计</a></li>
<li><a href="#casestudies.perftroub">123。性能/故障排除</a></li>
</ul>
</li>
<li><a href="#ops_mgt">Apache HBase运营管理</a>
<ul class="sectlevel1">
<li><a href="#tools">124。HBase工具和实用程序</a></li>
<li><a href="#ops.regionmgt">125。区域管理</a></li>
<li><a href="#node.management">126。节点管理</a></li>
<li><a href="#_hbase_metrics">127。HBase指标</a></li>
<li><a href="#ops.monitoring">128。HBase监控</a></li>
<li><a href="#_cluster_replication">129。集群复制</a></li>
<li><a href="#ops.backup">130。HBase备份</a></li>
<li><a href="#ops.snapshots">131。HBase快照</a></li>
<li><a href="#ops.capacity">132。容量规划和区域调整</a></li>
<li><a href="#table.rename">133。表重命名</a></li>
</ul>
</li>
<li><a href="#developer">构建和开发Apache HBase</a>
<ul class="sectlevel1">
<li><a href="#getting.involved">134。卷入</a></li>
<li><a href="#repos">135。Apache HBase存储库</a></li>
<li><a href="#_ides">136。集成开发环境</a></li>
<li><a href="#build">137。构建Apache HBase</a></li>
<li><a href="#releasing">138。发布Apache HBase</a></li>
<li><a href="#hbase.rc.voting">139。对释放候选人进行投票</a></li>
<li><a href="#documentation">140。生成《 HBase参考指南》</a></li>
<li><a href="#hbase.org">141。更新</a> <a href="https://hbase.apache.org">hbase.apache.org</a></li>
<li><a href="#hbase.tests">142。测验</a></li>
<li><a href="#developing">143。开发人员指南</a></li>
</ul>
</li>
<li><a href="#unit.tests">单元测试HBase应用程序</a>
<ul class="sectlevel1">
<li><a href="#_junit">144。JUnit的</a></li>
<li><a href="#_mockito">145。莫基托</a></li>
<li><a href="#_mrunit">146。MRUnit</a></li>
<li><a href="#_integration_testing_with_a_hbase_mini_cluster">147。与HBase Mini-Cluster的集成测试</a></li>
</ul>
</li>
<li><a href="#zookeeper">动物园管理员</a>
<ul class="sectlevel1">
<li><a href="#_using_existing_zookeeper_ensemble">148。使用现有的ZooKeeper合奏</a></li>
<li><a href="#zk.sasl.auth">149。ZooKeeper的SASL身份验证</a></li>
</ul>
</li>
<li><a href="#community">社区</a>
<ul class="sectlevel1">
<li><a href="#_decisions">150。决定</a></li>
<li><a href="#community.roles">151。社区角色</a></li>
<li><a href="#hbase.commit.msg.format">152。提交消息格式</a></li>
</ul>
</li>
<li><a href="#_appendix">附录</a>
<ul class="sectlevel1">
<li><a href="#appendix_contributing_to_documentation">附录A：贡献文档</a></li>
<li><a href="#faq">附录B：常见问题</a></li>
<li><a href="#hbck.in.depth">附录C：hbck深度</a></li>
<li><a href="#appendix_acl_matrix">附录D：访问控制矩阵</a></li>
<li><a href="#compression">附录E：HBase中的压缩和数据块编码</a></li>
<li><a href="#data.block.encoding.enable">153。启用数据块编码</a></li>
<li><a href="#sql">附录F：基于HBase的SQL</a></li>
<li><a href="#_ycsb">附录G：YCSB</a></li>
<li><a href="#_hfile_format_2">附录H：HFile格式</a></li>
<li><a href="#other.info">附录一：有关HBase的其他信息</a></li>
<li><a href="#hbase.history">附录J：HBase历史</a></li>
<li><a href="#asf">附录K：HBase和Apache软件基金会</a></li>
<li><a href="#orca">附录L：Apache HBase Orca</a></li>
<li><a href="#tracing">附录M：在HBase中启用类似Dapper的跟踪</a></li>
<li><a href="#tracing.client.modifications">154。客户修改</a></li>
<li><a href="#tracing.client.shell">155。从HBase Shell进行跟踪</a></li>
<li><a href="#hbase.rpc">附录N：0.95 RPC规范</a></li>
</ul>
</li>
</ul>
</div>
</div>
<div id="content">
<div id="preamble">
<div class="sectionbody">
<div>
  <a href="http://hbase.apache.org"><img src="images/hbase_logo_with_orca.png" alt="Apache HBase徽标"></a>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_preface"><a class="anchor" href="#_preface"></a>前言</h2>
<div class="sectionbody">
<div class="paragraph">
<p>这是其随附的<a href="http://hbase.apache.org/">HBase</a>版本的官方参考指南。</p>
</div>
<div class="paragraph">
<p>在这里，您可以找到有关HBase主题的权威性文档（指当引用的HBase版本发运时的状态），或者指向<a href="http://hbase.apache.org/apidocs/index.html">Javadoc</a> ， <a href="https://issues.apache.org/jira/browse/HBASE">JIRA</a>或<a href="http://wiki.apache.org/hadoop/Hbase">Wiki</a>中可以找到相关信息的位置。</p>
</div>
<div class="paragraph">
<div class="title">关于本指南</div>
<p>本参考指南正在进行中。可以在HBase源代码的_src / main / asciidoc目录中找到本指南的源代码。使用<a href="http://asciidoc.org/">AsciiDoc</a>对本参考指南进行了标记，由此生成的最终指南作为“站点”构建目标的一部分。跑</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bourne">mvn site</code></pre>
</div>
</div>
<div class="paragraph">
<p>生成此文档。欢迎对文档进行修改和改进。单击<a href="https://issues.apache.org/jira/secure/CreateIssueDetails!init.jspa?pid=12310753&issuetype=1&components=12312132&summary=SHORT+DESCRIPTION">此链接</a>可以针对Apache HBase提交新的文档错误，并预先选择一些值。</p>
</div>
<div class="paragraph">
<div class="title">撰写文档</div>
<p>有关AsciiDoc的概述以及开始对文档做出贡献的建议，请参阅<a href="#appendix_contributing_to_documentation">本文档后面</a>的<a href="#appendix_contributing_to_documentation">相关部分</a> 。</p>
</div>
<div class="paragraph">
<div class="title">如果这是您首次涉足分布式计算领域，请注意...</div>
<p>如果这是您首次进入分布式计算的美好世界，那么您将处于一段有趣的时期。首先，分布式系统很难。使分布式系统嗡嗡声需要跨越系统（硬件和软件）和网络的不同技能。</p>
</div>
<div class="paragraph">
<p>群集运行可能会因各种原因而打h，原因包括：HBase本身的错误，错误配置（HBase的错误配置以及操作系统的错误配置），以及硬件问题（无论是网卡驱动程序中的错误还是RAM总线不足） （要提到两个最近的硬件问题示例，这些问题表现为“ HBase缓慢”）。如果您已将计算结果绑定到单个框，则还需要进行重新校准。这是一个很好的起点： <a href="http://en.wikipedia.org/wiki/Fallacies_of_Distributed_Computing">分布式计算的谬误</a> 。</p>
</div>
<div class="paragraph">
<p>就是说，不客气。<br>这是一个有趣的地方。<br>您的HBase社区。</p>
</div>
<div class="paragraph">
<div class="title">报告错误</div>
<p>请使用<a href="https://issues.apache.org/jira/browse/hbase">JIRA</a>报告与安全无关的错误。</p>
</div>
<div class="paragraph">
<p>为了保护现有的HBase安装不受新的漏洞的影响，请<strong>不要</strong>使用JIRA报告与安全性有关的错误。而是将您的报告发送到邮件列表<a href="mailto:private@apache.org">private@apache.org</a> ，该列表允许任何人发送消息，但限制了可以读取消息的人。该列表中的某人将与您联系以跟进您的报告。</p>
</div>
<div class="paragraph">
<div class="title">支持和测试期望</div>
<p>在本指南中，短语/ supported /，/不支持/，/ tested /和/ not测试/出现在几个地方。为了清楚起见，这里简要说明了在HBase上下文中这些短语的一般含义。</p>
</div>
<div class="admonitionblock note">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-note" title="注意"></i>
</td>
<td class="content">许多Hadoop供应商为Apache HBase提供了商业技术支持。这不是在Apache HBase项目的上下文中使用术语/ support /的意义。Apache HBase团队对您的HBase集群，您的配置或数据不承担任何责任。
</td>
</tr>
</tbody></table>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">支持的</dt>
<dd>
<p>在Apache HBase的上下文中，/ supported /表示HBase旨在按所述方式工作，并且偏离已定义行为或功能的情况应报告为错误。</p>
</dd>
<dt class="hdlist1">不支持</dt>
<dd>
<p>在Apache HBase的上下文中，/ notsupported /表示用例或使用模式不起作用，应将其视为反模式。如果您认为应该为给定的功能或使用模式重新考虑此指定，请提交JIRA或在其中一个邮件列表上进行讨论。</p>
</dd>
<dt class="hdlist1">经过测试</dt>
<dd>
<p>在Apache HBase的上下文中，/ tested /表示该功能已包含在单元测试或集成测试中，并且已被证明可以按预期工作。</p>
</dd>
<dt class="hdlist1">未测试</dt>
<dd>
<p>在Apache HBase的上下文中，/ not testing /表示某个功能或使用模式可能会或可能无法以给定的方式工作，并且可能会或可能不会破坏您的数据或导致操作问题。这是一个未知数，并且无法保证。如果您可以提供证明/未测试的功能确实可以通过给定的方式工作的证据，请提交测试和/或度量标准，以便其他用户可以确定此类功能或使用模式。</p>
</dd>
</dl>
</div>
</div>
</div>
<h1 id="getting_started" class="sect0"><a class="anchor" href="#getting_started"></a>入门</h1>
<div class="sect1">
<h2 id="_introduction"><a class="anchor" href="#_introduction"></a> 1。介绍</h2>
<div class="sectionbody">
<div class="paragraph">
<p><a href="#quickstart">快速入门</a>将使您在HBase的单节点独立实例上运行，然后在伪分布式单机实例上运行，最后在完整分布式集群上运行。</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="quickstart"><a class="anchor" href="#quickstart"></a> 2。快速入门-独立HBase</h2>
<div class="sectionbody">
<div class="paragraph">
<p>本指南描述了针对本地文件系统运行的独立HBase实例的设置。对于HBase的生产实例，这不是适当的配置，但可以让您尝试使用HBase。本节说明如何使用HBase在HBase中创建表<code>hbase shell</code> CLI，将行插入表中，对表执行放置和扫描操作，启用或禁用表，以及启动和停止HBase。除了下载HBase之外，此过程还需要不到10分钟的时间。</p>
</div>
<div class="sect2">
<h3 id="_jdk_version_requirements"><a class="anchor" href="#_jdk_version_requirements"></a> 2.1。JDK版本要求</h3>
<div class="paragraph">
<p>HBase要求安装JDK。有关受支持的JDK版本的信息，请参见<a href="#java">Java</a> 。</p>
</div>
</div>
<div class="sect2">
<h3 id="_get_started_with_hbase"><a class="anchor" href="#_get_started_with_hbase"></a> 2.2。HBase入门</h3>
<div class="olist arabic">
<div class="title">过程：下载，配置和启动HBase</div>
<ol class="arabic">
<li>
<p>从此<a href="http://www.apache.org/dyn/closer.cgi/hbase/">Apache下载镜像</a>列表中选择一个下载站点。单击建议的顶部链接。这将带您了解<em>HBase版本</em> 。单击名为<em>稳定</em>的文件夹，然后将以<em>.tar.gz</em>结尾的二进制文件下载到本地文件系统。确保选择与以后可能使用的Hadoop版本相对应的版本。在大多数情况下，应该为Hadoop 2选择文件，该文件的名称将类似于<em>hbase-0.98.3-hadoop2-bin.tar.gz</em> 。现在不要下载以<em>src.tar.gz</em>结尾的文件。</p>
</li>
<li>
<p>解压缩下载的文件，然后转到新创建的目录。</p>
<div class="listingblock">
<div class="content">
<pre>$ tar xzvf hbase-&lt;?eval ${project.version}?&gt;-hadoop2-bin.tar.gz
$ cd hbase-&lt;?eval ${project.version}?&gt;-hadoop2/</pre>
</div>
</div>
</li>
<li>
<p>对于HBase 0.98.5及更高版本，您需要设置<code>JAVA_HOME</code>启动HBase之前的环境变量。在0.98.5之前，如果未设置变量，则HBase尝试检测Java的位置。您可以通过操作系统的常用机制来设置变量，但是HBase提供了一个中心机制<em>conf / hbase-env.sh</em> 。编辑此文件，取消注释以<code>JAVA_HOME</code> ，并将其设置为适合您的操作系统的位置。的<code>JAVA_HOME</code>变量应设置为包含可执行文件<em>bin / java的目录</em> 。大多数现代Linux操作系统都提供了一种机制，例如RHEL或CentOS上的/ usr / bin / alternatives，可在诸如Java之类的可执行文件版本之间进行透明切换。在这种情况下，您可以设置<code>JAVA_HOME</code>到包含到<em>bin / java</em>的符号链接的目录，通常是<em>/ usr</em> 。</p>
<div class="listingblock">
<div class="content">
<pre>JAVA_HOME=/usr</pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-note" title="注意"></i>
</td>
<td class="content">这些说明假定群集的每个节点使用相同的配置。如果不是这种情况，则可能需要设置<code>JAVA_HOME</code>每个节点分别。
</td>
</tr>
</tbody></table>
</div>
</li>
<li>
<p>编辑<em>conf / hbase-site.xml</em> ，这是主要的HBase配置文件。这时，您需要在本地文件系统上指定HBase和ZooKeeper写入数据的目录并确认一些风险。默认情况下，在/ tmp下创建一个新目录。许多服务器配置为在重新引导时删除<em>/ tmp</em>的内容，因此您应该将数据存储在其他位置。以下配置会将HBase的数据存储在<em>hbase</em>目录中，该目录位于用户的主目录中<code>testuser</code> 。粘贴<code><property></code>下方的标签<code><configuration></code>标记，在新的HBase安装中应该为空。</p>
<div class="exampleblock">
<div class="title">范例1。独立HBase的示例<em>hbase-site.xml</em></div>
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="xml"><span class="tag">&lt;configuration&gt;</span>
  <span class="tag">&lt;property&gt;</span>
    <span class="tag">&lt;name&gt;</span>hbase.rootdir<span class="tag">&lt;/name&gt;</span>
    <span class="tag">&lt;value&gt;</span>file:///home/testuser/hbase<span class="tag">&lt;/value&gt;</span>
  <span class="tag">&lt;/property&gt;</span>
  <span class="tag">&lt;property&gt;</span>
    <span class="tag">&lt;name&gt;</span>hbase.zookeeper.property.dataDir<span class="tag">&lt;/name&gt;</span>
    <span class="tag">&lt;value&gt;</span>/home/testuser/zookeeper<span class="tag">&lt;/value&gt;</span>
  <span class="tag">&lt;/property&gt;</span>
  <span class="tag">&lt;property&gt;</span>
    <span class="tag">&lt;name&gt;</span>hbase.unsafe.stream.capability.enforce<span class="tag">&lt;/name&gt;</span>
    <span class="tag">&lt;value&gt;</span>false<span class="tag">&lt;/value&gt;</span>
    <span class="tag">&lt;description&gt;</span>
      Controls whether HBase will check for stream capabilities (hflush/hsync).

      Disable this if you intend to run on LocalFileSystem, denoted by a rootdir
      with the 'file://' scheme, but be mindful of the NOTE below.

      WARNING: Setting this to false blinds you to potential data loss and
      inconsistent system state in the event of process and/or node failures. If
      HBase is complaining of an inability to use hsync or hflush it's most
      likely not a false positive.
    <span class="tag">&lt;/description&gt;</span>
  <span class="tag">&lt;/property&gt;</span>
<span class="tag">&lt;/configuration&gt;</span></code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>您不需要创建HBase数据目录。HBase将为您完成此任务。如果创建目录，则HBase将尝试进行迁移，这不是您想要的。</p>
</div>
<div class="admonitionblock note">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-note" title="注意"></i>
</td>
<td class="content">上例中的<em>hbase.rootdir</em>指向<em>本地文件系统中</em>的目录。“ file：//”前缀是我们表示本地文件系统的方式。您应该牢记配置示例中的“警告”。在独立模式下，HBase使用Apache Hadoop项目中的本地文件系统抽象。这种抽象不能提供HBase安全运行所需的持久性保证。这对于很好地控制集群故障成本的本地开发和测试用例来说是很好的选择。它不适用于生产部署；最终您将丢失数据。
</td>
</tr>
</tbody></table>
</div>
</li>
</ol>
</div>
<div class="paragraph">
<p>要将HBase放置在现有HDFS实例上，请将<em>hbase.rootdir</em>设置为指向您实例上的目录：例如<em>hdfs：//namenode.example.org：8020 / hbase</em> 。有关此变体的更多信息，请参见下面有关基于HDFS的独立HBase的部分。</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>提供<em>bin / start-hbase.sh</em>脚本是启动HBase的便捷方法。发出命令，如果一切顺利，则会在标准输出中记录一条消息，表明HBase已成功启动。您可以使用<code>jps</code>命令以验证您有一个正在运行的进程，称为<code>HMaster</code> 。在独立模式下，HBase在此单个JVM中运行所有守护程序，即HMaster，单个HRegionServer和ZooKeeper守护程序。</p>
<div class="admonitionblock note">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-note" title="注意"></i>
</td>
<td class="content">Java需要安装并可用。如果收到指示未安装Java的错误，但该错误在您的系统上（可能位于非标准位置），请编辑<em>conf / hbase-env.sh</em>文件并修改<code>JAVA_HOME</code>设置指向包含系统<em>bin / java</em>的目录。
</td>
</tr>
</tbody></table>
</div>
</li>
</ol>
</div>
<div id="shell_exercises" class="olist arabic">
<div class="title">过程：首次使用HBase</div>
<ol class="arabic">
<li>
<p>连接到HBase。</p>
<div class="paragraph">
<p>使用以下命令连接到正在运行的HBase实例<code>hbase shell</code>命令，位于HBase安装的<em class="path">bin /</em>目录中。在此示例中，省略了启动HBase Shell时打印的一些用法和版本信息。HBase Shell提示符以<code>></code>字符。</p>
</div>
<div class="listingblock">
<div class="content">
<pre>$ ./bin/hbase shell
hbase(main):001:0&gt;</pre>
</div>
</div>
</li>
<li>
<p>显示HBase Shell帮助文本。</p>
<div class="paragraph">
<p>类型<code>help</code>并按Enter键，以显示HBase Shell的一些基本用法信息以及一些示例命令。注意，表名，行，列都必须用引号引起来。</p>
</div>
</li>
<li>
<p>创建一个表。</p>
<div class="paragraph">
<p>使用<code>create</code>命令创建一个新表。您必须指定表名称和ColumnFamily名称。</p>
</div>
<div class="listingblock">
<div class="content">
<pre>hbase(main):001:0&gt; create 'test', 'cf'
0 row(s) in 0.4170 seconds

=&gt; Hbase::Table - test</pre>
</div>
</div>
</li>
<li>
<p>列出有关表的信息</p>
<div class="paragraph">
<p>使用<code>list</code>命令以确认您的表存在</p>
</div>
<div class="listingblock">
<div class="content">
<pre>hbase(main):002:0&gt; list 'test'
TABLE
test
1 row(s) in 0.0180 seconds

=&gt; ["test"]</pre>
</div>
</div>
</li>
<li>
<p>将数据放入表中。</p>
<div class="paragraph">
<p>要将数据放入表中，请使用<code>put</code>命令。</p>
</div>
<div class="listingblock">
<div class="content">
<pre>hbase(main):003:0&gt; put 'test', 'row1', 'cf:a', 'value1'
0 row(s) in 0.0850 seconds

hbase(main):004:0&gt; put 'test', 'row2', 'cf:b', 'value2'
0 row(s) in 0.0110 seconds

hbase(main):005:0&gt; put 'test', 'row3', 'cf:c', 'value3'
0 row(s) in 0.0100 seconds</pre>
</div>
</div>
<div class="paragraph">
<p>在这里，我们插入三个值，一次插入一个。第一次插入是在<code>row1</code> ，栏<code>cf:a</code> ，值为<code>value1</code> 。HBase中的列由列族前缀组成， <code>cf</code>在此示例中，后跟冒号，然后是列限定符后缀， <code>a</code>在这种情况下。</p>
</div>
</li>
<li>
<p>一次扫描表中的所有数据。</p>
<div class="paragraph">
<p>从HBase获取数据的一种方法是扫描。使用<code>scan</code>命令以扫描表中的数据。您可以限制扫描范围，但是现在，所有数据都已获取。</p>
</div>
<div class="listingblock">
<div class="content">
<pre>hbase(main):006:0&gt; scan 'test'
ROW                                      COLUMN+CELL
 row1                                    column=cf:a, timestamp=1421762485768, value=value1
 row2                                    column=cf:b, timestamp=1421762491785, value=value2
 row3                                    column=cf:c, timestamp=1421762496210, value=value3
3 row(s) in 0.0230 seconds</pre>
</div>
</div>
</li>
<li>
<p>获取单行数据。</p>
<div class="paragraph">
<p>要一次获取一行数据，请使用<code>get</code>命令。</p>
</div>
<div class="listingblock">
<div class="content">
<pre>hbase(main):007:0&gt; get 'test', 'row1'
COLUMN                                   CELL
 cf:a                                    timestamp=1421762485768, value=value1
1 row(s) in 0.0350 seconds</pre>
</div>
</div>
</li>
<li>
<p>禁用表格。</p>
<div class="paragraph">
<p>如果要删除表或更改其设置，以及在某些其他情况下，则需要先禁用该表，方法是使用<code>disable</code>命令。您可以使用来重新启用它<code>enable</code>命令。</p>
</div>
<div class="listingblock">
<div class="content">
<pre>hbase(main):008:0&gt; disable 'test'
0 row(s) in 1.1820 seconds

hbase(main):009:0&gt; enable 'test'
0 row(s) in 0.1770 seconds</pre>
</div>
</div>
<div class="paragraph">
<p>如果您测试了<code>enable</code>上面的命令：</p>
</div>
<div class="listingblock">
<div class="content">
<pre>hbase(main):010:0&gt; disable 'test'
0 row(s) in 1.1820 seconds</pre>
</div>
</div>
</li>
<li>
<p>放下桌子。</p>
<div class="paragraph">
<p>要删除（删除）表格，请使用<code>drop</code>命令。</p>
</div>
<div class="listingblock">
<div class="content">
<pre>hbase(main):011:0&gt; drop 'test'
0 row(s) in 0.1370 seconds</pre>
</div>
</div>
</li>
<li>
<p>退出HBase Shell。</p>
<div class="paragraph">
<p>要退出HBase Shell并从群集断开连接，请使用<code>quit</code>命令。HBase仍在后台运行。</p>
</div>
</li>
</ol>
</div>
<div class="olist arabic">
<div class="title">过程：停止HBase</div>
<ol class="arabic">
<li>
<p>与提供<em>bin / start-hbase.sh</em>脚本以方便地启动所有HBase守护程序相同， <em>bin / stop-hbase.sh</em>脚本将停止它们。</p>
<div class="listingblock">
<div class="content">
<pre>$ ./bin/stop-hbase.sh
stopping hbase....................
$</pre>
</div>
</div>
</li>
<li>
<p>发出命令后，关闭进程可能需要几分钟。使用<code>jps</code>确保关闭HMaster和HRegionServer进程。</p>
</li>
</ol>
</div>
</div>
<div class="sect2">
<h3 id="quickstart_pseudo"><a class="anchor" href="#quickstart_pseudo"></a> 2.3。中级-伪分布式本地安装</h3>
<div class="paragraph">
<p>在完成<a href="#quickstart">快速入门之后</a> ，您可以将HBase重新配置为以伪分布式模式运行。伪分布式模式意味着HBase仍完全在单个主机上运行，但是每个HBase守护程序（HMaster，HRegionServer和Zookeeper）作为单独的进程运行。默认情况下，除非您配置<code>hbase.rootdir</code>属性（如<a href="#quickstart">快速入门中</a>所述），您的数据仍存储在<em>/ tmp /中</em> 。在本演练中，假设您有可用的HDFS，我们将数据存储在HDFS中。您可以跳过HDFS配置，以继续将数据存储在本地文件系统中。</p>
</div>
<div class="admonitionblock note">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-note" title="注意"></i>
</td>
<td class="content">
<div class="title">Hadoop配置</div>
<div class="paragraph">
<p>此过程假定您已在本地系统和/或远程系统上配置了Hadoop和HDFS，并且它们正在运行并且可用。它还假定您正在使用Hadoop 2。当前，Hadoop网站上的文档并未包括Hadoop 2的快速入门，但是该链接的指南为：http：//www.alexjf.net/blog/distributed-systems/hadoop-yarn-installation-definitive-guide一个很好的起点。</p>
</div>
</td>
</tr>
</tbody></table>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>如果HBase正在运行，请停止它。</p>
<div class="paragraph">
<p>如果您刚刚完成<a href="#quickstart">快速入门</a>而HBase仍在运行，请停止它。此过程将创建一个全新的目录，HBase将在该目录中存储其数据，因此您之前创建的所有数据库都将丢失。</p>
</div>
</li>
<li>
<p>配置HBase。</p>
<div class="paragraph">
<p>编辑<em>hbase-site.xml</em>配置。首先，添加以下属性。它指示HBase在分布式模式下运行，每个守护程序一个JVM实例。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="xml"><span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>hbase.cluster.distributed<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>true<span class="tag">&lt;/value&gt;</span>
<span class="tag">&lt;/property&gt;</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>接下来，更改<code>hbase.rootdir</code>使用以下命令从本地文件系统到您的HDFS实例的地址<code>hdfs:////</code> URI语法。在此示例中，HDFS在本地主机上的端口8020上运行。确保删除以下条目<code>hbase.unsafe.stream.capability.enforce</code>或将其设置为true。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="xml"><span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>hbase.rootdir<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>hdfs://localhost:8020/hbase<span class="tag">&lt;/value&gt;</span>
<span class="tag">&lt;/property&gt;</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>您无需在HDFS中创建目录。 HBase将为您完成此任务。如果创建目录，则HBase将尝试进行迁移，这不是您想要的。</p>
</div>
</li>
<li>
<p>启动HBase。</p>
<div class="paragraph">
<p>使用<em>bin / start-hbase.sh</em>命令启动HBase。如果系统配置正确，则<code>jps</code>命令应显示正在运行的HMaster和HRegionServer进程。</p>
</div>
</li>
<li>
<p>检查HDFS中的HBase目录。</p>
<div class="paragraph">
<p>如果一切正常，HBase将在HDFS中创建其目录。在上面的配置中，它存储在HDFS上的<em>/ hbase /</em>中。您可以使用<code>hadoop fs</code> Hadoop的<em>bin /</em>目录中的命令以列出此目录。</p>
</div>
<div class="listingblock">
<div class="content">
<pre>$ ./bin/hadoop fs -ls /hbase
Found 7 items
drwxr-xr-x   - hbase users          0 2014-06-25 18:58 /hbase/.tmp
drwxr-xr-x   - hbase users          0 2014-06-25 21:49 /hbase/WALs
drwxr-xr-x   - hbase users          0 2014-06-25 18:48 /hbase/corrupt
drwxr-xr-x   - hbase users          0 2014-06-25 18:58 /hbase/data
-rw-r--r--   3 hbase users         42 2014-06-25 18:41 /hbase/hbase.id
-rw-r--r--   3 hbase users          7 2014-06-25 18:41 /hbase/hbase.version
drwxr-xr-x   - hbase users          0 2014-06-25 21:49 /hbase/oldWALs</pre>
</div>
</div>
</li>
<li>
<p>创建一个表并用数据填充它。</p>
<div class="paragraph">
<p>您可以使用HBase Shell创建一个表，使用数据填充该表，扫描并从中获取值，方法与<a href="#shell_exercises">Shell练习中</a>相同。</p>
</div>
</li>
<li>
<p>启动和停止备用HBase主服务器（HMaster）服务器。</p>
<div class="admonitionblock note">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-note" title="注意"></i>
</td>
<td class="content">在生产环境中，在同一硬件上运行多个HMaster实例没有任何意义，就像在生产环境中运行伪分布式集群没有意义。此步骤仅用于测试和学习目的。
</td>
</tr>
</tbody></table>
</div>
<div class="paragraph">
<p>HMaster服务器控制HBase群集。您最多可以启动9台备用HMaster服务器，这使总数为10台HMaster成为主要服务器。要启动备份HMaster，请使用<code>local-master-backup.sh</code> 。对于要启动的每个备份主服务器，添加一个代表该主服务器的端口偏移量的参数。每个HMaster使用三个端口（默认情况下为16010、16020和16030）。端口偏移量已添加到这些端口，因此，使用偏移量2时，备份HMaster将使用端口16012、16022和16032。以下命令使用端口16012/16022 / 16032、16013 / 16023/16033和16015/16025/16035启动3个备份服务器。</p>
</div>
<div class="listingblock">
<div class="content">
<pre>$ ./bin/local-master-backup.sh 2 3 5</pre>
</div>
</div>
<div class="paragraph">
<p>要杀死备份主服务器而不杀死整个集群，您需要找到其进程ID（PID）。PID以类似<em>/tmp/hbase-USER-X-master.pid</em>的名称存储在文件中。该文件的唯一内容是PID。您可以使用<code>kill -9</code>命令杀死该PID。以下命令将杀死端口偏移为1的主服务器，但使集群保持运行状态：</p>
</div>
<div class="listingblock">
<div class="content">
<pre>$ cat /tmp/hbase-testuser-1-master.pid |xargs kill -9</pre>
</div>
</div>
</li>
<li>
<p>启动和停止其他RegionServer</p>
<div class="paragraph">
<p>HRegionServer按照HMaster的指示管理其StoreFiles中的数据。通常，群集中的每个节点都运行一个HRegionServer。在同一系统上运行多个HRegionServer对于在伪分布式模式下进行测试非常有用。的<code>local-regionservers.sh</code>命令允许您运行多个RegionServer。它的工作方式与<code>local-master-backup.sh</code>命令，因为您提供的每个参数都代表实例的端口偏移量。每个RegionServer需要两个端口，默认端口为16020和16030。但是，附加的RegionServers的基本端口不是默认端口，因为默认端口由HMaster使用，HMaster从HBase版本1.0.0开始也是RegionServer。基本端口改为16200和16300。您可以在服务器上运行99个不是HMaster或备份HMaster的其他RegionServer。以下命令启动四个附加的RegionServer，它们在从16202/16302开始的顺序端口（基本端口16200/16300加2）上运行。</p>
</div>
<div class="listingblock">
<div class="content">
<pre>$ .bin/local-regionservers.sh start 2 3 4 5</pre>
</div>
</div>
<div class="paragraph">
<p>要手动停止RegionServer，请使用<code>local-regionservers.sh</code>用命令<code>stop</code>参数和要停止的服务器的偏移量。</p>
</div>
<div class="listingblock">
<div class="content">
<pre>$ .bin/local-regionservers.sh stop 3</pre>
</div>
</div>
</li>
<li>
<p>停止HBase。</p>
<div class="paragraph">
<p>您可以使用<em>bin / stop-hbase.sh</em>命令以与<a href="#quickstart">快速入门</a>过程中相同的方式停止HBase。</p>
</div>
</li>
</ol>
</div>
</div>
<div class="sect2">
<h3 id="quickstart_fully_distributed"><a class="anchor" href="#quickstart_fully_distributed"></a> 2.4。高级-完全分布式</h3>
<div class="paragraph">
<p>实际上，您需要一个完全分布式的配置来全面测试HBase并在实际场景中使用它。在分布式配置中，集群包含多个节点，每个节点运行一个或多个HBase守护程序。其中包括主实例和备份Master实例，多个Zookeeper节点和多个RegionServer节点。</p>
</div>
<div class="paragraph">
<p>此高级快速入门为集群添加了两个以上的节点。架构如下：</p>
</div>
<table class="tableblock frame-all grid-all spread">
<caption class="title">表格1。分布式集群演示架构</caption>
<colgroup>
<col style="width:25%">
<col style="width:25%">
<col style="width:25%">
<col style="width:25%">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">节点名称</th>
<th class="tableblock halign-left valign-top">主</th>
<th class="tableblock halign-left valign-top">动物园管理员</th>
<th class="tableblock halign-left valign-top">区域服务器</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">node-a.example.com</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">是</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">是</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">没有</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">node-b.example.com</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">后备</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">是</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">是</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">node-c.example.com</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">没有</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">是</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">是</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p>本快速入门假定每个节点都是虚拟机，并且它们都在同一网络上。它建立在先前的快速入门“ <a href="#quickstart_pseudo">中级-伪分布式本地安装”的基础上</a> ，假设您在该过程中配置的系统现在已<code>node-a</code> 。停止HBase <code>node-a</code>在继续之前。</p>
</div>
<div class="admonitionblock note">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-note" title="注意"></i>
</td>
<td class="content">确保所有节点都具有完全的通信访问权限，并且没有适当的防火墙规则可能阻止它们相互通信。如果您看到任何类似的错误<code>no route to host</code> ，请检查您的防火墙。
</td>
</tr>
</tbody></table>
</div>
<div id="passwordless.ssh.quickstart" class="paragraph">
<div class="title">过程：配置无密码的SSH访问</div>
<p><code>node-a</code>需要能够登录<code>node-b</code>和<code>node-c</code> （及其本身）以启动守护程序。完成此操作的最简单方法是在所有主机上使用相同的用户名，并从以下位置配置无密码的SSH登录： <code>node-a</code>给其他人。</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>上<code>node-a</code> ，生成密钥对。</p>
<div class="paragraph">
<p>以将要运行HBase的用户身份登录后，使用以下命令生成SSH密钥对：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">$ ssh-keygen -t rsa</code></pre>
</div>
</div>
<div class="paragraph">
<p>如果命令成功执行，则将密钥对的位置打印到标准输出。公钥的默认名称是<em>id_rsa.pub</em> 。</p>
</div>
</li>
<li>
<p>创建将在其他节点上保存共享密钥的目录。</p>
<div class="paragraph">
<p>上<code>node-b</code>和<code>node-c</code> ，以HBase用户身份登录，并在用户的主目录中创建<em>.ssh /</em>目录（如果尚不存在）。如果已经存在，请注意它可能已经包含其他密钥。</p>
</div>
</li>
<li>
<p>将公钥复制到其他节点。</p>
<div class="paragraph">
<p>从安全地复制公钥<code>node-a</code>通过使用<code>scp</code>或其他一些安全手段。在其他每个节点上，创建一个名为<em>.ssh / authorized_keys</em>的新文件（ <em>如果尚不存在）</em> ，并将<em>id_rsa.pub</em>文件的内容附加到文件末尾。请注意，您还需要为此<code>node-a</code>本身。</p>
</div>
<div class="listingblock">
<div class="content">
<pre>$ cat id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys</pre>
</div>
</div>
</li>
<li>
<p>测试无密码登录。</p>
<div class="paragraph">
<p>如果您正确执行了该过程，并且从<code>node-a</code>使用相同的用户名访问其他节点之一，则不会提示您输入密码。</p>
</div>
</li>
<li>
<p>以来<code>node-b</code>将运行一个备份主服务器，重复上述步骤，替换为<code>node-b</code>随处可见<code>node-a</code> 。确保不要覆盖现有的<em>.ssh / authorized_keys</em>文件，而应使用来将新密钥连接到现有文件上。 <code>>></code>运算符，而不是<code>></code>操作员。</p>
</li>
</ol>
</div>
<div class="paragraph">
<div class="title">程序：准备<code>node-a</code></div>
<p><code>node-a</code>将运行您的主要master和ZooKeeper进程，但不会运行RegionServer。。停止启动RegionServer <code>node-a</code> 。</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>编辑<em>conf / regionservers</em>并删除包含以下内容的行<code>localhost</code> 。添加带有主机名或IP地址的行<code>node-b</code>和<code>node-c</code> 。</p>
<div class="paragraph">
<p>即使您确实想在<code>node-a</code> ，则应使用其他服务器用来与之通信的主机名来引用它。在这种情况下， <code>node-a.example.com</code> 。这使您可以将任何主机名冲突将配置分发到群集的每个节点。保存文件。</p>
</div>
</li>
<li>
<p>配置HBase以使用<code>node-b</code>作为备份大师。</p>
<div class="paragraph">
<p>在<em>conf /中</em>创建一个名为<em>backup-masters</em>的新文件，并在其中添加新行，其主机名为<code>node-b</code> 。在此演示中，主机名是<code>node-b.example.com</code> 。</p>
</div>
</li>
<li>
<p>配置ZooKeeper</p>
<div class="paragraph">
<p>实际上，您应该仔细考虑您的ZooKeeper配置。您可以找到有关在<a href="#zookeeper">zookeeper中</a>配置ZooKeeper的更多信息。此配置将指导HBase在群集的每个节点上启动和管理ZooKeeper实例。</p>
</div>
<div class="paragraph">
<p>上<code>node-a</code> ，编辑<em>conf / hbase-site.xml</em>并添加以下属性。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="xml"><span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>hbase.zookeeper.quorum<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>node-a.example.com,node-b.example.com,node-c.example.com<span class="tag">&lt;/value&gt;</span>
<span class="tag">&lt;/property&gt;</span>
<span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>hbase.zookeeper.property.dataDir<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>/usr/local/zookeeper<span class="tag">&lt;/value&gt;</span>
<span class="tag">&lt;/property&gt;</span></code></pre>
</div>
</div>
</li>
<li>
<p>您引用的配置中的任何地方<code>node-a</code>如<code>localhost</code> ，将引用更改为指向其他节点将用来引用的主机名<code>node-a</code> 。在这些示例中，主机名是<code>node-a.example.com</code> 。</p>
</li>
</ol>
</div>
<div class="paragraph">
<div class="title">程序：准备<code>node-b</code>和<code>node-c</code></div>
<p><code>node-b</code>将运行一个备份主服务器和一个ZooKeeper实例。</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>下载并解压缩HBase。</p>
<div class="paragraph">
<p>将HBase下载并解压缩到<code>node-b</code> ，就像您对独立和伪分布式快速入门所做的那样。</p>
</div>
</li>
<li>
<p>从复制配置文件<code>node-a</code>至<code>node-b</code> 。和<code>node-c</code> 。</p>
<div class="paragraph">
<p>群集的每个节点都需要具有相同的配置信息。将<em>conf /</em>目录的内容复制到<em>conf /</em>目录中<code>node-b</code>和<code>node-c</code> 。</p>
</div>
</li>
</ol>
</div>
<div class="olist arabic">
<div class="title">过程：启动和测试集群</div>
<ol class="arabic">
<li>
<p>确保HBase不在任何节点上运行。</p>
<div class="paragraph">
<p>如果您忘记从先前的测试中停止HBase，则将出现错误。使用以下命令检查HBase是否在您的任何节点上运行<code>jps</code>命令。寻找过程<code>HMaster</code> ， <code>HRegionServer</code>和<code>HQuorumPeer</code> 。如果它们存在，杀死它们。</p>
</div>
</li>
<li>
<p>启动集群。</p>
<div class="paragraph">
<p>上<code>node-a</code> ，发出<code>start-hbase.sh</code>命令。您的输出将类似于以下内容。</p>
</div>
<div class="listingblock">
<div class="content">
<pre>$ bin/start-hbase.sh
node-c.example.com: starting zookeeper, logging to /home/hbuser/hbase-0.98.3-hadoop2/bin/../logs/hbase-hbuser-zookeeper-node-c.example.com.out
node-a.example.com: starting zookeeper, logging to /home/hbuser/hbase-0.98.3-hadoop2/bin/../logs/hbase-hbuser-zookeeper-node-a.example.com.out
node-b.example.com: starting zookeeper, logging to /home/hbuser/hbase-0.98.3-hadoop2/bin/../logs/hbase-hbuser-zookeeper-node-b.example.com.out
starting master, logging to /home/hbuser/hbase-0.98.3-hadoop2/bin/../logs/hbase-hbuser-master-node-a.example.com.out
node-c.example.com: starting regionserver, logging to /home/hbuser/hbase-0.98.3-hadoop2/bin/../logs/hbase-hbuser-regionserver-node-c.example.com.out
node-b.example.com: starting regionserver, logging to /home/hbuser/hbase-0.98.3-hadoop2/bin/../logs/hbase-hbuser-regionserver-node-b.example.com.out
node-b.example.com: starting master, logging to /home/hbuser/hbase-0.98.3-hadoop2/bin/../logs/hbase-hbuser-master-nodeb.example.com.out</pre>
</div>
</div>
<div class="paragraph">
<p>ZooKeeper首先启动，然后是主机，然后是RegionServers，最后是备份主机。</p>
</div>
</li>
<li>
<p>验证进程正在运行。</p>
<div class="paragraph">
<p>在群集的每个节点上，运行<code>jps</code>命令并验证每个服务器上是否正在运行正确的进程。如果将其他Java进程用于其他目的，则可能还会看到它们在服务器上运行。</p>
</div>
<div class="exampleblock">
<div class="title">示例2 <code>node-a</code><code>jps</code> 输出量</div>
<div class="content">
<div class="listingblock">
<div class="content">
<pre>$ jps
20355 Jps
20071 HQuorumPeer
20137 HMaster</pre>
</div>
</div>
</div>
</div>
<div class="exampleblock">
<div class="title">范例3。 <code>node-b</code><code>jps</code> 输出量</div>
<div class="content">
<div class="listingblock">
<div class="content">
<pre>$ jps
15930 HRegionServer
16194 Jps
15838 HQuorumPeer
16010 HMaster</pre>
</div>
</div>
</div>
</div>
<div class="exampleblock">
<div class="title">示例4 <code>node-a</code><code>jps</code> 输出量</div>
<div class="content">
<div class="listingblock">
<div class="content">
<pre>$ jps
13901 Jps
13639 HQuorumPeer
13737 HRegionServer</pre>
</div>
</div>
</div>
</div>
<div class="admonitionblock note">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-note" title="注意"></i>
</td>
<td class="content">
<div class="title">ZooKeeper进程名称</div>
<div class="paragraph">
<p>的<code>HQuorumPeer</code>进程是一个由HBase控制和启动的ZooKeeper实例。如果以这种方式使用ZooKeeper，则每个群集节点仅限一个实例，并且仅适用于测试。如果ZooKeeper在HBase之外运行，则该过程称为<code>QuorumPeer</code> 。有关ZooKeeper配置的更多信息，包括将外部ZooKeeper实例与HBase一起使用，请参阅<a href="#zookeeper">zookeeper</a> 。</p>
</div>
</td>
</tr>
</tbody></table>
</div>
</li>
<li>
<p>浏览到Web UI。</p>
<div class="admonitionblock note">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-note" title="注意"></i>
</td>
<td class="content">
<div class="title">Web UI端口更改</div>Web UI端口更改</td>
</tr>
</tbody></table>
</div>
<div class="paragraph">
<p>在低于0.98.x的HBase中，HBase Web UI使用的HTTP端口从Master的60010和每个RegionServer的60030变为Master的16010和RegionServer的16030。</p>
</div>
<div class="paragraph">
<p>如果一切设置正确，则您应该可以连接到Master的用户界面<code><a href="http://node-a.example.com:16010/" class="bare">http://node-a.example.com:16010/</a></code>或在<code><a href="http://node-b.example.com:16010/" class="bare">http://node-b.example.com:16010/</a></code>使用网络浏览器访问二级主服务器。如果可以通过<code>localhost</code>但不能从其他主机访问，请检查防火墙规则。您可以在其IP地址的端口16030上单击每个RegionServer的Web UI，也可以单击主服务器的Web UI中的链接。</p>
</div>
</li>
<li>
<p>测试当节点或服务消失时会发生什么。</p>
<div class="paragraph">
<p>使用已配置的三节点群集，事情将不会非常灵活。不过，您可以通过杀死进程并查看日志来测试当主Master或RegionServer消失时发生的情况。</p>
</div>
</li>
</ol>
</div>
</div>
<div class="sect2">
<h3 id="_where_to_go_next"><a class="anchor" href="#_where_to_go_next"></a> 2.5。接下来去哪里</h3>
<div class="paragraph">
<p>下一章<a href="#configuration">configuration</a>提供了有关不同HBase运行模式，运行HBase的系统要求以及用于设置分布式HBase群集的关键配置区域的更多信息。</p>
</div>
</div>
</div>
</div>
<h1 id="configuration" class="sect0"><a class="anchor" href="#configuration"></a> Apache HBase配置</h1>
<div class="openblock partintro">
<div class="content">本章在“ <a href="#getting_started">入门”</a>一章的基础上进行扩展，以进一步说明Apache HBase的配置。请仔细阅读本章，尤其是<a href="#basic.prerequisites">基本先决条件，</a>以确保您的HBase测试和部署顺利进行。<a href="#hbase_supported_tested_definitions">也要</a>熟悉<a href="#hbase_supported_tested_definitions">[hbase_supported_tested_definitions]</a> 。
</div>
</div>
<div class="sect1">
<h2 id="_configuration_files"><a class="anchor" href="#_configuration_files"></a> 3。配置文件</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Apache HBase使用与Apache Hadoop相同的配置系统。所有配置文件都位于<em>conf /</em>目录中，该文件需要与集群中的每个节点保持同步。</p>
</div>
<div class="dlist">
<div class="title">HBase配置文件说明</div>
<dl>
<dt class="hdlist1"><em>备份大师</em></dt>
<dd>
<p>默认情况下不存在。一个纯文本文件，其中列出了主机应在其上启动备份主机进程的主机，每行一个主机。</p>
</dd>
<dt class="hdlist1"><em>hadoop-metrics2-hbase.properties</em></dt>
<dd>
<p>用于连接HBase Hadoop的Metrics2框架。有关Metrics2的更多信息，请参见<a href="http://wiki.apache.org/hadoop/HADOOP-6728-MetricsV2">Hadoop Wiki条目</a> 。默认情况下仅包含注释掉的示例。</p>
</dd>
<dt class="hdlist1"><em>hbase-env.cmd</em>和<em>hbase-env.sh</em></dt>
<dd>
<p>用于Windows和Linux / Unix环境的脚本，用于设置HBase的工作环境，包括Java的位置，Java选项和其他环境变量。该文件包含许多已注释掉的示例，以提供指导。</p>
</dd>
<dt class="hdlist1"><em>hbase-policy.xml</em></dt>
<dd>
<p>RPC服务器用来对客户端请求做出授权决策的默认策略配置文件。仅在启用HBase <a href="#security">安全性时</a>使用。</p>
</dd>
<dt class="hdlist1"><em>hbase-site.xml</em></dt>
<dd>
<p>HBase主配置文件。该文件指定了覆盖HBase默认配置的配置选项。您可以在<em>docs / hbase-default.xml上</em>查看（但不能编辑）默认配置文件。您还可以在HBase Web UI的“ <span class="label">HBase配置”</span>选项卡中查看群集的整个有效配置（默认值和替代值）。</p>
</dd>
<dt class="hdlist1"><em>log4j.properties</em></dt>
<dd>
<p>通过HBase日志记录的配置文件<code>log4j</code> 。</p>
</dd>
<dt class="hdlist1"><em>区域服务器</em></dt>
<dd>
<p>一个纯文本文件，其中包含应在HBase群集中运行RegionServer的主机列表。默认情况下，此文件包含单个条目<code>localhost</code> 。它应包含一个主机名或IP地址的列表，每行一个，并且仅应包含<code>localhost</code>如果集群中的每个节点都将在其节点上运行RegionServer <code>localhost</code>接口。</p>
</dd>
</dl>
</div>
<div class="admonitionblock tip">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-tip" title="小费"></i>
</td>
<td class="content">
<div class="title">检查XML有效性</div>
<div class="paragraph">
<p>在编辑XML时，最好使用支持XML的编辑器，以确保语法正确且XML格式正确。您也可以使用<code>xmllint</code>实用程序，以检查您的XML格式是否正确。默认， <code>xmllint</code>重新进行流处理并将XML打印到标准输出。要检查格式是否正确并仅在存在错误的情况下才打印输出，请使用以下命令<code>xmllint -noout filename.xml</code> 。</p>
</div>
</td>
</tr>
</tbody></table>
</div>
<div class="admonitionblock warning">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-warning" title="警告"></i>
</td>
<td class="content">
<div class="title">使配置在整个群集中保持同步</div>
<div class="paragraph">
<p>在分布式模式下运行时，对HBase配置进行编辑后，请确保将<em>conf /</em>目录的内容复制到群集的所有节点。HBase不会为您这样做。使用<code>rsync</code> ， <code>scp</code> ，或用于将配置文件复制到您的节点的另一种安全机制。对于大多数配置，服务器需要重新启动才能获取更改。动态配置是一个例外。稍后将描述。</p>
</div>
</td>
</tr>
</tbody></table>
</div>
</div>
</div>
<div class="sect1">
<h2 id="basic.prerequisites"><a class="anchor" href="#basic.prerequisites"></a> 4。基本先决条件</h2>
<div class="sectionbody">
<div class="paragraph">
<p>本节列出了必需的服务和一些必需的系统配置。</p>
</div>
<div id="java" class="paragraph">
<div class="title">爪哇</div>
<p>下表总结了在各种Java版本上部署的HBase社区的建议。一种<span class="icon green"><i class="fa fa-check-circle"></i></span>符号表示测试的基本水平以及愿意帮助诊断和解决您可能遇到的问题的意愿。同样， <span class="icon yellow"><i class="fa fa-exclamation-circle"></i></span>要么<span class="icon red"><i class="fa fa-times-circle"></i></span>通常意味着，如果您遇到问题，社区可能会在继续提供帮助之前要求您更改Java环境。在某些情况下，还将注意有关限制的特定指南（例如，编译/单元测试是否有效，特定的操作问题等）。</p>
</div>
<div class="admonitionblock tip">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-tip" title="小费"></i>
</td>
<td class="content">
<div class="title">推荐长期支持JDK</div>
<div class="paragraph">
<p>HBase建议下游用户使用来自OpenJDK项目或供应商的标记为长期支持（LTS）的JDK版本。截至2018年3月，这意味着Java 8是唯一适用的版本，下一个可能进行测试的版本将是2018年第三季度附近的Java 11。</p>
</div>
</td>
</tr>
</tbody></table>
</div>
<table class="tableblock frame-all grid-all spread">
<caption class="title">表2。发行行对Java的支持</caption>
<colgroup>
<col style="width:16%">
<col style="width:16%">
<col style="width:16%">
<col style="width:16%">
<col style="width:16%">
<col style="width:16%">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-center valign-middle">HBase版本</th>
<th class="tableblock halign-center valign-middle">JDK 7</th>
<th class="tableblock halign-center valign-middle">JDK 8</th>
<th class="tableblock halign-center valign-middle">JDK 9（非LTS）</th>
<th class="tableblock halign-center valign-middle">JDK 10（非LTS）</th>
<th class="tableblock halign-center valign-middle">JDK 11</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-center valign-middle"><p class="tableblock">2.0+</p></td>
<td class="tableblock halign-center valign-middle"><p class="tableblock"><span class="icon red"><i class="fa fa-times-circle"></i></span></p></td>
<td class="tableblock halign-center valign-middle"><p class="tableblock"><span class="icon green"><i class="fa fa-check-circle"></i></span></p></td>
<td class="tableblock halign-center valign-middle"><div class="verse"><span class="icon yellow"><i class="fa fa-exclamation-circle"></i></span> <a href="https://issues.apache.org/jira/browse/HBASE-20264">HBASE-20264</a></div></td>
<td class="tableblock halign-center valign-middle"><div class="verse"><span class="icon yellow"><i class="fa fa-exclamation-circle"></i></span> <a href="https://issues.apache.org/jira/browse/HBASE-20264">HBASE-20264</a></div></td>
<td class="tableblock halign-center valign-middle"><div class="verse"><span class="icon yellow"><i class="fa fa-exclamation-circle"></i></span> <a href="https://issues.apache.org/jira/browse/HBASE-21110">HBASE-21110</a></div></td>
</tr>
<tr>
<td class="tableblock halign-center valign-middle"><p class="tableblock">1.2+</p></td>
<td class="tableblock halign-center valign-middle"><p class="tableblock"><span class="icon green"><i class="fa fa-check-circle"></i></span></p></td>
<td class="tableblock halign-center valign-middle"><p class="tableblock"><span class="icon green"><i class="fa fa-check-circle"></i></span></p></td>
<td class="tableblock halign-center valign-middle"><div class="verse"><span class="icon yellow"><i class="fa fa-exclamation-circle"></i></span> <a href="https://issues.apache.org/jira/browse/HBASE-20264">HBASE-20264</a></div></td>
<td class="tableblock halign-center valign-middle"><div class="verse"><span class="icon yellow"><i class="fa fa-exclamation-circle"></i></span> <a href="https://issues.apache.org/jira/browse/HBASE-20264">HBASE-20264</a></div></td>
<td class="tableblock halign-center valign-middle"><div class="verse"><span class="icon yellow"><i class="fa fa-exclamation-circle"></i></span> <a href="https://issues.apache.org/jira/browse/HBASE-21110">HBASE-21110</a></div></td>
</tr>
</tbody>
</table>
<div class="admonitionblock note">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-note" title="注意"></i>
</td>
<td class="content">HBase既不会构建也不会与Java 6一起运行。
</td>
</tr>
</tbody></table>
</div>
<div class="admonitionblock note">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-note" title="注意"></i>
</td>
<td class="content">你必须设置<code>JAVA_HOME</code>在群集的每个节点上。 <em>hbase-env.sh</em>提供了一种方便的机制来执行此操作。
</td>
</tr>
</tbody></table>
</div>
<div class="dlist">
<div class="title">操作系统实用程序</div>
<dl>
<dt class="hdlist1">ssh</dt>
<dd>
<p>HBase广泛使用Secure Shell（ssh）命令和实用程序在群集节点之间进行通信。集群中的每个服务器必须正在运行<code>ssh</code>这样就可以管理Hadoop和HBase守护程序。您必须能够使用共享密钥而不是密码通过SSH通过SSH从Master以及任何备份Master连接到所有节点，包括本地节点。您可以在“ <a href="#passwordless.ssh.quickstart">过程：配置无密码SSH访问</a> ”中<a href="#passwordless.ssh.quickstart">查看</a>在Linux或Unix系统中进行此类设置的基本方法。如果您的群集节点使用OS X，请参阅Hadoop Wiki上的<a href="http://wiki.apache.org/hadoop/Running_Hadoop_On_OS_X_10.5_64-bit_%28Single-Node_Cluster%29">SSH：设置远程桌面和启用自登录部分</a> 。</p>
</dd>
<dt class="hdlist1">域名解析</dt>
<dd>
<p>HBase使用本地主机名自报告其IP地址。</p>
</dd>
<dt class="hdlist1">NTP</dt>
<dd>
<p>群集节点上的时钟应同步。少量的变化是可以接受的，但是较大的偏斜会导致不稳定和意外的行为。时间同步是检查集群中是否出现无法解释的问题的首要检查之一。建议您在群集上运行网络时间协议（NTP）服务或其他时间同步机制，并且所有节点都希望使用同一服务进行时间同步。请参阅<em class="citetitle">Linux文档项目（TLDP）</em>上的“ <a href="http://www.tldp.org/LDP/sag/html/basic-ntp-config.html">基本NTP配置</a> <em class="citetitle">”</em>以设置NTP。</p>
</dd>
<dt class="hdlist1">文件和进程数限制（ulimit）</dt>
<dd>
<p>Apache HBase是一个数据库。它要求能够一次打开大量文件。许多Linux发行版都限制了允许单个用户打开的文件数<code>1024</code> （要么<code>256</code>在旧版的OS X上）。您可以通过运行以下命令在服务器上检查此限制<code>ulimit -n</code>以运行HBase的用户身份登录时。如果限制太低，可能会遇到一些问题，请参阅<a href="#trouble.rs.runtime.filehandles">“故障排除”部分</a> 。您可能还会注意到以下错误：</p>
<div class="listingblock">
<div class="content">
<pre>2010-04-06 03:04:37,542 INFO org.apache.hadoop.hdfs.DFSClient: Exception increateBlockOutputStream java.io.EOFException
2010-04-06 03:04:37,542 INFO org.apache.hadoop.hdfs.DFSClient: Abandoning block blk_-6935524980745310745_1391901</pre>
</div>
</div>
<div class="paragraph">
<p>建议将ulimit至少提高到10,000，但更可能是10,240，因为该值通常以1024的倍数表示。每个ColumnFamily至少有一个StoreFile，如果该区域处于加载状态，则可能有六个以上的StoreFile。所需打开文件的数量取决于ColumnFamilies的数量和区域的数量。以下是用于计算RegionServer上打开文件的潜在数量的粗略公式。</p>
</div>
<div class="listingblock">
<div class="title">计算打开文件的潜在数量</div>
<div class="content">
<pre>(StoreFiles per ColumnFamily) x (regions per RegionServer)</pre>
</div>
</div>
<div class="paragraph">
<p>例如，假设一个模式每个区域有3个ColumnFamily，每个ColumnFamily平均有3个StoreFiles，并且每个RegionServer有100个区域，那么JVM将打开<code>3 * 3 * 100 = 900</code>文件描述符，不计算打开的JAR文件，配置文件和其他文件。打开文件不会占用太多资源，并且允许用户打开太多文件的风险很小。</p>
</div>
<div class="paragraph">
<p>另一个相关的设置是允许用户一次运行的进程数。在Linux和Unix中，使用<code>ulimit -u</code>命令。这不应与<code>nproc</code>命令，用于控制给定用户可用的CPU数量。在负载下<code>ulimit -u</code>太低会导致OutOfMemoryError异常。</p>
</div>
<div class="paragraph">
<p>为运行HBase进程的用户配置文件描述符和进程的最大数量是操作系统配置，而不是HBase配置。确保为实际运行HBase的用户更改设置也很重要。要查看哪个用户启动了HBase，以及该用户的ulimit配置，请查看该实例的HBase日志的第一行。</p>
</div>
<div class="exampleblock">
<div class="title">示例5 <code>ulimit</code> Ubuntu上的设置</div>
<div class="content">
<div class="paragraph">
<p>要在Ubuntu上配置ulimit设置，请编辑<em>/etc/security/limits.conf</em> ，这是一个由空格分隔的四列文件。有关此文件格式的详细信息，请参考关于<em>limits.conf</em>的手册页。在下面的示例中，第一行将具有用户名hadoop的操作系统用户的打开文件（nofile）数量的软限制和硬限制都设置为32768。第二行将同一用户的进程数设置为32000。</p>
</div>
<div class="listingblock">
<div class="content">
<pre>hadoop  -       nofile  32768
hadoop  -       nproc   32000</pre>
</div>
</div>
<div class="paragraph">
<p>仅当直接使用可插拔身份验证模块（PAM）环境时才应用设置。要将PAM配置为使用这些限制，请确保<em>/etc/pam.d/common-session</em>文件包含以下行：</p>
</div>
<div class="listingblock">
<div class="content">
<pre>session required  pam_limits.so</pre>
</div>
</div>
</div>
</div>
</dd>
<dt class="hdlist1">Linux Shell</dt>
<dd>
<p>HBase附带的所有shell脚本都依赖于<a href="http://www.gnu.org/software/bash">GNU Bash</a> shell。</p>
</dd>
<dt class="hdlist1">视窗</dt>
<dd>
<p>不建议在Windows计算机上运行生产系统。</p>
</dd>
</dl>
</div>
<div class="sect2">
<h3 id="hadoop"><a class="anchor" href="#hadoop"></a> 4.1。<a href="http://hadoop.apache.org">Hadoop的</a></h3>
<div class="paragraph">
<p>下表总结了每个HBase版本支持的Hadoop版本。该表中未出现的较旧版本被认为不支持，并且可能缺少必要的功能，而较新版本未经测试，但可能合适。</p>
</div>
<div class="paragraph">
<p>基于HBase的版本，您应该选择最合适的Hadoop版本。您可以使用Apache Hadoop或供应商的Hadoop发行版。这里没有区别。有关<a href="http://wiki.apache.org/hadoop/Distributions and Commercial Support">Hadoop</a>供应商的信息，请参见<a href="http://wiki.apache.org/hadoop/Distributions and Commercial Support">Hadoop Wiki</a> 。</p>
</div>
<div class="admonitionblock tip">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-tip" title="小费"></i>
</td>
<td class="content">
<div class="title">推荐使用Hadoop2.x。</div>
<div class="paragraph">
<p>Hadoop 2.x速度更快，并且具有诸如短路读取（请参见<a href="#perf.hdfs.configs.localread">利用本地数据</a> ）之类的功能，这将有助于改善HBase随机读取配置文件。Hadoop 2.x还包括重要的错误修复程序，这些改进将改善您的总体HBase体验。HBase不支持与Hadoop的早期版本一起运行。有关特定于不同HBase版本的要求，请参见下表。</p>
</div>
<div class="paragraph">
<p>Hadoop 3.x仍处于早期访问版本中，尚未通过HBase社区针对生产用例的充分测试。</p>
</div>
</td>
</tr>
</tbody></table>
</div>
<div class="paragraph">
<p>使用以下图例解释此表：</p>
</div>
<div class="ulist">
<div class="title">Hadoop版本支持表</div>
<ul>
<li>
<p><span class="icon green"><i class="fa fa-check-circle"></i></span> =经过测试可正常运行</p>
</li>
<li>
<p><span class="icon red"><i class="fa fa-times-circle"></i></span> =已知功能不完整</p>
</li>
<li>
<p><span class="icon yellow"><i class="fa fa-exclamation-circle"></i></span> =未测试，可能/可能不起作用</p>
</li>
</ul>
</div>
<table class="tableblock frame-all grid-all spread">
<colgroup>
<col style="width:14%">
<col style="width:14%">
<col style="width:14%">
<col style="width:14%">
<col style="width:14%">
<col style="width:14%">
<col style="width:14%">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top"></th>
<th class="tableblock halign-center valign-middle">HBase-1.2.x，HBase-1.3.x</th>
<th class="tableblock halign-center valign-middle">HBase-1.4.x</th>
<th class="tableblock halign-center valign-middle">HBase-1.5.x</th>
<th class="tableblock halign-center valign-middle">HBase-2.0.x</th>
<th class="tableblock halign-center valign-middle">HBase-2.1.x</th>
<th class="tableblock halign-center valign-middle">HBase-2.2.x</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Hadoop-2.4.x</p></td>
<td class="tableblock halign-center valign-middle"><p class="tableblock"><span class="icon green"><i class="fa fa-check-circle"></i></span></p></td>
<td class="tableblock halign-center valign-middle"><p class="tableblock"><span class="icon red"><i class="fa fa-times-circle"></i></span></p></td>
<td class="tableblock halign-center valign-middle"><p class="tableblock"><span class="icon red"><i class="fa fa-times-circle"></i></span></p></td>
<td class="tableblock halign-center valign-middle"><p class="tableblock"><span class="icon red"><i class="fa fa-times-circle"></i></span></p></td>
<td class="tableblock halign-center valign-middle"><p class="tableblock"><span class="icon red"><i class="fa fa-times-circle"></i></span></p></td>
<td class="tableblock halign-center valign-middle"><p class="tableblock"><span class="icon red"><i class="fa fa-times-circle"></i></span></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Hadoop-2.5.x</p></td>
<td class="tableblock halign-center valign-middle"><p class="tableblock"><span class="icon green"><i class="fa fa-check-circle"></i></span></p></td>
<td class="tableblock halign-center valign-middle"><p class="tableblock"><span class="icon red"><i class="fa fa-times-circle"></i></span></p></td>
<td class="tableblock halign-center valign-middle"><p class="tableblock"><span class="icon red"><i class="fa fa-times-circle"></i></span></p></td>
<td class="tableblock halign-center valign-middle"><p class="tableblock"><span class="icon red"><i class="fa fa-times-circle"></i></span></p></td>
<td class="tableblock halign-center valign-middle"><p class="tableblock"><span class="icon red"><i class="fa fa-times-circle"></i></span></p></td>
<td class="tableblock halign-center valign-middle"><p class="tableblock"><span class="icon red"><i class="fa fa-times-circle"></i></span></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Hadoop-2.6.0</p></td>
<td class="tableblock halign-center valign-middle"><p class="tableblock"><span class="icon red"><i class="fa fa-times-circle"></i></span></p></td>
<td class="tableblock halign-center valign-middle"><p class="tableblock"><span class="icon red"><i class="fa fa-times-circle"></i></span></p></td>
<td class="tableblock halign-center valign-middle"><p class="tableblock"><span class="icon red"><i class="fa fa-times-circle"></i></span></p></td>
<td class="tableblock halign-center valign-middle"><p class="tableblock"><span class="icon red"><i class="fa fa-times-circle"></i></span></p></td>
<td class="tableblock halign-center valign-middle"><p class="tableblock"><span class="icon red"><i class="fa fa-times-circle"></i></span></p></td>
<td class="tableblock halign-center valign-middle"><p class="tableblock"><span class="icon red"><i class="fa fa-times-circle"></i></span></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Hadoop-2.6.1 +</p></td>
<td class="tableblock halign-center valign-middle"><p class="tableblock"><span class="icon green"><i class="fa fa-check-circle"></i></span></p></td>
<td class="tableblock halign-center valign-middle"><p class="tableblock"><span class="icon red"><i class="fa fa-times-circle"></i></span></p></td>
<td class="tableblock halign-center valign-middle"><p class="tableblock"><span class="icon red"><i class="fa fa-times-circle"></i></span></p></td>
<td class="tableblock halign-center valign-middle"><p class="tableblock"><span class="icon green"><i class="fa fa-check-circle"></i></span></p></td>
<td class="tableblock halign-center valign-middle"><p class="tableblock"><span class="icon red"><i class="fa fa-times-circle"></i></span></p></td>
<td class="tableblock halign-center valign-middle"><p class="tableblock"><span class="icon red"><i class="fa fa-times-circle"></i></span></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Hadoop-2.7.0</p></td>
<td class="tableblock halign-center valign-middle"><p class="tableblock"><span class="icon red"><i class="fa fa-times-circle"></i></span></p></td>
<td class="tableblock halign-center valign-middle"><p class="tableblock"><span class="icon red"><i class="fa fa-times-circle"></i></span></p></td>
<td class="tableblock halign-center valign-middle"><p class="tableblock"><span class="icon red"><i class="fa fa-times-circle"></i></span></p></td>
<td class="tableblock halign-center valign-middle"><p class="tableblock"><span class="icon red"><i class="fa fa-times-circle"></i></span></p></td>
<td class="tableblock halign-center valign-middle"><p class="tableblock"><span class="icon red"><i class="fa fa-times-circle"></i></span></p></td>
<td class="tableblock halign-center valign-middle"><p class="tableblock"><span class="icon red"><i class="fa fa-times-circle"></i></span></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Hadoop-2.7.1以上</p></td>
<td class="tableblock halign-center valign-middle"><p class="tableblock"><span class="icon green"><i class="fa fa-check-circle"></i></span></p></td>
<td class="tableblock halign-center valign-middle"><p class="tableblock"><span class="icon green"><i class="fa fa-check-circle"></i></span></p></td>
<td class="tableblock halign-center valign-middle"><p class="tableblock"><span class="icon red"><i class="fa fa-times-circle"></i></span></p></td>
<td class="tableblock halign-center valign-middle"><p class="tableblock"><span class="icon green"><i class="fa fa-check-circle"></i></span></p></td>
<td class="tableblock halign-center valign-middle"><p class="tableblock"><span class="icon green"><i class="fa fa-check-circle"></i></span></p></td>
<td class="tableblock halign-center valign-middle"><p class="tableblock"><span class="icon red"><i class="fa fa-times-circle"></i></span></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Hadoop-2.8。[0-1]</p></td>
<td class="tableblock halign-center valign-middle"><p class="tableblock"><span class="icon red"><i class="fa fa-times-circle"></i></span></p></td>
<td class="tableblock halign-center valign-middle"><p class="tableblock"><span class="icon red"><i class="fa fa-times-circle"></i></span></p></td>
<td class="tableblock halign-center valign-middle"><p class="tableblock"><span class="icon red"><i class="fa fa-times-circle"></i></span></p></td>
<td class="tableblock halign-center valign-middle"><p class="tableblock"><span class="icon red"><i class="fa fa-times-circle"></i></span></p></td>
<td class="tableblock halign-center valign-middle"><p class="tableblock"><span class="icon red"><i class="fa fa-times-circle"></i></span></p></td>
<td class="tableblock halign-center valign-middle"><p class="tableblock"><span class="icon red"><i class="fa fa-times-circle"></i></span></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Hadoop-2.8.2</p></td>
<td class="tableblock halign-center valign-middle"><p class="tableblock"><span class="icon yellow"><i class="fa fa-exclamation-circle"></i></span></p></td>
<td class="tableblock halign-center valign-middle"><p class="tableblock"><span class="icon yellow"><i class="fa fa-exclamation-circle"></i></span></p></td>
<td class="tableblock halign-center valign-middle"><p class="tableblock"><span class="icon green"><i class="fa fa-check-circle"></i></span></p></td>
<td class="tableblock halign-center valign-middle"><p class="tableblock"><span class="icon yellow"><i class="fa fa-exclamation-circle"></i></span></p></td>
<td class="tableblock halign-center valign-middle"><p class="tableblock"><span class="icon yellow"><i class="fa fa-exclamation-circle"></i></span></p></td>
<td class="tableblock halign-center valign-middle"><p class="tableblock"><span class="icon green"><i class="fa fa-check-circle"></i></span></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Hadoop-2.8.3 +</p></td>
<td class="tableblock halign-center valign-middle"><p class="tableblock"><span class="icon yellow"><i class="fa fa-exclamation-circle"></i></span></p></td>
<td class="tableblock halign-center valign-middle"><p class="tableblock"><span class="icon yellow"><i class="fa fa-exclamation-circle"></i></span></p></td>
<td class="tableblock halign-center valign-middle"><p class="tableblock"><span class="icon green"><i class="fa fa-check-circle"></i></span></p></td>
<td class="tableblock halign-center valign-middle"><p class="tableblock"><span class="icon green"><i class="fa fa-check-circle"></i></span></p></td>
<td class="tableblock halign-center valign-middle"><p class="tableblock"><span class="icon green"><i class="fa fa-check-circle"></i></span></p></td>
<td class="tableblock halign-center valign-middle"><p class="tableblock"><span class="icon green"><i class="fa fa-check-circle"></i></span></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Hadoop-2.9.0</p></td>
<td class="tableblock halign-center valign-middle"><p class="tableblock"><span class="icon red"><i class="fa fa-times-circle"></i></span></p></td>
<td class="tableblock halign-center valign-middle"><p class="tableblock"><span class="icon red"><i class="fa fa-times-circle"></i></span></p></td>
<td class="tableblock halign-center valign-middle"><p class="tableblock"><span class="icon red"><i class="fa fa-times-circle"></i></span></p></td>
<td class="tableblock halign-center valign-middle"><p class="tableblock"><span class="icon red"><i class="fa fa-times-circle"></i></span></p></td>
<td class="tableblock halign-center valign-middle"><p class="tableblock"><span class="icon red"><i class="fa fa-times-circle"></i></span></p></td>
<td class="tableblock halign-center valign-middle"><p class="tableblock"><span class="icon red"><i class="fa fa-times-circle"></i></span></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Hadoop-2.9.1 +</p></td>
<td class="tableblock halign-center valign-middle"><p class="tableblock"><span class="icon yellow"><i class="fa fa-exclamation-circle"></i></span></p></td>
<td class="tableblock halign-center valign-middle"><p class="tableblock"><span class="icon yellow"><i class="fa fa-exclamation-circle"></i></span></p></td>
<td class="tableblock halign-center valign-middle"><p class="tableblock"><span class="icon yellow"><i class="fa fa-exclamation-circle"></i></span></p></td>
<td class="tableblock halign-center valign-middle"><p class="tableblock"><span class="icon yellow"><i class="fa fa-exclamation-circle"></i></span></p></td>
<td class="tableblock halign-center valign-middle"><p class="tableblock"><span class="icon yellow"><i class="fa fa-exclamation-circle"></i></span></p></td>
<td class="tableblock halign-center valign-middle"><p class="tableblock"><span class="icon yellow"><i class="fa fa-exclamation-circle"></i></span></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Hadoop-3.0。[0-2]</p></td>
<td class="tableblock halign-center valign-middle"><p class="tableblock"><span class="icon red"><i class="fa fa-times-circle"></i></span></p></td>
<td class="tableblock halign-center valign-middle"><p class="tableblock"><span class="icon red"><i class="fa fa-times-circle"></i></span></p></td>
<td class="tableblock halign-center valign-middle"><p class="tableblock"><span class="icon red"><i class="fa fa-times-circle"></i></span></p></td>
<td class="tableblock halign-center valign-middle"><p class="tableblock"><span class="icon red"><i class="fa fa-times-circle"></i></span></p></td>
<td class="tableblock halign-center valign-middle"><p class="tableblock"><span class="icon red"><i class="fa fa-times-circle"></i></span></p></td>
<td class="tableblock halign-center valign-middle"><p class="tableblock"><span class="icon red"><i class="fa fa-times-circle"></i></span></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Hadoop-3.0.3 +</p></td>
<td class="tableblock halign-center valign-middle"><p class="tableblock"><span class="icon red"><i class="fa fa-times-circle"></i></span></p></td>
<td class="tableblock halign-center valign-middle"><p class="tableblock"><span class="icon red"><i class="fa fa-times-circle"></i></span></p></td>
<td class="tableblock halign-center valign-middle"><p class="tableblock"><span class="icon red"><i class="fa fa-times-circle"></i></span></p></td>
<td class="tableblock halign-center valign-middle"><p class="tableblock"><span class="icon green"><i class="fa fa-check-circle"></i></span></p></td>
<td class="tableblock halign-center valign-middle"><p class="tableblock"><span class="icon green"><i class="fa fa-check-circle"></i></span></p></td>
<td class="tableblock halign-center valign-middle"><p class="tableblock"><span class="icon green"><i class="fa fa-check-circle"></i></span></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Hadoop-3.1.0</p></td>
<td class="tableblock halign-center valign-middle"><p class="tableblock"><span class="icon red"><i class="fa fa-times-circle"></i></span></p></td>
<td class="tableblock halign-center valign-middle"><p class="tableblock"><span class="icon red"><i class="fa fa-times-circle"></i></span></p></td>
<td class="tableblock halign-center valign-middle"><p class="tableblock"><span class="icon red"><i class="fa fa-times-circle"></i></span></p></td>
<td class="tableblock halign-center valign-middle"><p class="tableblock"><span class="icon red"><i class="fa fa-times-circle"></i></span></p></td>
<td class="tableblock halign-center valign-middle"><p class="tableblock"><span class="icon red"><i class="fa fa-times-circle"></i></span></p></td>
<td class="tableblock halign-center valign-middle"><p class="tableblock"><span class="icon red"><i class="fa fa-times-circle"></i></span></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Hadoop-3.1.1 +</p></td>
<td class="tableblock halign-center valign-middle"><p class="tableblock"><span class="icon red"><i class="fa fa-times-circle"></i></span></p></td>
<td class="tableblock halign-center valign-middle"><p class="tableblock"><span class="icon red"><i class="fa fa-times-circle"></i></span></p></td>
<td class="tableblock halign-center valign-middle"><p class="tableblock"><span class="icon red"><i class="fa fa-times-circle"></i></span></p></td>
<td class="tableblock halign-center valign-middle"><p class="tableblock"><span class="icon green"><i class="fa fa-check-circle"></i></span></p></td>
<td class="tableblock halign-center valign-middle"><p class="tableblock"><span class="icon green"><i class="fa fa-check-circle"></i></span></p></td>
<td class="tableblock halign-center valign-middle"><p class="tableblock"><span class="icon green"><i class="fa fa-check-circle"></i></span></p></td>
</tr>
</tbody>
</table>
<div class="admonitionblock tip">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-tip" title="小费"></i>
</td>
<td class="content">
<div class="title">Hadoop 2.1.6版和JDK 1.8 Kerberos</div>
<div class="paragraph">
<p>在Kerberos环境中使用2.6.1之前的Hadoop版本和JDK 1.8时，由于Kerberos keytab重新登录错误，HBase服务器可能会失败并中止。JDK 1.7的较新版本（1.7.0_80）也存在此问题。有关更多详细信息，请参见<a href="https://issues.apache.org/jira/browse/HADOOP-10786">HADOOP-10786</a> 。在这种情况下，请考虑升级到Hadoop 2.6.1+。</p>
</div>
</td>
</tr>
</tbody></table>
</div>
<div class="admonitionblock tip">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-tip" title="小费"></i>
</td>
<td class="content">
<div class="title">Hadoop 2.6.x</div>
<div class="paragraph">
<p>如果您计划在HDFS加密区域上运行HBase，则基于2.6.x行的Hadoop发行版<strong>必须</strong>已应用<a href="https://issues.apache.org/jira/browse/HADOOP-11710">HADOOP-11710</a> 。否则将导致群集故障和数据丢失。该修补程序存在于Apache Hadoop 2.6.1+版本中。</p>
</div>
</td>
</tr>
</tbody></table>
</div>
<div class="admonitionblock tip">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-tip" title="小费"></i>
</td>
<td class="content">
<div class="title">Hadoop 2.y.0版本</div>
<div class="paragraph">
<p>从Hadoop 2.7.0版本开始，Hadoop PMC习惯于在其主要版本2发行行中召集新的次要版本，因为它们不稳定或尚未准备就绪。因此，HBase明确建议下游用户避免在这些版本之上运行。请注意，Hadoop PMC还为2.8.1版本提供了相同的警告。作为参考，请参阅<a href="https://s.apache.org/hadoop-2.7.0-announcement">Apache Hadoop 2.7.0</a> ， <a href="https://s.apache.org/hadoop-2.8.0-announcement">Apache Hadoop 2.8.0</a> ， <a href="https://s.apache.org/hadoop-2.8.1-announcement">Apache Hadoop 2.8.1</a>和<a href="https://s.apache.org/hadoop-2.9.0-announcement">Apache Hadoop 2.9.0</a>的发行公告。</p>
</div>
</td>
</tr>
</tbody></table>
</div>
<div class="admonitionblock tip">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-tip" title="小费"></i>
</td>
<td class="content">
<div class="title">Hadoop 3.0.x版本</div>
<div class="paragraph">
<p>包含应用程序时间线服务功能的Hadoop发行版可能会导致应用程序类路径中出现意外版本的HBase类。计划使用HBase运行MapReduce应用程序的用户应确保其YARN服务中存在<a href="https://issues.apache.org/jira/browse/YARN-7190">YARN-7190</a> （当前在2.9.1+和3.1.0+中已修复）。</p>
</div>
</td>
</tr>
</tbody></table>
</div>
<div class="admonitionblock tip">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-tip" title="小费"></i>
</td>
<td class="content">
<div class="title">Hadoop 3.1.0版本</div>
<div class="paragraph">
<p>Hadoop PMC将3.1.0版本称为不稳定/生产就绪。因此，HBase明确建议下游用户避免在此版本之上运行。作为参考，请参阅<a href="https://s.apache.org/hadoop-3.1.0-announcement">Hadoop 3.1.0</a>的<a href="https://s.apache.org/hadoop-3.1.0-announcement">发行公告</a> 。</p>
</div>
</td>
</tr>
</tbody></table>
</div>
<div class="admonitionblock note">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-note" title="注意"></i>
</td>
<td class="content">
<div class="title">用HBase替换捆绑的Hadoop！</div>
<div class="paragraph">
<p>因为HBase依赖Hadoop，所以它将Hadoop jar捆绑在其<em>lib</em>目录下。捆绑的罐子只能在独立模式下使用。在分布式模式下，群集上的Hadoop版本与HBase下的Hadoop版本匹配<em>至关重要</em> 。将HBase lib目录中找到的hadoop jar替换为您在集群上运行的版本中的等效hadoop jar，以避免版本不匹配的问题。确保在整个群集中替换HBase下的jar。Hadoop版本不匹配问题有多种表现形式。如果HBase似乎挂起，请检查是否不匹配。</p>
</div>
</td>
</tr>
</tbody></table>
</div>
<div class="sect3">
<h4 id="dfs.datanode.max.transfer.threads"><a class="anchor" href="#dfs.datanode.max.transfer.threads"></a> 4.1.1。 <code>dfs.datanode.max.transfer.threads</code> </h4>
<div class="paragraph">
<p>HDFS DataNode可以随时提供服务的文件数量上限。在执行任何加载之前，请确保已配置Hadoop的<em>conf / hdfs-site.xml</em> ，并设置<code>dfs.datanode.max.transfer.threads</code>至少具有以下价值：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="xml"><span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>dfs.datanode.max.transfer.threads<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>4096<span class="tag">&lt;/value&gt;</span>
<span class="tag">&lt;/property&gt;</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>完成上述配置后，请务必重新启动HDFS。</p>
</div>
<div class="paragraph">
<p>如果没有适当的配置，则会导致外观异常。一种表现是对缺少块的抱怨。例如：</p>
</div>
<div class="listingblock">
<div class="content">
<pre>10/12/08 20:10:31 INFO hdfs.DFSClient: Could not obtain block
          blk_XXXXXXXXXXXXXXXXXXXXXX_YYYYYYYY from any node: java.io.IOException: No live nodes
          contain current block. Will get new block locations from namenode and retry...</pre>
</div>
</div>
<div class="paragraph">
<p>另请参阅<a href="#casestudies.max.transfer.threads">casestudies.max.transfer.threads，</a>并注意此属性以前称为<code>dfs.datanode.max.xcievers</code> （例如<a href="http://ccgtech.blogspot.com/2010/02/hadoop-hdfs-deceived-by-xciever.html">Hadoop HDFS：由Xciever欺骗</a> ）。</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="zookeeper.requirements"><a class="anchor" href="#zookeeper.requirements"></a> 4.2。ZooKeeper要求</h3>
<div class="paragraph">
<p>ZooKeeper 3.4.x是必需的。</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="standalone_dist"><a class="anchor" href="#standalone_dist"></a> 5，HBase运行模式：独立和分布式</h2>
<div class="sectionbody">
<div class="paragraph">
<p>HBase有两种运行模式： <a href="#standalone">独立</a>运行和<a href="#distributed">分布式</a>运行。开箱即用，HBase以独立模式运行。无论使用哪种模式，都需要通过编辑HBase <em>conf</em>目录中的文件来配置HBase。至少，您必须编辑<span class="code">conf / hbase-env.sh</span>以告知HBase使用哪个Java。在此文件中，您可以设置HBase环境变量，例如堆大小和其他<code>JVM</code> ，日志文件的首选位置等。将<span class="var">JAVA_HOME设置</span>为指向Java安装的根目录。</p>
</div>
<div class="sect2">
<h3 id="standalone"><a class="anchor" href="#standalone"></a> 5.1。独立的HBase</h3>
<div class="paragraph">
<p>这是默认模式。<a href="#quickstart">快速入门</a>部分介绍了独立模式。在独立模式下，HBase不使用HDFS，而是使用本地文件系统，并且在同一JVM中运行所有HBase守护程序和本地ZooKeeper。 Zookeeper绑定到一个知名端口，因此客户端可以与HBase进行通信。</p>
</div>
</div>
<div class="sect2">
<h3 id="distributed"><a class="anchor" href="#distributed"></a> 5.2。分散式</h3>
<div class="paragraph">
<p>可以将分布式模式细分为分布式模式，但是所有守护程序都在单个节点上运行（也称为<em>伪分布式）</em> ，并且可以<em>完全分布式</em> ，其中，守护程序分布在群集中的所有节点上。<em>伪分布式</em>和<em>全分布式</em>术语来自Hadoop。</p>
</div>
<div class="paragraph">
<p>伪分布式模式可以针对本地文件系统运行，也可以针对<em>Hadoop分布式文件系统</em> （HDFS）实例运行。全分布式模式只能在HDFS上运行。有关如何设置HDFS的<a href="http://hadoop.apache.org/docs/current/">信息</a> ，请参阅Hadoop <a href="http://hadoop.apache.org/docs/current/">文档</a> 。可在<a href="http://www.alexjf.net/blog/distributed-systems/hadoop-yarn-installation-definitive-guide" class="bare">http://www.alexjf.net/blog/distributed-systems/hadoop-yarn-installation-definitive-guide中</a>找到有关在Hadoop 2上设置HDFS的很好的演练。</p>
</div>
<div class="sect3">
<h4 id="pseudo"><a class="anchor" href="#pseudo"></a> 5.2.1。伪分布式</h4>
<div class="admonitionblock note">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-note" title="注意"></i>
</td>
<td class="content">
<div class="title">伪分布式快速入门</div>
<div class="paragraph">
<p>快速入门已添加到<a href="#quickstart">快速入门</a>一章。请参阅<a href="#quickstart_pseudo">quickstart-pseudo</a> 。本节中最初的某些信息已移至此处。</p>
</div>
</td>
</tr>
</tbody></table>
</div>
<div class="paragraph">
<p>伪分布式模式只是在单个主机上运行的完全分布式模式。在HBase上使用此配置测试和原型。请勿将此配置用于生产或评估HBase性能。</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="fully_dist"><a class="anchor" href="#fully_dist"></a> 5.3。完全分布</h3>
<div class="paragraph">
<p>默认情况下，HBase在独立模式下运行。提供独立模式和伪分布式模式都是为了进行小型测试。对于生产环境，分布式模式是合适的。在分布式模式下，HBase守护程序的多个实例在群集中的多个服务器上运行。</p>
</div>
<div class="paragraph">
<p>就像在伪分布式模式下一样，完全分布式配置要求您设置<code>hbase-cluster.distributed</code>财产<code>true</code> 。通常， <code>hbase.rootdir</code>配置为指向高度可用的HDFS文件系统。</p>
</div>
<div class="paragraph">
<p>此外，还配置了群集，以便多个群集节点可以注册为RegionServer，ZooKeeper QuorumPeers和备份HMaster服务器。这些配置基础都在<a href="#quickstart_fully_distributed">quickstart-full-distributed中</a>进行了演示。</p>
</div>
<div class="paragraph">
<div class="title">分布式RegionServer</div>
<p>通常，您的群集将包含运行在不同服务器上的多个RegionServer，以及主和备份Master和Zookeeper守护程序。主服务器上的<em>conf / regionservers</em>文件包含其RegionServer与该群集关联的主机列表。每个主机都位于单独的行上。当主服务器启动或停止时，此文件中列出的所有主机都将启动和停止其RegionServer进程。</p>
</div>
<div class="paragraph">
<div class="title">ZooKeeper和HBase</div>
<p>有关HBase的ZooKeeper设置说明，请参见<a href="#zookeeper">ZooKeeper</a>部分。</p>
</div>
<div class="exampleblock">
<div class="title">范例6。分布式HBase集群示例</div>
<div class="content">
<div class="paragraph">
<p>这是分布式HBase群集的基本<em>conf / hbase-site.xml</em> 。用于实际工作的群集将包含更多自定义配置参数。大多数HBase配置指令都有默认值，除非在<em>hbase-site.xml中</em>覆盖了该值，否则将使用默认值。有关更多信息，请参见“ <a href="#config.files">配置文件</a> ”。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="xml"><span class="tag">&lt;configuration&gt;</span>
  <span class="tag">&lt;property&gt;</span>
    <span class="tag">&lt;name&gt;</span>hbase.rootdir<span class="tag">&lt;/name&gt;</span>
    <span class="tag">&lt;value&gt;</span>hdfs://namenode.example.org:8020/hbase<span class="tag">&lt;/value&gt;</span>
  <span class="tag">&lt;/property&gt;</span>
  <span class="tag">&lt;property&gt;</span>
    <span class="tag">&lt;name&gt;</span>hbase.cluster.distributed<span class="tag">&lt;/name&gt;</span>
    <span class="tag">&lt;value&gt;</span>true<span class="tag">&lt;/value&gt;</span>
  <span class="tag">&lt;/property&gt;</span>
  <span class="tag">&lt;property&gt;</span>
    <span class="tag">&lt;name&gt;</span>hbase.zookeeper.quorum<span class="tag">&lt;/name&gt;</span>
    <span class="tag">&lt;value&gt;</span>node-a.example.com,node-b.example.com,node-c.example.com<span class="tag">&lt;/value&gt;</span>
  <span class="tag">&lt;/property&gt;</span>
<span class="tag">&lt;/configuration&gt;</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>这是一个示例<em>conf / regionservers</em>文件，其中包含应在集群中运行RegionServer的节点的列表。这些节点需要安装HBase，并且需要使用与主服务器相同的<em>conf /</em>目录内容</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">node-a.example.com
node-b.example.com
node-c.example.com</code></pre>
</div>
</div>
<div class="paragraph">
<p>这是示例<em>conf / backup-masters</em>文件，其中包含应运行备份Master实例的每个节点的列表。除非主控主机不可用，否则备份主控实例将处于空闲状态。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">node-b.example.com
node-c.example.com</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<div class="title">分布式HBase快速入门</div>
<p>有关具有多个ZooKeeper，备份HMaster和RegionServer实例的简单三节点群集配置的演练，请参阅<a href="#quickstart_fully_distributed">快速分发</a> 。</p>
</div>
<div class="olist arabic">
<div class="title">过程：HDFS客户端配置</div>
<ol class="arabic">
<li>
<p>值得注意的是，如果您在Hadoop集群上进行了HDFS客户端配置更改（例如HDFS客户端的配置指令），而不是服务器端配置，则必须使用以下方法之一使HBase能够查看和使用这些配置更改：</p>
<div class="olist loweralpha">
<ol class="loweralpha" type="a">
<li>
<p>添加指向您的指针<code>HADOOP_CONF_DIR</code>到<code>HBASE_CLASSPATH</code> <em>hbase-env.sh中的</em>环境变量。</p>
</li>
<li>
<p>在<em>$ {HBASE_HOME} / conf</em>下添加<em>hdfs-site.xml</em> （或<em>hadoop-site.xml</em> ）或更佳的符号链接的<em>副本</em> ，或</p>
</li>
<li>
<p>如果只有一小部分HDFS客户端配置，请将其添加到<em>hbase-site.xml</em> 。</p>
</li>
</ol>
</div>
</li>
</ol>
</div>
<div class="paragraph">
<p>这种HDFS客户端配置的示例是<code>dfs.replication</code> 。例如，如果要以5的复制因子运行，除非您执行上述操作以使配置可用于HBase，否则HBase将创建默认值为3的文件。</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="confirm"><a class="anchor" href="#confirm"></a> 6。运行并确认安装</h2>
<div class="sectionbody">
<div class="paragraph">
<p>确保首先运行HDFS。通过在目录中运行<em>bin / start-hdfs.sh</em>来启动和停止Hadoop HDFS守护程序。 <code>HADOOP_HOME</code>目录。您可以通过测试<code>put</code>和<code>get</code>文件放入Hadoop文件系统。HBase通常不使用MapReduce或YARN守护程序。这些不需要启动。</p>
</div>
<div class="paragraph">
<p><em>如果</em>您正在管理自己的ZooKeeper，请启动它并确认其正在运行，否则HBase将在启动过程中为您启动ZooKeeper。</p>
</div>
<div class="paragraph">
<p>使用以下命令启动HBase：</p>
</div>
<div class="listingblock">
<div class="content">
<pre>bin/start-hbase.sh</pre>
</div>
</div>
<div class="paragraph">
<p>从上面运行<code>HBASE_HOME</code>目录。</p>
</div>
<div class="paragraph">
<p>现在，您应该有一个正在运行的HBase实例。HBase日志可在<em>logs</em>子目录中找到。检查它们，特别是如果HBase无法启动。</p>
</div>
<div class="paragraph">
<p>HBase还建立了一个列出重要属性的UI。默认情况下，它部署在主主机上的端口16010上（HBase RegionServers默认在端口16020上侦听，并在端口16030上建立一个信息性HTTP服务器）。如果主服务器在名为的主机上运行<code>master.example.org</code>在默认端口上，将浏览器指向<em><a href="http://master.example.org:16010" class="bare">http://master.example.org:16010</a></em>以查看Web界面。</p>
</div>
<div class="paragraph">
<p>HBase启动后，请参阅<a href="#shell_exercises">外壳练习</a>部分，以了解如何创建表，添加数据，扫描插入以及最后禁用和删除表。</p>
</div>
<div class="paragraph">
<p>要在退出HBase Shell之后停止HBase，请输入</p>
</div>
<div class="listingblock">
<div class="content">
<pre>$ ./bin/stop-hbase.sh
stopping hbase...............</pre>
</div>
</div>
<div class="paragraph">
<p>关机可能需要一些时间才能完成。如果群集由许多计算机组成，则可能需要更长的时间。如果您正在运行分布式操作，请确保等到HBase完全关闭后再停止Hadoop守护程序。</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="config.files"><a class="anchor" href="#config.files"></a> 7。默认配置</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="hbase.site"><a class="anchor" href="#hbase.site"></a> 7.1。 <em>hbase-site.xml</em>和<em>hbase-default.xml</em></h3>
<div class="paragraph">
<p>就像在Hadoop中将特定于站点的HDFS配置添加到<em>hdfs-site.xml</em>文件中一样，针对HBase，特定于站点的自定义项也放入<em>conf / hbase-site.xml</em>文件中。有关可配置属性的列表，请参见下面的<a href="#hbase_default_configurations">hbase默认配置</a> ，或在<em>src / main / resources</em>的HBase源代码中查看原始的<em>hbase-default.xml</em>源文件。</p>
</div>
<div class="paragraph">
<p>并非所有配置选项都将其显示在<em>hbase-default.xml中</em> 。人们认为很少有人会改变的配置只能存在于代码中。出现这种配置的唯一方法是通过阅读源代码本身。</p>
</div>
<div class="paragraph">
<p>当前，此处的更改将要求HBase重新启动群集以注意到更改。</p>
</div>
</div>
<div class="sect2">
<h3 id="hbase_default_configurations"><a class="anchor" href="#hbase_default_configurations"></a> 7.2。HBase默认配置</h3>
<div class="paragraph">
<p>以下文档是使用默认的hbase配置文件<em>hbase-default.xml</em>作为源生成的。</p>
</div>
<div id="hbase.tmp.dir" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.tmp.dir</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>本地文件系统上的临时目录。更改此设置以指向比“ / tmp”更永久的位置（java.io.tmpdir的通常解析方法），因为在重新启动计算机时会清除“ / tmp”目录。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>${java.io.tmpdir}/hbase-${user.name}</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.rootdir" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.rootdir</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>区域服务器共享的目录，HBase保留在该目录中。URL应该是“完全限定”的，以包括文件系统方案。例如，要指定HDFS目录“ / hbase”，其中HDFS实例的namenode在端口9000上的namenode.example.org上运行，请将此值设置为：hdfs：//namenode.example.org：9000 / hbase。默认情况下，我们也会写入设置为$ {hbase.tmp.dir}的任何内容（通常是/ tmp），因此请更改此配置，否则所有数据都会在计算机重新启动时丢失。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>${hbase.tmp.dir}/hbase</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.fs.tmp.dir" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.fs.tmp.dir</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>默认文件系统（HDFS）中的暂存目录，用于保留临时数据。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>/user/${user.name}/hbase-staging</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.bulkload.staging.dir" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.bulkload.staging.dir</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>默认文件系统（HDFS）中的暂存目录，用于批量加载。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>${hbase.fs.tmp.dir}</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.cluster.distributed" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.cluster.distributed</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>群集将处于的模式。对于独立模式，可能的值为false；对于分布式模式，可能的值为true。如果为false，则启动将在一个JVM中同时运行所有HBase和ZooKeeper守护程序。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>false</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.zookeeper.quorum" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.zookeeper.quorum</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>ZooKeeper集合中服务器的逗号分隔列表（此配置应已命名为hbase.zookeeper.ensemble）。例如，“ host1.mydomain.com，host2.mydomain.com，host3.mydomain.com”。默认情况下，对于本地和伪分布式操作模式，此选项设置为localhost。对于完全分布式的设置，应将其设置为ZooKeeper集成服务器的完整列表。如果在hbase-env.sh中设置了HBASE_MANAGES_ZK，则这是hbase在群集启动/停止过程中将启动/停止ZooKeeper的服务器列表。在客户端，我们将使用此集合成员列表，并将其与hbase.zookeeper.clientPort配置放在一起。并将其作为connectString参数传递到zookeeper构造函数中。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>localhost</code></p>
</div>
</dd>
</dl>
</div>
<div id="zookeeper.recovery.retry.maxsleeptime" class="dlist">
<dl>
<dt class="hdlist1"><code>zookeeper.recovery.retry.maxsleeptime</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>重试动物园管理员操作之前的最大睡眠时间（以毫秒为单位），此处需要一个最大时间，以使睡眠时间不会无限制地增长</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>60000</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.local.dir" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.local.dir</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>本地文件系统上用作本地存储的目录。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>${hbase.tmp.dir}/local/</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.master.port" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.master.port</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>HBase主站应绑定的端口。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>16000</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.master.info.port" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.master.info.port</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>HBase Master Web UI的端口。如果不希望运行UI实例，则设置为-1。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>16010</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.master.info.bindAddress" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.master.info.bindAddress</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>HBase Master Web UI的绑定地址</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>0.0.0.0</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.master.logcleaner.plugins" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.master.logcleaner.plugins</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>LogsCleaner服务调用的以逗号分隔的BaseLogCleanerDelegate列表。这些WAL清理程序是按顺序调用的，因此将修剪最多文件的清理程序放在前面。要实现自己的BaseLogCleanerDelegate，只需将其放在HBase的类路径中，然后在此处添加完全限定的类名。始终在列表中添加以上默认的日志清除器。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>org.apache.hadoop.hbase.master.cleaner.TimeToLiveLogCleaner</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.master.logcleaner.ttl" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.master.logcleaner.ttl</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>WAL可以保留在.oldlogdir目录中的最长时间，之后它将由主线程清除。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>600000</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.master.hfilecleaner.plugins" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.master.hfilecleaner.plugins</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>由HFileCleaner服务调用的BaseHFileCleanerDelegate的逗号分隔列表。这些HFiles清理程序是按顺序调用的，因此将修剪大多数文件的清理程序放在前面。要实现自己的BaseHFileCleanerDelegate，只需将其放在HBase的类路径中，然后在此处添加完全限定的类名。请始终在列表中添加上述默认日志清除器，因为它们将在hbase-site.xml中被覆盖。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>org.apache.hadoop.hbase.master.cleaner.TimeToLiveHFileCleaner</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.master.infoserver.redirect" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.master.infoserver.redirect</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>Master是否侦听Master Web UI端口（hbase.master.info.port）并将请求重定向到Master和RegionServer共享的Web UI服务器。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>true</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.regionserver.port" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.regionserver.port</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>HBase RegionServer绑定到的端口。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>16020</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.regionserver.info.port" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.regionserver.info.port</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>如果您不希望运行RegionServer UI，请将HBase RegionServer Web UI的端口设置为-1。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>16030</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.regionserver.info.bindAddress" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.regionserver.info.bindAddress</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>HBase RegionServer Web UI的地址</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>0.0.0.0</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.regionserver.info.port.auto" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.regionserver.info.port.auto</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>Master或RegionServer UI是否应搜索要绑定的端口。如果hbase.regionserver.info.port已在使用中，则启用自动端口搜索。对于测试很有用，默认情况下处于关闭状态。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>false</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.regionserver.handler.count" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.regionserver.handler.count</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>在RegionServer上旋转的RPC侦听器实例数。主机将相同的属性用于主机处理程序的计数。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>30</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.ipc.server.callqueue.handler.factor" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.ipc.server.callqueue.handler.factor</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>确定呼叫队列数量的因素。值为0表示在所有处理程序之间共享一个队列。值为1表示每个处理程序都有自己的队列。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>0.1</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.ipc.server.callqueue.read.ratio" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.ipc.server.callqueue.read.ratio</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>将呼叫队列划分为读写队列。指定的间隔（应在0.0到1.0之间）将乘以呼叫队列的数量。值为0表示不拆分呼叫队列，这意味着读取和写入请求都将被推送到同一组队列中。小于0.5的值表示读队列少于写队列。值为0.5表示将有相同数量的读取和写入队列。大于0.5的值表示将有比写队列更多的读队列。值1.0表示除一个队列外的所有队列均用于调度读取请求。示例：给定呼叫队列的总数为10，则read.ratio为0表示：10个队列将包含两个读/写请求。 read.ratio为0.3表示：3个队列仅包含读取请求，而7个队列仅包含写入请求。 read.ratio为0.5表示：5个队列仅包含读取请求，而5个队列仅包含写入请求。 read.ratio为0.8表示：8个队列将仅包含读取请求，而2个队列将仅包含写入请求。 read.ratio为1表示：9个队列将仅包含读取请求，而1个队列将仅包含写入请求。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>0</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.ipc.server.callqueue.scan.ratio" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.ipc.server.callqueue.scan.ratio</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>给定读取呼叫队列的数量（根据呼叫队列总数乘以callqueue.read.ratio计算得出），scan.ratio属性会将读取呼叫队列分为小读取队列和长读取队列。小于0.5的值表示长读队列少于短读队列。值为0.5表示将有相同数量的短读和长读队列。大于0.5的值表示长读取队列比短读取队列多。值为0或1表示使用相同的队列进行获取和扫描。示例：假设读取呼叫队列的总数为8，则scan.ratio为0或1表示：8个队列将同时包含长读取请求和短读取请求。 scan.ratio为0.3表示：2个队列将仅包含长读请求，而6个队列将仅包含短读请求。 scan.ratio为0.5表示：4个队列将仅包含长读请求，而4个队列将仅包含短读请求。 scan.ratio为0.8表示：6个队列将仅包含长读请求，而2个队列将仅包含短读请求。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>0</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.regionserver.msginterval" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.regionserver.msginterval</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>从RegionServer到Master的消息之间的时间间隔（以毫秒为单位）。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>3000</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.regionserver.logroll.period" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.regionserver.logroll.period</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>无论提交多少编辑，我们都将滚动提交日志的时间段。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>3600000</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.regionserver.logroll.errors.tolerated" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.regionserver.logroll.errors.tolerated</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>在触发服务器异常终止之前，我们将允许的连续WAL关闭错误数。如果在日志滚动过程中关闭当前WAL编写器失败，则设置为0将导致区域服务器中止。甚至很小的值（2或3）也将使区域服务器能够克服瞬态HDFS错误。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>2</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.regionserver.hlog.reader.impl" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.regionserver.hlog.reader.impl</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>WAL文件阅读器实现。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>org.apache.hadoop.hbase.regionserver.wal.ProtobufLogReader</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.regionserver.hlog.writer.impl" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.regionserver.hlog.writer.impl</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>WAL文件编写器实现。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>org.apache.hadoop.hbase.regionserver.wal.ProtobufLogWriter</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.regionserver.global.memstore.size" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.regionserver.global.memstore.size</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>在阻止新更新并强制进行刷新之前，区域服务器中所有内存存储区的最大大小。默认为堆的40％（0.4）。阻止更新并强制执行刷新，直到区域服务器中所有内存存储的大小达到hbase.regionserver.global.memstore.size.lower.limit。为了尊重旧的hbase.regionserver.global.memstore.upperLimit属性（如果存在），有意将此配置中的默认值保留为空。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p>没有</p>
</div>
</dd>
</dl>
</div>
<div id="hbase.regionserver.global.memstore.size.lower.limit" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.regionserver.global.memstore.size.lower.limit</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>强制刷新之前，区域服务器中所有内存存储区的最大大小。默认为hbase.regionserver.global.memstore.size（0.95）的95％。如果由于内存存储限制而阻止更新，则此值的100％值将导致最小的刷新发生。此配置中的默认值有意保留为空，以便使用旧的hbase.regionserver.global.memstore.lowerLimit属性（如果存在）。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p>没有</p>
</div>
</dd>
</dl>
</div>
<div id="hbase.regionserver.optionalcacheflushinterval" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.regionserver.optionalcacheflushinterval</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>编辑内容在自动刷新之前在内存中保留的最长时间。默认值1小时。将其设置为0以禁用自动刷新。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>3600000</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.regionserver.dns.interface" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.regionserver.dns.interface</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>区域服务器应从中报告其IP地址的网络接口的名称。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>default</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.regionserver.dns.nameserver" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.regionserver.dns.nameserver</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>区域服务器应使用该名称服务器（DNS）的主机名或IP地址来确定主机用于通信和显示目的的主机名。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>default</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.regionserver.region.split.policy" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.regionserver.region.split.policy</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>拆分策略确定何时应拆分区域。当前可用的其他各种拆分策略为BusyRegionSplitPolicy，ConstantSizeRegionSplitPolicy，DisabledRegionSplitPolicy，DelimitedKeyPrefixRegionSplitPolicy，KeyPrefixRegionSplitPolicy等。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>org.apache.hadoop.hbase.regionserver.IncreasingToUpperBoundRegionSplitPolicy</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.regionserver.regionSplitLimit" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.regionserver.regionSplitLimit</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>区域数量的限制，之后将不再进行区域划分。这不是对区域数量的硬限制，但可作为区域服务器在特定限制后停止拆分的准则。默认设置为1000。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>1000</code></p>
</div>
</dd>
</dl>
</div>
<div id="zookeeper.session.timeout" class="dlist">
<dl>
<dt class="hdlist1"><code>zookeeper.session.timeout</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>ZooKeeper会话超时（以毫秒为单位）。它以两种不同的方式使用。首先，在HBase用于连接到集成体的ZK客户端中使用此值。HBase在启动ZK服务器时也使用它，并将其作为“ maxSessionTimeout”传递。请参阅<a href="http://hadoop.apache.org/zookeeper/docs/current/zookeeperProgrammers.html#ch_zkSessions" class="bare">http://hadoop.apache.org/zookeeper/docs/current/zookeeperProgrammers.html#ch_zkSessions</a> 。例如，如果HBase区域服务器连接到也由HBase管理的ZK集成，则会话超时将是此配置指定的会话超时。但是，连接到使用不同配置管理的集成服务器的区域服务器将受到该集成服务器的maxSessionTimeout的影响。因此，即使HBase可能建议使用90秒，该集合的最大超时值也可以低于此值，并且它将具有优先权。ZK附带的当前默认值为40秒，比HBase的默认值低。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>90000</code></p>
</div>
</dd>
</dl>
</div>
<div id="zookeeper.znode.parent" class="dlist">
<dl>
<dt class="hdlist1"><code>zookeeper.znode.parent</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>ZooKeeper中用于HBase的根ZNode。配置有相对路径的所有HBase的ZooKeeper文件都将位于此节点下。默认情况下，所有HBase的ZooKeeper文件路径都配置有相对路径，因此除非更改，否则它们都将位于此目录下。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>/hbase</code></p>
</div>
</dd>
</dl>
</div>
<div id="zookeeper.znode.acl.parent" class="dlist">
<dl>
<dt class="hdlist1"><code>zookeeper.znode.acl.parent</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>根ZNode用于访问控制列表。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>acl</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.zookeeper.dns.interface" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.zookeeper.dns.interface</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>ZooKeeper服务器应从其报告其IP地址的网络接口的名称。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>default</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.zookeeper.dns.nameserver" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.zookeeper.dns.nameserver</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>ZooKeeper服务器应使用其名称服务器（DNS）的主机名或IP地址来确定主机用于通信和显示目的的主机名。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>default</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.zookeeper.peerport" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.zookeeper.peerport</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>ZooKeeper对等方用来互相通信的端口。有关更多信息，请参见<a href="http://hadoop.apache.org/zookeeper/docs/r3.1.1/zookeeperStarted.html#sc_RunningReplicatedZooKeeper" class="bare">http://hadoop.apache.org/zookeeper/docs/r3.1.1/zookeeperStarted.html#sc_RunningReplicatedZooKeeper</a> 。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>2888</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.zookeeper.leaderport" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.zookeeper.leaderport</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>ZooKeeper用于领导者选举的端口。有关更多信息，请参见<a href="http://hadoop.apache.org/zookeeper/docs/r3.1.1/zookeeperStarted.html#sc_RunningReplicatedZooKeeper" class="bare">http://hadoop.apache.org/zookeeper/docs/r3.1.1/zookeeperStarted.html#sc_RunningReplicatedZooKeeper</a> 。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>3888</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.zookeeper.useMulti" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.zookeeper.useMulti</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>指示HBase使用ZooKeeper的多重更新功能。这样可以使某些ZooKeeper操作更快地完成，并避免出现罕见的复制失败情况下的某些问题（有关示例，请参阅HBASE-2611的发行说明）。重要说明：仅当群集中的所有ZooKeeper服务器都在3.4+版且不会降级时，才将其设置为true。3.4之前的ZooKeeper版本不支持多重更新，并且如果调用多重更新，也不会正常失败（请参阅ZOOKEEPER-1495）。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>true</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.config.read.zookeeper.config" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.config.read.zookeeper.config</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>设置为true允许HBaseConfiguration读取ZooKeeper属性的zoo.cfg文件。不建议将其切换为true，因为不建议使用zoo.cfg文件读取ZK属性的功能。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>false</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.zookeeper.property.initLimit" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.zookeeper.property.initLimit</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>ZooKeeper的配置zoo.cfg中的属性。初始同步阶段可以进行的滴答声数量。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>10</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.zookeeper.property.syncLimit" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.zookeeper.property.syncLimit</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>ZooKeeper的配置zoo.cfg中的属性。发送请求和获得确认之间可以经过的滴答声数量。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>5</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.zookeeper.property.dataDir" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.zookeeper.property.dataDir</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>ZooKeeper的配置zoo.cfg中的属性。快照存储的目录。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>${hbase.tmp.dir}/zookeeper</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.zookeeper.property.clientPort" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.zookeeper.property.clientPort</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>ZooKeeper的配置zoo.cfg中的属性。客户端将连接的端口。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>2181</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.zookeeper.property.maxClientCnxns" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.zookeeper.property.maxClientCnxns</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>ZooKeeper的配置zoo.cfg中的属性。限制单个客户端通过IP地址标识到ZooKeeper集成中的单个成员的并发连接数（在套接字级别）。设置为高值可以避免独立运行和伪分布式运行的zk连接问题。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>300</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.client.write.buffer" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.client.write.buffer</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>HTable客户端写缓冲区的默认大小（以字节为单位）。较大的缓冲区会占用更多内存（在客户端和服务器端都需要，因为服务器会实例化传递的写缓冲区以对其进行处理），但是较大的缓冲区大小会减少制作的RPC的数量。要估计服务器端使用的内存，请评估hbase.client.write.buffer * hbase.regionserver.handler.count</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>2097152</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.client.pause" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.client.pause</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>常规客户端暂停值。在运行重试失败的获取，区域查找等之前，主要用作等待值。请参见hbase.client.retries.number，以获取有关我们如何从此初始暂停量回退以及此暂停如何进行重试的描述。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>100</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.client.pause.cqtbe" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.client.pause.cqtbe</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>是否对CallQueueTooBigException（cqtbe）使用特殊的客户端暂停。如果您观察到来自同一RegionServer的CQTBE频繁并且那里的呼叫队列保持满状态，则将此属性设置为比hbase.client.pause高的值。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p>没有</p>
</div>
</dd>
</dl>
</div>
<div id="hbase.client.retries.number" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.client.retries.number</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>最大重试次数。用作所有可重试操作的最大值，例如获取单元格的值，开始行更新等。重试间隔是基于hbase.client.pause的粗略函数。首先，我们以该时间间隔重试，但随着退避，我们很快就达到了每十秒钟重试一次的目的。有关备份如何增加的信息，请参见HConstants＃RETRY_BACKOFF。更改此设置和hbase.client.pause以适合您的工作量。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>35</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.client.max.total.tasks" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.client.max.total.tasks</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>一个HTable实例将发送到群集的最大并发变异任务数。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>100</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.client.max.perserver.tasks" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.client.max.perserver.tasks</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>单个HTable实例将发送到单个区域服务器的最大并发变异任务数。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>5</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.client.max.perregion.tasks" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.client.max.perregion.tasks</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>客户将维护到一个区域的最大并发突变任务数。也就是说，如果已经对该区域进行了hbase.client.max.perregion.tasks写入，则在完成某些写入之前，不会将新的puts发送到该区域。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>1</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.client.perserver.requests.threshold" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.client.perserver.requests.threshold</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>所有客户端线程（进程级别）中一台服务器的并发暂挂请求的最大数量。超出的请求将立即引发ServerTooBusyException，以防止仅一台慢速区域服务器占用和阻塞用户的线程。如果您使用固定数量的线程以同步方式访问HBase，请将其设置为与线程数量相关的合适值将对您有所帮助。有关详细信息，请参见<a href="https://issues.apache.org/jira/browse/HBASE-16388" class="bare">https://issues.apache.org/jira/browse/HBASE-16388</a> 。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>2147483647</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.client.scanner.caching" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.client.scanner.caching</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>如果未从（本地，客户端）内存提供服务，则在扫描器上调用next时尝试获取的行数。此配置与hbase.client.scanner.max.result.size一起使用，以尝试有效地使用网络。默认值为整数。默认情况下为MAX_VALUE，以便网络将填充hbase.client.scanner.max.result.size定义的块大小，而不是受特定的行数限制，因为行的大小因表而异。如果您提前知道一次扫描不需要多于一定数量的行，则应通过Scan＃setCaching将此配置设置为该行限制。较高的缓存值将启用更快的扫描程序，但会消耗更多的内存，并且当缓存为空时，对next的某些调用可能会花费越来越长的时间。请勿将此值设置为使得两次调用之间的时间大于扫描程序超时；即hbase.client.scanner.timeout.period</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>2147483647</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.client.keyvalue.maxsize" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.client.keyvalue.maxsize</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>指定KeyValue实例的组合最大允许大小。这是为保存在存储文件中的单个条目设置上限。由于无法拆分它们，因此有助于避免由于数据太大而无法进一步拆分区域。将其设置为最大区域大小的一小部分似乎是明智的。将其设置为零或更少将禁用检查。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>10485760</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.server.keyvalue.maxsize" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.server.keyvalue.maxsize</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>单个单元格的最大允许大小，包括值和所有关键组件。小于或等于0的值将禁用该检查。默认值为10MB。这是一项安全设置，可以保护服务器免受OOM情况的影响。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>10485760</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.client.scanner.timeout.period" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.client.scanner.timeout.period</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>客户端扫描程序的租用期限（以毫秒为单位）。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>60000</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.client.localityCheck.threadPoolSize" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.client.localityCheck.threadPoolSize</code></dt>
<dd>
<div class="paragraph">
<div class="title">默认</div>
<p><code>2</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.bulkload.retries.number" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.bulkload.retries.number</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>最大重试次数。这是面对分裂操作时尝试进行的原子批量加载的最大迭代次数0表示永不放弃。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>10</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.master.balancer.maxRitPercent" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.master.balancer.maxRitPercent</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>平衡时过渡区域的最大百分比。默认值为1.0。因此，没有平衡器节流。如果将此配置设置为0.01，则表示平衡时最多有1％的过渡区域。然后，平衡时群集的可用性至少为99％。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>1.0</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.balancer.period" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.balancer.period</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>区域平衡器在主服务器中运行的时间段。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>300000</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.normalizer.period" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.normalizer.period</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>区域规范化器在主服务器中运行的时间段。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>1800000</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.regions.slop" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.regions.slop</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>如果任何区域服务器具有平均+（平均*斜率）区域，则重新平衡。在StochasticLoadBalancer（默认的负载均衡器）中，此参数的默认值为0.001，而在其他负载均衡器（即SimpleLoadBalancer）中，默认值为0.2。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>0.001</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.server.thread.wakefrequency" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.server.thread.wakefrequency</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>两次搜索工作之间的睡眠时间（以毫秒为单位）。由服务线程（例如对数辊）用作睡眠间隔。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>10000</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.server.versionfile.writeattempts" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.server.versionfile.writeattempts</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>在中止之前有多少时间重试尝试写入版本文件。每次尝试都由hbase.server.thread.wakefrequency毫秒分隔。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>3</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.hregion.memstore.flush.size" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.hregion.memstore.flush.size</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>如果内存区的大小超过此字节数，则内存区将刷新到磁盘。值由运行每个hbase.server.thread.wakefrequency的线程检查。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>134217728</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.hregion.percolumnfamilyflush.size.lower.bound" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.hregion.percolumnfamilyflush.size.lower.bound</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>如果使用FlushLargeStoresPolicy，则每当我们达到总内存存储限制时，我们都会找出其内存存储超过此值的所有列族，仅刷新它们，同时保留其他那些低于此限制的存储。如果没有一个家庭的内存大小超过此大小，则将刷新所有内存（就像往常一样）。此值应小于总内存存储阈值（hbase.hregion.memstore.flush.size）的一半。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>16777216</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.hregion.preclose.flush.size" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.hregion.preclose.flush.size</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>如果在关闭时某个区域中的存储器大小等于或大于此大小，则在设置区域已关闭标志并使该区域脱机之前，运行“预冲洗”以清除存储器。关闭时，在关闭标志下运行刷新以清空内存。在这段时间内，该地区处于离线状态，我们没有进行任何写操作。如果内存存储内容很大，则刷新可能需要很长时间才能完成。预刷新的目的是在放置关闭标志并使区域脱机之前清理掉大部分的内存存储，因此在关闭标志下运行的刷新几乎没有作用。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>5242880</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.hregion.memstore.block.multiplier" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.hregion.memstore.block.multiplier</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>如果memstore具有hbase.hregion.memstore.block.multiplier乘以hbase.hregion.memstore.flush.size字节，则阻止更新。防止更新流量激增期间失控的存储器。如果没有上限，则内存存储将进行填充，以便在刷新结果刷新文件时需要花费很长时间来压缩或拆分，或更糟糕的是，我们OOME。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>4</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.hregion.memstore.mslab.enabled" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.hregion.memstore.mslab.enabled</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>启用MemStore-Local Allocation Buffer，该功能可防止在重写入负载下发生堆碎片。这可以减少大堆上停止世界GC暂停的频率。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>true</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.hregion.max.filesize" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.hregion.max.filesize</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>HStoreFile的最大大小。如果列族的HStoreFiles中的任何一个增长到超过该值，则托管HRegion都会分为两部分。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>10737418240</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.hregion.majorcompaction" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.hregion.majorcompaction</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>区域中所有HStoreFile的“主要”压缩之间的时间（以毫秒为单位）。默认值：设置为7天。大型压缩往往恰好在您最不需要它们时发生，因此请启用它们，使其在非高峰期运行以进行部署；或者，因为此设置的周期不太可能与您的负载相匹配，所以可以通过cron作业或其他类似方式通过外部调用来运行压缩。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>604800000</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.hregion.majorcompaction.jitter" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.hregion.majorcompaction.jitter</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>抖动外边界，用于大型压实。在每个区域服务器上，我们将hbase.region.majorcompaction间隔乘以该最大值范围内的某个随机分数。然后，当下一次主要压缩运行时，我们将此+或-产品添加到。这个想法是，在每个区域服务器上确实会同时进行大型压缩。该数字越小，压实作用越紧密。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>0.50</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.hstore.compactionThreshold" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.hstore.compactionThreshold</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>如果任何一个HStore中的HStoreFiles数量超过此数目（每次刷新memstore写入一个HStoreFile），则运行压缩以将所有HStoreFiles文件重写为一个。较大的数字会推迟压缩，但是当压缩运行时，需要更长的时间才能完成。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>3</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.regionserver.compaction.enabled" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.regionserver.compaction.enabled</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>通过设置true / false启用/禁用压缩。我们可以使用compaction_switch shell命令进一步动态地切换压缩。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>true</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.hstore.flusher.count" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.hstore.flusher.count</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>刷新线程数。如果线程较少，则将对存储区刷新进行排队。如果线程更多，则刷新将并行执行，从而增加了hdfs负载。这也可能导致更多的压缩。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>2</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.hstore.blockingStoreFiles" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.hstore.blockingStoreFiles</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>如果任何一个存储中的存储文件数量都超过此数目（每次刷新MemStore写入一个StoreFile），则此HRegion的更新将被阻止，直到压缩完成或超过hbase.hstore.blockingWaitTime。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>10</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.hstore.blockingWaitTime" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.hstore.blockingWaitTime</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>HRegion达到hbase.hstore.blockingStoreFiles定义的StoreFile限制后将阻止更新的时间。经过这段时间后，即使压缩尚未完成，HRegion也会停止阻止更新。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>90000</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.hstore.compaction.max" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.hstore.compaction.max</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>每“次要”压缩要压缩的HStoreFiles的最大数目。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>10</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.hstore.compaction.kv.max" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.hstore.compaction.kv.max</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>刷新或压缩时，批量读取和写入多少个KeyValue。如果有较大的KeyValues和OOME问题，请减少处理。如果行宽较小，则执行更多操作。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>10</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.hstore.time.to.purge.deletes" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.hstore.time.to.purge.deletes</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>延迟清除带有未来时间戳记的删除标记的时间。如果未设置或设置为0，则所有删除标记（包括带有未来时间戳记的标记）将在下一次主要压缩期间清除。否则，将保留删除标记，直到在标记的时间戳加上此设置的值之后发生的主要压缩为止（以毫秒为单位）。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>0</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.regionserver.majorcompaction.pagecache.drop" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.regionserver.majorcompaction.pagecache.drop</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>指定是否通过主要压缩将读取/写入的页面丢弃到系统页面缓存中。将其设置为true有助于防止大型压缩污染页面缓存，这几乎总是需要的，尤其是对于内存/存储比率低/中等的群集。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>true</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.regionserver.minorcompaction.pagecache.drop" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.regionserver.minorcompaction.pagecache.drop</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>指定是否通过较小的压缩将读取/写入的页面丢弃到系统页面缓存中。将其设置为true有助于防止较小的压缩污染页面缓存，这在内存与存储比率低或写入量很大的群集中最有用。当大量读取都在最近写入的数据上时，您可能希望在中等到低的写入工作量下将其设置为false。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>true</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.storescanner.parallel.seek.enable" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.storescanner.parallel.seek.enable</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>在StoreScanner中启用StoreFileScanner并行搜索功能，该功能可以减少特殊情况下的响应延迟。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>false</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.storescanner.parallel.seek.threads" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.storescanner.parallel.seek.threads</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>如果启用了并行查找功能，则为默认线程池大小。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>10</code></p>
</div>
</dd>
</dl>
</div>
<div id="hfile.block.cache.size" class="dlist">
<dl>
<dt class="hdlist1"><code>hfile.block.cache.size</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>分配给HFile / StoreFile使用的块缓存的最大堆的百分比（-Xmx设置）。默认值为0.4表示分配40％。设置为0以禁用，但不建议使用；您至少需要足够的缓存来保存存储文件索引。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>0.4</code></p>
</div>
</dd>
</dl>
</div>
<div id="hfile.block.index.cacheonwrite" class="dlist">
<dl>
<dt class="hdlist1"><code>hfile.block.index.cacheonwrite</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>这允许在写入索引时将非根多级索引块放入块高速缓存中。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>false</code></p>
</div>
</dd>
</dl>
</div>
<div id="hfile.index.block.max.size" class="dlist">
<dl>
<dt class="hdlist1"><code>hfile.index.block.max.size</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>当多级块索引中的叶级，中间级或根级索引块的大小增长到该大小时，将写出该块并开始一个新块。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>131072</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.bucketcache.ioengine" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.bucketcache.ioengine</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>存储桶式缓存内容的位置。其中之一：堆，堆或文件。如果是文件，请将其设置为file：PATH_TO_FILE。有关更多信息，请参见<a href="http://hbase.apache.org/book.html#offheap.blockcache" class="bare">http://hbase.apache.org/book.html#offheap.blockcache</a> 。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p>没有</p>
</div>
</dd>
</dl>
</div>
<div id="hbase.hstore.compaction.throughput.lower.bound" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.hstore.compaction.throughput.lower.bound</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>聚合压缩吞吐量的目标下限，以字节/秒为单位。当PressureAwareCompactionThroughputController吞吐量控制器处于活动状态时，允许您调整最小可用压实吞吐量。（默认情况下处于活动状态。）</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>52428800</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.hstore.compaction.throughput.higher.bound" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.hstore.compaction.throughput.higher.bound</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>聚合压缩吞吐量的目标上限，以字节/秒为单位。当PressureAwareCompactionThroughputController吞吐量控制器处于活动状态时，允许您控制总压实吞吐量需求。（默认情况下处于活动状态。）当压实压力在[0.0，1.0]范围内时，最大产量将在上下限之间调整。如果压实压力为1.0或更高，则上限将被忽略，直到压力返回正常范围。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>104857600</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.bucketcache.combinedcache.enabled" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.bucketcache.combinedcache.enabled</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>桶式缓存是否与LRU堆式块缓存一起使用。在这种模式下，索引和bloom保留在LRU块缓存中，数据块保留在存储桶中。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>true</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.bucketcache.size" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.bucketcache.size</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>EITHER表示要提供给缓存的总堆内存大小的百分比的浮点数（如果<1.0），或者，它是BucketCache的总容量（以兆字节为单位）。默认值：0.0</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p>没有</p>
</div>
</dd>
</dl>
</div>
<div id="hbase.bucketcache.bucket.sizes" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.bucketcache.bucket.sizes</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>以逗号分隔的存储区存储区大小列表。可以是多种尺寸。按从小到大的顺序列出块大小。您使用的大小将取决于您的数据访问模式。必须是256的倍数，否则您将遇到'java.io。IOException：当您从缓存中读取时，无效的HFile块魔术。如果在此处未指定任何值，则将选择代码中设置的默认存储桶大小（请参见BucketAllocator＃DEFAULT_BUCKET_SIZES）。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p>没有</p>
</div>
</dd>
</dl>
</div>
<div id="hfile.format.version" class="dlist">
<dl>
<dt class="hdlist1"><code>hfile.format.version</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>用于新文件的HFile格式版本。第3版增加了对hfiles中标签的支持（请参阅<a href="http://hbase.apache.org/book.html#hbase.tags" class="bare">http://hbase.apache.org/book.html#hbase.tags</a> ）。分布式日志重播要求启用标签。另请参阅配置“ hbase.replication.rpc.codec”。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>3</code></p>
</div>
</dd>
</dl>
</div>
<div id="hfile.block.bloom.cacheonwrite" class="dlist">
<dl>
<dt class="hdlist1"><code>hfile.block.bloom.cacheonwrite</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>为复合Bloom过滤器的内联块启用写时缓存。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>false</code></p>
</div>
</dd>
</dl>
</div>
<div id="io.storefile.bloom.block.size" class="dlist">
<dl>
<dt class="hdlist1"><code>io.storefile.bloom.block.size</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>复合Bloom过滤器的单个块（“块”）的大小（以字节为单位）。此大小是近似值，因为Bloom块只能插入数据块的边界，并且每个数据块的键数有所不同。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>131072</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.rs.cacheblocksonwrite" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.rs.cacheblocksonwrite</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>块完成后是否应将HFile块添加到块缓存中。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>false</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.rpc.timeout" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.rpc.timeout</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>这是为RPC层定义的，HBase客户端应用程序需要花费多长时间（毫秒）来进行远程调用以使超时。它使用ping来检查连接，但最终将抛出TimeoutException。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>60000</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.client.operation.timeout" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.client.operation.timeout</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>操作超时是一个顶级限制（毫秒），可确保Table中的阻止操作不会超过此限制。在每个操作中，如果rpc请求由于超时或其他原因而失败，它将重试直到成功或抛出RetriesExhaustedException。但是，如果阻塞的总时间在重试用尽之前达到了操作超时，它将提前中断并抛出SocketTimeoutException。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>1200000</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.cells.scanned.per.heartbeat.check" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.cells.scanned.per.heartbeat.check</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>在两次心跳检查之间扫描的细胞数。心跳检查在扫描处理期间进行，以确定服务器是否应停止扫描以便将心跳消息发送回客户端。心跳消息用于在长时间运行的扫描期间保持客户端-服务器连接保持活动状态。较小的值表示心跳检查将更频繁地发生，因此将对扫描的执行时间提供更严格的限制。较大的值表示心跳检查发生的频率较低</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>10000</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.rpc.shortoperation.timeout" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.rpc.shortoperation.timeout</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>这是“ hbase.rpc.timeout”的另一个版本。对于集群内的那些RPC操作，我们依靠此配置为短操作设置短超时限制。例如，区域服务器尝试向活动主服务器报告的较短rpc超时可以使主服务器故障转移过程更快。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>10000</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.ipc.client.tcpnodelay" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.ipc.client.tcpnodelay</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>设置rpc套接字连接没有延迟。参见<a href="http://docs.oracle.com/javase/1.5.0/docs/api/java/net/Socket.html#getTcpNoDelay(" class="bare">http://docs.oracle.com/javase/1.5.0/docs/api/java/net/Socket.html#getTcpNoDelay（</a> ）</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>true</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.regionserver.hostname" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.regionserver.hostname</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>此配置适用于专家：除非您真的知道自己在做什么，否则请勿设置其值。设置为非空值时，它表示基础服务器的（外部）主机名。有关详细信息，请参见<a href="https://issues.apache.org/jira/browse/HBASE-12954" class="bare">https://issues.apache.org/jira/browse/HBASE-12954</a> 。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p>没有</p>
</div>
</dd>
</dl>
</div>
<div id="hbase.regionserver.hostname.disable.master.reversedns" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.regionserver.hostname.disable.master.reversedns</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>此配置适用于专家：除非您真的知道自己在做什么，否则请勿设置其值。设置为true时，regionserver将使用当前节点的主机名作为服务器名，而HMaster将跳过反向DNS查找，而是使用regionserver发送的主机名。请注意，此配置和hbase.regionserver.hostname是互斥的。有关更多详细信息，请参见<a href="https://issues.apache.org/jira/browse/HBASE-18226" class="bare">https://issues.apache.org/jira/browse/HBASE-18226</a> 。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>false</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.master.keytab.file" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.master.keytab.file</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>kerberos keytab文件的完整路径，用于登录已配置的HMaster服务器主体。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p>没有</p>
</div>
</dd>
</dl>
</div>
<div id="hbase.master.kerberos.principal" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.master.kerberos.principal</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>例如“ hbase/_HOST@EXAMPLE.COM”。用来运行HMaster进程的Kerberos主体名称。主体名称应采用以下格式：user / hostname @ DOMAIN。如果将“ _HOST”用作主机名部分，它将被正在运行的实例的实际主机名替换。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p>没有</p>
</div>
</dd>
</dl>
</div>
<div id="hbase.regionserver.keytab.file" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.regionserver.keytab.file</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>kerberos keytab文件的完整路径，用于登录已配置的HRegionServer服务器主体。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p>没有</p>
</div>
</dd>
</dl>
</div>
<div id="hbase.regionserver.kerberos.principal" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.regionserver.kerberos.principal</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>例如“ hbase/_HOST@EXAMPLE.COM”。用来运行HRegionServer进程的kerberos主体名称。主体名称应采用以下格式：user / hostname @ DOMAIN。如果将“ _HOST”用作主机名部分，它将被正在运行的实例的实际主机名替换。该主体的条目必须存在于hbase.regionserver.keytab.file中指定的文件中</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p>没有</p>
</div>
</dd>
</dl>
</div>
<div id="hadoop.policy.file" class="dlist">
<dl>
<dt class="hdlist1"><code>hadoop.policy.file</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>RPC服务器用于对客户端请求做出授权决策的策略配置文件。仅在启用HBase安全性时使用。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>hbase-policy.xml</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.superuser" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.superuser</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>在整个集群中，无论存储的是什么ACL，都被授予完全特权的用户或组（逗号分隔）的列表。仅在启用HBase安全性时使用。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p>没有</p>
</div>
</dd>
</dl>
</div>
<div id="hbase.auth.key.update.interval" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.auth.key.update.interval</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>服务器中认证令牌的主密钥的更新间隔（以毫秒为单位）。仅在启用HBase安全性时使用。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>86400000</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.auth.token.max.lifetime" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.auth.token.max.lifetime</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>认证令牌过期的最大生存时间（以毫秒为单位）。仅在启用HBase安全性时使用。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>604800000</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.ipc.client.fallback-to-simple-auth-allowed" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.ipc.client.fallback-to-simple-auth-allowed</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>当客户端配置为尝试安全连接，但尝试连接到不安全的服务器时，该服务器可能会指示客户端切换到SASL SIMPLE（不安全）身份验证。此设置控制客户端是否将接受来自服务器的此指令。如果为false（默认值），则客户端将不允许回退到SIMPLE身份验证，并将中止连接。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>false</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.ipc.server.fallback-to-simple-auth-allowed" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.ipc.server.fallback-to-simple-auth-allowed</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>当服务器配置为需要安全连接时，它将使用SASL SIMPLE（不安全）身份验证拒绝来自客户端的连接尝试。此设置允许安全服务器在客户端请求时接受来自客户端的SASL SIMPLE连接。如果为false（默认值），则服务器将不允许回退到SIMPLE身份验证，并且将拒绝连接。警告：在将客户端转换为安全身份验证时，仅应将此设置用作临时措施。为了安全操作，必须禁用它。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>false</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.coprocessor.enabled" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.coprocessor.enabled</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>启用或禁用协处理器加载。如果为“ false”（禁用），则将忽略任何其他与协处理器相关的配置。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>true</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.coprocessor.user.enabled" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.coprocessor.user.enabled</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>启用或禁用用户（aka表）协处理器加载。如果为“ false”（禁用），则将忽略表描述符中的任何表协处理器属性。如果“ hbase.coprocessor.enabled”为“ false”，则此设置无效。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>true</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.coprocessor.region.classes" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.coprocessor.region.classes</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>默认情况下，在所有表上加载的逗号分隔的协处理器列表。对于任何覆盖协处理器方法，将按顺序调用这些类。在实现自己的协处理器之后，只需将其放在HBase的类路径中，然后在此处添加完全限定的类名即可。也可以通过设置HTableDescriptor来按需加载协处理器。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p>没有</p>
</div>
</dd>
</dl>
</div>
<div id="hbase.rest.port" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.rest.port</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>HBase REST服务器的端口。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>8080</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.rest.readonly" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.rest.readonly</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>定义启动REST服务器的模式。可能的值为：false：允许所有HTTP方法-GET / PUT / POST / DELETE。 true：仅允许GET方法。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>false</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.rest.threads.max" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.rest.threads.max</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>REST服务器线程池的最大线程数。池中的线程被重用以处理REST请求。这控制了并发处理的最大请求数。这可能有助于控制REST服务器使用的内存，以避免OOM问题。如果线程池已满，则传入的请求将排队，并等待一些空闲线程。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>100</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.rest.threads.min" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.rest.threads.min</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>REST服务器线程池的最小线程数。线程池始终至少具有这些线程数，因此REST服务器已准备就绪，可以处理传入的请求。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>2</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.rest.support.proxyuser" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.rest.support.proxyuser</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>允许运行REST服务器以支持代理用户模式。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>false</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.defaults.for.version.skip" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.defaults.for.version.skip</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>设置为true以跳过“ hbase.defaults.for.version”检查。将其设置为true可能在Maven生成的另一端以外的环境中有用。即在思想上运行。您需要将此布尔值设置为true以避免看到RuntimException投诉：“ hbase-default.xml文件似乎适用于旧版本的HBase（\ $ {hbase.version}），此版本为XXX-SNAPSHOT”</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>false</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.coprocessor.master.classes" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.coprocessor.master.classes</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>以逗号分隔的org.apache.hadoop.hbase.coprocessor列表。在活动HMaster进程上默认加载的MasterObserver协处理器。对于任何已实现的协处理器方法，将按顺序调用列出的类。在实现自己的MasterObserver之后，只需将其放入HBase的类路径中，并在此处添加完全限定的类名。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p>没有</p>
</div>
</dd>
</dl>
</div>
<div id="hbase.coprocessor.abortonerror" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.coprocessor.abortonerror</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>设置为true会导致如果协处理器无法加载，初始化失败或引发意外的Throwable对象，则导致托管服务器（主服务器或区域服务器）中止。将其设置为false将允许服务器继续执行，但是相关协处理器的系统范围状态将变得不一致，因为它将仅在一部分服务器中正确执行，因此这仅对调试最有用。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>true</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.online.schema.update.enable" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.online.schema.update.enable</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>设置为true启用联机模式更改。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>true</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.table.lock.enable" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.table.lock.enable</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>设置为true以启用将锁锁定在zookeeper中以进行模式更改操作。来自主服务器的表锁定可防止将并行模式修改为损坏的表状态。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>true</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.table.max.rowsize" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.table.max.rowsize</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>没有设置行内扫描标志的“获取”或“扫描”单行的最大大小（以字节为单位）（默认为1 Gb）。如果行大小超过此限制，则将RowTooBigException抛出给客户端。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>1073741824</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.thrift.minWorkerThreads" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.thrift.minWorkerThreads</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>线程池的“核心大小”。在每个连接上都会创建新线程，直到创建了这么多线程。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>16</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.thrift.maxWorkerThreads" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.thrift.maxWorkerThreads</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>线程池的最大大小。当挂起的请求队列溢出时，将创建新线程，直到它们的数量达到该数量为止。此后，服务器开始断开连接。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>1000</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.thrift.maxQueuedRequests" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.thrift.maxQueuedRequests</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>在队列中等待的未决Thrift连接的最大数量。如果池中没有空闲线程，则服务器会将请求排队。仅当队列溢出时，才添加新线程，直到hbase.thrift.maxQueuedRequests线程。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>1000</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.regionserver.thrift.framed" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.regionserver.thrift.framed</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>在服务器端使用Thrift TFramedTransport。对于节俭服务器，这是建议的传输方式，并且在客户端需要类似的设置。将其更改为false将选择默认传输方式，当由于THRIFT-601发出格式错误的请求时，该传输方式容易受到DoS攻击。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>false</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.regionserver.thrift.framed.max_frame_size_in_mb" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.regionserver.thrift.framed.max_frame_size_in_mb</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>使用成帧传输时的默认帧大小</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>2</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.regionserver.thrift.compact" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.regionserver.thrift.compact</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>使用Thrift TCompactProtocol二进制序列化协议。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>false</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.rootdir.perms" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.rootdir.perms</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>安全（kerberos）设置中根目录的FS权限。当master启动时，它将创建具有此权限的rootdir或设置不匹配的权限。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>700</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.wal.dir.perms" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.wal.dir.perms</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>安全（kerberos）设置中的根WAL目录的FS权限。当master启动时，它将使用此权限创建WAL目录，或者在不匹配时设置权限。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>700</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.data.umask.enable" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.data.umask.enable</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>启用（如果为true），应将文件权限分配给由regionserver写入的文件</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>false</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.data.umask" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.data.umask</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>hbase.data.umask.enable为true时应用于写入数据文件的文件权限</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>000</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.snapshot.enabled" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.snapshot.enabled</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>设置为true以允许拍摄/还原/克隆快照。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>true</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.snapshot.restore.take.failsafe.snapshot" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.snapshot.restore.take.failsafe.snapshot</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>设置为true以在还原操作之前进行快照。发生故障时将使用拍摄的快照来还原以前的状态。在还原操作结束时，此快照将被删除</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>true</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.snapshot.restore.failsafe.name" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.snapshot.restore.failsafe.name</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>还原操作获取的故障安全快照的名称。您可以使用{snapshot.name}，{table.name}和{restore.timestamp}变量根据要还原的内容创建名称。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>hbase-failsafe-{snapshot.name}-{restore.timestamp}</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.snapshot.working.dir" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.snapshot.working.dir</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>快照过程将发生的位置。完成的快照的位置不会更改，但是快照过程发生的临时目录将设置为此位置。为了提高性能，这可以是与根目录不同的文件系统。有关更多信息，请参见HBASE-21098</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p>没有</p>
</div>
</dd>
</dl>
</div>
<div id="hbase.server.compactchecker.interval.multiplier" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.server.compactchecker.interval.multiplier</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>该数字确定我们进行扫描以查看是否有必要进行压缩的频率。通常，压缩是在某些事件（例如memstore刷新）之后完成的，但是，如果区域在一段时间内未收到大量写入，或者由于不同的压缩策略，则可能有必要定期对其进行检查。检查之间的间隔是hbase.server.compactchecker.interval.multiplier乘以hbase.server.thread.wakefrequency。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>1000</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.lease.recovery.timeout" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.lease.recovery.timeout</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>在放弃之前，我们等待dfs租赁恢复的总时间为多长时间。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>900000</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.lease.recovery.dfs.timeout" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.lease.recovery.dfs.timeout</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>dfs之间恢复租约调用的时间。应该大于名称节点作为数据节点的一部分发出块恢复命令所花费的时间总和； dfs.heartbeat.interval以及主数据节点所花费的时间，在死数据节点上执行块恢复到超时；通常是dfs.client.socket-timeout。有关更多信息，请参见HBASE-8389的末尾。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>64000</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.column.max.version" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.column.max.version</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>新的列族描述符将使用此值作为要保留的默认版本数。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>1</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.dfs.client.read.shortcircuit.buffer.size" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.dfs.client.read.shortcircuit.buffer.size</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>如果未设置DFSClient配置dfs.client.read.shortcircuit.buffer.size，我们将使用此处配置的短路读取默认直接字节缓冲区大小。DFSClient本机默认值为1MB； HBase保持其HDFS文件处于打开状态，因此文件块数* 1MB很快就开始增加，并由于直接内存不足而威胁了OOME。因此，我们将其设置为默认值。使其>在HColumnDescriptor中设置的默认hbase块大小，通常为64k。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>131072</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.regionserver.checksum.verify" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.regionserver.checksum.verify</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>如果设置为true（默认值），则HBase会验证hfile块的校验和。HBase在写出hfile时，将校验和与数据内联。HDFS（在撰写本文时）将校验和写入数据文件之外的单独文件，这需要额外的查找。设置该标志可节省一些I / O。设置此标志时，将在hfile流上内部禁用HDFS的校验和验证。如果hbase-checksum验证失败，我们将切换回使用HDFS校验和（因此请不要禁用HDFS校验和！此外，此功能仅适用于hfile，不适用于WAL。如果将此参数设置为false，则hbase将不会验证任何校验和，而是取决于HDFS客户端中进行的校验和验证。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>true</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.hstore.bytes.per.checksum" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.hstore.bytes.per.checksum</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>hfile块中HBase级别校验和的新创建校验和块中的字节数。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>16384</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.hstore.checksum.algorithm" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.hstore.checksum.algorithm</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>用于计算校验和的算法的名称。可能的值为NULL，CRC32，CRC32C。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>CRC32C</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.client.scanner.max.result.size" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.client.scanner.max.result.size</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>调用扫描仪的下一个方法时返回的最大字节数。请注意，当单行大于此限制时，该行仍将完全返回。默认值为2MB，适用于1ge网络。对于更快和/或更高延迟的网络，此值应增加。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>2097152</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.server.scanner.max.result.size" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.server.scanner.max.result.size</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>调用扫描仪的下一个方法时返回的最大字节数。请注意，当单行大于此限制时，该行仍将完全返回。默认值为100MB。这是一项安全设置，可以保护服务器免受OOM情况的影响。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>104857600</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.status.published" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.status.published</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>此设置激活主服务器发布区域服务器状态。当区域服务器停止运行并开始恢复时，主服务器会将此信息推送到客户端应用程序，以使它们立即断开连接，而不必等待超时。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>false</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.status.publisher.class" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.status.publisher.class</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>使用多播消息实现状态发布。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>org.apache.hadoop.hbase.master.ClusterStatusPublisher$MulticastPublisher</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.status.listener.class" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.status.listener.class</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>使用多播消息实现状态侦听器。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>org.apache.hadoop.hbase.client.ClusterStatusListener$MulticastListener</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.status.multicast.address.ip" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.status.multicast.address.ip</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>用于通过多播发布状态的多播地址。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>226.1.1.3</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.status.multicast.address.port" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.status.multicast.address.port</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>组播端口，用于通过组播发布状态。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>16100</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.dynamic.jars.dir" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.dynamic.jars.dir</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>区域服务器无需重新启动即可从中动态加载定制过滤器/协处理器jar的目录。但是，已经加载的过滤器/协处理器类不会被卸载。有关更多详细信息，请参见HBASE-1936。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>${hbase.rootdir}/lib</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.security.authentication" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.security.authentication</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>控制是否为HBase启用安全身份验证。可能的值为“简单”（不进行身份验证）和“ kerberos”。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>simple</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.rest.filter.classes" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.rest.filter.classes</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>REST服务的Servlet过滤器。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>org.apache.hadoop.hbase.rest.filter.GzipFilter</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.master.loadbalancer.class" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.master.loadbalancer.class</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>在周期发生时用于执行区域平衡的类。有关其工作原理的更多信息，请参见类注释<a href="http://hbase.apache.org/devapidocs/org/apache/hadoop/hbase/master/balancer/StochasticLoadBalancer.html" class="bare">。http://hbase.apache.org/devapidocs/org/apache/hadoop/hbase/master/balancer/StochasticLoadBalancer.html</a>它将DefaultLoadBalancer替换为默认值（因为重命名为SimpleLoadBalancer ）。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>org.apache.hadoop.hbase.master.balancer.StochasticLoadBalancer</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.rest.csrf.enabled" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.rest.csrf.enabled</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>设置为true以启用针对跨站点请求伪造（CSRF）的保护</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>false</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.rest-csrf.browser-useragents-regex" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.rest-csrf.browser-useragents-regex</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>通过将hbase.rest.csrf.enabled设置为true来为REST服务器启用跨站点请求伪造（CSRF）保护时，用逗号分隔的正则表达式列表，用于与HTTP请求的User-Agent标头匹配。如果传入的User-Agent与这些正则表达式中的任何一个匹配，则该请求被认为是由浏览器发送的，因此将强制执行CSRF防护。如果请求的User-Agent与这些正则表达式都不匹配，则认为该请求是由浏览器以外的其他设备（例如脚本化自动化）发送的。在这种情况下，CSRF并不是潜在的攻击媒介，因此无法执行预防措施。这有助于实现与尚未更新为发送CSRF预防标头的现有自动化的向后兼容性。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code><sup>Mozilla.<strong>,</strong></sup><strong>Opera.</strong></code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.security.exec.permission.checks" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.security.exec.permission.checks</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>如果启用此设置并且基于ACL的访问控制处于活动状态（AccessController协处理器既可以作为系统协处理器安装，也可以作为表协处理器安装在表上），那么如果所有相关用户需要执行协处理器端点的能力，则必须授予他们EXEC特权电话。像任何其他权限一样，EXEC特权可以全局授予用户，也可以基于每个表或每个命名空间授予用户。有关协处理器端点的更多信息，请参见HBase在线手册的协处理器部分。有关使用AccessController授予或撤消权限的更多信息，请参见HBase在线手册的安全性部分。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>false</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.procedure.regionserver.classes" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.procedure.regionserver.classes</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>逗号分隔的org.apache.hadoop.hbase.procedure列表。RegionServerProcedureManager过程管理器，默认情况下在活动的HRegionServer进程中加载。生命周期方法（init / start / stop）将由活动的HRegionServer进程调用以执行特定的全局受阻过程。在实现自己的RegionServerProcedureManager之后，只需将其放在HBase的类路径中，然后在此处添加完全限定的类名即可。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p>没有</p>
</div>
</dd>
</dl>
</div>
<div id="hbase.procedure.master.classes" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.procedure.master.classes</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>逗号分隔的org.apache.hadoop.hbase.procedure列表。MasterProcedureManager过程管理器，默认情况下在活动的HMaster进程上加载。过程由其签名标识，用户可以使用签名和即时名称来触发全局障碍过程的执行。在实现自己的MasterProcedureManager之后，只需将其放在HBase的类路径中，然后在此处添加完全限定的类名即可。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p>没有</p>
</div>
</dd>
</dl>
</div>
<div id="hbase.coordinated.state.manager.class" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.coordinated.state.manager.class</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>实现协调状态管理器的类的全限定名称。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>org.apache.hadoop.hbase.coordination.ZkCoordinatedStateManager</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.regionserver.storefile.refresh.period" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.regionserver.storefile.refresh.period</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>刷新辅助区域的存储文件的时间段（以毫秒为单位）。 0表示此功能被禁用。一旦二级区域刷新了该区域中的文件列表（没有通知机制），二级区域就会从主区域看到新文件（通过刷新和压缩）。但是过于频繁的刷新可能会导致额外的Namenode压力。如果文件刷新的时间不能超过HFile TTL（hbase.master.hfilecleaner.ttl），则拒绝请求。还建议通过此设置将HFile TTL配置为更大的值。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>0</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.region.replica.replication.enabled" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.region.replica.replication.enabled</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>是否启用了到辅助区域副本的异步WAL复制。如果启用此功能，将创建一个名为“ region_replica_replication”的复制对等方，它将复制日志尾部并将变异复制到具有区域复制> 1的表的区域副本中。如果一次启用此功能，则禁用此复制还需要使用shell或ReplicationAdmin java类禁用复制对等项。到辅助区域副本的复制通过标准的群集间复制进行。因此，如果显式禁用了复制，则还必须通过将“ hbase.replication”设置为true来启用此功能。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>false</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.http.filter.initializers" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.http.filter.initializers</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>用逗号分隔的类名称列表。列表中的每个类都必须扩展org.apache.hadoop.hbase.http。FilterInitializer。相应的过滤器将被初始化。然后，该筛选器将应用于所有面向用户的jsp和servlet网页。列表的顺序定义了过滤器的顺序。默认的StaticUserWebFilter添加一个由hbase.http.staticuser.user属性定义的用户主体。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>org.apache.hadoop.hbase.http.lib.StaticUserWebFilter</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.security.visibility.mutations.checkauths" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.security.visibility.mutations.checkauths</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>如果启用此属性，将检查可见性表达式中的标签是否与发出突变的用户相关联</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>false</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.http.max.threads" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.http.max.threads</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>HTTP Server将在其ThreadPool中创建的最大线程数。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>10</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.replication.rpc.codec" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.replication.rpc.codec</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>启用复制时要使用的编解码器，以便也复制标签。与HFileV3一起使用，后者支持其中的标签。如果未使用标签，或者使用的hfile版本为HFileV2，则可以将KeyValueCodec用作复制编解码器。请注意，在没有标签的情况下使用KeyValueCodecWithTags进行复制不会造成任何危害。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>org.apache.hadoop.hbase.codec.KeyValueCodecWithTags</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.replication.source.maxthreads" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.replication.source.maxthreads</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>任何复制源用于将编辑并行传送到接收器的最大线程数。这也限制了每个复制批处理分成的块数。较大的值可以提高主群集和从群集之间的复制吞吐量。默认值10几乎不需要更改。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>10</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.http.staticuser.user" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.http.staticuser.user</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>呈现内容时在静态Web筛选器上作为筛选条件的用户名。HDFS Web UI（用于浏览文件的用户）是一个示例用法。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>dr.stack</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.master.normalizer.class" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.master.normalizer.class</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>发生周期时用于执行区域规范化的类。有关其工作原理的更多信息，请参见类注释<a href="http://hbase.apache.org/devapidocs/org/apache/hadoop/hbase/master/normalizer/SimpleRegionNormalizer.html" class="bare">。http://hbase.apache.org/devapidocs/org/apache/hadoop/hbase/master/normalizer/SimpleRegionNormalizer.html</a></p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>org.apache.hadoop.hbase.master.normalizer.SimpleRegionNormalizer</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.regionserver.handler.abort.on.error.percent" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.regionserver.handler.abort.on.error.percent</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>区域服务器RPC线程无法中止RS的百分比。 -1禁用中止； 0即使有一个处理程序死亡，也中止； 0.x仅在此百分比的处理程序已死亡时才中止； 1只有中止所有处理程序的人都死了。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>0.5</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.snapshot.master.timeout.millis" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.snapshot.master.timeout.millis</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>快照过程执行的主服务器超时</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>300000</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.snapshot.region.timeout" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.snapshot.region.timeout</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>区域服务器将线程保留在快照请求池中的等待时间</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>300000</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.rpc.rows.warning.threshold" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.rpc.rows.warning.threshold</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>批处理操作中的行数，超过该行数将记录警告。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>5000</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.master.cleaner.snapshot.interval" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.master.cleaner.snapshot.interval</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>快照清理琐事间隔（以毫秒为单位）。清理线程按此时间间隔运行，以查找所有基于TTL过期的快照并将其删除。</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>1800000</code></p>
</div>
</dd>
</dl>
</div>
<div id="hbase.master.snapshot.ttl" class="dlist">
<dl>
<dt class="hdlist1"><code>hbase.master.snapshot.ttl</code></dt>
<dd>
<div class="paragraph">
<div class="title">描述</div>
<p>当用户在创建快照时未指定TTL时，将考虑默认快照TTL。默认值0表示永远-快照必须手动删除后才能自动删除</p>
</div>
<div class="paragraph">
<div class="title">默认</div>
<p><code>0</code></p>
</div>
</dd>
</dl>
</div>
</div>
<div class="sect2">
<h3 id="hbase.env.sh"><a class="anchor" href="#hbase.env.sh"></a> 7.3。 <em>hbase-env.sh</em></h3>
<div class="paragraph">
<p>在此文件中设置HBase环境变量。示例包括在HBase守护程序启动时传递JVM的选项，例如堆大小和垃圾收集器配置。您还可以设置HBase配置的配置，日志目录，niceness，ssh选项，在何处查找进程pid文件等。在<em>conf / hbase-env.sh中</em>打开文件并仔细阅读其内容。每个选项都有充分的文档记录。如果希望在启动时由HBase守护程序读取环境变量，请在此处添加您自己的环境变量。</p>
</div>
<div class="paragraph">
<p>此处的更改将要求群集重新启动，以便HBase注意到更改。</p>
</div>
</div>
<div class="sect2">
<h3 id="log4j"><a class="anchor" href="#log4j"></a> 7.4。 <em>log4j.properties</em></h3>
<div class="paragraph">
<p>编辑此文件以更改HBase文件的滚动速率并更改HBase记录消息的级别。</p>
</div>
<div class="paragraph">
<p>尽管可以通过HBase UI更改特定守护程序的日志级别，但此处的更改将要求HBase重新启动集群以注意到更改。</p>
</div>
</div>
<div class="sect2">
<h3 id="client_dependencies"><a class="anchor" href="#client_dependencies"></a> 7.5。客户端配置和依赖关系连接到HBase集群</h3>
<div class="paragraph">
<p>如果您以独立模式运行HBase，则无需配置任何内容即可让客户端正常工作，只要它们都在同一台计算机上即可。</p>
</div>
<div class="paragraph">
<p>由于HBase Master可能会四处移动，因此客户端可以通过向ZooKeeper查找当前的关键位置来进行引导。ZooKeeper是保留所有这些值的位置。因此，客户在执行其他任何操作之前，需要先确定ZooKeeper合奏的位置。通常，此合奏位置保留在<em>hbase-site.xml中</em> ，并由客户端从<code>CLASSPATH</code> 。</p>
</div>
<div class="paragraph">
<p>如果正在配置要运行HBase客户端的IDE，则应在类路径中包含<em>conf /</em>目录，以便可以找到<em>hbase-site.xml</em>设置（或添加<em>src / test / resources</em>来选择使用的hbase-site.xml通过测试）。</p>
</div>
<div class="paragraph">
<p>最低限度，HBase的客户端需要在其基础上提供多个库<code>CLASSPATH</code>连接到集群时，包括：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">commons-configuration (commons-configuration-<span class="float">1.6</span>.jar)
commons-lang (commons-lang-<span class="float">2.5</span>.jar)
commons-logging (commons-logging-<span class="float">1.1</span><span class="float">.1</span>.jar)
hadoop-core (hadoop-core-<span class="float">1.0</span><span class="float">.0</span>.jar)
hbase (hbase-<span class="float">0.92</span><span class="float">.0</span>.jar)
log4j (log4j-<span class="float">1.2</span><span class="float">.16</span>.jar)
slf4j-api (slf4j-api-<span class="float">1.5</span><span class="float">.8</span>.jar)
slf4j-log4j (slf4j-log4j12-<span class="float">1.5</span><span class="float">.8</span>.jar)
zookeeper (zookeeper-<span class="float">3.4</span><span class="float">.2</span>.jar)</code></pre>
</div>
</div>
<div class="paragraph">
<p>仅用于客户端的示例基本<em>hbase-site.xml</em>可能如下所示：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="xml"><span class="preprocessor">&lt;?xml version=&quot;1.0&quot;?&gt;</span>
<span class="preprocessor">&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;</span>
<span class="tag">&lt;configuration&gt;</span>
  <span class="tag">&lt;property&gt;</span>
    <span class="tag">&lt;name&gt;</span>hbase.zookeeper.quorum<span class="tag">&lt;/name&gt;</span>
    <span class="tag">&lt;value&gt;</span>example1,example2,example3<span class="tag">&lt;/value&gt;</span>
    <span class="tag">&lt;description&gt;</span>The directory shared by region servers.
    <span class="tag">&lt;/description&gt;</span>
  <span class="tag">&lt;/property&gt;</span>
<span class="tag">&lt;/configuration&gt;</span></code></pre>
</div>
</div>
<div class="sect3">
<h4 id="java.client.config"><a class="anchor" href="#java.client.config"></a> 7.5.1。Java客户端配置</h4>
<div class="paragraph">
<p>Java客户端使用的配置保留在<a href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/HBaseConfiguration">HBaseConfiguration</a>实例中。</p>
</div>
<div class="paragraph">
<p>HBaseConfiguration上的工厂方法， <code>HBaseConfiguration.create();</code>调用时，将读取在客户端的服务器上找到的第一个<em>hbase-site.xml</em>的内容。 <code>CLASSPATH</code> ，如果存在的话（调用还将包括找到的任何<em>hbase-default.xml</em> ； <em>hbase</em>内附带一个<em>hbase-default.xml</em> <em>。XXXjar</em> ）。还可以直接指定配置，而不必从<em>hbase-site.xml中</em>读取。例如，以编程方式为集群设置ZooKeeper集成，请执行以下操作：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="predefined-type">Configuration</span> config = HBaseConfiguration.create();
config.set(<span class="string"><span class="delimiter">&quot;</span><span class="content">hbase.zookeeper.quorum</span><span class="delimiter">&quot;</span></span>, <span class="string"><span class="delimiter">&quot;</span><span class="content">localhost</span><span class="delimiter">&quot;</span></span>);  <span class="comment">// Here we are running zookeeper locally</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>如果多个ZooKeeper实例组成了ZooKeeper集合，则可以在用逗号分隔的列表中指定它们（就像在<em>hbase-site.xml</em>文件中一样）。这人口<code>Configuration</code>实例然后可以传递给<a href="https://hbase.apache.org/apidocs/org/apache/hadoop/hbase/client/Table.html">Table</a> ，依此类推。</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="config_timeouts"><a class="anchor" href="#config_timeouts"></a> 7.6。超时设定</h3>
<div class="paragraph">
<p>HBase提供了各种各样的超时设置，以限制各种远程操作的执行时间。</p>
</div>
<div class="ulist">
<ul>
<li>
<p>hbase.rpc.timeout</p>
</li>
<li>
<p>hbase.rpc.read.timeout</p>
</li>
<li>
<p>hbase.rpc.write.timeout</p>
</li>
<li>
<p>hbase.client.operation.timeout</p>
</li>
<li>
<p>hbase.client.meta.operation.timeout</p>
</li>
<li>
<p>hbase.client.scanner.timeout.period</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>的<code>hbase.rpc.timeout</code>属性限制了单个RPC调用在超时之前可以运行多长时间。调整读写相关的RPC超时设置<code>hbase.rpc.read.timeout</code>和<code>hbase.rpc.write.timeout</code>配置属性。在没有这些特性的情况下<code>hbase.rpc.timeout</code>将会被使用。</p>
</div>
<div class="paragraph">
<p>较高级别的超时是<code>hbase.client.operation.timeout</code>对每个客户呼叫均有效。当RPC呼叫失败时，例如由于<code>hbase.rpc.timeout</code>它将重试直到<code>hbase.client.operation.timeout</code>到达了。可以通过设置微调系统表的客户端操作超时<code>hbase.client.meta.operation.timeout</code>配置值。如果未设置，则使用<code>hbase.client.operation.timeout</code> 。</p>
</div>
<div class="paragraph">
<p>扫描操作的超时控制不同。使用<code>hbase.client.scanner.timeout.period</code>属性设置此超时时间。</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="example_config"><a class="anchor" href="#example_config"></a> 8。示例配置</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_basic_distributed_hbase_install"><a class="anchor" href="#_basic_distributed_hbase_install"></a> 8.1。基本的分布式HBase安装</h3>
<div class="paragraph">
<p>这是分布式十节点群集的示例基本配置：*节点名为<code>example0</code> ， <code>example1</code>等，通过节点<code>example9</code>在这个例子中。* HBase主节点和HDFS NameNode在该节点上运行<code>example0</code> 。* RegionServers在节点上运行<code>example1</code> -- <code>example9</code> 。* 3节点ZooKeeper合奏在<code>example1</code> ， <code>example2</code>和<code>example3</code>在默认端口上。* ZooKeeper数据保留在目录<em>/ export / zookeeper中</em> 。</p>
</div>
<div class="paragraph">
<p>下面，我们显示在HBase <em>conf</em>目录中找到的主要配置文件<em>-hbase-site.xml</em> ， <em>regionservers</em>和<em>hbase-env.sh</em> 。</p>
</div>
<div class="sect3">
<h4 id="hbase_site"><a class="anchor" href="#hbase_site"></a> 8.1.1。 <em>hbase-site.xml</em></h4>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="xml"><span class="preprocessor">&lt;?xml version=&quot;1.0&quot;?&gt;</span>
<span class="preprocessor">&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;</span>
<span class="tag">&lt;configuration&gt;</span>
  <span class="tag">&lt;property&gt;</span>
    <span class="tag">&lt;name&gt;</span>hbase.zookeeper.quorum<span class="tag">&lt;/name&gt;</span>
    <span class="tag">&lt;value&gt;</span>example1,example2,example3<span class="tag">&lt;/value&gt;</span>
    <span class="tag">&lt;description&gt;</span>The directory shared by RegionServers.
    <span class="tag">&lt;/description&gt;</span>
  <span class="tag">&lt;/property&gt;</span>
  <span class="tag">&lt;property&gt;</span>
    <span class="tag">&lt;name&gt;</span>hbase.zookeeper.property.dataDir<span class="tag">&lt;/name&gt;</span>
    <span class="tag">&lt;value&gt;</span>/export/zookeeper<span class="tag">&lt;/value&gt;</span>
    <span class="tag">&lt;description&gt;</span>Property from ZooKeeper config zoo.cfg.
    The directory where the snapshot is stored.
    <span class="tag">&lt;/description&gt;</span>
  <span class="tag">&lt;/property&gt;</span>
  <span class="tag">&lt;property&gt;</span>
    <span class="tag">&lt;name&gt;</span>hbase.rootdir<span class="tag">&lt;/name&gt;</span>
    <span class="tag">&lt;value&gt;</span>hdfs://example0:8020/hbase<span class="tag">&lt;/value&gt;</span>
    <span class="tag">&lt;description&gt;</span>The directory shared by RegionServers.
    <span class="tag">&lt;/description&gt;</span>
  <span class="tag">&lt;/property&gt;</span>
  <span class="tag">&lt;property&gt;</span>
    <span class="tag">&lt;name&gt;</span>hbase.cluster.distributed<span class="tag">&lt;/name&gt;</span>
    <span class="tag">&lt;value&gt;</span>true<span class="tag">&lt;/value&gt;</span>
    <span class="tag">&lt;description&gt;</span>The mode the cluster will be in. Possible values are
      false: standalone and pseudo-distributed setups with managed Zookeeper
      true: fully-distributed with unmanaged Zookeeper Quorum (see hbase-env.sh)
    <span class="tag">&lt;/description&gt;</span>
  <span class="tag">&lt;/property&gt;</span>
<span class="tag">&lt;/configuration&gt;</span></code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="regionservers"><a class="anchor" href="#regionservers"></a> 8.1.2。 <em>区域服务器</em></h4>
<div class="paragraph">
<p>在此文件中，列出将运行RegionServers的节点。在我们的例子中，这些节点是<code>example1</code> -- <code>example9</code> 。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">example1
example2
example3
example4
example5
example6
example7
example8
example9</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="hbase_env"><a class="anchor" href="#hbase_env"></a> 8.1.3。 <em>hbase-env.sh</em></h4>
<div class="paragraph">
<p><em>hbase-env.sh</em>文件中的以下几行显示了如何设置<code>JAVA_HOME</code>环境变量（HBase必需）并将堆设置为4 GB（而不是默认值1 GB）。如果您复制并粘贴此示例，请务必调整<code>JAVA_HOME</code>以适合您的环境。</p>
</div>
<div class="listingblock">
<div class="content">
<pre># The java implementation to use.
export JAVA_HOME=/usr/java/jdk1.7.0/

# The maximum amount of heap to use. Default is left to JVM default.
export HBASE_HEAPSIZE=4G</pre>
</div>
</div>
<div class="paragraph">
<p>使用rsync将<em>conf</em>目录的内容复制到群集的所有节点。</p>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="important_configurations"><a class="anchor" href="#important_configurations"></a> 9。重要配置</h2>
<div class="sectionbody">
<div class="paragraph">
<p>下面我们列出了一些<em>重要的</em>配置。我们将本节分为所需的配置和值得一看的推荐配置。</p>
</div>
<div class="sect2">
<h3 id="required_configuration"><a class="anchor" href="#required_configuration"></a> 9.1。所需配置</h3>
<div class="paragraph">
<p>查看<a href="#os">os</a>和<a href="#hadoop">hadoop</a>部分。</p>
</div>
<div class="sect3">
<h4 id="big.cluster.config"><a class="anchor" href="#big.cluster.config"></a> 9.1.1。大集群配置</h4>
<div class="paragraph">
<p>如果您的群集具有很多区域，则在主服务器启动后，Regionserver可能会短暂签入，而所有其他RegionServer都将滞后。这第一台要签入的服务器将被分配所有非最佳区域。为防止发生上述情况，请向上<code>hbase.master.wait.on.regionservers.mintostart</code>属性从其默认值1开始。请参阅<a href="https://issues.apache.org/jira/browse/HBASE-6389">HBASE-6389修改条件以确保主服务器在启动区域分配之前等待足够数量的区域服务器</a> 。</p>
</div>
</div>
<div class="sect3">
<h4 id="backup.master.fail.fast"><a class="anchor" href="#backup.master.fail.fast"></a> 9.1.2。如果存在备用主服务器，请使主主服务器快速故障</h4>
<div class="paragraph">
<p>如果主要的Master失去与ZooKeeper的连接，它将陷入一个循环，在该循环中它将继续尝试重新连接。如果您运行多个Master（即备用Master），请禁用此功能。失败的话，垂死的Master可能会继续接收RPC，尽管另一个Master已经承担了Primary的角色。请参阅配置<a href="#fail.fast.expired.active.master">fail.fast.expired.active.master</a> 。</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_recommended_configurations"><a class="anchor" href="#_recommended_configurations"></a> 9.2。推荐配置</h3>
<div class="sect3">
<h4 id="recommended_configurations.zk"><a class="anchor" href="#recommended_configurations.zk"></a> 9.2.1。ZooKeeper配置</h4>
<div class="sect4">
<h5 id="sect.zookeeper.session.timeout"><a class="anchor" href="#sect.zookeeper.session.timeout"></a><code>zookeeper.session.timeout</code></h5>
<div class="paragraph">
<p>默认超时为三分钟（以毫秒为单位）。这意味着，如果服务器崩溃，则主服务器将在三分钟后通知崩溃并开始恢复。您可能希望将超时时间缩短至一分钟或更短，以便主服务器能够更快地注意到故障。在更改此值之前，请确保已控制JVM垃圾收集配置，否则，持续超过ZooKeeper会话超时的长垃圾收集将占用RegionServer（您可能会满意，您可能会满意的-您可能希望在服务器上开始恢复服务器（如果RegionServer长时间处于GC中）。</p>
</div>
<div class="paragraph">
<p>要更改此配置，请编辑<em>hbase-site.xml</em> ，将更改后的文件复制到群集中，然后重新启动。</p>
</div>
<div class="paragraph">
<p>我们将此值设置得很高，以免我们不得不在邮件列表中提出问题，询问在大规模导入期间为什么RegionServer出现故障。通常的原因是未调整其JVM，并且它们正在运行很长时间的GC暂停。我们的想法是，当用户熟悉HBase时，我们不必为他们省去了解其所有复杂性。稍后，当他们建立起一定的信心时，他们便可以使用这样的配置。</p>
</div>
</div>
<div class="sect4">
<h5 id="zookeeper.instances"><a class="anchor" href="#zookeeper.instances"></a> ZooKeeper实例数</h5>
<div class="paragraph">
<p>见<a href="#zookeeper">动物园管理员</a> 。</p>
</div>
</div>
</div>
<div class="sect3">
<h4 id="recommended.configurations.hdfs"><a class="anchor" href="#recommended.configurations.hdfs"></a> 9.2.2。HDFS配置</h4>
<div class="sect4">
<h5 id="dfs.datanode.failed.volumes.tolerated"><a class="anchor" href="#dfs.datanode.failed.volumes.tolerated"></a>允许dfs.datanode.failed.volumes。</h5>
<div class="paragraph">
<p>这是在DataNode停止提供服务之前允许失败的卷的数量。默认情况下，任何卷故障都将导致<em>hdfs-default.xml</em>描述中的数据<em>节点</em>关闭。您可能希望将其设置为可用磁盘数量的一半。</p>
</div>
</div>
</div>
<div class="sect3">
<h4 id="hbase.regionserver.handler.count_description"><a class="anchor" href="#hbase.regionserver.handler.count_description"></a> 9.2.3。<code>hbase.regionserver.handler.count</code></h4>
<div class="paragraph">
<p>此设置定义保持打开状态以响应对用户表的传入请求的线程数。经验法则是，当每个请求的有效负载接近MB时（大放置，使用大缓存进行扫描），此数字应保持较低；当有效负载较小（获取，小放置，ICV，删除）时，请保持较高的数字。进行中的查询的总大小受设置的限制<code>hbase.ipc.server.max.callqueue.size</code> 。</p>
</div>
<div class="paragraph">
<p>如果他们的有效负载很小，则可以安全地将该数目设置为最大数量的传入客户端，典型示例是为网站提供服务的群集，因为通常不对put进行缓冲，并且大多数操作都可以进行。</p>
</div>
<div class="paragraph">
<p>之所以将这个设置保持在较高水平是很危险的，原因是区域服务器中当前正在发生的所有看跌期权的总大小可能会对其内存施加过多压力，甚至触发OutOfMemoryError。在内存不足的情况下运行的RegionServer会触发其JVM的垃圾收集器更频繁地运行，直到明显的GC暂停为止（原因是，用于保留所有请求有效负载的所有内存都不能被废弃，垃圾收集器尝试）。一段时间后，整个群集的吞吐量会受到影响，因为命中该RegionServer的每个请求都将花费更长的时间，从而使问题更加严重。</p>
</div>
<div class="paragraph">
<p>通过在单个RegionServer上<a href="#rpc.logging">rpc.logging</a>然后拖尾其日志（排队的请求会消耗内存），您可以了解到您是否拥有过多的处理程序。</p>
</div>
</div>
<div class="sect3">
<h4 id="big_memory"><a class="anchor" href="#big_memory"></a> 9.2.4。大内存机器的配置</h4>
<div class="paragraph">
<p>HBase带有合理，保守的配置，几乎可以在人们可能要测试的所有计算机类型上使用。如果您拥有更大的计算机（HBase具有8G和更大的堆），那么以下配置选项可能会有所帮助。去做。</p>
</div>
</div>
<div class="sect3">
<h4 id="config.compression"><a class="anchor" href="#config.compression"></a> 9.2.5。压缩</h4>
<div class="paragraph">
<p>您应该考虑启用ColumnFamily压缩。有几个选项几乎是无摩擦的，在大多数情况下，它们通过减小StoreFiles的大小从而减少I / O来提高性能。</p>
</div>
<div class="paragraph">
<p>有关更多信息，请参见<a href="#compression">压缩</a> 。</p>
</div>
</div>
<div class="sect3">
<h4 id="config.wals"><a class="anchor" href="#config.wals"></a> 9.2.6。配置WAL文件的大小和数量</h4>
<div class="paragraph">
<p>如果RS发生故障，HBase使用<a href="#wal">wal</a>来恢复尚未刷新到磁盘的内存存储数据。这些WAL文件应配置为略小于HDFS块（默认情况下，HDFS块为64Mb，WAL文件为〜60Mb）。</p>
</div>
<div class="paragraph">
<p>HBase对WAL文件的数量也有限制，旨在确保在恢复过程中永远不会重放太多数据。需要根据memstore配置设置此限制，以便所有必需的数据都适合。建议分配足够的WAL文件以至少存储那么多的数据（当所有内存存储都快用完时）。例如，对于16Gb RS堆，默认内存存储设置（0.4）和默认WAL文件大小（〜60Mb），16Gb * 0.4 / 60，WAL文件计数的起点是〜109。但是，由于并非所有存储器都一直都在装满，因此可以分配较少的WAL文件。</p>
</div>
</div>
<div class="sect3">
<h4 id="disable.splitting"><a class="anchor" href="#disable.splitting"></a> 9.2.7。托管拆分</h4>
<div class="paragraph">
<p>HBase通常根据<em>hbase-default.xml</em>和<em>hbase-site.xml</em>配置文件中的设置来处理区域<em>划分</em> 。重要设置包括<code>hbase.regionserver.region.split.policy</code> ， <code>hbase.hregion.max.filesize</code> ， <code>hbase.regionserver.regionSplitLimit</code> 。一个简单的分割视图是，当区域增长到<code>hbase.hregion.max.filesize</code> ，它被分割了。对于大多数使用模式，大多数时候，应该使用自动拆分。有关<a href="#manual_region_splitting_decisions">手动区域分割</a>的更多信息，请参见<a href="#manual_region_splitting_decisions">手动区域分割决策</a> 。</p>
</div>
<div class="paragraph">
<p>您可以选择自己管理拆分，而不是让HBase自动拆分您的区域。如果您非常了解键空间，则可以手动管理拆分，否则让HBase为您确定拆分位置。手动拆分可以减轻区域创建和负载下的移动。它还使区域边界是已知且不变的（如果禁用区域分割）。如果使用手动拆分，则更容易进行基于时间的交错压缩，以分散网络IO负载。</p>
</div>
<div class="paragraph">
<div class="title">禁用自动拆分</div>
<p>要禁用自动拆分，请设置<code>hbase.hregion.max.filesize</code>很大的价值，例如<code>100 GB</code>不建议将其设置为的绝对最大值<code>Long.MAX_VALUE</code> 。</p>
</div>
<div class="admonitionblock note">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-note" title="注意"></i>
</td>
<td class="content">
<div class="title">推荐自动分割</div>
<div class="paragraph">
<p>如果禁用自动拆分以诊断问题或在数据快速增长期间，建议在情况变得更稳定时重新启用它们。管理区域分裂自己的潜在好处并非没有争议。</p>
</div>
</td>
</tr>
</tbody></table>
</div>
<div class="paragraph">
<div class="title">确定预分割区域的最佳数量</div>
<p>预分割区域的最佳数量取决于您的应用程序和环境。一个好的经验法则是从每个服务器10个预分割区域开始，并观察数据随时间增长的情况。最好在区域太少的一侧犯错误，然后再进行滚动拆分。最佳区域数取决于您所在区域中最大的StoreFile。如果数据量增加，则最大的StoreFile的大小将随时间增加。目的是使最大区域足够大，以使压缩选择算法仅在定时大压缩期间对其进行压缩。否则，群集可能易于遭受压缩风暴，其中大量区域同时受到压缩。重要的是要了解数据增长会导致压缩风暴，而不是手动拆分决策。</p>
</div>
<div class="paragraph">
<p>如果将区域分成太多大区域，则可以通过配置来增加主要压缩间隔<code>HConstants.MAJOR_COMPACTION_PERIOD</code> 。的<code>org.apache.hadoop.hbase.util.RegionSplitter</code>该实用程序还提供所有区域的网络IO安全滚动拆分。</p>
</div>
</div>
<div class="sect3">
<h4 id="managed.compactions"><a class="anchor" href="#managed.compactions"></a> 9.2.8。托管压缩</h4>
<div class="paragraph">
<p>默认情况下，大型压缩计划为每7天运行一次。</p>
</div>
<div class="paragraph">
<p>如果需要精确控制大型压缩的时间和频率，可以禁用托管大型压缩。看到条目<code>hbase.hregion.majorcompaction</code>有关详细信息，请参见<a href="#compaction.parameters">compaction.parameters</a>表。</p>
</div>
<div class="admonitionblock warning">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-warning" title="警告"></i>
</td>
<td class="content">
<div class="title">不要禁用重大压实</div>
<div class="paragraph">
<p>对于StoreFile清理，绝对必需进行大压缩。请勿完全禁用它们。您可以通过HBase Shell或<a href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/client/Admin.html#majorCompact(org.apache.hadoop.hbase.TableName)">Admin API</a>手动运行主要压缩。</p>
</div>
</td>
</tr>
</tbody></table>
</div>
<div class="paragraph">
<p>有关压缩和压缩文件选择过程的更多信息，请参见<a href="#compaction">压缩。</a></p>
</div>
</div>
<div class="sect3">
<h4 id="spec.ex"><a class="anchor" href="#spec.ex"></a> 9.2.9。投机执行</h4>
<div class="paragraph">
<p>默认情况下，MapReduce任务的推测执行是打开的，对于HBase群集，通常建议在系统级关闭推测执行，除非在特定情况下需要它，可以在每个作业中对其进行配置。设置属性<code>mapreduce.map.speculative</code>和<code>mapreduce.reduce.speculative</code>虚假。</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="other_configuration"><a class="anchor" href="#other_configuration"></a> 9.3。其他配置</h3>
<div class="sect3">
<h4 id="balancer_config"><a class="anchor" href="#balancer_config"></a> 9.3.1。平衡器</h4>
<div class="paragraph">
<p>平衡器是一种定期操作，在主服务器上运行，以重新分配群集上的区域。通过配置<code>hbase.balancer.period</code> ，默认值为300000（5分钟）。</p>
</div>
<div class="paragraph">
<p>有关LoadBalancer的更多信息，请参见<a href="#master.processes.loadbalancer">master.processes.loadbalancer</a> 。</p>
</div>
</div>
<div class="sect3">
<h4 id="disabling.blockcache"><a class="anchor" href="#disabling.blockcache"></a> 9.3.2。禁用块缓存</h4>
<div class="paragraph">
<p>不要关闭块缓存（您可以通过设置<code>hbase.block.cache.size</code>归零）。目前，如果您这样做的话，我们做得并不好，因为RegionServer将花费所有的时间一遍又一遍地加载HFile索引。如果您将工作区设置为对块缓存不利，请至少调整块缓存的大小，以使HFile索引保留在缓存中（您可以通过调查RegionServer UI来大致了解所需的大小；您将请参阅网页顶部附近的索引块大小）。</p>
</div>
</div>
<div class="sect3">
<h4 id="nagles"><a class="anchor" href="#nagles"></a> 9.3.3。<a href="http://en.wikipedia.org/wiki/Nagle%E2%80%99s_algorithm">Nagle</a>或小包装问题</h4>
<div class="paragraph">
<p>如果在针对HBase的操作中偶尔出现40ms左右的延迟，请尝试Nagles的设置。例如，请参阅用户邮件列表线程，“ <a href="http://search-hadoop.com/m/pduLg2fydtE/Inconsistent+scan+performance+with+caching+set+&subj=Re+Inconsistent+scan+performance+with+caching+set+to+1">缓存设置为1时的扫描性能不一致”</a>以及其中设置的问题。 <code>notcpdelay</code>改善扫描速度。您可能还会在<a href="https://issues.apache.org/jira/browse/HBASE-7008">HBASE-7008</a>的尾部看到图表， <a href="https://issues.apache.org/jira/browse/HBASE-7008">将扫描仪缓存设置为更好的默认设置</a> ，在此<a href="https://issues.apache.org/jira/browse/HBASE-7008">情况下</a> ，我们的Lars Hofhansl尝试打开和关闭Nagle来测量效果的各种数据大小。</p>
</div>
</div>
<div class="sect3">
<h4 id="mttr"><a class="anchor" href="#mttr"></a> 9.3.4。更好的平均恢复时间（MTTR）</h4>
<div class="paragraph">
<p>本节介绍的配置将使服务器在出现故障后更快地恢复。请参阅Deveraj Das和Nicolas Liochon博客文章<a href="http://hortonworks.com/blog/introduction-to-hbase-mean-time-to-recover-mttr/">HBase简介平均恢复时间（MTTR）</a> ，以获取简要介绍。</p>
</div>
<div class="paragraph">
<p><a href="https://issues.apache.org/jira/browse/HBASE-8389">HBASE-8354强制Namenode进入具有租约恢复请求的循环的过程</a>比较麻烦，但是在低超时时以及如何实现更快的恢复（包括引用添加到HDFS的修复程序）方面，到最后都有很多很好的讨论。阅读Varun Sharma的评论。以下建议的配置是Varun的建议经过提炼和测试的。确保您在最新版本的HDFS上运行，因此您也可以获得他所引用的修复程序，并且他自己添加了可帮助HBase MTTR的HDFS（例如，HDFS-3703，HDFS-3712和HDFS-4791-Hadoop 2肯定具有它们，并且Hadoop 1较晚）。在RegionServer中设置以下内容。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="xml"><span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>hbase.lease.recovery.dfs.timeout<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>23000<span class="tag">&lt;/value&gt;</span>
  <span class="tag">&lt;description&gt;</span>How much time we allow elapse between calls to recover lease.
  Should be larger than the dfs timeout.<span class="tag">&lt;/description&gt;</span>
<span class="tag">&lt;/property&gt;</span>
<span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>dfs.client.socket-timeout<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>10000<span class="tag">&lt;/value&gt;</span>
  <span class="tag">&lt;description&gt;</span>Down the DFS timeout from 60 to 10 seconds.<span class="tag">&lt;/description&gt;</span>
<span class="tag">&lt;/property&gt;</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>在NameNode / DataNode端，设置以下内容以启用HDFS-3703，HDFS-3912中引入的“陈旧性”。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="xml"><span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>dfs.client.socket-timeout<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>10000<span class="tag">&lt;/value&gt;</span>
  <span class="tag">&lt;description&gt;</span>Down the DFS timeout from 60 to 10 seconds.<span class="tag">&lt;/description&gt;</span>
<span class="tag">&lt;/property&gt;</span>
<span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>dfs.datanode.socket.write.timeout<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>10000<span class="tag">&lt;/value&gt;</span>
  <span class="tag">&lt;description&gt;</span>Down the DFS timeout from 8 * 60 to 10 seconds.<span class="tag">&lt;/description&gt;</span>
<span class="tag">&lt;/property&gt;</span>
<span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>ipc.client.connect.timeout<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>3000<span class="tag">&lt;/value&gt;</span>
  <span class="tag">&lt;description&gt;</span>Down from 60 seconds to 3.<span class="tag">&lt;/description&gt;</span>
<span class="tag">&lt;/property&gt;</span>
<span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>ipc.client.connect.max.retries.on.timeouts<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>2<span class="tag">&lt;/value&gt;</span>
  <span class="tag">&lt;description&gt;</span>Down from 45 seconds to 3 (2 == 3 retries).<span class="tag">&lt;/description&gt;</span>
<span class="tag">&lt;/property&gt;</span>
<span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>dfs.namenode.avoid.read.stale.datanode<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>true<span class="tag">&lt;/value&gt;</span>
  <span class="tag">&lt;description&gt;</span>Enable stale state in hdfs<span class="tag">&lt;/description&gt;</span>
<span class="tag">&lt;/property&gt;</span>
<span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>dfs.namenode.stale.datanode.interval<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>20000<span class="tag">&lt;/value&gt;</span>
  <span class="tag">&lt;description&gt;</span>Down from default 30 seconds<span class="tag">&lt;/description&gt;</span>
<span class="tag">&lt;/property&gt;</span>
<span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>dfs.namenode.avoid.write.stale.datanode<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>true<span class="tag">&lt;/value&gt;</span>
  <span class="tag">&lt;description&gt;</span>Enable stale state in hdfs<span class="tag">&lt;/description&gt;</span>
<span class="tag">&lt;/property&gt;</span></code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="jmx_config"><a class="anchor" href="#jmx_config"></a> 9.3.5。JMX</h4>
<div class="paragraph">
<p>JMX（Java管理扩展）提供了内置的工具，使您可以监视和管理Java VM。要从远程系统启用监视和管理，您需要设置系统属性<code>com.sun.management.jmxremote.port</code> （启动Java VM时要使用的端口号）。有关更多信息，请参见<a href="http://docs.oracle.com/javase/6/docs/technotes/guides/management/agent.html">官方文档</a> 。从历史上看，除了上述端口之外，JMX还打开了两个附加的随机TCP侦听端口，这可能会导致端口冲突问题。（有关详细信息，请参见<a href="https://issues.apache.org/jira/browse/HBASE-10289">HBASE-10289</a> ）</p>
</div>
<div class="paragraph">
<p>或者，您可以使用HBase提供的基于协处理器的JMX实现。要启用它，请在<em>hbase-site.xml中</em>添加以下属性：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="xml"><span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>hbase.coprocessor.regionserver.classes<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>org.apache.hadoop.hbase.JMXListener<span class="tag">&lt;/value&gt;</span>
<span class="tag">&lt;/property&gt;</span></code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-note" title="注意"></i>
</td>
<td class="content">不要设置<code>com.sun.management.jmxremote.port</code>同时使用Java VM。
</td>
</tr>
</tbody></table>
</div>
<div class="paragraph">
<p>当前，它支持Master和RegionServer Java VM。默认情况下，JMX侦听TCP端口10102，您可以使用以下属性进一步配置端口：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="xml"><span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>regionserver.rmi.registry.port<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>61130<span class="tag">&lt;/value&gt;</span>
<span class="tag">&lt;/property&gt;</span>
<span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>regionserver.rmi.connector.port<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>61140<span class="tag">&lt;/value&gt;</span>
<span class="tag">&lt;/property&gt;</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>在大多数情况下，注册表端口可以与连接器端口共享，因此您只需要配置regionserver.rmi.registry.port。但是，如果要使用SSL通信，则必须将2个端口配置为不同的值。</p>
</div>
<div class="paragraph">
<p>默认情况下，密码验证和SSL通信是禁用的。要启用密码身份验证，您需要更新<em>hbase-env.sh，</em>如下所示：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">export HBASE_JMX_BASE=&quot;-Dcom.sun.management.jmxremote.authenticate=true                  \
                       -Dcom.sun.management.jmxremote.password.file=your_password_file   \
                       -Dcom.sun.management.jmxremote.access.file=your_access_file&quot;

export HBASE_MASTER_OPTS=&quot;$HBASE_MASTER_OPTS $HBASE_JMX_BASE &quot;
export HBASE_REGIONSERVER_OPTS=&quot;$HBASE_REGIONSERVER_OPTS $HBASE_JMX_BASE &quot;</code></pre>
</div>
</div>
<div class="paragraph">
<p>请参阅<em>$ JRE_HOME / lib / management</em>下的示例密码/访问文件。</p>
</div>
<div class="paragraph">
<p>要通过密码验证启用SSL通信，请执行以下步骤：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">#1. generate a key pair, stored in myKeyStore
keytool -genkey -alias jconsole -keystore myKeyStore

#2. export it to file jconsole.cert
keytool -export -alias jconsole -keystore myKeyStore -file jconsole.cert

#3. copy jconsole.cert to jconsole client machine, import it to jconsoleKeyStore
keytool -import -alias jconsole -keystore jconsoleKeyStore -file jconsole.cert</code></pre>
</div>
</div>
<div class="paragraph">
<p>然后像下面这样更新<em>hbase-env.sh</em> ：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">export HBASE_JMX_BASE=&quot;-Dcom.sun.management.jmxremote.ssl=true                         \
                       -Djavax.net.ssl.keyStore=/home/tianq/myKeyStore                 \
                       -Djavax.net.ssl.keyStorePassword=your_password_in_step_1       \
                       -Dcom.sun.management.jmxremote.authenticate=true                \
                       -Dcom.sun.management.jmxremote.password.file=your_password file \
                       -Dcom.sun.management.jmxremote.access.file=your_access_file&quot;

export HBASE_MASTER_OPTS=&quot;$HBASE_MASTER_OPTS $HBASE_JMX_BASE &quot;
export HBASE_REGIONSERVER_OPTS=&quot;$HBASE_REGIONSERVER_OPTS $HBASE_JMX_BASE &quot;</code></pre>
</div>
</div>
<div class="paragraph">
<p>终于开始<code>jconsole</code>在使用密钥库的客户端上：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">jconsole -J-Djavax.net.ssl.trustStore=/home/tianq/jconsoleKeyStore</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-note" title="注意"></i>
</td>
<td class="content">要在Master上启用HBase JMX实现，还需要在<em>hbase-site.xml中</em>添加以下属性：</td>
</tr>
</tbody></table>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="xml"><span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;ame&gt;</span>hbase.coprocessor.master.classes<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>org.apache.hadoop.hbase.JMXListener<span class="tag">&lt;/value&gt;</span>
<span class="tag">&lt;/property&gt;</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>端口配置的相应属性是<code>master.rmi.registry.port</code> （默认为10101）和<code>master.rmi.connector.port</code> （默认情况下与registry.port相同）</p>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="dyn_config"><a class="anchor" href="#dyn_config"></a> 10。动态配置</h2>
<div class="sectionbody">
<div class="paragraph">
<p>可以更改配置的子集而无需重新启动服务器。在HBase Shell中，操作<code>update_config</code>和<code>update_all_config</code>将提示服务器或所有服务器重新加载配置。</p>
</div>
<div class="paragraph">
<p>当前，正在运行的服务器中只能更改所有配置的一部分。这是不完整的清单： <code>hbase.regionserver.thread.compaction.large</code> ， <code>hbase.regionserver.thread.compaction.small</code> ， <code>hbase.regionserver.thread.split</code> ， <code>hbase.regionserver.thread.merge</code> ，以及压缩策略和配置以及对非高峰时间的调整。有关完整列表，请参阅<a href="https://issues.apache.org/jira/browse/HBASE-12147">从89-fb</a>附加到<a href="https://issues.apache.org/jira/browse/HBASE-12147">HBASE-12147 Porting Online Config Change</a>的补丁。</p>
</div>
</div>
</div>
<h1 id="upgrading" class="sect0"><a class="anchor" href="#upgrading"></a>升级中</h1>
<div class="openblock partintro">
<div class="content">
<div class="paragraph">
<p>升级时不能跳过主要版本。如果要从0.98.x版本升级到2.x，则必须先从0.98.x升级到1.2.x，然后再从1.2.x升级到2.x。</p>
</div>
<div class="paragraph">
<p>查看<a href="#configuration">Apache HBase配置</a> ，尤其是<a href="#hadoop"></a> <a href="http://hadoop.apache.org">Hadoop的</a> 。熟悉<a href="#hbase_supported_tested_definitions">[hbase_supported_tested_definitions]</a> 。</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="hbase.versioning"><a class="anchor" href="#hbase.versioning"></a> 11。HBase版本号和兼容性</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="hbase.versioning.post10"><a class="anchor" href="#hbase.versioning.post10"></a> 11.1。理想的语义版本控制</h3>
<div class="paragraph">
<p>从1.0.0版本开始，HBase正在为其版本版本进行<a href="http://semver.org/">语义版本</a>控制。综上所述：</p>
</div>
<div class="ulist">
<div class="title">给定版本号MAJOR.MINOR.PATCH，增加：</div>
<ul>
<li>
<p>当您进行不兼容的API更改时的主要版本，</p>
</li>
<li>
<p>以向后兼容的方式添加功能时的MINOR版本，并且</p>
</li>
<li>
<p>进行向后兼容的错误修复时的PATCH版本。</p>
</li>
<li>
<p>可以使用预发布和构建元数据的其他标签作为MAJOR.MINOR.PATCH格式的扩展名。</p>
</li>
</ul>
</div>
<div id="hbase.versioning.compat" class="paragraph">
<div class="title">相容尺寸</div>
<p>除了通常的API版本控制注意事项之外，HBase还具有我们需要考虑的其他兼容性维度。</p>
</div>
<div class="ulist">
<div class="title">客户端-服务器有线协议兼容性</div>
<ul>
<li>
<p>允许更新客户端和服务器不同步。</p>
</li>
<li>
<p>我们只能先升级服务器。也就是说，服务器将与旧客户端向后兼容，这样新的API就可以了。</p>
</li>
<li>
<p>示例：用户应该能够使用旧客户端连接到升级的群集。</p>
</li>
</ul>
</div>
<div class="ulist">
<div class="title">服务器-服务器协议兼容性</div>
<ul>
<li>
<p>不同版本的服务器可以共存于同一群集中。</p>
</li>
<li>
<p>服务器之间的有线协议兼容。</p>
</li>
<li>
<p>复制和日志拆分等分布式任务的工作程序可以共存于同一群集中。</p>
</li>
<li>
<p>相关协议（例如使用ZK进行协调）也不会更改。</p>
</li>
<li>
<p>示例：用户可以执行滚动升级。</p>
</li>
</ul>
</div>
<div class="ulist">
<div class="title">文件格式兼容性</div>
<ul>
<li>
<p>支持文件格式向后和向前兼容</p>
</li>
<li>
<p>示例：作为HBase升级的一部分，文件，ZK编码，目录布局会自动升级。用户可以回滚到旧版本，一切将继续进行。</p>
</li>
</ul>
</div>
<div class="ulist">
<div class="title">客户端API兼容性</div>
<ul>
<li>
<p>允许更改或删除现有的客户端API。</p>
</li>
<li>
<p>我们需要在整个主要版本中弃用API，然后再进行更改/删除。</p>
<div class="ulist">
<ul>
<li>
<p>例如：API在2.0.1中已弃用，并在4.0.0中被标记为删除。另一方面，可以在3.0.0中删除在2.0.0中弃用的API。</p>
</li>
</ul>
</div>
</li>
<li>
<p>修补程序版本中提供的API将在所有更高的修补程序版本中提供。但是，可能会添加新的API，这些API在较早的修补程序版本中将不可用。</p>
</li>
<li>
<p>示例：使用新近弃用的api的用户无需使用hbase api调用即可修改应用程序代码，直到下一个主要版本。</p>
</li>
</ul>
</div>
<div class="ulist">
<div class="title">客户端二进制兼容性</div>
<ul>
<li>
<p>写入给定补丁程序版本中可用的API的客户端代码可以在更高版本的补丁程序的新jar上运行（无需重新编译）。</p>
</li>
<li>
<p>写入给定补丁程序版本中可用的API的客户端代码可能无法与早期补丁程序版本中的旧jar一起运行。</p>
</li>
<li>
<p>示例：旧的已编译客户端代码将与新的jar一起使用。</p>
</li>
</ul>
</div>
<div class="ulist">
<div class="title">服务器端受限API兼容性（取自Hadoop）</div>
<ul>
<li>
<p>内部API被标记为稳定，不断发展或不稳定</p>
</li>
<li>
<p>这意味着协处理器和插件（可插拔的类，包括复制）的二进制兼容性，只要它们仅使用标记的接口/类即可。</p>
</li>
<li>
<p>示例：旧的编译的协处理器，过滤器或插件代码将与新的jar一起使用。</p>
</li>
</ul>
</div>
<div class="ulist">
<div class="title">依赖相容性</div>
<ul>
<li>
<p>HBase的升级将不需要对依赖项目进行不兼容的升级，除了Apache Hadoop。</p>
</li>
<li>
<p>HBase的升级将不需要Java运行时的不兼容升级。</p>
</li>
<li>
<p>示例：将HBase升级到支持<em>依赖关系兼容性</em>的版本不需要您升级Apache ZooKeeper服务。</p>
</li>
<li>
<p>示例：如果当前的HBase版本支持在JDK 8上运行，则升级到支持<em>Dependency Compatibility</em>的版本也将在JDK 8上运行。</p>
</li>
</ul>
</div>
<div class="admonitionblock tip">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-tip" title="小费"></i>
</td>
<td class="content">
<div class="title">Hadoop版本</div>
<div class="paragraph">
<p>以前，我们尝试维护底层Hadoop服务的依赖项兼容性，但是在过去几年中，这已证明是站不住脚的。当HBase项目尝试维护对Hadoop较早版本的支持时，我们删除了“支持的”次要版本的标识符，这些子版本无法继续查看发行版。此外，Hadoop项目有一套自己的兼容性指南，这意味着在某些情况下，必须更新到较新的受支持的次要版本，可能会破坏我们的一些兼容性承诺。</p>
</div>
</td>
</tr>
</tbody></table>
</div>
<div class="ulist">
<div class="title">操作兼容性</div>
<ul>
<li>
<p>指标变化</p>
</li>
<li>
<p>服务的行为变化</p>
</li>
<li>
<p>网页API</p>
</li>
</ul>
</div>
<div class="ulist">
<div class="title">摘要</div>
<ul>
<li>
<p>修补程序升级是一种替代产品。与Java二进制不兼容的任何更改都将不允许。 <sup class="footnote">[ <a id="_footnoteref_1" class="footnote" href="#_footnote_1" title="查看脚注。">1</a> ]</sup>。修补程序版本中的降级版本可能不兼容。</p>
</li>
<li>
<p>较小的升级不需要修改应用程序/客户端代码。理想情况下，这将是直接替换，但是如果使用新的jar，则必须重新编译客户端代码，协处理器，过滤器等。</p>
</li>
<li>
<p>重大升级使HBase社区可以进行重大更改。</p>
</li>
</ul>
</div>
<table class="tableblock frame-all grid-all spread">
<caption class="title">表3。兼容性矩阵<sup class="footnote">[ <a id="_footnoteref_2" class="footnote" href="#_footnote_2" title="查看脚注。">2</a> ]</sup></caption>
<colgroup>
<col style="width:25%">
<col style="width:25%">
<col style="width:25%">
<col style="width:25%">
</colgroup>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">重大的</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">次要</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">补丁</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">客户端-服务器线兼容性</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">ñ</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">ÿ</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">ÿ</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">服务器-服务器兼容性</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">ñ</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">ÿ</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">ÿ</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">文件格式兼容性</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">N <sup class="footnote">[ <a id="_footnoteref_3" class="footnote" href="#_footnote_3" title="查看脚注。">3</a> ]</sup></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">ÿ</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">ÿ</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">客户端API兼容性</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">ñ</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">ÿ</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">ÿ</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">客户二进制兼容性</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">ñ</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">ñ</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">ÿ</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top" colspan="4"><p class="tableblock">服务器端受限API兼容性</p></td>
</tr>
<tr>
<td class="tableblock halign-right valign-top"><p class="tableblock">稳定</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">ñ</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">ÿ</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">ÿ</p></td>
</tr>
<tr>
<td class="tableblock halign-right valign-top"><p class="tableblock">不断发展</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">ñ</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">ñ</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">ÿ</p></td>
</tr>
<tr>
<td class="tableblock halign-right valign-top"><p class="tableblock">不稳定的</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">ñ</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">ñ</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">ñ</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">依赖相容性</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">ñ</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">ÿ</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">ÿ</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">操作兼容性</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">ñ</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">ñ</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">ÿ</p></td>
</tr>
</tbody>
</table>
<div class="sect3">
<h4 id="hbase.client.api.surface"><a class="anchor" href="#hbase.client.api.surface"></a> 11.1.1。HBase API表面</h4>
<div class="paragraph">
<p>HBase有很多API点，但是对于上面的兼容性矩阵，我们区分了Client API，Limited Private API和Private API。 HBase使用<a href="https://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-common/Compatibility.html">Hadoop接口分类</a>的版本。HBase的接口分类类可以在<a href="https://hbase.apache.org/apidocs/org/apache/hadoop/hbase/classification/package-summary.html">这里</a>找到。</p>
</div>
<div class="ulist">
<ul>
<li>
<p>InterfaceAudience：捕获目标受众，可能的值为Public（对于最终用户和外部项目），LimitedPrivate（对于其他项目，协处理器或其他插件点）和Private（对于内部使用）。</p>
</li>
<li>
<p>InterfaceStability：描述允许哪些类型的接口更改。可能的值是“稳定”，“正在演变”，“不稳定”和“已弃用”。</p>
</li>
</ul>
</div>
<div id="hbase.client.api" class="dlist">
<dl>
<dt class="hdlist1">HBase客户端API</dt>
<dd>
<p>HBase客户端API包含所有标有InterfaceAudience的类或方法。公共接口。hbase-client和从属模块中的所有主要类均具有InterfaceAudience。公共，InterfaceAudience。LimitedPrivate或InterfaceAudience。私人标记。并非其他模块（hbase-server等）中的所有类都具有标记。如果一个类未使用其中之一进行注释，则假定该类为InterfaceAudience。私人班。</p>
</dd>
</dl>
</div>
<div id="hbase.limitetprivate.api" class="dlist">
<dl>
<dt class="hdlist1">HBase LimitedPrivate API</dt>
<dd>
<p>LimitedPrivate批注随附了一组接口的目标使用者。这些使用者是协处理器，菲尼克斯，复制端点的象征或类似的东西。此时，HBase仅保证补丁程序版本之间的这些接口的源和二进制兼容性。</p>
</dd>
</dl>
</div>
<div id="hbase.private.api" class="dlist">
<dl>
<dt class="hdlist1">HBase专用API</dt>
<dd>
<p>所有类都用InterfaceAudience注释。没有注释的私有或所有类仅供HBase内部使用。接口和方法签名可以随时更改。如果您依赖于标记为“专用”的特定接口，则应打开“ jira”以建议将接口更改为“公共”或“有限私有”，或为此目的公开的接口。</p>
</dd>
</dl>
</div>
<div id="hbase.binary.compatibility" class="paragraph">
<div class="title">二进制兼容性</div>
<p>当我们说两个HBase版本是兼容的时，我们的意思是这些版本是有线和二进制兼容的。兼容的HBase版本意味着客户端可以与兼容但版本不同的服务器通信。这也意味着您可以换掉一个版本的jar，然后用另一个兼容版本的jar替换它们，所有这些都可以使用。除非另有说明，否则HBase点版本（主要）是二进制兼容的。您可以安全地在二进制兼容版本之间进行滚动升级；即跨维护版本：例如从1.2.4到1.2.6。请参阅链接：[版本之间的兼容性是否还意味着二进制兼容性？]关于HBase开发邮件列表的讨论。</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="hbase.rolling.upgrade"><a class="anchor" href="#hbase.rolling.upgrade"></a> 11.2。滚动升级</h3>
<div class="paragraph">
<p>滚动升级是一次更新群集中的服务器的过程。如果它们是二进制或有线兼容的，则可以跨HBase版本滚动升级。有关这意味着什么的更多信息，请参见<a href="#hbase.rolling.restart">在二进制/有线兼容版本之间滚动升级</a> 。粗略地讲，滚动升级是可以正常停止每个服务器，更新软件然后重新启动的操作。您为集群中的每个服务器执行此操作。通常，您首先升级主服务器，然后再升级RegionServers。请参阅<a href="#rolling">滚动重启，</a>以获取有助于使用滚动升级过程的工具。</p>
</div>
<div class="paragraph">
<p>例如，在下面的内容中，HBase被符号链接到实际的HBase安装。升级时，在通过cluser运行滚动重启之前，我们将符号链接更改为指向新的HBase软件版本，然后运行</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">$ HADOOP_HOME=~/hadoop-2.6.0-CRC-SNAPSHOT ~/hbase/bin/rolling-restart.sh --config ~/conf_hbase</code></pre>
</div>
</div>
<div class="paragraph">
<p>滚动重新启动脚本将首先正常停止并重新启动主服务器，然后依次停止每个RegionServer。由于符号链接已更改，因此在重新启动时，服务器将使用新的HBase版本启动。随着滚动升级的进行，请检查日志中是否有错误。</p>
</div>
<div id="hbase.rolling.restart" class="paragraph">
<div class="title">二进制/有线兼容版本之间的滚动升级</div>
<p>除非另有说明，否则HBase次要版本是二进制兼容的。您可以在HBase点版本之间进行<a href="#hbase.rolling.upgrade">滚动升级</a> 。例如，可以通过在群集上进行滚动升级来从1.2.6升级到1.2.4，将1.2.4二进制文件替换为1.2.6二进制文件。</p>
</div>
<div class="paragraph">
<p>在下面的次要版本特别部分中，我们指出了那些版本与线路/协议兼容的地方，在这种情况下，还可以进行<a href="#hbase.rolling.upgrade">滚动升级</a> 。</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_upgrade_paths"><a class="anchor" href="#_upgrade_paths"></a> 12升级路径</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="upgrade1.4"><a class="anchor" href="#upgrade1.4"></a> 12.1。升级到1.4+</h3>
<div class="sect3">
<h4 id="_replication_peer_s_tablecfs_config"><a class="anchor" href="#_replication_peer_s_tablecfs_config"></a> 12.1.1。复制对等方的TableCFs配置</h4>
<div class="paragraph">
<p>在1.4之前，表名称不能包含复制对等方的TableCFs配置的名称空间。通过将TableCF添加到存储在Zookeeper中的ReplicationPeerConfig中，可以修复该问题。因此，升级到1.4时，必须首先更新Zookeeper上的原始ReplicationPeerConfig数据。当群集具有带有TableCFs配置的复制对等方时，有四个升级步骤。</p>
</div>
<div class="ulist">
<ul>
<li>
<p>禁用复制对等方。</p>
</li>
<li>
<p>如果master具有写复制对等znode的权限，则直接滚动更新master。如果不是，请使用TableCFsUpdater工具更新复制对等方的配置。</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre>$ bin/hbase org.apache.hadoop.hbase.replication.master.TableCFsUpdater update</pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>滚动更新区域服务器。</p>
</li>
<li>
<p>启用复制对等方。</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>笔记：</p>
</div>
<div class="ulist">
<ul>
<li>
<p>无法使用旧客户端（1.4之前的版本）更改复制对等方的配置。由于客户端将配置直接写入Zookeeper，因此旧客户端将丢失TableCFs的配置。并且旧客户端将TableCFs配置写入旧tablecfs znode，它将不适用于新版本的regionserver。</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect2">
<h3 id="upgrade1.0"><a class="anchor" href="#upgrade1.0"></a> 12.2。从0.98.x升级到1.x</h3>
<div class="paragraph">
<p>在本节中，我们首先注意到1.0.0+ HBase附带的重大更改，然后介绍升级过程。请务必仔细阅读重要更改部分，以免引起意外。</p>
</div>
<div class="sect3">
<h4 id="_changes_of_note"><a class="anchor" href="#_changes_of_note"></a> 12.2.1。注意事项的变化！</h4>
<div class="paragraph">
<p>在此，我们列出了自0.98.x起1.0.0+版本中的重要更改，您应该意识到这些更改一旦升级就将生效。</p>
</div>
<div id="zookeeper.3.4" class="paragraph">
<div class="title">HBase 1.0.0+中需要ZooKeeper 3.4</div>
<p>请参阅<a href="#zookeeper.requirements">ZooKeeper要求</a> 。</p>
</div>
<div id="default.ports.changed" class="paragraph">
<div class="title">HBase默认端口已更改</div>
<p>HBase使用的端口已更改。它们曾经在600XX范围内。在HBase 1.0.0中，它们已移出临时端口范围，而改为160XX（主Web UI是60010，现在是16010； RegionServer Web UI是60030，现在是16030，依此类推）。如果要保留旧的端口位置，请将端口设置配置从<em>hbase-default.xml</em>复制到<em>hbase-site.xml</em> ，将其更改回HBase 0.98.x时代的旧值，并确保已分发重新启动之前进行配置。</p>
</div>
<div id="upgrade1.0.hbase.bucketcache.percentage.in.combinedcache" class="paragraph">
<div class="title">hbase.bucketcache.percentage.in.combinedcache配置已被删除</div>
<p>如果您正在使用BucketCache，则可能已使用此配置。如果未使用BucketCache，则此更改不会影响您。删除意味着您的L1 LruBlockCache现在使用<code>hfile.block.cache.size</code> —例如，如果您不执行BucketCache，则对堆L1 LruBlockCache进行大小调整的方式—并且BucketCache的大小与设置无关<code>hbase.bucketcache.size</code>是。您可能需要调整配置，以将LruBlockCache和BucketCache大小设置为0.98.x及之前版本中的大小。如果您未设置此配置，则其默认值为0.9。如果您什么也不做，那么BucketCache的大小将增加10％。您的L1 LruBlockCache将变为<code>hfile.block.cache.size</code>乘以您的Java堆大小（ <code>hfile.block.cache.size</code>是介于0.0和1.0之间的浮点数）。要了解更多信息，请参阅<a href="https://issues.apache.org/jira/browse/HBASE-11520">HBASE-11520，通过删除令人困惑的“ hbase.bucketcache.percentage.in.combinedcache”来简化offheap缓存配置</a> 。</p>
</div>
<div id="hbase-12068" class="paragraph">
<div class="title">如果您有自己的客户过滤器。</div>
<p>请参阅关于此问题的发行说明<a href="https://issues.apache.org/jira/browse/HBASE-12068">HBASE-12068 [Branch-1]避免始终为Filter transformCell做KeyValueUtil＃ensureKeyValue</a> ；确保遵循其中的建议。</p>
</div>
<div id="dlr" class="paragraph">
<div class="title">分布式日志重播</div>
<p>默认情况下，HBase 1.0.0中的<a href="#distributed.log.replay">分布式日志重播</a>处于关闭状态。启用它可以大大改善HBase MTTR。如果要在升级时进行干净的停止/启动，请启用此功能。您不能滚动升级到此功能（如果您在超过HBase 0.98.4的HBase版本上运行，请注意，有关更多信息，请参见<a href="https://issues.apache.org/jira/browse/HBASE-12577">HBASE-12577默认情况下禁用分布式日志重放</a> ）。</p>
</div>
<div class="paragraph">
<div class="title">日期分层压缩的可用性。</div>
<p>从1.3.0版开始的1.y发布行中提供了从0.98.19开始可用的日期分层压缩功能。如果为任何表启用了此功能，则必须升级到1.3.0或更高版本。如果您尝试使用早期的1.y版本，则任何配置为使用日期分层压缩的表都将无法打开其区域。</p>
</div>
</div>
<div class="sect3">
<h4 id="upgrade1.0.rolling.upgrade"><a class="anchor" href="#upgrade1.0.rolling.upgrade"></a> 12.2.2。从0.98.x滚动升级到HBase 1.0.0</h4>
<div class="paragraph">
<p>从HBase 0.98.x <a href="#hbase.rolling.upgrade">滚动升级</a>到HBase 1.0.0没有已知问题。</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="upgrade2.0"><a class="anchor" href="#upgrade2.0"></a> 12.3。升级到2.x</h3>
<div class="paragraph">
<p>请参阅最新2.x版本的参考指南以获取升级指导。</p>
</div>
</div>
</div>
</div>
<h1 id="shell" class="sect0"><a class="anchor" href="#shell"></a> Apache HBase Shell</h1>
<div class="openblock partintro">
<div class="content">
<div class="paragraph">
<p>Apache HBase Shell是<a href="http://jruby.org">（J）Ruby</a>的IRB，其中添加了一些HBase特定命令。在IRB中可以执行的任何操作，都应该可以在HBase Shell中执行。</p>
</div>
<div class="paragraph">
<p>要运行HBase Shell，请执行以下操作：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">$ ./bin/hbase shell</code></pre>
</div>
</div>
<div class="paragraph">
<p>类型<code>help</code>然后<code><RETURN></code>查看shell命令和选项列表。至少浏览帮助输出末尾的段落，以了解如何将变量和命令参数输入HBase shell；特别注意表名，行和列等必须加引号。</p>
</div>
<div class="paragraph">
<p>请参阅<a href="#shell_exercises">shell练习</a> ，例如基本的shell操作。</p>
</div>
<div class="paragraph">
<p>这是Rajeshbabu Chintaguntla编写的<a href="http://learnhbase.wordpress.com/2013/03/02/hbase-shell-commands/">所有shell命令</a>的格式良好的清单。</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="scripting"><a class="anchor" href="#scripting"></a> 13用Ruby编写脚本</h2>
<div class="sectionbody">
<div class="paragraph">
<p>有关编写Apache HBase脚本的示例，请查看HBase <em>bin</em>目录。查看以<em>* .rb</em>结尾的文件。要运行这些文件之一，请执行以下操作：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">$ ./bin/hbase org.jruby.Main PATH_TO_SCRIPT</code></pre>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_running_the_shell_in_non_interactive_mode"><a class="anchor" href="#_running_the_shell_in_non_interactive_mode"></a> 14。在非交互模式下运行命令行管理程序</h2>
<div class="sectionbody">
<div class="paragraph">
<p>新的非交互模式已添加到HBase Shell（ <a href="https://issues.apache.org/jira/browse/HBASE-11658">HBASE-11658）</a> 。非交互模式捕获HBase Shell命令的退出状态（成功或失败），并将该状态传递回命令解释器。如果您使用普通交互模式，则HBase Shell将仅返回其自己的退出状态，该退出状态几乎总是<code>0</code>为成功。</p>
</div>
<div class="paragraph">
<p>要调用非交互模式，请传递<code>-n</code>要么<code>--non-interactive</code> HBase Shell的选项。</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="hbase.shell.noninteractive"><a class="anchor" href="#hbase.shell.noninteractive"></a> 15OS脚本中的HBase Shell</h2>
<div class="sectionbody">
<div class="paragraph">
<p>您可以在操作系统脚本解释器（例如Bash shell）中使用HBase shell，而Bash shell是大多数Linux和UNIX发行版的默认命令解释器。以下准则使用Bash语法，但可以进行调整以与C样式的外壳程序（例如csh或tcsh）一起使用，并且可以进行修改以与Microsoft Windows脚本解释器一起使用。欢迎提交。</p>
</div>
<div class="admonitionblock note">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-note" title="注意"></i>
</td>
<td class="content">以这种方式生成HBase Shell命令的速度很慢，因此在决定何时将HBase操作与操作系统命令行结合使用时要牢记这一点。
</td>
</tr>
</tbody></table>
</div>
<div class="exampleblock">
<div class="title">范例7。将命令传递到HBase Shell</div>
<div class="content">
<div class="paragraph">
<p>您可以使用以下命令以非交互方式将命令传递给HBase Shell（请参阅<a href="#hbasee.shell.noninteractive">hbasee.shell.noninteractive</a> ）： <code>echo</code>命令和<code>|</code> （管道）运算符。确保在HBase命令中转义字符，否则这些字符会被Shell解释。下面的示例已截断了某些调试级别的输出。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">$ echo &quot;describe 'test1'&quot; | ./hbase shell -n

Version 0.98.3-hadoop2, rd5e65a9144e315bb0a964e7730871af32f5018d5, Sat May 31 19:56:09 PDT 2014

describe 'test1'

DESCRIPTION                                          ENABLED
 'test1', {NAME =&gt; 'cf', DATA_BLOCK_ENCODING =&gt; 'NON true
 E', BLOOMFILTER =&gt; 'ROW', REPLICATION_SCOPE =&gt; '0',
  VERSIONS =&gt; '1', COMPRESSION =&gt; 'NONE', MIN_VERSIO
 NS =&gt; '0', TTL =&gt; 'FOREVER', KEEP_DELETED_CELLS =&gt;
 'false', BLOCKSIZE =&gt; '65536', IN_MEMORY =&gt; 'false'
 , BLOCKCACHE =&gt; 'true'}
1 row(s) in 3.2410 seconds</code></pre>
</div>
</div>
<div class="paragraph">
<p>要取消所有输出，请将其回显到<em>/ dev / null：</em></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">$ echo &quot;describe 'test'&quot; | ./hbase shell -n &gt; /dev/null 2&gt;&amp;1</code></pre>
</div>
</div>
</div>
</div>
<div class="exampleblock">
<div class="title">范例8。检查脚本命令的结果</div>
<div class="content">
<div class="paragraph">
<p>由于脚本并非旨在以交互方式运行，因此您需要一种方法来检查命令是失败还是成功。HBase Shell使用返回值的标准约定<code>0</code>对于成功的命令，对于失败的命令，一些非零值。Bash将命令的返回值存储在称为的特殊环境变量中<code>$?</code> 。由于该变量每次在Shell运行任何命令时都会被覆盖，因此您应将结果存储在脚本定义的其他变量中。</p>
</div>
<div class="paragraph">
<p>这是一个幼稚的脚本，它显示了一种存储返回值并基于该值进行决策的方法。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">#!/bin/bash

echo &quot;describe 'test'&quot; | ./hbase shell -n &gt; /dev/null 2&gt;&amp;1
status=$?
echo &quot;The status was &quot; $status
if ($status == 0); then
    echo &quot;The command succeeded&quot;
else
    echo &quot;The command may have failed.&quot;
fi
return $status</code></pre>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_checking_for_success_or_failure_in_scripts"><a class="anchor" href="#_checking_for_success_or_failure_in_scripts"></a> 15.1。检查脚本中的成功或失败</h3>
<div class="paragraph">
<p>获取的退出代码<code>0</code>表示您编写的命令肯定成功。但是，获得非零的退出代码并不一定意味着命令失败。该命令可以成功执行，但是客户端失去连接，或者其他事件掩盖了其成功。这是因为RPC命令是无状态的。确保操作状态的唯一方法是检查。例如，如果您的脚本创建了一个表，但是返回了一个非零的退出值，则应在再次尝试创建表之前检查该表是否已实际创建。</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_read_hbase_shell_commands_from_a_command_file"><a class="anchor" href="#_read_hbase_shell_commands_from_a_command_file"></a> 16。从命令文件中读取HBase Shell命令</h2>
<div class="sectionbody">
<div class="paragraph">
<p>您可以将HBase Shell命令输入到文本文件中，每行一个命令，然后将该文件传递给HBase Shell。</p>
</div>
<div class="exampleblock">
<div class="title">范例9。示例命令文件</div>
<div class="content">
<div class="listingblock">
<div class="content">
<pre>create 'test', 'cf'
list 'test'
put 'test', 'row1', 'cf:a', 'value1'
put 'test', 'row2', 'cf:b', 'value2'
put 'test', 'row3', 'cf:c', 'value3'
put 'test', 'row4', 'cf:d', 'value4'
scan 'test'
get 'test', 'row1'
disable 'test'
enable 'test'</pre>
</div>
</div>
</div>
</div>
<div class="exampleblock">
<div class="title">示例10指导HBase Shell执行命令</div>
<div class="content">
<div class="paragraph">
<p>将路径传递到命令文件作为唯一的参数<code>hbase shell</code>命令。每个命令都会执行，并显示其输出。如果您不包括<code>exit</code>命令在脚本中返回到HBase shell提示符。无法以编程方式检查每个命令的成功或失败。另外，尽管您看到了每个命令的输出，但命令本身并未回显到屏幕，因此可能很难将命令与其输出对齐。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">$ ./hbase shell ./sample_commands.txt
0 row(s) in 3.4170 seconds

TABLE
test
1 row(s) in 0.0590 seconds

0 row(s) in 0.1540 seconds

0 row(s) in 0.0080 seconds

0 row(s) in 0.0060 seconds

0 row(s) in 0.0060 seconds

ROW                   COLUMN+CELL
 row1                 column=cf:a, timestamp=1407130286968, value=value1
 row2                 column=cf:b, timestamp=1407130286997, value=value2
 row3                 column=cf:c, timestamp=1407130287007, value=value3
 row4                 column=cf:d, timestamp=1407130287015, value=value4
4 row(s) in 0.0420 seconds

COLUMN                CELL
 cf:a                 timestamp=1407130286968, value=value1
1 row(s) in 0.0110 seconds

0 row(s) in 1.5630 seconds

0 row(s) in 0.4360 seconds</code></pre>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_passing_vm_options_to_the_shell"><a class="anchor" href="#_passing_vm_options_to_the_shell"></a> 17。将VM选项传递到命令行管理程序</h2>
<div class="sectionbody">
<div class="paragraph">
<p>您可以使用以下命令将VM选项传递给HBase Shell： <code>HBASE_SHELL_OPTS</code>环境变量。您可以在环境中进行设置，例如通过编辑<em>〜/ .bashrc</em> ，或将其设置为启动HBase Shell的命令的一部分。以下示例仅在运行HBase Shell的VM的生命周期内设置了几个与垃圾回收相关的变量。该命令应全部在一行上运行，但会被<code>\</code>字符，以提高可读性。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">$ HBASE_SHELL_OPTS=&quot;-verbose:gc -XX:+PrintGCApplicationStoppedTime -XX:+PrintGCDateStamps \
  -XX:+PrintGCDetails -Xloggc:$HBASE_HOME/logs/gc-hbase.log&quot; ./bin/hbase shell</code></pre>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_overriding_configuration_starting_the_hbase_shell"><a class="anchor" href="#_overriding_configuration_starting_the_hbase_shell"></a> 18岁覆盖启动HBase Shell的配置</h2>
<div class="sectionbody">
<div class="paragraph">
<p>从hbase-2.0.5 / hbase-2.1.3 / hbase-2.2.0 / hbase-1.4.10 / hbase-1.5.0开始，您可以按照以下说明指定的方式传递或覆盖hbase配置： <code>hbase-*.xml</code>通过传递以/开头的键/值<code>-D</code>在命令行上如下：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">$ ./bin/hbase shell -Dhbase.zookeeper.quorum=ZK0.remote.cluster.example.org,ZK1.remote.cluster.example.org,ZK2.remote.cluster.example.org -Draining=false
...
hbase(main):001:0&gt; @shell.hbase.configuration.get(&quot;hbase.zookeeper.quorum&quot;)
=&gt; &quot;ZK0.remote.cluster.example.org,ZK1.remote.cluster.example.org,ZK2.remote.cluster.example.org&quot;
hbase(main):002:0&gt; @shell.hbase.configuration.get(&quot;raining&quot;)
=&gt; &quot;false&quot;</code></pre>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_shell_tricks"><a class="anchor" href="#_shell_tricks"></a> 19贝壳技巧</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_table_variables"><a class="anchor" href="#_table_variables"></a> 19.1。表变量</h3>
<div class="paragraph">
<p>HBase 0.95添加了Shell命令，这些命令为表提供了jruby样式的面向对象的引用。以前，作用于表的所有shell命令都具有一种程序样式，该样式始终将表的名称作为参数。HBase 0.95引入了将表分配给jruby变量的功能。该表引用可用于执行数据读写操作，例如放置，扫描以及获取良好的管理功能，例如禁用，删除，描述表。</p>
</div>
<div class="paragraph">
<p>例如，以前您总是要指定一个表名：</p>
</div>
<div class="listingblock">
<div class="content">
<pre>hbase(main):000:0&gt; create ‘t’, ‘f’
0 row(s) in 1.0970 seconds
hbase(main):001:0&gt; put 't', 'rold', 'f', 'v'
0 row(s) in 0.0080 seconds

hbase(main):002:0&gt; scan 't'
ROW                                COLUMN+CELL
 rold                              column=f:, timestamp=1378473207660, value=v
1 row(s) in 0.0130 seconds

hbase(main):003:0&gt; describe 't'
DESCRIPTION                                                                           ENABLED
 't', {NAME =&gt; 'f', DATA_BLOCK_ENCODING =&gt; 'NONE', BLOOMFILTER =&gt; 'ROW', REPLICATION_ true
 SCOPE =&gt; '0', VERSIONS =&gt; '1', COMPRESSION =&gt; 'NONE', MIN_VERSIONS =&gt; '0', TTL =&gt; '2
 147483647', KEEP_DELETED_CELLS =&gt; 'false', BLOCKSIZE =&gt; '65536', IN_MEMORY =&gt; 'false
 ', BLOCKCACHE =&gt; 'true'}
1 row(s) in 1.4430 seconds

hbase(main):004:0&gt; disable 't'
0 row(s) in 14.8700 seconds

hbase(main):005:0&gt; drop 't'
0 row(s) in 23.1670 seconds

hbase(main):006:0&gt;</pre>
</div>
</div>
<div class="paragraph">
<p>现在，您可以将表分配给变量，并在jruby shell代码中使用结果。</p>
</div>
<div class="listingblock">
<div class="content">
<pre>hbase(main):007 &gt; t = create 't', 'f'
0 row(s) in 1.0970 seconds

=&gt; Hbase::Table - t
hbase(main):008 &gt; t.put 'r', 'f', 'v'
0 row(s) in 0.0640 seconds
hbase(main):009 &gt; t.scan
ROW                           COLUMN+CELL
 r                            column=f:, timestamp=1331865816290, value=v
1 row(s) in 0.0110 seconds
hbase(main):010:0&gt; t.describe
DESCRIPTION                                                                           ENABLED
 't', {NAME =&gt; 'f', DATA_BLOCK_ENCODING =&gt; 'NONE', BLOOMFILTER =&gt; 'ROW', REPLICATION_ true
 SCOPE =&gt; '0', VERSIONS =&gt; '1', COMPRESSION =&gt; 'NONE', MIN_VERSIONS =&gt; '0', TTL =&gt; '2
 147483647', KEEP_DELETED_CELLS =&gt; 'false', BLOCKSIZE =&gt; '65536', IN_MEMORY =&gt; 'false
 ', BLOCKCACHE =&gt; 'true'}
1 row(s) in 0.0210 seconds
hbase(main):038:0&gt; t.disable
0 row(s) in 6.2350 seconds
hbase(main):039:0&gt; t.drop
0 row(s) in 0.2340 seconds</pre>
</div>
</div>
<div class="paragraph">
<p>如果已经创建了表，则可以使用get_table方法将表分配给变量：</p>
</div>
<div class="listingblock">
<div class="content">
<pre>hbase(main):011 &gt; create 't','f'
0 row(s) in 1.2500 seconds

=&gt; Hbase::Table - t
hbase(main):012:0&gt; tab = get_table 't'
0 row(s) in 0.0010 seconds

=&gt; Hbase::Table - t
hbase(main):013:0&gt; tab.put ‘r1’ ,’f’, ‘v’
0 row(s) in 0.0100 seconds
hbase(main):014:0&gt; tab.scan
ROW                                COLUMN+CELL
 r1                                column=f:, timestamp=1378473876949, value=v
1 row(s) in 0.0240 seconds
hbase(main):015:0&gt;</pre>
</div>
</div>
<div class="paragraph">
<p>列表功能也得到了扩展，以便它以字符串形式返回表名列表。然后，您可以使用jruby根据这些名称对表操作进行脚本编写。list_snapshots命令的行为也类似。</p>
</div>
<div class="listingblock">
<div class="content">
<pre>hbase(main):016 &gt; tables = list(‘t.*’)
TABLE
t
1 row(s) in 0.1040 seconds

=&gt; #&lt;#&lt;Class:0x7677ce29&gt;:0x21d377a4&gt;
hbase(main):017:0&gt; tables.map { |t| disable t ; drop  t}
0 row(s) in 2.2510 seconds

=&gt; [nil]
hbase(main):018:0&gt;</pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="irbrc"><a class="anchor" href="#irbrc"></a> 19.2。 <em>irbrc</em></h3>
<div class="paragraph">
<p>在您的主目录中为自己创建一个<em>.irbrc</em>文件。添加自定义项。命令历史是一个有用的命令，因此命令可在Shell调用之间保存：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">$ more .irbrc
require 'irb/ext/save-history'
IRB.conf[:SAVE_HISTORY] = 100
IRB.conf[:HISTORY_FILE] = &quot;#{ENV['HOME']}/.irb-save-history&quot;</code></pre>
</div>
</div>
<div class="paragraph">
<p>如果您想避免将对每个表达式求值的结果打印到stderr，例如，从“ list”命令返回的表数组：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">$ echo &quot;IRB.conf[:ECHO] = false&quot; &gt;&gt;~/.irbrc</code></pre>
</div>
</div>
<div class="paragraph">
<p>见<code>ruby</code> <em>.irbrc的</em>文档以了解其他可能的配置。</p>
</div>
</div>
<div class="sect2">
<h3 id="_log_data_to_timestamp"><a class="anchor" href="#_log_data_to_timestamp"></a> 19.3。将数据记录到时间戳</h3>
<div class="paragraph">
<p>要将日期“ 08/08/16 20:56:29”从hbase日志转换为时间戳，请执行以下操作：</p>
</div>
<div class="listingblock">
<div class="content">
<pre>hbase(main):021:0&gt; import java.text.SimpleDateFormat
hbase(main):022:0&gt; import java.text.ParsePosition
hbase(main):023:0&gt; SimpleDateFormat.new("yy/MM/dd HH:mm:ss").parse("08/08/16 20:56:29", ParsePosition.new(0)).getTime() =&gt; 1218920189000</pre>
</div>
</div>
<div class="paragraph">
<p>要走另一个方向：</p>
</div>
<div class="listingblock">
<div class="content">
<pre>hbase(main):021:0&gt; import java.util.Date
hbase(main):022:0&gt; Date.new(1218920189000).toString() =&gt; "Sat Aug 16 20:56:29 UTC 2008"</pre>
</div>
</div>
<div class="paragraph">
<p>要以与HBase日志格式完全相同的格式输出，将使<a href="http://download.oracle.com/javase/6/docs/api/java/text/SimpleDateFormat.html">SimpleDateFormat</a>有点混乱。</p>
</div>
</div>
<div class="sect2">
<h3 id="_debug"><a class="anchor" href="#_debug"></a> 19.4。除错</h3>
<div class="sect3">
<h4 id="_shell_debug_switch"><a class="anchor" href="#_shell_debug_switch"></a> 19.4.1。外壳调试开关</h4>
<div class="paragraph">
<p>您可以在外壳程序中设置调试开关，以在运行命令时查看更多输出（例如，更多有关异常的堆栈跟踪）：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">hbase&gt; debug &lt;RETURN&gt;</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_debug_log_level"><a class="anchor" href="#_debug_log_level"></a> 19.4.2。调试日志级别</h4>
<div class="paragraph">
<p>要在外壳中启用DEBUG级别的日志记录，请使用<code>-d</code>选项。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">$ ./bin/hbase shell -d</code></pre>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_commands"><a class="anchor" href="#_commands"></a> 19.5。指令</h3>
<div class="sect3">
<h4 id="_count"><a class="anchor" href="#_count"></a> 19.5.1。计数</h4>
<div class="paragraph">
<p>Count命令返回表中的行数。当配置正确的CACHE时，速度非常快</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">hbase&gt; count <span class="string"><span class="delimiter">'</span><span class="content">&lt;tablename&gt;</span><span class="delimiter">'</span></span>, CACHE =&gt; <span class="integer">1000</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>上面的计数一次获取1000行。如果行很大，请将CACHE降低。默认值为一次获取一行。</p>
</div>
</div>
</div>
</div>
</div>
<h1 id="datamodel" class="sect0"><a class="anchor" href="#datamodel"></a>资料模型</h1>
<div class="openblock partintro">
<div class="content">
<div class="paragraph">
<p>在HBase中，数据存储在具有行和列的表中。这是与关系数据库（RDBMS）的术语重叠，但这并不是一个有用的类比。相反，将HBase表视为多维映射可能会有所帮助。</p>
</div>
<div class="dlist">
<div class="title">HBase数据模型术语</div>
<dl>
<dt class="hdlist1">表</dt>
<dd>
<p>一个HBase表由多行组成。</p>
</dd>
<dt class="hdlist1">行</dt>
<dd>
<p>HBase中的一行由行键和一列或多列与它们相关联的值组成。行在存储时按行键按字母顺序排序。因此，行键的设计非常重要。目标是以相关行彼此靠近的方式存储数据。常见的行密钥模式是网站域。如果行键是域，则可能应该反向存储它们（org.apache.www，org.apache.mail，org.apache.jira）。这样，所有Apache域在表中彼此靠近，而不是根据子域的第一个字母散布开。</p>
</dd>
<dt class="hdlist1">柱</dt>
<dd>
<p>HBase中的列由列族和列限定符组成，它们由<code>:</code> （冒号）字符。</p>
</dd>
<dt class="hdlist1">列族</dt>
<dd>
<p>出于性能考虑，列族实际上将一组列及其值并置在一起。每个列族都有一组存储属性，例如是否应将其值缓存在内存中，如何压缩其数据或对其行键进行编码等。表中的每一行都具有相同的列族，尽管给定的行可能不会在给定的列族中存储任何内容。</p>
</dd>
<dt class="hdlist1">列限定词</dt>
<dd>
<p>将列限定符添加到列族，以提供给定数据段的索引。给定列族<code>content</code> ，列限定符可能是<code>content:html</code> ，另一个可能是<code>content:pdf</code> 。尽管列族在创建表时是固定的，但列限定符是可变的，并且行之间的差异可能很大。</p>
</dd>
<dt class="hdlist1">细胞</dt>
<dd>
<p>单元格是行，列族和列限定符的组合，并包含一个值和一个时间戳，代表该值的版本。</p>
</dd>
<dt class="hdlist1">时间戳记</dt>
<dd>
<p>时间戳记写在每个值旁边，并且是值的给定版本的标识符。默认情况下，时间戳表示写入数据时在RegionServer上的时间，但是在将数据放入单元格时可以指定其他时间戳值。</p>
</dd>
</dl>
</div>
</div>
</div>
<div class="sect1">
<h2 id="conceptual.view"><a class="anchor" href="#conceptual.view"></a> 20概念观点</h2>
<div class="sectionbody">
<div class="paragraph">
<p>您可以在Jim R. Wilson的博客文章《 <a href="https://dzone.com/articles/understanding-hbase-and-bigtab">了解HBase和BigTable》中</a>阅读有关HBase数据模型的非常容易理解的解释。Amandeep Khurana的PDF <a href="http://0b4af6cdc2f0c5998459-c0245c5c937c5dedcca3f1764ecc9b2f.r43.cf2.rackcdn.com/9353-login1210_khurana.pdf">《基本模式设计简介》中</a>提供了另一个很好的解释。</p>
</div>
<div class="paragraph">
<p>可能有助于阅读不同的观点，以便对HBase模式设计有深入的了解。链接的文章与本节中的信息内容相同。</p>
</div>
<div class="paragraph">
<p>以下示例是<a href="http://research.google.com/archive/bigtable.html">BigTable</a>论文第2页上的形式的略微修改形式。有一张桌子叫<code>webtable</code>包含两行（ <code>com.cnn.www</code>和<code>com.example.www</code> ）和三个列族<code>contents</code> ， <code>anchor</code>和<code>people</code> 。在此示例中，对于第一行（ <code>com.cnn.www</code> ）， <code>anchor</code>包含两列（ <code>anchor:cssnsi.com</code> ， <code>anchor:my.look.ca</code> ）和<code>contents</code>包含一列（ <code>contents:html</code> ）。本示例包含具有行键的行的5个版本<code>com.cnn.www</code> ，以及带有行键的行的一个版本<code>com.example.www</code> 。的<code>contents:html</code>列限定符包含给定网站的整个HTML。预选赛<code>anchor</code>列族每个都包含链接到该行表示的站点的外部站点，以及在其链接的锚点中使用的文本。的<code>people</code>列族代表与网站相关的人员。</p>
</div>
<div class="admonitionblock note">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-note" title="注意"></i>
</td>
<td class="content">
<div class="title">列名</div>
<div class="paragraph">
<p>按照惯例，列名由其列族前缀和<em>限定符组成</em> 。例如，column <em>contents：html</em>列由列族组成<code>contents</code>和<code>html</code>限定词。冒号（ <code>:</code> ）从列系列<em>限定符</em>分隔列家族。</p>
</div>
</td>
</tr>
</tbody></table>
</div>
<table class="tableblock frame-all grid-all spread">
<caption class="title">表4。表<code>webtable</code></caption>
<colgroup>
<col style="width:20%">
<col style="width:20%">
<col style="width:20%">
<col style="width:20%">
<col style="width:20%">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">行键</th>
<th class="tableblock halign-left valign-top">时标</th>
<th class="tableblock halign-left valign-top">专栏家庭<code>contents</code></th>
<th class="tableblock halign-left valign-top">专栏家庭<code>anchor</code></th>
<th class="tableblock halign-left valign-top">专栏家庭<code>people</code></th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">“ com.cnn.www”</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">9天</p></td>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">anchor：cnnsi.com =“ CNN”</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">“ com.cnn.www”</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">8天</p></td>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">anchor：my.look.ca =“ CNN.com”</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">“ com.cnn.www”</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">6天</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">contents：html =“……”</p></td>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">“ com.cnn.www”</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">5天</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">contents：html =“……”</p></td>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">“ com.cnn.www”</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">3天</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">contents：html =“……”</p></td>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p>该表中看起来为空的单元格在HBase中不占用空间，或者实际上不存在。这就是使HBase“稀疏”的原因。表格视图不是查看HBase中数据的唯一可能的方法，甚至不是最准确的方法。以下代表与多维地图相同的信息。这仅是出于说明目的的模型，可能并非严格准确。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="json">{
  <span class="key"><span class="delimiter">&quot;</span><span class="content">com.cnn.www</span><span class="delimiter">&quot;</span></span>: {
    <span class="error">c</span><span class="error">o</span><span class="error">n</span><span class="error">t</span><span class="error">e</span><span class="error">n</span><span class="error">t</span><span class="error">s</span>: {
      <span class="error">t</span><span class="integer">6</span>: <span class="error">c</span><span class="error">o</span><span class="error">n</span><span class="error">t</span><span class="error">e</span><span class="error">n</span><span class="error">t</span><span class="error">s</span>:<span class="error">h</span><span class="error">t</span><span class="error">m</span><span class="error">l</span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">&lt;html&gt;...</span><span class="delimiter">&quot;</span></span>
      <span class="error">t</span><span class="integer">5</span>: <span class="error">c</span><span class="error">o</span><span class="error">n</span><span class="error">t</span><span class="error">e</span><span class="error">n</span><span class="error">t</span><span class="error">s</span>:<span class="error">h</span><span class="error">t</span><span class="error">m</span><span class="error">l</span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">&lt;html&gt;...</span><span class="delimiter">&quot;</span></span>
      <span class="error">t</span><span class="integer">3</span>: <span class="error">c</span><span class="error">o</span><span class="error">n</span><span class="error">t</span><span class="error">e</span><span class="error">n</span><span class="error">t</span><span class="error">s</span>:<span class="error">h</span><span class="error">t</span><span class="error">m</span><span class="error">l</span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">&lt;html&gt;...</span><span class="delimiter">&quot;</span></span>
    }
    <span class="error">a</span><span class="error">n</span><span class="error">c</span><span class="error">h</span><span class="error">o</span><span class="error">r</span>: {
      <span class="error">t</span><span class="integer">9</span>: <span class="error">a</span><span class="error">n</span><span class="error">c</span><span class="error">h</span><span class="error">o</span><span class="error">r</span>:<span class="error">c</span><span class="error">n</span><span class="error">n</span><span class="error">s</span><span class="error">i</span><span class="error">.</span><span class="error">c</span><span class="error">o</span><span class="error">m</span> <span class="error">=</span> <span class="string"><span class="delimiter">&quot;</span><span class="content">CNN</span><span class="delimiter">&quot;</span></span>
      <span class="error">t</span><span class="integer">8</span>: <span class="error">a</span><span class="error">n</span><span class="error">c</span><span class="error">h</span><span class="error">o</span><span class="error">r</span>:<span class="error">m</span><span class="error">y</span><span class="error">.</span><span class="error">l</span><span class="error">o</span><span class="error">o</span><span class="error">k</span><span class="error">.</span><span class="error">c</span><span class="error">a</span> <span class="error">=</span> <span class="string"><span class="delimiter">&quot;</span><span class="content">CNN.com</span><span class="delimiter">&quot;</span></span>
    }
    <span class="error">p</span><span class="error">e</span><span class="error">o</span><span class="error">p</span><span class="error">l</span><span class="error">e</span>: {}
  }
  <span class="key"><span class="delimiter">&quot;</span><span class="content">com.example.www</span><span class="delimiter">&quot;</span></span>: {
    <span class="error">c</span><span class="error">o</span><span class="error">n</span><span class="error">t</span><span class="error">e</span><span class="error">n</span><span class="error">t</span><span class="error">s</span>: {
      <span class="error">t</span><span class="integer">5</span>: <span class="error">c</span><span class="error">o</span><span class="error">n</span><span class="error">t</span><span class="error">e</span><span class="error">n</span><span class="error">t</span><span class="error">s</span>:<span class="error">h</span><span class="error">t</span><span class="error">m</span><span class="error">l</span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">&lt;html&gt;...</span><span class="delimiter">&quot;</span></span>
    }
    <span class="error">a</span><span class="error">n</span><span class="error">c</span><span class="error">h</span><span class="error">o</span><span class="error">r</span>: {}
    <span class="error">p</span><span class="error">e</span><span class="error">o</span><span class="error">p</span><span class="error">l</span><span class="error">e</span>: {
      <span class="error">t</span><span class="integer">5</span>: <span class="error">p</span><span class="error">e</span><span class="error">o</span><span class="error">p</span><span class="error">l</span><span class="error">e</span>:<span class="error">a</span><span class="error">u</span><span class="error">t</span><span class="error">h</span><span class="error">o</span><span class="error">r</span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">John Doe</span><span class="delimiter">&quot;</span></span>
    }
  }
}</code></pre>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="physical.view"><a class="anchor" href="#physical.view"></a> 21物理视图</h2>
<div class="sectionbody">
<div class="paragraph">
<p>尽管从概念上讲，表可以看作是行的稀疏集合，但它们实际上是按列族存储的。可以随时将新的列限定符（column_family：column_qualifier）添加到现有的列族。</p>
</div>
<table class="tableblock frame-all grid-all spread">
<caption class="title">表5。专栏家庭<code>anchor</code></caption>
<colgroup>
<col style="width:33%">
<col style="width:33%">
<col style="width:33%">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">行键</th>
<th class="tableblock halign-left valign-top">时标</th>
<th class="tableblock halign-left valign-top">列族<code>anchor</code></th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">“ com.cnn.www”</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">9天</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>anchor:cnnsi.com = "CNN"</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">“ com.cnn.www”</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">8天</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>anchor:my.look.ca = "CNN.com"</code></p></td>
</tr>
</tbody>
</table>
<table class="tableblock frame-all grid-all spread">
<caption class="title">表6。专栏家庭<code>contents</code></caption>
<colgroup>
<col style="width:33%">
<col style="width:33%">
<col style="width:33%">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">行键</th>
<th class="tableblock halign-left valign-top">时标</th>
<th class="tableblock halign-left valign-top">专栏家庭<code>contents:</code></th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">“ com.cnn.www”</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">6天</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">contents：html =“……”</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">“ com.cnn.www”</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">5天</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">contents：html =“……”</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">“ com.cnn.www”</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">3天</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">contents：html =“……”</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p>概念视图中显示的空单元格根本不存储。因此，要求<code>contents:html</code>时间戳列<code>t8</code>不会返回任何值。同样，要求<code>anchor:my.look.ca</code>时间戳值<code>t9</code>不会返回任何值。但是，如果未提供时间戳记，则将返回特定列的最新值。给定多个版本，由于时间戳以降序存储，因此最新的也是找到的第一个版本。因此，请求该行中所有列的值<code>com.cnn.www</code>如果未指定时间戳，则为：的值<code>contents:html</code>从时间戳记<code>t6</code> ， 的价值<code>anchor:cnnsi.com</code>从时间戳记<code>t9</code> ， 的价值<code>anchor:my.look.ca</code>从时间戳记<code>t8</code> 。</p>
</div>
<div class="paragraph">
<p>有关Apache HBase如何存储数据的内部信息的更多信息，请参见<a href="#regions.arch">regions.arch</a> 。</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_namespace"><a class="anchor" href="#_namespace"></a> 22命名空间</h2>
<div class="sectionbody">
<div class="paragraph">
<p>命名空间是表的逻辑分组，类似于关系数据库系统中的数据库。这种抽象为即将到来的多租户相关功能奠定了基础：</p>
</div>
<div class="ulist">
<ul>
<li>
<p>配额管理（ <a href="https://issues.apache.org/jira/browse/HBASE-8410">HBASE-8410</a> ）-限制名称空间可以消耗的资源（即区域，表）数量。</p>
</li>
<li>
<p>命名空间安全管理（ <a href="https://issues.apache.org/jira/browse/HBASE-9206">HBASE-9206</a> ）-为租户提供另一级别的安全管理。</p>
</li>
<li>
<p>区域服务器组（ <a href="https://issues.apache.org/jira/browse/HBASE-6721">HBASE-6721</a> ）-可以将名称空间/表固定在RegionServers的子集上，从而保证了课程的隔离级别。</p>
</li>
</ul>
</div>
<div class="sect2">
<h3 id="namespace_creation"><a class="anchor" href="#namespace_creation"></a> 22.1命名空间管理</h3>
<div class="paragraph">
<p>可以创建，删除或更改名称空间。命名空间成员资格是在表创建期间通过指定以下格式的标准表名来确定的：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="xml"><span class="tag">&lt;table</span> <span class="attribute-name">namespace</span><span class="tag">&gt;</span>:<span class="tag">&lt;table</span> <span class="attribute-name">qualifier</span><span class="tag">&gt;</span></code></pre>
</div>
</div>
<div class="exampleblock">
<div class="title">示例11例子</div>
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bourne">#Create a namespace
create_namespace 'my_ns'</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bourne">#create my_table in my_ns namespace
create 'my_ns:my_table', 'fam'</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bourne">#drop namespace
drop_namespace 'my_ns'</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bourne">#alter namespace
alter_namespace 'my_ns', {METHOD =&gt; 'set', 'PROPERTY_NAME' =&gt; 'PROPERTY_VALUE'}</code></pre>
</div>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="namespace_special"><a class="anchor" href="#namespace_special"></a> 22.2。预定义的名称空间</h3>
<div class="paragraph">
<p>有两个预定义的特殊名称空间：</p>
</div>
<div class="ulist">
<ul>
<li>
<p>hbase-系统名称空间，用于包含HBase内部表</p>
</li>
<li>
<p>默认-没有显式指定名称空间的表将自动落入该名称空间</p>
</li>
</ul>
</div>
<div class="exampleblock">
<div class="title">范例12。例子</div>
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bourne">#namespace=foo and table qualifier=bar
create 'foo:bar', 'fam'

#namespace=default and table qualifier=bar
create 'bar', 'fam'</code></pre>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_table"><a class="anchor" href="#_table"></a> 23。表</h2>
<div class="sectionbody">
<div class="paragraph">
<p>表在架构定义时预先声明。</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_row"><a class="anchor" href="#_row"></a> 24行</h2>
<div class="sectionbody">
<div class="paragraph">
<p>行键是未解释的字节。行按字典顺序排序，最低顺序在表中排在最前面。空字节数组用于表示表名称空间的开始和结束。</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="columnfamily"><a class="anchor" href="#columnfamily"></a> 25岁列族</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Apache HBase中的<em>列</em>被分组为<em>列族</em> 。列族的所有列成员都具有相同的前缀。例如，列<em>courses：history</em>和<em>courses：math</em>都是<em>courses</em>列族的成员。冒号（ <code>:</code> ）从列族限定符中分隔列族。列族前缀必须由<em>可打印</em>字符组成。限定尾部（列族<em>限定符</em> ）可以由任意字节组成。列族必须在架构定义时预先声明，而不必在架构时定义列，但是可以在表运行时动态地对其进行构想。</p>
</div>
<div class="paragraph">
<p>实际上，所有列族成员都一起存储在文件系统上。由于调整和存储规范是在列族级别上完成的，因此建议所有列族成员都具有相同的常规访问模式和大小特征。</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_cells"><a class="anchor" href="#_cells"></a> 26细胞</h2>
<div class="sectionbody">
<div class="paragraph">
<p><em>{行，列，版本}</em>元组准确地指定了<code>cell</code>在HBase中。单元格内容是未解释的字节</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_data_model_operations"><a class="anchor" href="#_data_model_operations"></a> 27。数据模型操作</h2>
<div class="sectionbody">
<div class="paragraph">
<p>四个主要的数据模型操作是“获取”，“放置”，“扫描”和“删除”。通过<a href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/client/Table.html">Table</a>实例应用操作。</p>
</div>
<div class="sect2">
<h3 id="_get"><a class="anchor" href="#_get"></a> 27.1。得到</h3>
<div class="paragraph">
<p><a href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/client/Get.html">获取</a>指定行的返回属性。通过<a href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/client/Table.html#get(org.apache.hadoop.hbase.client.Get)">Table.get</a>执行获取。</p>
</div>
</div>
<div class="sect2">
<h3 id="_put"><a class="anchor" href="#_put"></a> 27.2。放</h3>
<div class="paragraph">
<p><a href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/client/Put.html">Put</a>可以将新行添加到表中（如果键是新键），也可以更新现有行（如果键已经存在）。通过<a href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/client/Table.html#put(org.apache.hadoop.hbase.client.Put)">Table.put</a> （writeBuffer）或链接执行<a href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/client/Table.html#put(org.apache.hadoop.hbase.client.Put)">看跌</a>期权。Object []）[Table.batch]（非writeBuffer）。</p>
</div>
</div>
<div class="sect2">
<h3 id="scan"><a class="anchor" href="#scan"></a> 27.3。扫瞄</h3>
<div class="paragraph">
<p><a href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/client/Scan.html">扫描</a>允许对指定属性的多行迭代。</p>
</div>
<div class="paragraph">
<p>以下是“扫描表”实例的示例。假设一个表中填充了键为“ row1”，“ row2”，“ row3”的行，然后填充了另一组键为“ abc1”，“ abc2”和“ abc3”的行。以下示例显示如何设置Scan实例以返回以“ row”开头的行。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="directive">public</span> <span class="directive">static</span> <span class="directive">final</span> <span class="type">byte</span><span class="type">[]</span> CF = <span class="string"><span class="delimiter">&quot;</span><span class="content">cf</span><span class="delimiter">&quot;</span></span>.getBytes();
<span class="directive">public</span> <span class="directive">static</span> <span class="directive">final</span> <span class="type">byte</span><span class="type">[]</span> ATTR = <span class="string"><span class="delimiter">&quot;</span><span class="content">attr</span><span class="delimiter">&quot;</span></span>.getBytes();
...

Table table = ...      <span class="comment">// instantiate a Table instance</span>

Scan scan = <span class="keyword">new</span> Scan();
scan.addColumn(CF, ATTR);
scan.setRowPrefixFilter(Bytes.toBytes(<span class="string"><span class="delimiter">&quot;</span><span class="content">row</span><span class="delimiter">&quot;</span></span>));
ResultScanner rs = table.getScanner(scan);
<span class="keyword">try</span> {
  <span class="keyword">for</span> (<span class="predefined-type">Result</span> r = rs.next(); r != <span class="predefined-constant">null</span>; r = rs.next()) {
    <span class="comment">// process result...</span>
  }
} <span class="keyword">finally</span> {
  rs.close();  <span class="comment">// always close the ResultScanner!</span>
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>请注意，通常，为扫描指定特定停止点的最简单方法是使用<a href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/filter/InclusiveStopFilter.html">InclusiveStopFilter</a>类。</p>
</div>
</div>
<div class="sect2">
<h3 id="_delete"><a class="anchor" href="#_delete"></a> 27.4。删除</h3>
<div class="paragraph">
<p><a href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/client/Delete.html">删除</a>从表中删除一行。删除是通过<a href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/client/Table.html#delete(org.apache.hadoop.hbase.client.Delete)">Table.delete</a>执行的。</p>
</div>
<div class="paragraph">
<p>HBase不会就地修改数据，因此删除操作通过创建称为<em>墓碑的</em>新标记来处理。这些墓碑以及固定价格将在大型压实中清理。</p>
</div>
<div class="paragraph">
<p>有关删除列<a href="#version.delete">版本</a>的更多信息，请参见<a href="#version.delete">version.delete</a> ；有关<a href="#compaction">压缩</a>的更多信息，请参见压缩。</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="versions"><a class="anchor" href="#versions"></a> 28岁版本号</h2>
<div class="sectionbody">
<div class="paragraph">
<p><em>{行，列，版本}</em>元组准确地指定了<code>cell</code>在HBase中。可能会有无数的单元格，其中行和列相同，但单元格地址仅在其版本维度上有所不同。</p>
</div>
<div class="paragraph">
<p>当行键和列键表示为字节时，使用长整数指定版本。通常，此long包含时间实例，例如由<code>java.util.Date.getTime()</code>要么<code>System.currentTimeMillis()</code> ，即： <em class="quote">当前时间与UTC 1970年1月1日午夜之间的差（以毫秒为单位）</em> 。</p>
</div>
<div class="paragraph">
<p>HBase版本维以降序存储，因此从存储文件中读取时，将首先找到最新值。</p>
</div>
<div class="paragraph">
<p>关于...的语义有很多困惑<code>cell</code>版本，在HBase中。特别是：</p>
</div>
<div class="ulist">
<ul>
<li>
<p>如果对一个单元的多次写入具有相同版本，则只有最后一次写入是可获取的。</p>
</li>
<li>
<p>可以按非递增版本顺序写入单元格。</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>下面，我们描述HBase中的版本维度当前如何工作。有关HBase版本的讨论，请参见<a href="https://issues.apache.org/jira/browse/HBASE-2406">HBASE-2406</a> 。<a href="http://outerthought.org/blog/417-ot.html">HBase中的弯曲时间</a>使您可以更好地阅读<a href="http://outerthought.org/blog/417-ot.html">HBase中</a>的版本或时间维度。与此处提供的版本相比，它具有更多有关版本控制的详细信息。在撰写本文时，HBase中不再<em>存在</em>本文中提到的在<em>现有时间戳上覆盖值</em>的限制。本部分基本上是Bruno Dumon撰写的本文的提要。</p>
</div>
<div class="sect2">
<h3 id="specify.number.of.versions"><a class="anchor" href="#specify.number.of.versions"></a> 28.1。指定要存储的版本数</h3>
<div class="paragraph">
<p>给定列存储的最大版本数是列架构的一部分，并在创建表时指定，或通过<code>alter</code>命令，通过<code>HColumnDescriptor.DEFAULT_VERSIONS</code> 。在HBase 0.96之前，保留的默认版本为<code>3</code> ，但在0.96及更高版本中已更改为<code>1</code> 。</p>
</div>
<div class="exampleblock">
<div class="title">范例13。修改列系列的最大版本数</div>
<div class="content">
<div class="paragraph">
<p>本示例使用HBase Shell保留列族中所有列的最多5个版本<code>f1</code> 。您也可以使用<a href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/HColumnDescriptor.html">HColumnDescriptor</a> 。</p>
</div>
<div class="listingblock">
<div class="content">
<pre>hbase&gt; alter ‘t1′, NAME =&gt; ‘f1′, VERSIONS =&gt; 5</pre>
</div>
</div>
</div>
</div>
<div class="exampleblock">
<div class="title">范例14。修改列族的最小版本数</div>
<div class="content">
<div class="paragraph">
<p>您还可以指定每个列系列要存储的最小版本数。默认情况下，它设置为0，这意味着该功能被禁用。下面的示例设置列族中所有列的最小版本数<code>f1</code>至<code>2</code> ，通过HBase Shell。您也可以使用<a href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/HColumnDescriptor.html">HColumnDescriptor</a> 。</p>
</div>
<div class="listingblock">
<div class="content">
<pre>hbase&gt; alter ‘t1′, NAME =&gt; ‘f1′, MIN_VERSIONS =&gt; 2</pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>从HBase 0.98.2开始，可以通过设置以下内容为所有新创建的列保留的最大版本数指定全局默认值： <code>hbase.column.max.version</code>在<em>hbase-site.xml中</em> 。参见<a href="#hbase.column.max.version">hbase.column.max.version</a> 。</p>
</div>
</div>
<div class="sect2">
<h3 id="versions.ops"><a class="anchor" href="#versions.ops"></a> 28.2。版本和HBase操作</h3>
<div class="paragraph">
<p>在本节中，我们研究每个核心HBase操作的版本维度的行为。</p>
</div>
<div class="sect3">
<h4 id="_get_scan"><a class="anchor" href="#_get_scan"></a> 28.2.1。获取/扫描</h4>
<div class="paragraph">
<p>获取是在“扫描”之上实现的。以下有关<a href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/client/Get.html">Get的</a>讨论同样适用于<a href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/client/Scan.html">Scans</a> 。</p>
</div>
<div class="paragraph">
<p>默认情况下，即，如果您未指定显式版本，则执行<code>get</code> ，则返回其版本值最大的单元格（该单元格可能不是最新写入的单元格，请参阅稍后）。可以通过以下方式修改默认行为：</p>
</div>
<div class="ulist">
<ul>
<li>
<p>返回多个版本，请参见<a href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/client/Get.html#setMaxVersions()">Get.setMaxVersions（）</a></p>
</li>
<li>
<p>返回除最新版本以外的版本，请参见<a href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/client/Get.html#setTimeRange(long, long)">Get.setTimeRange（）</a></p>
<div class="paragraph">
<p>要检索小于或等于给定值的最新版本，从而在某个时间点给出记录的“最新”状态，只需使用0到所需版本的范围并将最大版本设置为1 。</p>
</div>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_default_get_example"><a class="anchor" href="#_default_get_example"></a> 28.2.2。默认获取示例</h4>
<div class="paragraph">
<p>以下“获取”将仅检索该行的当前版本</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="directive">public</span> <span class="directive">static</span> <span class="directive">final</span> <span class="type">byte</span><span class="type">[]</span> CF = <span class="string"><span class="delimiter">&quot;</span><span class="content">cf</span><span class="delimiter">&quot;</span></span>.getBytes();
<span class="directive">public</span> <span class="directive">static</span> <span class="directive">final</span> <span class="type">byte</span><span class="type">[]</span> ATTR = <span class="string"><span class="delimiter">&quot;</span><span class="content">attr</span><span class="delimiter">&quot;</span></span>.getBytes();
...
Get get = <span class="keyword">new</span> Get(Bytes.toBytes(<span class="string"><span class="delimiter">&quot;</span><span class="content">row1</span><span class="delimiter">&quot;</span></span>));
<span class="predefined-type">Result</span> r = table.get(get);
<span class="type">byte</span><span class="type">[]</span> b = r.getValue(CF, ATTR);  <span class="comment">// returns current version of value</span></code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_versioned_get_example"><a class="anchor" href="#_versioned_get_example"></a> 28.2.3。版本化获取示例</h4>
<div class="paragraph">
<p>下面的Get将返回该行的最后3个版本。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="directive">public</span> <span class="directive">static</span> <span class="directive">final</span> <span class="type">byte</span><span class="type">[]</span> CF = <span class="string"><span class="delimiter">&quot;</span><span class="content">cf</span><span class="delimiter">&quot;</span></span>.getBytes();
<span class="directive">public</span> <span class="directive">static</span> <span class="directive">final</span> <span class="type">byte</span><span class="type">[]</span> ATTR = <span class="string"><span class="delimiter">&quot;</span><span class="content">attr</span><span class="delimiter">&quot;</span></span>.getBytes();
...
Get get = <span class="keyword">new</span> Get(Bytes.toBytes(<span class="string"><span class="delimiter">&quot;</span><span class="content">row1</span><span class="delimiter">&quot;</span></span>));
get.setMaxVersions(<span class="integer">3</span>);  <span class="comment">// will return last 3 versions of row</span>
<span class="predefined-type">Result</span> r = table.get(get);
<span class="type">byte</span><span class="type">[]</span> b = r.getValue(CF, ATTR);  <span class="comment">// returns current version of value</span>
<span class="predefined-type">List</span>&lt;KeyValue&gt; kv = r.getColumn(CF, ATTR);  <span class="comment">// returns all versions of this column</span></code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_put_2"><a class="anchor" href="#_put_2"></a> 28.2.4。放</h4>
<div class="paragraph">
<p>进行看跌期权总是会创建一个新版本的<code>cell</code> ，在某个时间戳记上。默认情况下，系统使用服务器的<code>currentTimeMillis</code> ，但是您可以在每个列级别上自行指定版本（=长整数）。这意味着您可以分配过去或将来的时间，或将long值用于非时间目的。</p>
</div>
<div class="paragraph">
<p>要覆盖现有值，请在与要覆盖的单元格完全相同的行，列和版本上进行放置。</p>
</div>
<div class="sect4">
<h5 id="_implicit_version_example"><a class="anchor" href="#_implicit_version_example"></a>隐式版本示例</h5>
<div class="paragraph">
<p>HBase将使用当前时间对以下Put进行隐式版本控制。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="directive">public</span> <span class="directive">static</span> <span class="directive">final</span> <span class="type">byte</span><span class="type">[]</span> CF = <span class="string"><span class="delimiter">&quot;</span><span class="content">cf</span><span class="delimiter">&quot;</span></span>.getBytes();
<span class="directive">public</span> <span class="directive">static</span> <span class="directive">final</span> <span class="type">byte</span><span class="type">[]</span> ATTR = <span class="string"><span class="delimiter">&quot;</span><span class="content">attr</span><span class="delimiter">&quot;</span></span>.getBytes();
...
Put put = <span class="keyword">new</span> Put(Bytes.toBytes(row));
put.add(CF, ATTR, Bytes.toBytes( data));
table.put(put);</code></pre>
</div>
</div>
</div>
<div class="sect4">
<h5 id="_explicit_version_example"><a class="anchor" href="#_explicit_version_example"></a>显式版本示例</h5>
<div class="paragraph">
<p>下面的Put具有明确设置的版本时间戳。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="directive">public</span> <span class="directive">static</span> <span class="directive">final</span> <span class="type">byte</span><span class="type">[]</span> CF = <span class="string"><span class="delimiter">&quot;</span><span class="content">cf</span><span class="delimiter">&quot;</span></span>.getBytes();
<span class="directive">public</span> <span class="directive">static</span> <span class="directive">final</span> <span class="type">byte</span><span class="type">[]</span> ATTR = <span class="string"><span class="delimiter">&quot;</span><span class="content">attr</span><span class="delimiter">&quot;</span></span>.getBytes();
...
Put put = <span class="keyword">new</span> Put( Bytes.toBytes(row));
<span class="type">long</span> explicitTimeInMs = <span class="integer">555</span>;  <span class="comment">// just an example</span>
put.add(CF, ATTR, explicitTimeInMs, Bytes.toBytes(data));
table.put(put);</code></pre>
</div>
</div>
<div class="paragraph">
<p>注意：HBase在内部使用版本时间戳记来进行生存时间计算。通常最好避免自己设置此时间戳。首选使用行的单独时间戳属性，或将时间戳作为行键的一部分，或两者兼而有之。</p>
</div>
</div>
</div>
<div class="sect3">
<h4 id="version.delete"><a class="anchor" href="#version.delete"></a> 28.2.5。删除</h4>
<div class="paragraph">
<p>有三种不同类型的内部删除标记。请参阅Lars Hofhansl的博客，以了解有关他尝试添加其他内容的尝试，即“ <a href="http://hadoop-hbase.blogspot.com/2012/01/scanning-in-hbase.html">在HBase中扫描：前缀删除标记”</a> 。</p>
</div>
<div class="ulist">
<ul>
<li>
<p>删除：列的特定版本。</p>
</li>
<li>
<p>删除列：适用于列的所有版本。</p>
</li>
<li>
<p>删除族：针对特定ColumnFamily的所有列</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>删除整行时，HBase会在内部为每个ColumnFamily（即不是每个单独的列）创建一个逻辑删除。</p>
</div>
<div class="paragraph">
<p>通过创建<em>逻辑删除</em>标记来删除工作。例如，假设我们要删除一行。为此，您可以指定一个版本，否则默认情况下<code>currentTimeMillis</code>用来。这意味着<em>删除版本小于或等于此版本的所有单元格</em> 。HBase永远不会修改数据，例如，删除操作不会立即删除（或标记为已删除）存储文件中与删除条件相对应的条目。而是写了一个所谓的<em>墓碑</em> ，它将掩盖已删除的值。当HBase进行重大压缩时，将处理逻辑删除以实际删除无效值以及逻辑删除本身。如果删除行时指定的版本大于该行中任何值的版本，则可以考虑删除整个行。</p>
</div>
<div class="paragraph">
<p>有关删除和版本控制如何交互的信息性讨论，请参阅线程在用户邮件列表上出现“ <a href="http://comments.gmane.org/gmane.comp.java.hadoop.hbase.user/28421">放置w /时间戳”→Deleteall→“放置w /时间戳”失败</a> 。</p>
</div>
<div class="paragraph">
<p>另请参阅<a href="#keyvalue">键值</a> ，以获取有关内部键值格式的更多信息。</p>
</div>
<div class="paragraph">
<p>删除标记会在下一次大型存储压缩期间清除，除非<code>KEEP_DELETED_CELLS</code>选项在列族中设置（请参阅“ <a href="#cf.keep.deleted">保留已删除的单元格”</a> ）。要使删除保持可配置的时间，可以通过<em>hbase-site.xml中</em>的hbase.hstore.time.to.purge.deletes属性设置删除TTL。如果<code>hbase.hstore.time.to.purge.deletes</code>如果未将其设置为0或将其设置为0，则所有删除标记（包括将来带有时间戳的标记）都将在下一次重大压缩时清除。否则，将保留将来带有时间戳的删除标记，直到在该标记的时间戳加上的值所表示的时间之后发生的重大压缩为止。 <code>hbase.hstore.time.to.purge.deletes</code> ，以毫秒为单位。</p>
</div>
<div class="admonitionblock note">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-note" title="注意"></i>
</td>
<td class="content">此行为表示对HBase 0.94中引入的意外更改的修复，并在<a href="https://issues.apache.org/jira/browse/HBASE-10118">HBASE-10118中进行了修复</a> 。所做的更改已反向移植到HBase 0.94和更新的分支中。
</td>
</tr>
</tbody></table>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_current_limitations"><a class="anchor" href="#_current_limitations"></a> 28.3。电流限制</h3>
<div class="sect3">
<h4 id="_deletes_mask_puts"><a class="anchor" href="#_deletes_mask_puts"></a> 28.3.1。删除面膜放置</h4>
<div class="paragraph">
<p>删除蒙版看跌期权，甚至是输入删除后发生的看跌期权。参见<a href="https://issues.apache.org/jira/browse/HBASE-2256">HBASE-2256</a> 。请记住，删除操作会写入一个墓碑，该墓碑只有在下一次重大压缩运行后才会消失。假设您删除了所有内容⇐T。此后，您将使用时间戳记do T进行新的放置。此放置，即使它在删除后发生，也会被删除逻辑删除掩盖。进行认沽不会失败，但是当您进行认沽时，您会注意到认沽没有任何效果。在大型压实运行之后，它将重新开始工作。如果您为新的看跌期权连续使用不断增加的版本，那么这些问题应该不会成为问题。但是，即使您不在乎时间，它们也会发生：只需删除并立即放置就可以了，它们有可能在同一毫秒内发生。</p>
</div>
</div>
<div class="sect3">
<h4 id="major.compactions.change.query.results"><a class="anchor" href="#major.compactions.change.query.results"></a> 28.3.2。重大压缩会更改查询结果</h4>
<div class="paragraph">
<p><em>…在t1，t2和t3创建三个单元格版本，最大版本设置为2。因此，获取所有版本时，将仅返回t2和t3处的值。但是，如果您在t2或t3删除该版本，则t1的版本将再次出现。显然，一旦主要的压实运行后，这种行为将不会是这样了......（</em>中看到的<em>垃圾收集</em> <a href="http://outerthought.org/blog/417-ot.html">弯曲时间HBase的</a> 。）</p>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="dm.sort"><a class="anchor" href="#dm.sort"></a> 29。排序</h2>
<div class="sectionbody">
<div class="paragraph">
<p>HBase的所有数据模型操作均按排序顺序返回数据。首先是按行，然后是ColumnFamily，然后是列限定符，最后是时间戳（反向排序，因此首先返回最新记录）。</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="dm.column.metadata"><a class="anchor" href="#dm.column.metadata"></a> 30岁列元数据</h2>
<div class="sectionbody">
<div class="paragraph">
<p>在ColumnFamily的内部KeyValue实例之外没有任何列元数据存储。因此，尽管HBase不仅可以支持每行大量列，而且还可以支持行之间的异构列集，但您有责任跟踪列名。</p>
</div>
<div class="paragraph">
<p>获取ColumnFamily存在的一组完整列的唯一方法是处理所有行。有关HBase如何在内部存储数据的更多信息，请参见<a href="#keyvalue">keyvalue</a> 。</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_joins"><a class="anchor" href="#_joins"></a> 31。加入</h2>
<div class="sectionbody">
<div class="paragraph">
<p>HBase是否支持联接是dist列表上的一个常见问题，并且有一个简单的答案：它至少在RDBMS支持联接的方式上不支持（例如，在SQL中使用等联接或外部联接） ）。如本章所述，HBase中的读取数据模型操作是Get和Scan。</p>
</div>
<div class="paragraph">
<p>但是，这并不意味着您的应用程序不支持等效的联接功能，而是您必须自己做。两种主要策略是在写入HBase时对数据进行非规范化，或者在应用程序或MapReduce代码中具有查找表并在HBase表之间进行联接（并且正如RDBMS所演示的那样，有多种策略可用于此操作，具体取决于表，例如嵌套循环与哈希联接）。那么哪种方法最好呢？这取决于您要尝试执行的操作，因此，没有一个适用于每个用例的答案。</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_acid"><a class="anchor" href="#_acid"></a> 32。酸</h2>
<div class="sectionbody">
<div class="paragraph">
<p>请参阅<a href="http://hbase.apache.org/acid-semantics.html">ACID语义</a> 。Lars Hofhansl还在<a href="http://hadoop-hbase.blogspot.com/2012/03/acid-in-hbase.html">HBase中</a>撰写了有关<a href="http://hadoop-hbase.blogspot.com/2012/03/acid-in-hbase.html">ACID</a>的说明。</p>
</div>
</div>
</div>
<h1 id="schema" class="sect0"><a class="anchor" href="#schema"></a> HBase和架构设计</h1>
<div class="openblock partintro">
<div class="content">Ian Varley的硕士论文《 <a href="http://ianvarley.com/UT/MR/Varley_MastersReport_Full_2009-08-07.pdf">无关系：非关系数据库的混合祝福》</a>很好地介绍了各种非rdbms数据存储上的优缺点模型。另外，读<a href="#keyvalue">键值</a>为HBase的存储如何在内部数据，并在部分<a href="#schema.casestudies">schema.casestudies</a> 。
</div>
</div>
<div class="sect1">
<h2 id="schema.creation"><a class="anchor" href="#schema.creation"></a> 33。模式创建</h2>
<div class="sectionbody">
<div class="paragraph">
<p>可以使用<a href="#shell">Apache HBase Shell</a>或Java API中的<a href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/client/Admin.html">Admin</a>创建或更新HBase模式。</p>
</div>
<div class="paragraph">
<p>进行ColumnFamily修改时，必须禁用表，例如：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="predefined-type">Configuration</span> config = HBaseConfiguration.create();
Admin admin = <span class="keyword">new</span> Admin(conf);
<span class="predefined-type">String</span> table = <span class="string"><span class="delimiter">&quot;</span><span class="content">myTable</span><span class="delimiter">&quot;</span></span>;

admin.disableTable(table);

HColumnDescriptor cf1 = ...;
admin.addColumn(table, cf1);      <span class="comment">// adding new ColumnFamily</span>
HColumnDescriptor cf2 = ...;
admin.modifyColumn(table, cf2);    <span class="comment">// modifying existing ColumnFamily</span>

admin.enableTable(table);</code></pre>
</div>
</div>
<div class="paragraph">
<p>有关配置客户端连接的更多信息，请参见<a href="#client_dependencies">客户端依赖性</a> 。</p>
</div>
<div class="admonitionblock note">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-note" title="注意"></i>
</td>
<td class="content">0.92.x代码库支持联机模式更改，但是0.90.x代码库要求禁用该表。
</td>
</tr>
</tbody></table>
</div>
<div class="sect2">
<h3 id="schema.updates"><a class="anchor" href="#schema.updates"></a> 33.1。架构更新</h3>
<div class="paragraph">
<p>当对Table或ColumnFamilies进行更改（例如，区域大小，块大小）时，这些更改将在下次进行重大压缩时生效，并且StoreFiles将被重写。</p>
</div>
<div class="paragraph">
<p>有关StoreFiles的更多信息，请参见<a href="#store">store</a> 。</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="number.of.cfs"><a class="anchor" href="#number.of.cfs"></a> 34。关于列族的数量</h2>
<div class="sectionbody">
<div class="paragraph">
<p>HBase当前不能很好地处理超过两个或三个列族的任何事物，因此请保持架构中列族的数量少。当前，刷新和压缩是在每个区域的基础上进行的，因此，如果一个列族正在承载大量要进行刷新的数据，即使相邻族也将被刷新，即使它们携带的数据量很小。当存在许多色谱柱系列时，冲洗和压实相互作用会导致大量不必要的I / O（通过更改冲洗和压实以在每个色谱柱族的基础上解决）。有关压缩的更多信息，请参见<a href="#compaction">[compaction]</a> 。</p>
</div>
<div class="paragraph">
<p>如果可以，请尝试使用一个列族。仅在数据访问通常是列范围的情况下才引入第二和第三列族。即，您查询一个列族或另一个列族，但通常一次不查询。</p>
</div>
<div class="sect2">
<h3 id="number.of.cfs.card"><a class="anchor" href="#number.of.cfs.card"></a> 34.1。ColumnFamilies的基数</h3>
<div class="paragraph">
<p>在单个表中存在多个ColumnFamilies的地方，请注意基数（即行数）。如果ColumnFamilyA有100万行，而ColumnFamilyB有10亿行，则ColumnFamilyA的数据可能会分布在许多区域（和RegionServers）中。这使得对ColumnFamilyA进行批量扫描的效率较低。</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="rowkey.design"><a class="anchor" href="#rowkey.design"></a> 35岁行键设计</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_hotspotting"><a class="anchor" href="#_hotspotting"></a> 35.1。热点发现</h3>
<div class="paragraph">
<p>HBase中的行按行键按字典顺序排序。该设计针对扫描进行了优化，使您可以将相关行或将一起读取的行彼此靠近存储。但是，设计不当的行键是引起<em class="firstterm">热点</em>的常见<em class="firstterm">原因</em> 。当大量客户端流量定向到群集的一个节点或仅几个节点时，就会发生热点。此流量可能表示读取，写入或其他操作。流量使负责托管该区域的单台计算机不堪重负，从而导致性能下降并可能导致区域不可用。这也可能对由同一区域服务器托管的其他区域产生不利影响，因为该主机无法满足请求的负载。设计数据访问模式非常重要，这样才能充分，均匀地利用群集。</p>
</div>
<div class="paragraph">
<p>为防止写入时出现热点，请设计行键，以使确实确实需要在同一区域中的行存在，但从更大的角度看，数据被写入集群中的多个区域，而不是一次写入一个区域。下面介绍了一些避免热点的常用技术，以及它们的一些优点和缺点。</p>
</div>
<div class="paragraph">
<div class="title">盐</div>
<p>从这种意义上讲，加盐与加密无关，而是指将随机数据添加到行密钥的开头。在这种情况下，加盐是指在行键上添加一个随机分配的前缀，以使其排序不同于其他方式。可能的前缀数量对应于您要分布数据的区域数量。如果您在其他分布更均匀的行中反复出现一些“热”行键模式，则盐析会有所帮助。考虑下面的示例，该示例表明加盐可以将写入负载分散到多个RegionServer上，并说明对读取的某些负面影响。</p>
</div>
<div class="exampleblock">
<div class="title">示例15加盐的例子</div>
<div class="content">
<div class="paragraph">
<p>假设您具有以下行键列表，并且对表进行了拆分，以使字母表中的每个字母都有一个区域。前缀“ a”是一个区域，前缀“ b”是另一个区域。在此表中，所有以'f'开头的行都在同一区域中。本示例重点介绍具有以下键的行：</p>
</div>
<div class="listingblock">
<div class="content">
<pre>foo0001
foo0002
foo0003
foo0004</pre>
</div>
</div>
<div class="paragraph">
<p>现在，假设您想将它们分布在四个不同的区域。您决定使用四种不同的盐： <code>a</code> ， <code>b</code> ， <code>c</code>和<code>d</code> 。在这种情况下，这些字母前缀中的每一个都将位于不同的区域。应用盐后，将改为使用以下行键。由于您现在可以写入四个单独的区域，因此理论上写入时的吞吐量是所有写入相同区域时的吞吐量的四倍。</p>
</div>
<div class="listingblock">
<div class="content">
<pre>a-foo0003
b-foo0001
c-foo0004
d-foo0002</pre>
</div>
</div>
<div class="paragraph">
<p>然后，如果您添加另一行，则会随机为其分配四个可能的盐值之一，并最终靠近现有行之一。</p>
</div>
<div class="listingblock">
<div class="content">
<pre>a-foo0003
b-foo0001
c-foo0003
c-foo0004
d-foo0002</pre>
</div>
</div>
<div class="paragraph">
<p>由于此分配是随机的，因此，如果要按字典顺序检索行，则需要做更多的工作。这样，盐化会尝试增加写入的吞吐量，但是会在读取期间增加成本。</p>
</div>
</div>
</div>
<div class="paragraph">
<div class="title">散列</div>
<p>代替随机分配，您可以使用单向<em class="firstterm">散列</em> ，该<em class="firstterm">散列</em>将导致始终使用相同的前缀对给定的行“加盐”，以这种方式将负载分散到RegionServer上，但允许在读取期间进行可预测性。使用确定性哈希可以使客户端重建完整的行键，并使用Get操作正常检索该行。</p>
</div>
<div class="exampleblock">
<div class="title">示例16。散列示例</div>
<div class="content">给定上面盐化示例中的相同情况，您可以改为应用单向哈希，这将导致具有键的行<code>foo0003</code>总是并且可以预期地收到<code>a</code>字首。然后，要检索该行，您将已经知道密钥。您还可以优化事物，例如使某些对密钥始终位于同一区域。
</div>
</div>
<div class="paragraph">
<div class="title">倒转钥匙</div>
<p>防止热点的第三个常见技巧是反转固定宽度或数字行键，以使变化最频繁的部分（最低有效位）在第一位。这有效地使行键随机化，但牺牲了行排序属性。</p>
</div>
<div class="paragraph">
<p>请参阅<a href="https://communities.intel.com/community/itpeernetwork/datastack/blog/2013/11/10/discussion-on-designing-hbase-tables" class="bare">https://communities.intel.com/community/itpeernetwork/datastack/blog/2013/11/10/discussion-on-designing-hbase-tables</a>以及Phoenix项目中<a href="http://phoenix.apache.org/salted.html">关于咸表的文章</a> ，以及有关避免热点的更多信息，请参见<a href="https://issues.apache.org/jira/browse/HBASE-11682">HBASE-11682</a>的注释。</p>
</div>
</div>
<div class="sect2">
<h3 id="timeseries"><a class="anchor" href="#timeseries"></a> 35.2。单调增加行键/时间序列数据</h3>
<div class="paragraph">
<p>在汤姆·怀特（Tom White）的《 <a href="http://oreilly.com/catalog/9780596521981">Hadoop：权威指南》</a> （O'Reilly）的HBase章节中，有一个优化注释，用于注意一种现象，在该现象中，导入过程与所有客户齐心协力地敲击桌子的一个区域（因此，是一个节点），然后移到下一个区域，依此类推。随着单调增加行键（即使用时间戳），这种情况将会发生。请参见IKai Lan的漫画，这是关于为什么单调递增的行键在类似BigTable的数据存储区中会出现问题： <a href="http://ikaisays.com/2011/01/25/app-engine-datastore-tip-monotonically-increasing-values-are-bad/">单调递增的值是不好的</a> 。可以通过将输入记录随机化而不是按排序顺序来减轻单调递增键在单个区域上的堆积，但是通常最好避免使用时间戳或序列（例如1、2、3）作为行键。</p>
</div>
<div class="paragraph">
<p>如果确实需要将时间序列数据上传到HBase，则应学习<a href="http://opentsdb.net/">OpenTSDB</a>作为成功的示例。它具有描述链接的页面：它在HBase中使用的<a href="http://opentsdb.net/schema.html">架构</a> 。OpenTSDB中的密钥格式实际上是[metric_type] [event_timestamp]，乍一看似乎与先前关于不使用时间戳作为密钥的建议相矛盾。但是，不同之处在于时间戳不在密钥的<em>领先</em>位置，而设计假设是存在数十个或数百个（或更多）不同的度量标准类型。因此，即使连续输入数据流混合使用各种度量标准类型，Put也会分布在表中区域的各个点上。</p>
</div>
<div class="paragraph">
<p>有关某些行键设计示例，请参见<a href="#schema.casestudies">schema.casestudies</a> 。</p>
</div>
</div>
<div class="sect2">
<h3 id="keysize"><a class="anchor" href="#keysize"></a> 35.3。尝试最小化行和列的大小</h3>
<div class="paragraph">
<p>在HBase中，值总是随其坐标一起运送；当单元格值通过系统时，将始终伴随其行，列名和时间戳记。如果行名和列名很大，尤其是与单元格值的大小相比，则可能会遇到一些有趣的情况。Marc Limotte在<a href="https://issues.apache.org/jira/browse/HBASE-3551?page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel&focusedCommentId=13005272#comment-13005272">HBASE-3551</a>的尾部描述了这种情况（推荐！）。其中，为方便随机访问而保存在HBase存储文件（ <a href="#hfile">StoreFile（HFile）</a> ）上的索引可能最终会占用HBase分配的RAM的大块，因为单元值坐标很大。上面引用的注释中的Mark建议增加块大小，以便在存储文件索引中的条目以较大的间隔发生或修改表模式，从而使行和列名更小。压缩还将使索引更大。请在用户邮件列表中查看有关<a href="http://search-hadoop.com/m/hemBv1LiN4Q1/a+question+storefileIndexSize&subj=a+question+storefileIndexSize">问题storefileIndexSize</a>的线程。</p>
</div>
<div class="paragraph">
<p>在大多数情况下，效率低下并不重要。不幸的是，这是他们这样做的情况。无论为ColumnFamilies，属性和行键选择了哪种模式，它们都可以在数据中重复数十亿次。</p>
</div>
<div class="paragraph">
<p>有关HBase内部存储数据的更多信息，请参见<a href="#keyvalue">keyvalue</a> ，以了解为什么这很重要。</p>
</div>
<div class="sect3">
<h4 id="keysize.cf"><a class="anchor" href="#keysize.cf"></a> 35.3.1。列族</h4>
<div class="paragraph">
<p>尝试使ColumnFamily名称尽可能的小，最好是一个字符（例如，“ d”表示数据/默认值）。</p>
</div>
<div class="paragraph">
<p>有关HBase内部存储数据的更多信息，请参见<a href="#keyvalue">[keyvalue]</a> ，以了解为什么这很重要。</p>
</div>
</div>
<div class="sect3">
<h4 id="keysize.attributes"><a class="anchor" href="#keysize.attributes"></a> 35.3.2。属性</h4>
<div class="paragraph">
<p>尽管详细的属性名称（例如“ myVeryImportantAttribute”）更易于阅读，但更喜欢使用较短的属性名称（例如“ via”）存储在HBase中。</p>
</div>
<div class="paragraph">
<p>有关HBase内部存储数据的更多信息，请参见<a href="#keyvalue">keyvalue</a> ，以了解为什么这很重要。</p>
</div>
</div>
<div class="sect3">
<h4 id="keysize.row"><a class="anchor" href="#keysize.row"></a> 35.3.3。行键长度</h4>
<div class="paragraph">
<p>使其尽可能短，以使它们仍可用于所需的数据访问（例如，获取与扫描）。对于数据访问无用的短键并不比具有更好的获取/扫描属性的长键更好。设计行键时需要权衡取舍。</p>
</div>
</div>
<div class="sect3">
<h4 id="keysize.patterns"><a class="anchor" href="#keysize.patterns"></a> 35.3.4。字节模式</h4>
<div class="paragraph">
<p>长为8个字节。您可以在这八个字节中存储最多18,446,744,073,709,551,615个无符号数。如果将此数字存储为字符串（假定每个字符一个字节），则需要将近3倍的字节。</p>
</div>
<div class="paragraph">
<p>不服气吗？下面是一些示例代码，您可以自己运行。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="comment">// long</span>
<span class="comment">//</span>
<span class="type">long</span> l = <span class="integer">1234567890L</span>;
<span class="type">byte</span><span class="type">[]</span> lb = Bytes.toBytes(l);
<span class="predefined-type">System</span>.out.println(<span class="string"><span class="delimiter">&quot;</span><span class="content">long bytes length: </span><span class="delimiter">&quot;</span></span> + lb.length);   <span class="comment">// returns 8</span>

<span class="predefined-type">String</span> s = <span class="predefined-type">String</span>.valueOf(l);
<span class="type">byte</span><span class="type">[]</span> sb = Bytes.toBytes(s);
<span class="predefined-type">System</span>.out.println(<span class="string"><span class="delimiter">&quot;</span><span class="content">long as string length: </span><span class="delimiter">&quot;</span></span> + sb.length);    <span class="comment">// returns 10</span>

<span class="comment">// hash</span>
<span class="comment">//</span>
<span class="predefined-type">MessageDigest</span> md = <span class="predefined-type">MessageDigest</span>.getInstance(<span class="string"><span class="delimiter">&quot;</span><span class="content">MD5</span><span class="delimiter">&quot;</span></span>);
<span class="type">byte</span><span class="type">[]</span> digest = md.digest(Bytes.toBytes(s));
<span class="predefined-type">System</span>.out.println(<span class="string"><span class="delimiter">&quot;</span><span class="content">md5 digest bytes length: </span><span class="delimiter">&quot;</span></span> + digest.length);    <span class="comment">// returns 16</span>

<span class="predefined-type">String</span> sDigest = <span class="keyword">new</span> <span class="predefined-type">String</span>(digest);
<span class="type">byte</span><span class="type">[]</span> sbDigest = Bytes.toBytes(sDigest);
<span class="predefined-type">System</span>.out.println(<span class="string"><span class="delimiter">&quot;</span><span class="content">md5 digest as string length: </span><span class="delimiter">&quot;</span></span> + sbDigest.length);    <span class="comment">// returns 26</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>不幸的是，使用类型的二进制表示形式会使您的数据难以在代码外部读取。例如，这是在增加值时在外壳中看到的内容：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">hbase(main):<span class="octal">001</span>:<span class="integer">0</span>&gt; incr <span class="string"><span class="delimiter">'</span><span class="content">t</span><span class="delimiter">'</span></span>, <span class="string"><span class="delimiter">'</span><span class="content">r</span><span class="delimiter">'</span></span>, <span class="string"><span class="delimiter">'</span><span class="content">f:q</span><span class="delimiter">'</span></span>, <span class="integer">1</span>
COUNTER VALUE = <span class="integer">1</span>

hbase(main):<span class="octal">002</span>:<span class="integer">0</span>&gt; get <span class="string"><span class="delimiter">'</span><span class="content">t</span><span class="delimiter">'</span></span>, <span class="string"><span class="delimiter">'</span><span class="content">r</span><span class="delimiter">'</span></span>
COLUMN                                        CELL
 f:q                                          timestamp=<span class="integer">1369163040570</span>, value=<span class="error">\</span>x00<span class="error">\</span>x00<span class="error">\</span>x00<span class="error">\</span>x00<span class="error">\</span>x00<span class="error">\</span>x00<span class="error">\</span>x00<span class="error">\</span>x01
<span class="integer">1</span> row(s) in <span class="float">0.0310</span> seconds</code></pre>
</div>
</div>
<div class="paragraph">
<p>外壳程序会尽力打印字符串，在这种情况下，它决定只打印十六进制。区域名称内的行键也会发生同样的情况。如果您知道要存储的内容，可以这样做，但是如果可以将任意数据放在相同的单元格中，则可能也无法读取。这是主要的权衡。</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="reverse.timestamp"><a class="anchor" href="#reverse.timestamp"></a> 35.4。反向时间戳</h3>
<div class="admonitionblock note">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-note" title="注意"></i>
</td>
<td class="content">
<div class="title">反向扫描API</div>
<div class="paragraph">
<p><a href="https://issues.apache.org/jira/browse/HBASE-4811">HBASE-4811</a>实现了一个API，可以反向扫描表或表中的范围，从而减少了为进行正向或反向扫描而优化架构的需求。HBase 0.98和更高版本中提供了此功能。有关更多信息，请参见<a href="https://hbase.apache.org/apidocs/org/apache/hadoop/hbase/client/Scan.html#setReversed%28boolean" class="bare">https://hbase.apache.org/apidocs/org/apache/hadoop/hbase/client/Scan.html#setReversed%28boolean</a> 。</p>
</div>
</td>
</tr>
</tbody></table>
</div>
<div class="paragraph">
<p>数据库处理中的一个常见问题是快速找到值的最新版本。使用反向时间戳作为键的一部分的技术可以在此问题的特殊情况下极大地帮助您。该技术还可以在汤姆·怀特（Tom White）的《 Hadoop：权威指南》（O'Reilly）的HBase一章中找到，该技术涉及附加（ <code>Long.MAX_VALUE - timestamp</code> ）到任何键的末尾，例如[key] [reverse_timestamp]。</p>
</div>
<div class="paragraph">
<p>通过执行[key]扫描并获取第一条记录，可以找到表中[key]的最新值。由于HBase键是按排序顺序排列的，因此此键在[key]的任何较旧的行键之前进行排序，因此是第一个。</p>
</div>
<div class="paragraph">
<p>将使用此技术代替使用<a href="#schema.versions">“版本号”，</a>以“永久”（或很长时间）保留所有版本，并同时使用相同的扫描技术快速获取对任何其他版本的访问权限。</p>
</div>
</div>
<div class="sect2">
<h3 id="rowkey.scope"><a class="anchor" href="#rowkey.scope"></a> 35.5。Rowkey和ColumnFamilies</h3>
<div class="paragraph">
<p>行键的作用域为ColumnFamilies。因此，相同的行键可以存在于表中的每个ColumnFamily中而不会发生冲突。</p>
</div>
</div>
<div class="sect2">
<h3 id="changing.rowkeys"><a class="anchor" href="#changing.rowkeys"></a> 35.6。行键的不变性</h3>
<div class="paragraph">
<p>行键不能更改。可以在表中“更改”它们的唯一方法是删除行然后将其重新插入。这是HBase dist-list上的一个相当普遍的问题，因此第一次（和/或在插入大量数据之前）正确获取行键是值得的。</p>
</div>
</div>
<div class="sect2">
<h3 id="rowkey.regionsplits"><a class="anchor" href="#rowkey.regionsplits"></a> 35.7。RowKey与区域分割之间的关系</h3>
<div class="paragraph">
<p>如果您预先分割了表格，那么了解行键如何在区域边界上分布<em>至关重要</em> 。作为为什么如此重要的示例，请考虑使用可显示的十六进制字符作为键的开头位置的示例（例如，“ 0000000000000000”到“ ffffffffffffffff”）。通过运行这些关键范围<code>Bytes.split</code> （这是在中创建区域时使用的拆分策略<code>Admin.createTable(byte[] startKey, byte[] endKey, numRegions)</code> 10个地区将产生以下分裂...</p>
</div>
<div class="listingblock">
<div class="content">
<pre>48 48 48 48 48 48 48 48 48 48 48 48 48 48 48 48                                // 0
54 -10 -10 -10 -10 -10 -10 -10 -10 -10 -10 -10 -10 -10 -10 -10                 // 6
61 -67 -67 -67 -67 -67 -67 -67 -67 -67 -67 -67 -67 -67 -67 -68                 // =
68 -124 -124 -124 -124 -124 -124 -124 -124 -124 -124 -124 -124 -124 -124 -126  // D
75 75 75 75 75 75 75 75 75 75 75 75 75 75 75 72                                // K
82 18 18 18 18 18 18 18 18 18 18 18 18 18 18 14                                // R
88 -40 -40 -40 -40 -40 -40 -40 -40 -40 -40 -40 -40 -40 -40 -44                 // X
95 -97 -97 -97 -97 -97 -97 -97 -97 -97 -97 -97 -97 -97 -97 -102                // _
102 102 102 102 102 102 102 102 102 102 102 102 102 102 102 102                // f</pre>
</div>
</div>
<div class="paragraph">
<p>（注意：引导字节在右侧列为注释。）假设第一个分割为'0'，最后一个分割为'f'，一切都很好，对吗？没那么快。</p>
</div>
<div class="paragraph">
<p>问题在于所有数据都将在前两个区域和最后一个区域堆积，从而造成“块状”（可能还有“热”）区域问题。要了解原因，请参考<a href="http://www.asciitable.com">ASCII表</a> 。“ 0”是字节48，而“ f”是字节102，但是字节值（字节58至96）之间存在巨大差异，该间隙<em>永远不会出现在此键空间中，</em>因为唯一的值是[0-9]和[af ]。因此，中间区域将永远不会被使用。为了使此示例键空间可以进行预拆分，需要自定义拆分定义（即，不依赖于内置的split方法）。</p>
</div>
<div class="paragraph">
<p>第1课：通常，最佳做法是预先分割表，但是您需要以能够在键空间中访问所有区域的方式预先分割表。尽管此示例演示了十六进制键空间的问题，但<em>任何</em>键空间都可能发生相同的问题。了解您的数据。</p>
</div>
<div class="paragraph">
<p>第2课：虽然通常不建议这样做，但是只要在键空间中可访问所有创建的区域，使用十六进制键（更常见的是可显示的数据）仍可与预分割表一起使用。</p>
</div>
<div class="paragraph">
<p>总结这个例子，下面是一个例子，说明如何为十六进制键预先创建适当的分割：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="directive">public</span> <span class="directive">static</span> <span class="type">boolean</span> createTable(Admin admin, HTableDescriptor table, <span class="type">byte</span><span class="type">[]</span><span class="type">[]</span> splits)
<span class="directive">throws</span> <span class="exception">IOException</span> {
  <span class="keyword">try</span> {
    admin.createTable( table, splits );
    <span class="keyword">return</span> <span class="predefined-constant">true</span>;
  } <span class="keyword">catch</span> (TableExistsException e) {
    logger.info(<span class="string"><span class="delimiter">&quot;</span><span class="content">table </span><span class="delimiter">&quot;</span></span> + table.getNameAsString() + <span class="string"><span class="delimiter">&quot;</span><span class="content"> already exists</span><span class="delimiter">&quot;</span></span>);
    <span class="comment">// the table already exists...</span>
    <span class="keyword">return</span> <span class="predefined-constant">false</span>;
  }
}

<span class="directive">public</span> <span class="directive">static</span> <span class="type">byte</span><span class="type">[]</span><span class="type">[]</span> getHexSplits(<span class="predefined-type">String</span> startKey, <span class="predefined-type">String</span> endKey, <span class="type">int</span> numRegions) {
  <span class="type">byte</span><span class="type">[]</span><span class="type">[]</span> splits = <span class="keyword">new</span> <span class="type">byte</span>[numRegions-<span class="integer">1</span>]<span class="type">[]</span>;
  <span class="predefined-type">BigInteger</span> lowestKey = <span class="keyword">new</span> <span class="predefined-type">BigInteger</span>(startKey, <span class="integer">16</span>);
  <span class="predefined-type">BigInteger</span> highestKey = <span class="keyword">new</span> <span class="predefined-type">BigInteger</span>(endKey, <span class="integer">16</span>);
  <span class="predefined-type">BigInteger</span> range = highestKey.subtract(lowestKey);
  <span class="predefined-type">BigInteger</span> regionIncrement = range.divide(<span class="predefined-type">BigInteger</span>.valueOf(numRegions));
  lowestKey = lowestKey.add(regionIncrement);
  <span class="keyword">for</span>(<span class="type">int</span> i=<span class="integer">0</span>; i &lt; numRegions-<span class="integer">1</span>;i++) {
    <span class="predefined-type">BigInteger</span> key = lowestKey.add(regionIncrement.multiply(<span class="predefined-type">BigInteger</span>.valueOf(i)));
    <span class="type">byte</span><span class="type">[]</span> b = <span class="predefined-type">String</span>.format(<span class="string"><span class="delimiter">&quot;</span><span class="content">%016x</span><span class="delimiter">&quot;</span></span>, key).getBytes();
    splits[i] = b;
  }
  <span class="keyword">return</span> splits;
}</code></pre>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="schema.versions"><a class="anchor" href="#schema.versions"></a> 36。版本数</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="schema.versions.max"><a class="anchor" href="#schema.versions.max"></a> 36.1。最大版本数</h3>
<div class="paragraph">
<p>通过<a href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/HColumnDescriptor.html">HColumnDescriptor</a>为每个列系列配置要存储的最大行版本数。最高版本的默认值为1。这是一个重要的参数，因为如上述<a href="#datamodel">数据模型</a>部HBase的<em>不</em>覆盖行值，而是通过时间（和限定符），而存储的每行不同的值。大型压缩期间将删除多余的版本。取决于应用程序的需要，最大版本数可能需要增加或减少。</p>
</div>
<div class="paragraph">
<p>不建议将最大版本数设置为过高的级别（例如，数百个或更多），除非您非常喜欢那些旧值，因为这将大大增加StoreFile的大小。</p>
</div>
</div>
<div class="sect2">
<h3 id="schema.minversions"><a class="anchor" href="#schema.minversions"></a> 36.2。最低版本数</h3>
<div class="paragraph">
<p>与最大行版本数类似，通过<a href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/HColumnDescriptor.html">HColumnDescriptor</a>为每个列系列配置要保留的最小行版本数。最低版本的默认值为0，这表示该功能已禁用。参数与时间的生存参数一起使用，并且可以与行版本的数量参数，以允许配置，例如“保留的数据的最后Ť分钟值得，至多N个版本进行组合行版本的最小数量， <em>但至少保持M个版本在</em> “ <em>附近</em> ”（其中M是最小行版本数的值，M <n). this="" parameter="" should="" only="" be="" set="" when="" time-to-live="" is="" enabled="" for="" a="" column="" family="" and="" must="" less="" than="" the="" number="" of="" row="" versions.<="" p="">
</n).></p></div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="supported.datatypes"><a class="anchor" href="#supported.datatypes"></a> 37。支持的数据类型</h2>
<div class="sectionbody">
<div class="paragraph">
<p>HBase通过<a href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/client/Put.html">Put</a>和<a href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/client/Result.html">Result</a>支持“ bytes-in / bytes-out”接口，因此任何可以转换为字节数组的内容都可以存储为值。输入可以是字符串，数字，复杂对象甚至是图像，只要它们可以呈现为字节即可。</p>
</div>
<div class="paragraph">
<p>值的大小有实际限制（例如，在HBase中存储10-50MB对象可能要求太多）；在邮件列表中搜索有关此主题的对话。HBase中的所有行均符合<a href="#datamodel">Data Model</a> ，其中包括版本控制。设计时要考虑到这一点，以及ColumnFamily的块大小。</p>
</div>
<div class="sect2">
<h3 id="_counters"><a class="anchor" href="#_counters"></a> 37.1。专柜</h3>
<div class="paragraph">
<p>需要特别提及的一种受支持的数据类型是“计数器”（即进行原子原子递增的能力）。见<a href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/client/Table.html#increment%28org.apache.hadoop.hbase.client.Increment%29">增量</a> <code>Table</code> 。</p>
</div>
<div class="paragraph">
<p>计数器同步在RegionServer上完成，而不在客户端上完成。</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="schema.joins"><a class="anchor" href="#schema.joins"></a> 38。加入</h2>
<div class="sectionbody">
<div class="paragraph">
<p>如果您有多个表，请不要忘记将<a href="#joins">[joins]</a>纳入模式设计的可能性。</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="ttl"><a class="anchor" href="#ttl"></a> 39。生存时间（TTL）</h2>
<div class="sectionbody">
<div class="paragraph">
<p>ColumnFamilies可以设置以秒为单位的TTL长度，并且一旦达到到期时间，HBase将自动删除行。这适用于一行的<em>所有</em>版本-甚至是当前版本。在HBase中为该行编码的TTL时间以UTC指定。</p>
</div>
<div class="paragraph">
<p>较小的压缩会删除仅包含过期行的存储文件。设置<code>hbase.store.delete.expired.storefile</code>至<code>false</code>禁用此功能。将最小版本数设置为非0也会禁用此功能。</p>
</div>
<div class="paragraph">
<p>有关更多信息，请参见<a href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/HColumnDescriptor.html">HColumnDescriptor</a> 。</p>
</div>
<div class="paragraph">
<p>HBase的最新版本还支持设置每个单元的生存时间。有关更多信息，请参见<a href="https://issues.apache.org/jira/browse/HBASE-10560">HBASE-10560</a> 。使用mutation＃setTTL将单元TTL作为属性提交给突变请求（追加，增量，放置等）。如果设置了TTL属性，它将应用于通过该操作在服务器上更新的所有单元。单元TTL处理和ColumnFamily TTL之间有两个显着区别：</p>
</div>
<div class="ulist">
<ul>
<li>
<p>单元TTL以毫秒为单位而不是秒。</p>
</li>
<li>
<p>单元TTL无法将单元的有效寿命延长到ColumnFamily级别TTL设置之外。</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect1">
<h2 id="cf.keep.deleted"><a class="anchor" href="#cf.keep.deleted"></a> 40保留删除的单元格</h2>
<div class="sectionbody">
<div class="paragraph">
<p>默认情况下，删除标记可追溯到时间的开始。因此，即使“获取”或“扫描”操作指示放置删除标记之前的时间范围，“ <a href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/client/Get.html">获取”</a>或“ <a href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/client/Scan.html">扫描”</a>操作也不会看到已删除的单元格（行或列）。</p>
</div>
<div class="paragraph">
<p>ColumnFamilies可以选择保留已删除的单元格。在这种情况下，只要这些操作指定的时间范围在影响该单元格的任何删除的时间戳记之前结束，仍可以检索已删除的单元格。即使存在删除操作，这也可以进行时间点查询。</p>
</div>
<div class="paragraph">
<p>删除的单元格仍然受TTL的约束，并且删除的单元格永远不会超过“最大版本数”。新的“原始”扫描选项将返回所有已删除的行和删除标记。</p>
</div>
<div class="exampleblock">
<div class="title">示例17改变价值<code>KEEP_DELETED_CELLS</code>使用HBase Shell</div>
<div class="content">
<div class="listingblock">
<div class="content">
<pre>hbase&gt; hbase&gt; alter ‘t1′, NAME =&gt; ‘f1′, KEEP_DELETED_CELLS =&gt; true</pre>
</div>
</div>
</div>
</div>
<div class="exampleblock">
<div class="title">示例18改变价值<code>KEEP_DELETED_CELLS</code>使用API</div>
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">...
HColumnDescriptor.setKeepDeletedCells(<span class="predefined-constant">true</span>);
...</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>让我们来说明设置<code>KEEP_DELETED_CELLS</code>表格上的属性。</p>
</div>
<div class="paragraph">
<p>首先，没有：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">create <span class="string"><span class="delimiter">'</span><span class="content">test</span><span class="delimiter">'</span></span>, {NAME=&gt;<span class="string"><span class="delimiter">'</span><span class="content">e</span><span class="delimiter">'</span></span>, VERSIONS=&gt;<span class="integer">2147483647</span>}
put <span class="string"><span class="delimiter">'</span><span class="content">test</span><span class="delimiter">'</span></span>, <span class="string"><span class="delimiter">'</span><span class="content">r1</span><span class="delimiter">'</span></span>, <span class="string"><span class="delimiter">'</span><span class="content">e:c1</span><span class="delimiter">'</span></span>, <span class="string"><span class="delimiter">'</span><span class="content">value</span><span class="delimiter">'</span></span>, <span class="integer">10</span>
put <span class="string"><span class="delimiter">'</span><span class="content">test</span><span class="delimiter">'</span></span>, <span class="string"><span class="delimiter">'</span><span class="content">r1</span><span class="delimiter">'</span></span>, <span class="string"><span class="delimiter">'</span><span class="content">e:c1</span><span class="delimiter">'</span></span>, <span class="string"><span class="delimiter">'</span><span class="content">value</span><span class="delimiter">'</span></span>, <span class="integer">12</span>
put <span class="string"><span class="delimiter">'</span><span class="content">test</span><span class="delimiter">'</span></span>, <span class="string"><span class="delimiter">'</span><span class="content">r1</span><span class="delimiter">'</span></span>, <span class="string"><span class="delimiter">'</span><span class="content">e:c1</span><span class="delimiter">'</span></span>, <span class="string"><span class="delimiter">'</span><span class="content">value</span><span class="delimiter">'</span></span>, <span class="integer">14</span>
delete <span class="string"><span class="delimiter">'</span><span class="content">test</span><span class="delimiter">'</span></span>, <span class="string"><span class="delimiter">'</span><span class="content">r1</span><span class="delimiter">'</span></span>, <span class="string"><span class="delimiter">'</span><span class="content">e:c1</span><span class="delimiter">'</span></span>,  <span class="integer">11</span>

hbase(main):<span class="octal">017</span>:<span class="integer">0</span>&gt; scan <span class="string"><span class="delimiter">'</span><span class="content">test</span><span class="delimiter">'</span></span>, {RAW=&gt;<span class="predefined-constant">true</span>, VERSIONS=&gt;<span class="integer">1000</span>}
ROW                                              COLUMN+CELL
 r1                                              column=e:c1, timestamp=<span class="integer">14</span>, value=value
 r1                                              column=e:c1, timestamp=<span class="integer">12</span>, value=value
 r1                                              column=e:c1, timestamp=<span class="integer">11</span>, type=DeleteColumn
 r1                                              column=e:c1, timestamp=<span class="integer">10</span>, value=value
<span class="integer">1</span> row(s) in <span class="float">0.0120</span> seconds

hbase(main):<span class="integer">018</span>:<span class="integer">0</span>&gt; flush <span class="string"><span class="delimiter">'</span><span class="content">test</span><span class="delimiter">'</span></span>
<span class="integer">0</span> row(s) in <span class="float">0.0350</span> seconds

hbase(main):<span class="integer">019</span>:<span class="integer">0</span>&gt; scan <span class="string"><span class="delimiter">'</span><span class="content">test</span><span class="delimiter">'</span></span>, {RAW=&gt;<span class="predefined-constant">true</span>, VERSIONS=&gt;<span class="integer">1000</span>}
ROW                                              COLUMN+CELL
 r1                                              column=e:c1, timestamp=<span class="integer">14</span>, value=value
 r1                                              column=e:c1, timestamp=<span class="integer">12</span>, value=value
 r1                                              column=e:c1, timestamp=<span class="integer">11</span>, type=DeleteColumn
<span class="integer">1</span> row(s) in <span class="float">0.0120</span> seconds

hbase(main):<span class="octal">020</span>:<span class="integer">0</span>&gt; major_compact <span class="string"><span class="delimiter">'</span><span class="content">test</span><span class="delimiter">'</span></span>
<span class="integer">0</span> row(s) in <span class="float">0.0260</span> seconds

hbase(main):<span class="octal">021</span>:<span class="integer">0</span>&gt; scan <span class="string"><span class="delimiter">'</span><span class="content">test</span><span class="delimiter">'</span></span>, {RAW=&gt;<span class="predefined-constant">true</span>, VERSIONS=&gt;<span class="integer">1000</span>}
ROW                                              COLUMN+CELL
 r1                                              column=e:c1, timestamp=<span class="integer">14</span>, value=value
 r1                                              column=e:c1, timestamp=<span class="integer">12</span>, value=value
<span class="integer">1</span> row(s) in <span class="float">0.0120</span> seconds</code></pre>
</div>
</div>
<div class="paragraph">
<p>注意如何释放删除单元格。</p>
</div>
<div class="paragraph">
<p>现在让我们仅使用<code>KEEP_DELETED_CELLS</code>在桌子上设置（您可以做桌子或按列家庭）：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">hbase(main):<span class="octal">005</span>:<span class="integer">0</span>&gt; create <span class="string"><span class="delimiter">'</span><span class="content">test</span><span class="delimiter">'</span></span>, {NAME=&gt;<span class="string"><span class="delimiter">'</span><span class="content">e</span><span class="delimiter">'</span></span>, VERSIONS=&gt;<span class="integer">2147483647</span>, KEEP_DELETED_CELLS =&gt; <span class="predefined-constant">true</span>}
<span class="integer">0</span> row(s) in <span class="float">0.2160</span> seconds

=&gt; Hbase::Table - test
hbase(main):<span class="octal">006</span>:<span class="integer">0</span>&gt; put <span class="string"><span class="delimiter">'</span><span class="content">test</span><span class="delimiter">'</span></span>, <span class="string"><span class="delimiter">'</span><span class="content">r1</span><span class="delimiter">'</span></span>, <span class="string"><span class="delimiter">'</span><span class="content">e:c1</span><span class="delimiter">'</span></span>, <span class="string"><span class="delimiter">'</span><span class="content">value</span><span class="delimiter">'</span></span>, <span class="integer">10</span>
<span class="integer">0</span> row(s) in <span class="float">0.1070</span> seconds

hbase(main):<span class="octal">007</span>:<span class="integer">0</span>&gt; put <span class="string"><span class="delimiter">'</span><span class="content">test</span><span class="delimiter">'</span></span>, <span class="string"><span class="delimiter">'</span><span class="content">r1</span><span class="delimiter">'</span></span>, <span class="string"><span class="delimiter">'</span><span class="content">e:c1</span><span class="delimiter">'</span></span>, <span class="string"><span class="delimiter">'</span><span class="content">value</span><span class="delimiter">'</span></span>, <span class="integer">12</span>
<span class="integer">0</span> row(s) in <span class="float">0.0140</span> seconds

hbase(main):<span class="integer">008</span>:<span class="integer">0</span>&gt; put <span class="string"><span class="delimiter">'</span><span class="content">test</span><span class="delimiter">'</span></span>, <span class="string"><span class="delimiter">'</span><span class="content">r1</span><span class="delimiter">'</span></span>, <span class="string"><span class="delimiter">'</span><span class="content">e:c1</span><span class="delimiter">'</span></span>, <span class="string"><span class="delimiter">'</span><span class="content">value</span><span class="delimiter">'</span></span>, <span class="integer">14</span>
<span class="integer">0</span> row(s) in <span class="float">0.0160</span> seconds

hbase(main):<span class="integer">009</span>:<span class="integer">0</span>&gt; delete <span class="string"><span class="delimiter">'</span><span class="content">test</span><span class="delimiter">'</span></span>, <span class="string"><span class="delimiter">'</span><span class="content">r1</span><span class="delimiter">'</span></span>, <span class="string"><span class="delimiter">'</span><span class="content">e:c1</span><span class="delimiter">'</span></span>,  <span class="integer">11</span>
<span class="integer">0</span> row(s) in <span class="float">0.0290</span> seconds

hbase(main):<span class="octal">010</span>:<span class="integer">0</span>&gt; scan <span class="string"><span class="delimiter">'</span><span class="content">test</span><span class="delimiter">'</span></span>, {RAW=&gt;<span class="predefined-constant">true</span>, VERSIONS=&gt;<span class="integer">1000</span>}
ROW                                                                                          COLUMN+CELL
 r1                                                                                          column=e:c1, timestamp=<span class="integer">14</span>, value=value
 r1                                                                                          column=e:c1, timestamp=<span class="integer">12</span>, value=value
 r1                                                                                          column=e:c1, timestamp=<span class="integer">11</span>, type=DeleteColumn
 r1                                                                                          column=e:c1, timestamp=<span class="integer">10</span>, value=value
<span class="integer">1</span> row(s) in <span class="float">0.0550</span> seconds

hbase(main):<span class="octal">011</span>:<span class="integer">0</span>&gt; flush <span class="string"><span class="delimiter">'</span><span class="content">test</span><span class="delimiter">'</span></span>
<span class="integer">0</span> row(s) in <span class="float">0.2780</span> seconds

hbase(main):<span class="octal">012</span>:<span class="integer">0</span>&gt; scan <span class="string"><span class="delimiter">'</span><span class="content">test</span><span class="delimiter">'</span></span>, {RAW=&gt;<span class="predefined-constant">true</span>, VERSIONS=&gt;<span class="integer">1000</span>}
ROW                                                                                          COLUMN+CELL
 r1                                                                                          column=e:c1, timestamp=<span class="integer">14</span>, value=value
 r1                                                                                          column=e:c1, timestamp=<span class="integer">12</span>, value=value
 r1                                                                                          column=e:c1, timestamp=<span class="integer">11</span>, type=DeleteColumn
 r1                                                                                          column=e:c1, timestamp=<span class="integer">10</span>, value=value
<span class="integer">1</span> row(s) in <span class="float">0.0620</span> seconds

hbase(main):<span class="octal">013</span>:<span class="integer">0</span>&gt; major_compact <span class="string"><span class="delimiter">'</span><span class="content">test</span><span class="delimiter">'</span></span>
<span class="integer">0</span> row(s) in <span class="float">0.0530</span> seconds

hbase(main):<span class="octal">014</span>:<span class="integer">0</span>&gt; scan <span class="string"><span class="delimiter">'</span><span class="content">test</span><span class="delimiter">'</span></span>, {RAW=&gt;<span class="predefined-constant">true</span>, VERSIONS=&gt;<span class="integer">1000</span>}
ROW                                                                                          COLUMN+CELL
 r1                                                                                          column=e:c1, timestamp=<span class="integer">14</span>, value=value
 r1                                                                                          column=e:c1, timestamp=<span class="integer">12</span>, value=value
 r1                                                                                          column=e:c1, timestamp=<span class="integer">11</span>, type=DeleteColumn
 r1                                                                                          column=e:c1, timestamp=<span class="integer">10</span>, value=value
<span class="integer">1</span> row(s) in <span class="float">0.0650</span> seconds</code></pre>
</div>
</div>
<div class="paragraph">
<p>KEEP_DELETED_CELLS是避免将单元格从HBase删除的<em>唯一</em>原因是删除标记。因此，在启用KEEP_DELETED_CELLS的情况下，如果您编写的版本超过配置的最大值，或者您拥有TTL并且单元格超出配置的超时时间，则删除的单元格将被删除。</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="secondary.indexes"><a class="anchor" href="#secondary.indexes"></a> 41。二级索引和备用查询路径</h2>
<div class="sectionbody">
<div class="paragraph">
<p>这部分也可以题为“如果我的表rowkey看起来是<em>这样</em> ，但我也希望我的查询表那样<em>的</em> 。” dist列表上的一个常见示例是其中行键的格式为“ user-timestamp”，但是对于某些时间范围内的用户活动有报告要求。因此，由用户进行选择很容易，因为它处于键的引导位置，而时间却不然。</p>
</div>
<div class="paragraph">
<p>解决这个问题的最佳方法没有一个答案，因为这取决于...</p>
</div>
<div class="ulist">
<ul>
<li>
<p>用户数</p>
</li>
<li>
<p>数据大小和数据到达率</p>
</li>
<li>
<p>报告要求的灵活性（例如，完全临时的日期选择与预配置的范围）</p>
</li>
<li>
<p>所需的查询执行速度（例如，对于某些临时报告，90秒可能是合理的，而对于另一些报告，这可能会太长）</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>解决方案还受群集大小以及必须在解决方案上投入多少处理能力的影响。常见技术在下面的小节中。这是方法的综合列表，但并不详尽。</p>
</div>
<div class="paragraph">
<p>二级索引需要额外的群集空间和处理也就不足为奇了。这正是RDBMS中发生的情况，因为创建备用索引的操作需要空间和处理周期来进行更新。RDBMS产品在这方面更先进，可以立即处理替代索引管理。但是，HBase在较大数据量时可更好地扩展，因此这是一个功能折衷。</p>
</div>
<div class="paragraph">
<p>实施任何一种方法时，请注意<a href="#performance">Apache HBase性能调优</a> 。</p>
</div>
<div class="paragraph">
<p>此外，请在此dist-list线程<a href="http://search-hadoop.com/m/nvbiBp2TDP/Stargate%252Bhbase&subj=Stargate+hbase">HBase中</a>查看David Butler的响应<a href="http://search-hadoop.com/m/nvbiBp2TDP/Stargate%252Bhbase&subj=Stargate+hbase">，邮件＃用户-Stargate + hbase</a></p>
</div>
<div class="sect2">
<h3 id="secondary.indexes.filter"><a class="anchor" href="#secondary.indexes.filter"></a> 41.1。筛选查询</h3>
<div class="paragraph">
<p>根据具体情况，使用<a href="#client.filter">客户端请求过滤器</a>可能是合适的。在这种情况下，不会创建二级索引。但是，请勿尝试从应用程序（例如，单线程客户端）对大型表进行完全扫描。</p>
</div>
</div>
<div class="sect2">
<h3 id="secondary.indexes.periodic"><a class="anchor" href="#secondary.indexes.periodic"></a> 41.2。定期更新二级索引</h3>
<div class="paragraph">
<p>可以在另一个表中创建二级索引，该表通过MapReduce作业定期更新。该作业可以在一天之内执行，但是根据负载策略，它仍可能与主数据表不同步。</p>
</div>
<div class="paragraph">
<p>有关更多信息，请参见<a href="#mapreduce.example.readwrite">mapreduce.example.readwrite</a> 。</p>
</div>
</div>
<div class="sect2">
<h3 id="secondary.indexes.dualwrite"><a class="anchor" href="#secondary.indexes.dualwrite"></a> 41.3双写二级索引</h3>
<div class="paragraph">
<p>另一种策略是在将数据发布到群集时（例如，写入数据表，写入索引表）构建辅助索引。如果在已经存在数据表之后采用这种方法，那么对于具有MapReduce作业的辅助索引，将需要进行引导（请参见<a href="#secondary.indexes.periodic">secondary.indexes.periodic</a> ）。</p>
</div>
</div>
<div class="sect2">
<h3 id="secondary.indexes.summary"><a class="anchor" href="#secondary.indexes.summary"></a> 41.4。汇总表</h3>
<div class="paragraph">
<p>在时间范围很广的地方（例如，长达一年的报告），并且数据量很大，因此汇总表是一种常见的方法。这些将通过MapReduce作业生成到另一个表中。</p>
</div>
<div class="paragraph">
<p>有关更多信息，请参见<a href="#mapreduce.example.summary">mapreduce.example.summary</a> 。</p>
</div>
</div>
<div class="sect2">
<h3 id="secondary.indexes.coproc"><a class="anchor" href="#secondary.indexes.coproc"></a> 41.5。协处理器二级索引</h3>
<div class="paragraph">
<p>协处理器的行为类似于RDBMS触发器。这些以0.92添加。有关更多信息，请参见<a href="#coprocessors">协处理器。</a></p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_constraints"><a class="anchor" href="#_constraints"></a> 42。约束条件</h2>
<div class="sectionbody">
<div class="paragraph">
<p>HBase当前在传统（SQL）数据库中支持“约束”。约束的建议用法是针对表中的属性强制执行业务规则（例如，确保值在1到10的范围内）。约束也可以用于强制执行参照完整性，但是强烈建议不要这样做，因为它会大大降低启用完整性检查的表的写吞吐量。有关使用约束的大量文档，请参见：自0.94版以来的<a href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/constraint">约束</a> 。</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="schema.casestudies"><a class="anchor" href="#schema.casestudies"></a> 43。模式设计案例研究</h2>
<div class="sectionbody">
<div class="paragraph">
<p>下面将描述一些使用HBase的典型数据摄取用例，以及如何进行行键设计和构造。注意：这仅是潜在方法的说明，而不是详尽的清单。了解您的数据，并了解您的处理要求。</p>
</div>
<div class="paragraph">
<p>强烈建议您在阅读这些案例研究之前，先阅读<a href="#schema">HBase和Schema Design</a>的其余部分。</p>
</div>
<div class="paragraph">
<p>描述了以下案例研究：</p>
</div>
<div class="ulist">
<ul>
<li>
<p>日志数据/时间序列数据</p>
</li>
<li>
<p>在类固醇上记录数据/时间序列</p>
</li>
<li>
<p>客户订单</p>
</li>
<li>
<p>高/宽/中方案设计</p>
</li>
<li>
<p>清单资料</p>
</li>
</ul>
</div>
<div class="sect2">
<h3 id="schema.casestudies.log_timeseries"><a class="anchor" href="#schema.casestudies.log_timeseries"></a> 43.1。案例研究-日志数据和时间序列数据</h3>
<div class="paragraph">
<p>假设正在收集以下数据元素。</p>
</div>
<div class="ulist">
<ul>
<li>
<p>主机名</p>
</li>
<li>
<p>时间戳记</p>
</li>
<li>
<p>记录事件</p>
</li>
<li>
<p>价值/讯息</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>我们可以将它们存储在名为LOG_DATA的HBase表中，但是行键是什么？从这些属性中，行键将是主机名，时间戳和日志事件的某种组合-但是具体是什么？</p>
</div>
<div class="sect3">
<h4 id="schema.casestudies.log_timeseries.tslead"><a class="anchor" href="#schema.casestudies.log_timeseries.tslead"></a> 43.1.1。Rowkey引导位置的时间戳</h4>
<div class="paragraph">
<p>行键<code>[timestamp][hostname][log-event]</code>遭受<a href="#timeseries">单调增加行键/时间序列数据中</a>描述的<a href="#timeseries">单调增加行键</a>问题。</p>
</div>
<div class="paragraph">
<p>通过在时间戳上执行mod操作，在dist列表中经常提到另一种关于“存储桶”时间戳的模式。如果面向时间的扫描很重要，那么这可能是一种有用的方法。必须注意存储桶的数量，因为这将需要相同数量的扫描才能返回结果。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="type">long</span> bucket = timestamp % numBuckets;</code></pre>
</div>
</div>
<div class="paragraph">
<p>构造：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">[bucket][timestamp][hostname][log-event]</code></pre>
</div>
</div>
<div class="paragraph">
<p>如上所述，要为特定时间范围选择数据，将需要为每个存储桶执行一次扫描。例如，100个存储桶将在键空间中提供广泛的分布，但是需要100次扫描才能获得单个时间戳的数据，因此需要权衡取舍。</p>
</div>
</div>
<div class="sect3">
<h4 id="schema.casestudies.log_timeseries.hostlead"><a class="anchor" href="#schema.casestudies.log_timeseries.hostlead"></a> 43.1.2。主持人在行键领导位置</h4>
<div class="paragraph">
<p>行键<code>[hostname][log-event][timestamp]</code>如果有大量主机可以将写入和读取分散到整个键空间中，则可以使用此选项。如果按主机名扫描是优先级，则此方法将很有用。</p>
</div>
</div>
<div class="sect3">
<h4 id="schema.casestudies.log_timeseries.revts"><a class="anchor" href="#schema.casestudies.log_timeseries.revts"></a> 43.1.3。时间戳还是反向时间戳？</h4>
<div class="paragraph">
<p>如果最重要的访问路径是提取最新事件，则将时间戳存储为反向时间戳（例如， <code>timestamp = Long.MAX_VALUE – timestamp</code> ）将创建能够进行扫描的属性<code>[hostname][log-event]</code>获得快速获取最近捕获的事件。</p>
</div>
<div class="paragraph">
<p>两种方法都没有错，仅取决于最适合这种情况的方法。</p>
</div>
<div class="admonitionblock note">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-note" title="注意"></i>
</td>
<td class="content">
<div class="title">反向扫描API</div>
<div class="paragraph">
<p><a href="https://issues.apache.org/jira/browse/HBASE-4811">HBASE-4811</a>实现了一个API，可以反向扫描表或表中的范围，从而减少了为进行正向或反向扫描而优化架构的需求。HBase 0.98和更高版本中提供了此功能。有关更多信息，请参见<a href="https://hbase.apache.org/apidocs/org/apache/hadoop/hbase/client/Scan.html#setReversed%28boolean" class="bare">https://hbase.apache.org/apidocs/org/apache/hadoop/hbase/client/Scan.html#setReversed%28boolean</a> 。</p>
</div>
</td>
</tr>
</tbody></table>
</div>
</div>
<div class="sect3">
<h4 id="schema.casestudies.log_timeseries.varkeys"><a class="anchor" href="#schema.casestudies.log_timeseries.varkeys"></a> 43.1.4。可变长度或固定长度的行键？</h4>
<div class="paragraph">
<p>重要的是要记住，行键标记在HBase的每一列上。如果主机名是<code>a</code>事件类型是<code>e1</code>那么结果行键将非常小。但是，如果摄取的主机名是<code>myserver1.mycompany.com</code>事件类型是<code>com.package1.subpackage2.subsubpackage3.ImportantService</code> ？</p>
</div>
<div class="paragraph">
<p>在行键中使用某些替换可能很有意义。至少有两种方法：散列和数字。在“ Rowkey Lead Position中的主机名”示例中，可能看起来像这样：</p>
</div>
<div class="paragraph">
<p>带有哈希的复合行键：</p>
</div>
<div class="ulist">
<ul>
<li>
<p>[主机名的MD5哈希] = 16个字节</p>
</li>
<li>
<p>[事件类型的MD5哈希] = 16个字节</p>
</li>
<li>
<p>[时间戳] = 8个字节</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>带有数字替换的复合行键：</p>
</div>
<div class="paragraph">
<p>对于这种方法，除了LOG_DATA外，还需要另一个查询表，称为LOG_TYPES。 LOG_TYPES的行键为：</p>
</div>
<div class="ulist">
<ul>
<li>
<p>[类型]（例如，指示主机名与事件类型的字节）</p>
</li>
<li>
<p>[bytes]原始主机名或事件类型的可变长度字节。</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>此行键的列可以是带有指定编号的长整数，可以使用<a href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/client/Table.html#incrementColumnValue%28byte" class="bare">http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/client/Table.html#incrementColumnValue%28byte</a>获得，％20byte []，％20byte []，％20long％29 [HBase计数器]。</p>
</div>
<div class="paragraph">
<p>因此，生成的复合行键将为：</p>
</div>
<div class="ulist">
<ul>
<li>
<p>[用主机名替换长] = 8个字节</p>
</li>
<li>
<p>[事件类型的长整数替换] = 8个字节</p>
</li>
<li>
<p>[时间戳] = 8个字节</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>在散列或数字替换方法中，主机名和事件类型的原始值可以存储为列。</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="schema.casestudies.log_steroids"><a class="anchor" href="#schema.casestudies.log_steroids"></a> 43.2。案例研究-类固醇上的日志数据和时间序列数据</h3>
<div class="paragraph">
<p>这实际上是OpenTSDB方法。OpenTSDB所做的是重写数据并将行在某些时间段内打包到列中。有关详细说明，请参见：链接：http：//opentsdb.net/schema.html，以及从HBaseCon2012的<a href="http://www.cloudera.com/content/cloudera/en/resources/library/hbasecon/video-hbasecon-2012-lessons-learned-from-opentsdb.html">OpenTSDB</a>获得的<a href="http://www.cloudera.com/content/cloudera/en/resources/library/hbasecon/video-hbasecon-2012-lessons-learned-from-opentsdb.html">经验教训</a> 。</p>
</div>
<div class="paragraph">
<p>但这就是一般概念的工作原理：例如以这种方式摄取数据...</p>
</div>
<div class="listingblock">
<div class="content">
<pre>[hostname][log-event][timestamp1]
[hostname][log-event][timestamp2]
[hostname][log-event][timestamp3]</pre>
</div>
</div>
<div class="paragraph">
<p>每个详细事件都有单独的行键，但是像这样重写...</p>
</div>
<div class="listingblock">
<div class="content">
<pre>[hostname][log-event][timerange]</pre>
</div>
</div>
<div class="paragraph">
<p>并将上述每个事件转换为以相对于开始时间范围的时间偏移（例如，每5分钟）存储的列。这显然是一种非常先进的处理技术，但是HBase使这成为可能。</p>
</div>
</div>
<div class="sect2">
<h3 id="schema.casestudies.custorder"><a class="anchor" href="#schema.casestudies.custorder"></a> 43.3。案例研究-客户/订单</h3>
<div class="paragraph">
<p>假定HBase用于存储客户和订单信息。提取了两种核心记录类型：客户记录类型和订单记录类型。</p>
</div>
<div class="paragraph">
<p>客户记录类型将包括您通常期望的所有内容：</p>
</div>
<div class="ulist">
<ul>
<li>
<p>顾客号码</p>
</li>
<li>
<p>顾客姓名</p>
</li>
<li>
<p>地址（例如，城市，州，邮政编码）</p>
</li>
<li>
<p>电话号码等</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>订单记录类型将包括以下内容：</p>
</div>
<div class="ulist">
<ul>
<li>
<p>顾客号码</p>
</li>
<li>
<p>订单号</p>
</li>
<li>
<p>销售日期</p>
</li>
<li>
<p>用于运输位置和行项目的一系列嵌套对象（有关详细信息，请参阅<a href="#schema.casestudies.custorder.obj">订购对象设计</a> ）</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>假设客户编号和销售订单的组合唯一地标识了一个订单，则这两个属性将组成行键，特别是一个组合键，例如：</p>
</div>
<div class="listingblock">
<div class="content">
<pre>[customer number][order number]</pre>
</div>
</div>
<div class="paragraph">
<p>用于ORDER表。但是，还有更多的设计决策： <em>原始</em>值是行键的最佳选择吗？</p>
</div>
<div class="paragraph">
<p>日志数据用例中的相同设计问题在这里也面临着我们。客户编号的密钥空间是什么，格式是什么（例如，数字？字母数字？）由于在HBase中使用固定长度的密钥以及可以在密钥空间中支持合理分布的密钥是有利的，因此出现了类似的选项：</p>
</div>
<div class="paragraph">
<p>带有哈希的复合行键：</p>
</div>
<div class="ulist">
<ul>
<li>
<p>[客户编号的MD5] = 16字节</p>
</li>
<li>
<p>[订单号的MD5] = 16个字节</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>复合数字/哈希组合行键：</p>
</div>
<div class="ulist">
<ul>
<li>
<p>[用客户编号代替长号] = 8个字节</p>
</li>
<li>
<p>[订单号的MD5] = 16个字节</p>
</li>
</ul>
</div>
<div class="sect3">
<h4 id="schema.casestudies.custorder.tables"><a class="anchor" href="#schema.casestudies.custorder.tables"></a> 43.3.1。单桌？多张桌子？</h4>
<div class="paragraph">
<p>传统的设计方法将为客户和销售提供单独的表格。另一个选择是将多个记录类型打包到一个表中（例如CUSTOMER ++）。</p>
</div>
<div class="paragraph">
<p>客户记录类型行键：</p>
</div>
<div class="ulist">
<ul>
<li>
<p>[客户ID]</p>
</li>
<li>
<p>[type] =表示客户记录类型为“ 1”的类型</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>订单记录类型行键：</p>
</div>
<div class="ulist">
<ul>
<li>
<p>[客户ID]</p>
</li>
<li>
<p>[type] =指示订单记录类型为“ 2”的类型</p>
</li>
<li>
<p>[订购]</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>这种特定的CUSTOMER ++方法的优点是，可以通过客户ID组织许多不同的记录类型（例如，一次扫描可以为您提供有关该客户的所有信息）。缺点是扫描特定的记录类型并不容易。</p>
</div>
</div>
<div class="sect3">
<h4 id="schema.casestudies.custorder.obj"><a class="anchor" href="#schema.casestudies.custorder.obj"></a> 43.3.2。订单对象设计</h4>
<div class="paragraph">
<p>现在我们需要解决如何对Order对象建模。假定类结构如下：</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">订购</dt>
<dd>
<p>（一个订单可以有多个发运地点</p>
</dd>
<dt class="hdlist1">LineItem</dt>
<dd>
<p>（一个ShippingLocation可以有多个LineItem</p>
</dd>
</dl>
</div>
<div class="paragraph">
<p>存储此数据有多种选择。</p>
</div>
<div class="sect4">
<h5 id="schema.casestudies.custorder.obj.norm"><a class="anchor" href="#schema.casestudies.custorder.obj.norm"></a>完全规范化</h5>
<div class="paragraph">
<p>使用这种方法，将为ORDER，SHIPPING_LOCATION和LINE_ITEM提供单独的表。</p>
</div>
<div class="paragraph">
<p>上面描述了ORDER表的行键： <a href="#schema.casestudies.custorder">schema.casestudies.custorder</a></p>
</div>
<div class="paragraph">
<p>SHIPPING_LOCATION的复合行键如下所示：</p>
</div>
<div class="ulist">
<ul>
<li>
<p>[订单行]</p>
</li>
<li>
<p>[托运地点编号]（例如，第一地点，第二地点等）</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>LINE_ITEM表的复合行键如下所示：</p>
</div>
<div class="ulist">
<ul>
<li>
<p>[订单行]</p>
</li>
<li>
<p>[托运地点编号]（例如，第一地点，第二地点等）</p>
</li>
<li>
<p>[订单项编号]（例如，第一个订单项，第二个订单项等）</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>这种标准化模型很可能是RDBMS的方法，但这不是HBase的唯一选择。这种方法的缺点是要检索有关任何订单的信息，您将需要：</p>
</div>
<div class="ulist">
<ul>
<li>
<p>进入订单的ORDER表</p>
</li>
<li>
<p>在SHIPPING_LOCATION表上扫描该订单以获取ShippingLocation实例</p>
</li>
<li>
<p>在LINE_ITEM上扫描每个送货地点</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>当然，这是RDBMS会在后台进行的操作，但是由于HBase中没有连接，因此您只需要了解这一事实。</p>
</div>
</div>
<div class="sect4">
<h5 id="schema.casestudies.custorder.obj.rectype"><a class="anchor" href="#schema.casestudies.custorder.obj.rectype"></a>具有记录类型的单表</h5>
<div class="paragraph">
<p>使用这种方法，将存在一个单个表ORDER，其中包含</p>
</div>
<div class="paragraph">
<p>订单行键已在上面进行了描述： <a href="#schema.casestudies.custorder">schema.casestudies.custorder</a></p>
</div>
<div class="ulist">
<ul>
<li>
<p>[订单行]</p>
</li>
<li>
<p>[订单记录类型]</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>ShippingLocation复合行键将如下所示：</p>
</div>
<div class="ulist">
<ul>
<li>
<p>[订单行]</p>
</li>
<li>
<p>[运输记录类型]</p>
</li>
<li>
<p>[托运地点编号]（例如，第一地点，第二地点等）</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>LineItem复合行键将如下所示：</p>
</div>
<div class="ulist">
<ul>
<li>
<p>[订单行]</p>
</li>
<li>
<p>[LINE记录类型]</p>
</li>
<li>
<p>[托运地点编号]（例如，第一地点，第二地点等）</p>
</li>
<li>
<p>[订单项编号]（例如，第一个订单项，第二个订单项等）</p>
</li>
</ul>
</div>
</div>
<div class="sect4">
<h5 id="schema.casestudies.custorder.obj.denorm"><a class="anchor" href="#schema.casestudies.custorder.obj.denorm"></a>非正规化</h5>
<div class="paragraph">
<p>“具有记录类型的单表”方法的一种变体是对某些对象层次结构进行非规范化和扁平化，例如将ShippingLocation属性折叠到每个LineItem实例上。</p>
</div>
<div class="paragraph">
<p>LineItem复合行键将如下所示：</p>
</div>
<div class="ulist">
<ul>
<li>
<p>[订单行]</p>
</li>
<li>
<p>[LINE记录类型]</p>
</li>
<li>
<p>[订单项编号]（例如，第一个订单项，第二个订单项等，必须注意整个订单中的商品是唯一的）</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>而LineItem列将如下所示：</p>
</div>
<div class="ulist">
<ul>
<li>
<p>项目编号</p>
</li>
<li>
<p>数量</p>
</li>
<li>
<p>价钱</p>
</li>
<li>
<p>shipToLine1（从ShippingLocation规范化）</p>
</li>
<li>
<p>shipToLine2（从ShippingLocation规范化）</p>
</li>
<li>
<p>shipToCity（从ShippingLocation规范化）</p>
</li>
<li>
<p>shipToState（从ShippingLocation规范化）</p>
</li>
<li>
<p>shipToZip（从ShippingLocation规范化）</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>这种方法的优点是对象层次结构不太复杂，但是缺点之一是万一这些信息发生更改，更新就会变得更加复杂。</p>
</div>
</div>
<div class="sect4">
<h5 id="schema.casestudies.custorder.obj.singleobj"><a class="anchor" href="#schema.casestudies.custorder.obj.singleobj"></a>对象BLOB</h5>
<div class="paragraph">
<p>通过这种方法，整个Order对象图以一种或另一种方式被视为BLOB。例如，上面描述了ORDER表的行键： <a href="#schema.casestudies.custorder">schema.casestudies.custorder</a>和一个名为“ order”的列将包含一个可以反序列化的对象，该对象包含容器Order，ShippingLocations和LineItems。</p>
</div>
<div class="paragraph">
<p>这里有许多选项：JSON，XML，Java序列化，Avro，Hadoop可写文件等。它们都是相同方法的变体：将对象图编码为字节数组。如果对象模型发生更改，以确保仍可以从HBase中读取较旧的持久化结构，则应谨慎使用此方法以确保向后兼容。</p>
</div>
<div class="paragraph">
<p>专业人士能够以最少的I / O管理复杂的对象图（例如，在此示例中为单个“按订单获取HBase”），但是缺点包括上述关于序列化向后兼容性，序列化的语言依赖性（例如Java序列化）的警告仅适用于Java客户端），必须对整个对象进行反序列化以在BLOB中获取任何信息这一事实，以及使诸如Hive之类的框架无法与此类自定义对象一起使用的困难。</p>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="schema.smackdown"><a class="anchor" href="#schema.smackdown"></a> 43.4。案例研究-“高/宽/中”方案设计精简</h3>
<div class="paragraph">
<p>本节将描述出现在dist列表中的其他架构设计问题，特别是有关高大桌子的问题。这些是一般准则，而不是法律-每个应用程序都必须考虑自己的需求。</p>
</div>
<div class="sect3">
<h4 id="schema.smackdown.rowsversions"><a class="anchor" href="#schema.smackdown.rowsversions"></a> 43.4.1。行与版本</h4>
<div class="paragraph">
<p>一个常见的问题是，是应该使用行还是HBase的内置版本控制。上下文通常是要保留行的“很多”版本的位置（例如，该位置明显高于HBase默认的1个最大版本）。行方法将需要在行键的某些部分中存储时间戳，以使它们不会在每次后续更新时都被覆盖。</p>
</div>
<div class="paragraph">
<p>首选项：行（通常而言）。</p>
</div>
</div>
<div class="sect3">
<h4 id="schema.smackdown.rowscols"><a class="anchor" href="#schema.smackdown.rowscols"></a> 43.4.2。行与列</h4>
<div class="paragraph">
<p>另一个常见的问题是，人们应该选择行还是列。该上下文通常在宽表的极端情况下使用，例如具有1行具有1百万个属性，或具有1百万行具有1列的属性。</p>
</div>
<div class="paragraph">
<p>首选项：行（通常而言）。需要明确的是，该指导原则是在非常广泛的情况下使用的，而不是在需要存储几十或数百列的标准用例中使用的。但是，这两个选项之间还有一条中间路径，那就是“行作为列”。</p>
</div>
</div>
<div class="sect3">
<h4 id="schema.smackdown.rowsascols"><a class="anchor" href="#schema.smackdown.rowsascols"></a> 43.4.3。行作为列</h4>
<div class="paragraph">
<p>行与列之间的中间路径是将某些行的数据打包成独立的行。OpenTSDB是这种情况的最佳示例，其中单行代表定义的时间范围，然后将离散事件视为列。这种方法通常更复杂，并且可能需要重新写入数据的额外复杂性，但是具有I / O高效的优势。有关此方法的概述，请参见<a href="#schema.casestudies.log_steroids">schema.casestudies.log-steroids</a> 。</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="casestudies.schema.listdata"><a class="anchor" href="#casestudies.schema.listdata"></a> 43.5。案例研究-列表数据</h3>
<div class="paragraph">
<p>以下是来自用户dist-list的一个相当普遍的问题的交换：如何在Apache HBase中处理每个用户的列表数据。</p>
</div>
<div class="ulist">
<ul>
<li>
<p>问题<strong>*</strong></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>我们正在研究如何在HBase中存储大量（每个用户）列表数据，并且试图找出哪种访问模式最有意义。一种选择是将大多数数据存储在一个密钥中，因此我们可以得到以下内容：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">&lt;FixedWidthUserName&gt;&lt;FixedWidthValueId1&gt;:<span class="string"><span class="delimiter">&quot;</span><span class="delimiter">&quot;</span></span> (no value)
&lt;FixedWidthUserName&gt;&lt;FixedWidthValueId2&gt;:<span class="string"><span class="delimiter">&quot;</span><span class="delimiter">&quot;</span></span> (no value)
&lt;FixedWidthUserName&gt;&lt;FixedWidthValueId3&gt;:<span class="string"><span class="delimiter">&quot;</span><span class="delimiter">&quot;</span></span> (no value)</code></pre>
</div>
</div>
<div class="paragraph">
<p>我们拥有的另一种选择是完全使用以下方法：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="xml"><span class="tag">&lt;FixedWidthUserName&gt;</span><span class="tag">&lt;FixedWidthPageNum0&gt;</span>:<span class="tag">&lt;FixedWidthLength&gt;</span><span class="tag">&lt;FixedIdNextPageNum&gt;</span><span class="tag">&lt;ValueId1&gt;</span><span class="tag">&lt;ValueId2&gt;</span><span class="tag">&lt;ValueId3&gt;</span>...
<span class="tag">&lt;FixedWidthUserName&gt;</span><span class="tag">&lt;FixedWidthPageNum1&gt;</span>:<span class="tag">&lt;FixedWidthLength&gt;</span><span class="tag">&lt;FixedIdNextPageNum&gt;</span><span class="tag">&lt;ValueId1&gt;</span><span class="tag">&lt;ValueId2&gt;</span><span class="tag">&lt;ValueId3&gt;</span>...</code></pre>
</div>
</div>
<div class="paragraph">
<p>每行将包含多个值。因此，在一种情况下，读取前三十个值将是：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">scan { STARTROW =&gt; <span class="string"><span class="delimiter">'</span><span class="content">FixedWidthUsername</span><span class="delimiter">'</span></span> LIMIT =&gt; <span class="integer">30</span>}</code></pre>
</div>
</div>
<div class="paragraph">
<p>在第二种情况下</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">get <span class="string"><span class="delimiter">'</span><span class="content">FixedWidthUserName</span><span class="content">\x00</span><span class="content">\x00</span><span class="content">\x00</span><span class="content">\x00</span><span class="delimiter">'</span></span></code></pre>
</div>
</div>
<div class="paragraph">
<p>通常的使用模式是只读取这些列表的前30个值，而很少的访问会更深入地读取列表。在这些列表中，某些用户的总价值为⇐30，而某些用户的百万价值（即幂律分布）</p>
</div>
<div class="paragraph">
<p>单值格式似乎会在HBase上占用更多空间，但会提供一些改进的检索/分页灵活性。通过获取进行分页与通过扫描进行分页是否会有任何显着的性能优势？</p>
</div>
<div class="paragraph">
<p>我最初的理解是，如果我们的分页大小未知（并且缓存设置适当），则扫描应该更快，但是如果我们始终需要相同的页面大小，则扫描应该更快。我最终听到不同的人告诉我有关性能的相反的事情。我认为页面大小会相对一致，因此对于大多数用例，我们可以保证在固定页面长度的情况下只需要一页数据。我还要假设我们不经常进行更新，但是可能在这些列表的中间插入了插入（这意味着我们需要更新所有后续行）。</p>
</div>
<div class="paragraph">
<p>感谢您的帮助/建议/后续问题。</p>
</div>
<div class="ulist">
<ul>
<li>
<p>答案<strong>*</strong></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>如果我理解正确，那么您最终将尝试以“用户，valueid，值”的形式存储三元组，对吗？例如，类似：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="string"><span class="delimiter">&quot;</span><span class="content">user123, firstname, Paul</span><span class="delimiter">&quot;</span></span>,
<span class="string"><span class="delimiter">&quot;</span><span class="content">user234, lastname, Smith</span><span class="delimiter">&quot;</span></span></code></pre>
</div>
</div>
<div class="paragraph">
<p>（但是用户名是固定宽度，而valueid是固定宽度）。</p>
</div>
<div class="paragraph">
<p>而且，您的访问模式如下：“对于用户X，列出接下来的30个值，以valueid Y开头”。那正确吗？而这些值应该按valueid排序返回？</p>
</div>
<div class="paragraph">
<p>tl; dr版本是每个用户+值可能只包含一行，并且除非您确实确定需要，否则不要自己构建复杂的行内分页方案。</p>
</div>
<div class="paragraph">
<p>您的两个选择反映了人们在设计HBase模式时遇到的一个常见问题：我应该“高”还是“宽”？您的第一个架构是“高层”：每一行代表一个用户一个值，因此表中有很多行针对每个用户；行键是用户+ valueid，并且（大概）将有一个单列限定符，表示“值”。如果您要按行键按排序顺序扫描行（这是我上面的问题，关于这些ID是否正确排序），这很好。您可以在任何用户名+值id处开始扫描，然后阅读下30个，然后完成。您要放弃的是能够为一个用户在所有行周围拥有事务保证，但这听起来并不是您需要的。通常建议以这种方式进行操作（请参见此处的链接：http：//hbase.apache.org/book.html#schema.smackdown）。</p>
</div>
<div class="paragraph">
<p>您的第二个选项是“宽”：使用不同的限定词（其中的限定词是valueid）将一堆值存储在一行中。这样做的简单方法是只将一个用户的所有值存储在一行中。我猜您跳到了“分页”版本，因为您假设在单行中存储数百万列会降低性能，这可能是正确的，也可能不是正确的。只要您不打算在单个请求中执行太多操作，或者执行诸如扫描并返回该行中所有单元格之类的操作，那么从根本上讲应该不会更糟。客户端具有允许您获取特定列列的方法。</p>
</div>
<div class="paragraph">
<p>请注意，两种情况从根本上都不比另一种情况使用更多的磁盘空间。您只是将标识信息的一部分“左移”（左移至选项1中的行键）或向右（右移至选项2中的列限定符）。在幕后，每个键/值仍存储整个行键和列族名称。（如果这有点令人困惑，请花一个小时，观看Lars George的精彩视频，内容涉及了解HBase模式设计：链接：http：//www.youtube.com/watch？v = _HLoH_PgrLk）。</p>
</div>
<div class="paragraph">
<p>如您所注意到的，手动分页版本具有更多的复杂性，例如必须跟踪每个页面中有多少东西，如果插入新值则需要重新排序等等。这似乎要复杂得多。它可能具有一些轻微的速度优势（或劣势！）以极高的吞吐率，真正了解这一点的唯一方法就是尝试一下。如果您没有时间同时构建和比较它，我的建议是从最简单的选项开始（每个用户+值一行）。从简单开始并进行迭代！ :)</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="schema.ops"><a class="anchor" href="#schema.ops"></a> 44。操作和性能配置选项</h2>
<div class="sectionbody">
<div class="paragraph">
<p>有关操作和性能模式设计选项的更多信息，请参见性能部分<a href="#perf.schema">perf.schema</a> ，例如Bloom Filters，表配置的区域大小，压缩和块大小。</p>
</div>
</div>
</div>
<h1 id="mapreduce" class="sect0"><a class="anchor" href="#mapreduce"></a> HBase和MapReduce</h1>
<div class="openblock partintro">
<div class="content">
<div class="paragraph">
<p>Apache MapReduce是用于分析大量数据的软件框架，并且是最常用于<a href="http://hadoop.apache.org/">Apache Hadoop</a>的框架。MapReduce本身不在本文档的范围之内。开始使用MapReduce的好地方是<a href="http://hadoop.apache.org/docs/r2.6.0/hadoop-mapreduce-client/hadoop-mapreduce-client-core/MapReduceTutorial.html" class="bare">http://hadoop.apache.org/docs/r2.6.0/hadoop-mapreduce-client/hadoop-mapreduce-client-core/MapReduceTutorial.html</a> 。 MapReduce版本2（MR2）现在是<a href="http://hadoop.apache.org/docs/r2.3.0/hadoop-yarn/hadoop-yarn-site/">YARN的</a>一部分。</p>
</div>
<div class="paragraph">
<p>本章讨论对HBase中的数据使用MapReduce时需要采取的特定配置步骤。此外，它还讨论了HBase和MapReduce作业之间的其他交互作用和问题。</p>
</div>
<div class="admonitionblock note">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-note" title="注意"></i>
</td>
<td class="content">
<div class="title"><code>mapred</code>和<code>mapreduce</code></div>
<div class="paragraph">
<p>与MapReduce本身一样，HBase中有两个mapreduce软件包： <em>org.apache.hadoop.hbase.mapred</em>和<em>org.apache.hadoop.hbase.mapreduce</em> 。前者使用旧样式的API，而后者则使用新样式。后者具有更多的功能，尽管您通常可以在较旧的程序包中找到等效的功能。选择MapReduce部署随附的软件包。如有疑问或从头开始，请选择<em>org.apache.hadoop.hbase.mapreduce</em> 。在下面的注释中，我们指的是oahhmapreduce，但如果您使用的是oahhmapred，则将其替换。</p>
</div>
</td>
</tr>
</tbody></table>
</div>
</div>
</div>
<div class="sect1">
<h2 id="hbase.mapreduce.classpath"><a class="anchor" href="#hbase.mapreduce.classpath"></a> 45。HBase，MapReduce和CLASSPATH</h2>
<div class="sectionbody">
<div class="paragraph">
<p>默认情况下，部署到MapReduce群集的MapReduce作业无法访问以下位置的HBase配置<code>$HBASE_CONF_DIR</code>或HBase类。</p>
</div>
<div class="paragraph">
<p>要为MapReduce作业提供所需的访问权限，您可以将<em>hbase-site.xml</em>添加到<em>$ HADOOP_HOME / conf中</em> ，并将HBase jar添加到<em>$ HADOOP_HOME / lib</em>目录中。然后，您需要在整个集群中复制这些更改。或者，您可以编辑<em>$ HADOOP_HOME / conf / hadoop-env.sh</em>并将其添加到<code>HADOOP_CLASSPATH</code>变量。但是，不建议使用此方法，因为它将使用HBase引用污染您的Hadoop安装。它还要求您在Hadoop可以使用HBase数据之前重新启动Hadoop集群。</p>
</div>
<div class="paragraph">
<p>推荐的方法是让HBase自己添加其依赖罐并使用<code>HADOOP_CLASSPATH</code>要么<code>-libjars</code> 。</p>
</div>
<div class="paragraph">
<p>从HBase 0.90.x开始，HBase将其依赖项JAR添加到作业配置本身。依赖项仅需要在本地可用<code>CLASSPATH</code> 。以下示例对名为的表运行捆绑的HBase <a href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/mapreduce/RowCounter.html">RowCounter</a> MapReduce作业<code>usertable</code> 。如果尚未设置命令中预期的环境变量（以“。”开头的部分<code>$</code>符号并用大括号括起来），您可以改用实际的系统路径。确保为您的系统使用正确版本的HBase JAR。反引号（ <code>`</code>符号）使外壳程序执行子命令，并设置输出<code>hbase classpath</code> （转储HBase CLASSPATH的命令）到<code>HADOOP_CLASSPATH</code> 。本示例假定您使用兼容BASH的外壳。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">$ HADOOP_CLASSPATH=`${HBASE_HOME}/bin/hbase classpath` ${HADOOP_HOME}/bin/hadoop jar ${HBASE_HOME}/lib/hbase-server-VERSION.jar rowcounter usertable</code></pre>
</div>
</div>
<div class="paragraph">
<p>当命令在内部运行时，HBase JAR会找到所需的依赖项并将其添加到MapReduce作业配置中。请参阅以下资源<code>TableMapReduceUtil#addDependencyJars(org.apache.hadoop.mapreduce.Job)</code>如何做到这一点。</p>
</div>
<div class="paragraph">
<p>命令<code>hbase mapredcp</code>还可以帮助您转储MapReduce所需的CLASSPATH条目，它们是相同的jar <code>TableMapReduceUtil#addDependencyJars</code>将添加。您可以将它们与HBase conf目录一起添加到<code>HADOOP_CLASSPATH</code> 。对于不打包依赖项或调用的作业<code>TableMapReduceUtil#addDependencyJars</code> ，以下命令结构是必需的：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">$ HADOOP_CLASSPATH=`${HBASE_HOME}/bin/hbase mapredcp`:${HBASE_HOME}/conf hadoop jar MyApp.jar MyJobMainClass -libjars $(${HBASE_HOME}/bin/hbase mapredcp | tr ':' ',') ...</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-note" title="注意"></i>
</td>
<td class="content">
<div class="paragraph">
<p>如果您从其构建目录而不是安装位置运行HBase，则该示例可能无法正常工作。您可能会看到类似以下的错误：</p>
</div>
<div class="listingblock">
<div class="content">
<pre>java.lang.RuntimeException: java.lang.ClassNotFoundException: org.apache.hadoop.hbase.mapreduce.RowCounter$RowCounterMapper</pre>
</div>
</div>
<div class="paragraph">
<p>如果发生这种情况，请尝试按以下方式修改命令，以便它使用构建环境中<em>target /</em>目录中的HBase JAR。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">$ HADOOP_CLASSPATH=${HBASE_BUILD_HOME}/hbase-server/target/hbase-server-VERSION-SNAPSHOT.jar:`${HBASE_BUILD_HOME}/bin/hbase classpath` ${HADOOP_HOME}/bin/hadoop jar ${HBASE_BUILD_HOME}/hbase-server/target/hbase-server-VERSION-SNAPSHOT.jar rowcounter usertable</code></pre>
</div>
</div>
</td>
</tr>
</tbody></table>
</div>
<div class="admonitionblock caution">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-caution" title="警告"></i>
</td>
<td class="content">
<div class="title">在0.96.1至0.98.4之间通知HBase的MapReduce用户</div>
<div class="paragraph">
<p>使用HBase的某些MapReduce作业无法启动。该症状是与以下内容类似的异常：</p>
</div>
<div class="listingblock">
<div class="content">
<pre>Exception in thread "main" java.lang.IllegalAccessError: class
    com.google.protobuf.ZeroCopyLiteralByteString cannot access its superclass
    com.google.protobuf.LiteralByteString
    at java.lang.ClassLoader.defineClass1(Native Method)
    at java.lang.ClassLoader.defineClass(ClassLoader.java:792)
    at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142)
    at java.net.URLClassLoader.defineClass(URLClassLoader.java:449)
    at java.net.URLClassLoader.access$100(URLClassLoader.java:71)
    at java.net.URLClassLoader$1.run(URLClassLoader.java:361)
    at java.net.URLClassLoader$1.run(URLClassLoader.java:355)
    at java.security.AccessController.doPrivileged(Native Method)
    at java.net.URLClassLoader.findClass(URLClassLoader.java:354)
    at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
    at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
    at
    org.apache.hadoop.hbase.protobuf.ProtobufUtil.toScan(ProtobufUtil.java:818)
    at
    org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil.convertScanToString(TableMapReduceUtil.java:433)
    at
    org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil.initTableMapperJob(TableMapReduceUtil.java:186)
    at
    org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil.initTableMapperJob(TableMapReduceUtil.java:147)
    at
    org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil.initTableMapperJob(TableMapReduceUtil.java:270)
    at
    org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil.initTableMapperJob(TableMapReduceUtil.java:100)
...</pre>
</div>
</div>
<div class="paragraph">
<p>这是由<a href="https://issues.apache.org/jira/browse/HBASE-9867">HBASE-9867</a>中引入的优化引起的，该优化无意中引入了类加载器依赖项。</p>
</div>
<div class="paragraph">
<p>这会影响使用<code>-libjars</code> option和“ fat jar”，它们将它们的运行时依赖项打包在一个嵌套文件中<code>lib</code>夹。</p>
</div>
<div class="paragraph">
<p>为了满足新的类加载器要求， <code>hbase-protocol.jar</code>必须包含在Hadoop的类路径中。有关解决类路径错误的最新建议，请参见<a href="#hbase.mapreduce.classpath">HBase，MapReduce和CLASSPATH</a> 。出于历史目的，包括以下内容。</p>
</div>
<div class="paragraph">
<p>可以通过引用以下内容来解决该问题： <code>hbase-protocol.jar</code>在Hadoop的lib目录中，通过符号链接或将jar复制到新位置。</p>
</div>
<div class="paragraph">
<p>也可以通过将其包含在<code>HADOOP_CLASSPATH</code>作业提交时的环境变量。启动打包其依赖项的作业时，以下所有三个作业启动命令均满足此要求：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">$ HADOOP_CLASSPATH=/path/to/hbase-protocol.jar:/path/to/hbase/conf hadoop jar MyJob.jar MyJobMainClass
$ HADOOP_CLASSPATH=$(hbase mapredcp):/path/to/hbase/conf hadoop jar MyJob.jar MyJobMainClass
$ HADOOP_CLASSPATH=$(hbase classpath) hadoop jar MyJob.jar MyJobMainClass</code></pre>
</div>
</div>
<div class="paragraph">
<p>对于不打包依赖项的jar，以下命令结构是必需的：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">$ HADOOP_CLASSPATH=$(hbase mapredcp):/etc/hbase/conf hadoop jar MyApp.jar MyJobMainClass -libjars $(hbase mapredcp | tr ':' ',') ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>有关此问题的进一步讨论，请参见<a href="https://issues.apache.org/jira/browse/HBASE-10304">HBASE-10304</a> 。</p>
</div>
</td>
</tr>
</tbody></table>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_mapreduce_scan_caching"><a class="anchor" href="#_mapreduce_scan_caching"></a> 46。MapReduce扫描缓存</h2>
<div class="sectionbody">
<div class="paragraph">
<p>TableMapReduceUtil现在恢复在传入的Scan对象上设置扫描程序缓存（将结果返回给客户端之前缓存的行数）的选项。该功能由于HBase 0.95（ <a href="https://issues.apache.org/jira/browse/HBASE-11558">HBASE-11558</a> ）中的错误而丢失，该错误已针对HBase 0.98.5和0.96.3进行了修复。选择扫描仪缓存的优先顺序如下：</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>在扫描对象上设置的缓存设置。</p>
</li>
<li>
<p>通过配置选项指定的缓存设置<code>hbase.client.scanner.caching</code> ，可以在<em>hbase-site.xml中</em>手动设置，也可以通过helper方法设置<code>TableMapReduceUtil.setScannerCaching()</code> 。</p>
</li>
<li>
<p>默认值<code>HConstants.DEFAULT_HBASE_CLIENT_SCANNER_CACHING</code> ，它设置为<code>100</code> 。</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>优化缓存设置是客户端等待结果的时间与客户端需要接收的结果集数量之间的平衡。如果缓存设置太大，客户端可能会等待很长时间，甚至请求可能会超时。如果设置太小，则扫描需要分多次返回结果。如果您将扫描视为铲子，则较大的缓存设置类似于较大的铲子，较小的缓存设置等效于进行更多铲斗以填充铲斗。</p>
</div>
<div class="paragraph">
<p>上面提到的优先级列表允许您设置合理的默认值，并针对特定操作覆盖它。</p>
</div>
<div class="paragraph">
<p>有关更多详细信息，请参见<a href="https://hbase.apache.org/apidocs/org/apache/hadoop/hbase/client/Scan.html">Scan</a>的API文档。</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_bundled_hbase_mapreduce_jobs"><a class="anchor" href="#_bundled_hbase_mapreduce_jobs"></a> 47。捆绑的HBase MapReduce作业</h2>
<div class="sectionbody">
<div class="paragraph">
<p>HBase JAR还可以用作某些捆绑的MapReduce作业的驱动程序。要了解捆绑的MapReduce作业，请运行以下命令。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">$ ${HADOOP_HOME}/bin/hadoop jar ${HBASE_HOME}/hbase-server-VERSION.jar
An example program must be given as the first argument.
Valid program names are:
  copytable: Export a table from local cluster to peer cluster
  completebulkload: Complete a bulk data load.
  export: Write table data to HDFS.
  import: Import data written by Export.
  importtsv: Import data in TSV format.
  rowcounter: Count rows in HBase table</code></pre>
</div>
</div>
<div class="paragraph">
<p>每个有效的程序名称都是捆绑的MapReduce作业。要运行这些作业之一，请在以下示例之后对命令进行建模。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">$ ${HADOOP_HOME}/bin/hadoop jar ${HBASE_HOME}/hbase-server-VERSION.jar rowcounter myTable</code></pre>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_hbase_as_a_mapreduce_job_data_source_and_data_sink"><a class="anchor" href="#_hbase_as_a_mapreduce_job_data_source_and_data_sink"></a> 48。HBase作为MapReduce作业数据源和数据接收器</h2>
<div class="sectionbody">
<div class="paragraph">
<p>HBase可用作MapReduce作业的数据源<a href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/mapreduce/TableInputFormat.html">TableInputFormat</a>和数据接收器<a href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/mapreduce/TableOutputFormat.html">TableOutputFormat</a>或<a href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/mapreduce/MultiTableOutputFormat.html">MultiTableOutputFormat</a> 。编写MapReduce作业以读取或写入HBase时，建议将<a href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/mapreduce/TableMapper.html">TableMapper</a>和/或<a href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/mapreduce/TableReducer.html">TableReducer</a>子类<a href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/mapreduce/TableReducer.html">化</a> 。有关基本用法，请参见无作用传递类<a href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/mapreduce/IdentityTableMapper.html">IdentityTableMapper</a>和<a href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/mapreduce/IdentityTableReducer.html">IdentityTableReducer</a> 。有关更多示例，请参见<a href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/mapreduce/RowCounter.html">RowCounter</a>或查看<code>org.apache.hadoop.hbase.mapreduce.TestTableMapReduce</code>单元测试。</p>
</div>
<div class="paragraph">
<p>如果运行将HBase用作源或接收器的MapReduce作业，则需要在配置中指定源和接收器表及列的名称。</p>
</div>
<div class="paragraph">
<p>从HBase读取时， <code>TableInputFormat</code>向HBase请求区域列表并制作地图，该地图可以是<code>map-per-region</code>要么<code>mapreduce.job.maps</code>地图，以较小者为准。如果您的工作只有两张地图，请加薪<code>mapreduce.job.maps</code>数量大于区域数量。如果您在每个节点上运行TaskTracer / NodeManager和RegionServer，则地图将在相邻的TaskTracker / NodeManager上运行。写入HBase时，应避免执行Reduce步骤，然后从地图内部写回HBase。当您的工作不需要MapReduce对地图发出的数据执行的排序和排序规则时，此方法将起作用。插入时，HBase会进行“排序”，因此除非需要，否则就不会进行点双重排序（并在MapReduce集群周围进行数据改组）。如果不需要精简，则地图可能会在作业结束时发出为报告而处理的记录计数，或者将精简数量设置为零并使用TableOutputFormat。如果在您的情况下运行Reduce步骤有意义，则通常应使用多个reducer，以便将负载分散在HBase群集上。</p>
</div>
<div class="paragraph">
<p>一个新的HBase分区程序<a href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/mapreduce/HRegionPartitioner.html">HRegionPartitioner</a>可以运行与现有区域数一样多的<a href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/mapreduce/HRegionPartitioner.html">缩减程序</a> 。HRegionPartitioner适用于表较大且上传完成后不会大大改变现有区域数的情况。否则，请使用默认分区程序。</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_writing_hfiles_directly_during_bulk_import"><a class="anchor" href="#_writing_hfiles_directly_during_bulk_import"></a> 49。批量导入期间直接写入HFile</h2>
<div class="sectionbody">
<div class="paragraph">
<p>如果要导入到新表中，则可以绕过HBase API并将内容直接写入文件系统，并格式化为HBase数据文件（HFiles）。您的导入将运行得更快，也许要快一个数量级。有关此机制如何工作的更多信息，请参见<a href="#arch.bulk.load">批量加载</a> 。</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_rowcounter_example"><a class="anchor" href="#_rowcounter_example"></a> 50RowCounter示例</h2>
<div class="sectionbody">
<div class="paragraph">
<p>随附的<a href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/mapreduce/RowCounter.html">RowCounter</a> MapReduce作业使用<code>TableInputFormat</code>并计算指定表中的所有行。要运行它，请使用以下命令：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">$ ./bin/hadoop jar hbase-X.X.X.jar</code></pre>
</div>
</div>
<div class="paragraph">
<p>这将调用HBase MapReduce驱动程序类。选择<code>rowcounter</code>从提供的工作中选择。这会将行计数器使用建议打印到标准输出。指定表名，要计数的列和输出目录。如果您遇到类路径错误，请参见<a href="#hbase.mapreduce.classpath">HBase，MapReduce和CLASSPATH</a> 。</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="splitter"><a class="anchor" href="#splitter"></a> 51。映射任务拆分</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="splitter.default"><a class="anchor" href="#splitter.default"></a> 51.1。默认的HBase MapReduce拆分器</h3>
<div class="paragraph">
<p>当使用<a href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/mapreduce/TableInputFormat.html">TableInputFormat</a>来在MapReduce作业中获取HBase表时，其拆分器将为表的每个区域创建一个映射任务。因此，如果表中有100个区域，则该作业将有100个映射任务-无论在“扫描”中选择了多少列族。</p>
</div>
</div>
<div class="sect2">
<h3 id="splitter.custom"><a class="anchor" href="#splitter.custom"></a> 51.2。定制分离器</h3>
<div class="paragraph">
<p>对于那些对实现自定义拆分器感兴趣的人，请参见方法<code>getSplits</code>在<a href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/mapreduce/TableInputFormatBase.html">TableInputFormatBase中</a> 。这就是映射任务分配的逻辑所在。</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="mapreduce.example"><a class="anchor" href="#mapreduce.example"></a> 52。HBase MapReduce示例</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="mapreduce.example.read"><a class="anchor" href="#mapreduce.example.read"></a> 52.1。HBase MapReduce阅读示例</h3>
<div class="paragraph">
<p>以下是以只读方式将HBase用作MapReduce源的示例。具体来说，有一个Mapper实例，但没有Reducer，并且没有从Mapper发出任何东西。该工作的定义如下...</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="predefined-type">Configuration</span> config = HBaseConfiguration.create();
Job job = <span class="keyword">new</span> Job(config, <span class="string"><span class="delimiter">&quot;</span><span class="content">ExampleRead</span><span class="delimiter">&quot;</span></span>);
job.setJarByClass(MyReadJob.class);     <span class="comment">// class that contains mapper</span>

Scan scan = <span class="keyword">new</span> Scan();
scan.setCaching(<span class="integer">500</span>);        <span class="comment">// 1 is the default in Scan, which will be bad for MapReduce jobs</span>
scan.setCacheBlocks(<span class="predefined-constant">false</span>);  <span class="comment">// don't set to true for MR jobs</span>
<span class="comment">// set other scan attrs</span>
...

TableMapReduceUtil.initTableMapperJob(
  tableName,        <span class="comment">// input HBase table name</span>
  scan,             <span class="comment">// Scan instance to control CF and attribute selection</span>
  MyMapper.class,   <span class="comment">// mapper</span>
  <span class="predefined-constant">null</span>,             <span class="comment">// mapper output key</span>
  <span class="predefined-constant">null</span>,             <span class="comment">// mapper output value</span>
  job);
job.setOutputFormatClass(NullOutputFormat.class);   <span class="comment">// because we aren't emitting anything from mapper</span>

<span class="type">boolean</span> b = job.waitForCompletion(<span class="predefined-constant">true</span>);
<span class="keyword">if</span> (!b) {
  <span class="keyword">throw</span> <span class="keyword">new</span> <span class="exception">IOException</span>(<span class="string"><span class="delimiter">&quot;</span><span class="content">error with job!</span><span class="delimiter">&quot;</span></span>);
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>...而mapper实例将扩展<a href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/mapreduce/TableMapper.html">TableMapper</a> ...</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="directive">public</span> <span class="directive">static</span> <span class="type">class</span> <span class="class">MyMapper</span> <span class="directive">extends</span> TableMapper&lt;Text, Text&gt; {

  <span class="directive">public</span> <span class="type">void</span> map(ImmutableBytesWritable row, <span class="predefined-type">Result</span> value, <span class="predefined-type">Context</span> context) <span class="directive">throws</span> <span class="exception">InterruptedException</span>, <span class="exception">IOException</span> {
    <span class="comment">// process data for the row from the Result instance.</span>
   }
}</code></pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="mapreduce.example.readwrite"><a class="anchor" href="#mapreduce.example.readwrite"></a> 52.2。HBase MapReduce读/写示例</h3>
<div class="paragraph">
<p>以下是通过MapReduce将HBase用作源和接收器的示例。此示例将简单地将数据从一个表复制到另一个表。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="predefined-type">Configuration</span> config = HBaseConfiguration.create();
Job job = <span class="keyword">new</span> Job(config,<span class="string"><span class="delimiter">&quot;</span><span class="content">ExampleReadWrite</span><span class="delimiter">&quot;</span></span>);
job.setJarByClass(MyReadWriteJob.class);    <span class="comment">// class that contains mapper</span>

Scan scan = <span class="keyword">new</span> Scan();
scan.setCaching(<span class="integer">500</span>);        <span class="comment">// 1 is the default in Scan, which will be bad for MapReduce jobs</span>
scan.setCacheBlocks(<span class="predefined-constant">false</span>);  <span class="comment">// don't set to true for MR jobs</span>
<span class="comment">// set other scan attrs</span>

TableMapReduceUtil.initTableMapperJob(
  sourceTable,      <span class="comment">// input table</span>
  scan,             <span class="comment">// Scan instance to control CF and attribute selection</span>
  MyMapper.class,   <span class="comment">// mapper class</span>
  <span class="predefined-constant">null</span>,             <span class="comment">// mapper output key</span>
  <span class="predefined-constant">null</span>,             <span class="comment">// mapper output value</span>
  job);
TableMapReduceUtil.initTableReducerJob(
  targetTable,      <span class="comment">// output table</span>
  <span class="predefined-constant">null</span>,             <span class="comment">// reducer class</span>
  job);
job.setNumReduceTasks(<span class="integer">0</span>);

<span class="type">boolean</span> b = job.waitForCompletion(<span class="predefined-constant">true</span>);
<span class="keyword">if</span> (!b) {
    <span class="keyword">throw</span> <span class="keyword">new</span> <span class="exception">IOException</span>(<span class="string"><span class="delimiter">&quot;</span><span class="content">error with job!</span><span class="delimiter">&quot;</span></span>);
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>需要说明什么<code>TableMapReduceUtil</code>正在做，尤其是在减速器上。<a href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/mapreduce/TableOutputFormat.html">TableOutputFormat</a>用作outputFormat类，并且在配置上设置了几个参数（例如， <code>TableOutputFormat.OUTPUT_TABLE</code> ），以及将减速机输出键设置为<code>ImmutableBytesWritable</code>和减速器的价值<code>Writable</code> 。这些可以由程序员在作业和配置上设置，但是<code>TableMapReduceUtil</code>试图使事情变得容易。</p>
</div>
<div class="paragraph">
<p>以下是示例映射器，它将创建一个<code>Put</code>并匹配输入<code>Result</code>并发出它。注意：这就是CopyTable实用程序的作用。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="directive">public</span> <span class="directive">static</span> <span class="type">class</span> <span class="class">MyMapper</span> <span class="directive">extends</span> TableMapper&lt;ImmutableBytesWritable, Put&gt;  {

  <span class="directive">public</span> <span class="type">void</span> map(ImmutableBytesWritable row, <span class="predefined-type">Result</span> value, <span class="predefined-type">Context</span> context) <span class="directive">throws</span> <span class="exception">IOException</span>, <span class="exception">InterruptedException</span> {
    <span class="comment">// this example is just copying the data from the source table...</span>
      context.write(row, resultToPut(row,value));
    }

    <span class="directive">private</span> <span class="directive">static</span> Put resultToPut(ImmutableBytesWritable key, <span class="predefined-type">Result</span> result) <span class="directive">throws</span> <span class="exception">IOException</span> {
      Put put = <span class="keyword">new</span> Put(key.get());
      <span class="keyword">for</span> (KeyValue kv : result.raw()) {
        put.add(kv);
      }
      <span class="keyword">return</span> put;
    }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>实际上没有减速器步骤，所以<code>TableOutputFormat</code>负责发送<code>Put</code>到目标表。</p>
</div>
<div class="paragraph">
<p>这只是一个例子，开发人员可以选择不使用<code>TableOutputFormat</code>并自己连接到目标表。</p>
</div>
</div>
<div class="sect2">
<h3 id="mapreduce.example.readwrite.multi"><a class="anchor" href="#mapreduce.example.readwrite.multi"></a> 52.3。具有多表输出的HBase MapReduce读/写示例</h3>
<div class="paragraph">
<p>TODO：示例<code>MultiTableOutputFormat</code> 。</p>
</div>
</div>
<div class="sect2">
<h3 id="mapreduce.example.summary"><a class="anchor" href="#mapreduce.example.summary"></a> 52.4。HBase MapReduce汇总到HBase示例</h3>
<div class="paragraph">
<p>下面的示例通过摘要步骤将HBase用作MapReduce源和接收器。本示例将对一个表中某个值的不同实例的数量进行计数，并将这些汇总计数写入另一个表中。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="predefined-type">Configuration</span> config = HBaseConfiguration.create();
Job job = <span class="keyword">new</span> Job(config,<span class="string"><span class="delimiter">&quot;</span><span class="content">ExampleSummary</span><span class="delimiter">&quot;</span></span>);
job.setJarByClass(MySummaryJob.class);     <span class="comment">// class that contains mapper and reducer</span>

Scan scan = <span class="keyword">new</span> Scan();
scan.setCaching(<span class="integer">500</span>);        <span class="comment">// 1 is the default in Scan, which will be bad for MapReduce jobs</span>
scan.setCacheBlocks(<span class="predefined-constant">false</span>);  <span class="comment">// don't set to true for MR jobs</span>
<span class="comment">// set other scan attrs</span>

TableMapReduceUtil.initTableMapperJob(
  sourceTable,        <span class="comment">// input table</span>
  scan,               <span class="comment">// Scan instance to control CF and attribute selection</span>
  MyMapper.class,     <span class="comment">// mapper class</span>
  Text.class,         <span class="comment">// mapper output key</span>
  IntWritable.class,  <span class="comment">// mapper output value</span>
  job);
TableMapReduceUtil.initTableReducerJob(
  targetTable,        <span class="comment">// output table</span>
  MyTableReducer.class,    <span class="comment">// reducer class</span>
  job);
job.setNumReduceTasks(<span class="integer">1</span>);   <span class="comment">// at least one, adjust as required</span>

<span class="type">boolean</span> b = job.waitForCompletion(<span class="predefined-constant">true</span>);
<span class="keyword">if</span> (!b) {
  <span class="keyword">throw</span> <span class="keyword">new</span> <span class="exception">IOException</span>(<span class="string"><span class="delimiter">&quot;</span><span class="content">error with job!</span><span class="delimiter">&quot;</span></span>);
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>在此示例映射器中，选择具有String值的列作为要汇总的值。此值用作从映射器发出的键，并且<code>IntWritable</code>代表实例计数器。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="directive">public</span> <span class="directive">static</span> <span class="type">class</span> <span class="class">MyMapper</span> <span class="directive">extends</span> TableMapper&lt;Text, IntWritable&gt;  {
  <span class="directive">public</span> <span class="directive">static</span> <span class="directive">final</span> <span class="type">byte</span><span class="type">[]</span> CF = <span class="string"><span class="delimiter">&quot;</span><span class="content">cf</span><span class="delimiter">&quot;</span></span>.getBytes();
  <span class="directive">public</span> <span class="directive">static</span> <span class="directive">final</span> <span class="type">byte</span><span class="type">[]</span> ATTR1 = <span class="string"><span class="delimiter">&quot;</span><span class="content">attr1</span><span class="delimiter">&quot;</span></span>.getBytes();

  <span class="directive">private</span> <span class="directive">final</span> IntWritable ONE = <span class="keyword">new</span> IntWritable(<span class="integer">1</span>);
  <span class="directive">private</span> Text text = <span class="keyword">new</span> Text();

  <span class="directive">public</span> <span class="type">void</span> map(ImmutableBytesWritable row, <span class="predefined-type">Result</span> value, <span class="predefined-type">Context</span> context) <span class="directive">throws</span> <span class="exception">IOException</span>, <span class="exception">InterruptedException</span> {
    <span class="predefined-type">String</span> val = <span class="keyword">new</span> <span class="predefined-type">String</span>(value.getValue(CF, ATTR1));
    text.set(val);     <span class="comment">// we can only emit Writables...</span>
    context.write(text, ONE);
  }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>在化简器中，对“ 1”进行计数（就像执行此操作的任何其他MR示例一样），然后发出<code>Put</code> 。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="directive">public</span> <span class="directive">static</span> <span class="type">class</span> <span class="class">MyTableReducer</span> <span class="directive">extends</span> TableReducer&lt;Text, IntWritable, ImmutableBytesWritable&gt;  {
  <span class="directive">public</span> <span class="directive">static</span> <span class="directive">final</span> <span class="type">byte</span><span class="type">[]</span> CF = <span class="string"><span class="delimiter">&quot;</span><span class="content">cf</span><span class="delimiter">&quot;</span></span>.getBytes();
  <span class="directive">public</span> <span class="directive">static</span> <span class="directive">final</span> <span class="type">byte</span><span class="type">[]</span> COUNT = <span class="string"><span class="delimiter">&quot;</span><span class="content">count</span><span class="delimiter">&quot;</span></span>.getBytes();

  <span class="directive">public</span> <span class="type">void</span> reduce(Text key, <span class="predefined-type">Iterable</span>&lt;IntWritable&gt; values, <span class="predefined-type">Context</span> context) <span class="directive">throws</span> <span class="exception">IOException</span>, <span class="exception">InterruptedException</span> {
    <span class="type">int</span> i = <span class="integer">0</span>;
    <span class="keyword">for</span> (IntWritable val : values) {
      i += val.get();
    }
    Put put = <span class="keyword">new</span> Put(Bytes.toBytes(key.toString()));
    put.add(CF, COUNT, Bytes.toBytes(i));

    context.write(<span class="predefined-constant">null</span>, put);
  }
}</code></pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="mapreduce.example.summary.file"><a class="anchor" href="#mapreduce.example.summary.file"></a> 52.5。HBase MapReduce摘要文件示例</h3>
<div class="paragraph">
<p>这与上面的摘要示例非常相似，不同的是，它使用HBase作为MapReduce源，但使用HDFS作为接收器。区别在于作业设置和减速机。映射器保持不变。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="predefined-type">Configuration</span> config = HBaseConfiguration.create();
Job job = <span class="keyword">new</span> Job(config,<span class="string"><span class="delimiter">&quot;</span><span class="content">ExampleSummaryToFile</span><span class="delimiter">&quot;</span></span>);
job.setJarByClass(MySummaryFileJob.class);     <span class="comment">// class that contains mapper and reducer</span>

Scan scan = <span class="keyword">new</span> Scan();
scan.setCaching(<span class="integer">500</span>);        <span class="comment">// 1 is the default in Scan, which will be bad for MapReduce jobs</span>
scan.setCacheBlocks(<span class="predefined-constant">false</span>);  <span class="comment">// don't set to true for MR jobs</span>
<span class="comment">// set other scan attrs</span>

TableMapReduceUtil.initTableMapperJob(
  sourceTable,        <span class="comment">// input table</span>
  scan,               <span class="comment">// Scan instance to control CF and attribute selection</span>
  MyMapper.class,     <span class="comment">// mapper class</span>
  Text.class,         <span class="comment">// mapper output key</span>
  IntWritable.class,  <span class="comment">// mapper output value</span>
  job);
job.setReducerClass(MyReducer.class);    <span class="comment">// reducer class</span>
job.setNumReduceTasks(<span class="integer">1</span>);    <span class="comment">// at least one, adjust as required</span>
FileOutputFormat.setOutputPath(job, <span class="keyword">new</span> Path(<span class="string"><span class="delimiter">&quot;</span><span class="content">/tmp/mr/mySummaryFile</span><span class="delimiter">&quot;</span></span>));  <span class="comment">// adjust directories as required</span>

<span class="type">boolean</span> b = job.waitForCompletion(<span class="predefined-constant">true</span>);
<span class="keyword">if</span> (!b) {
  <span class="keyword">throw</span> <span class="keyword">new</span> <span class="exception">IOException</span>(<span class="string"><span class="delimiter">&quot;</span><span class="content">error with job!</span><span class="delimiter">&quot;</span></span>);
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>如上所述，在此示例中，以前的Mapper可以不变地运行。至于Reducer，它是一个“通用” Reducer，而不是扩展TableMapper和发出Puts。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="directive">public</span> <span class="directive">static</span> <span class="type">class</span> <span class="class">MyReducer</span> <span class="directive">extends</span> Reducer&lt;Text, IntWritable, Text, IntWritable&gt;  {

  <span class="directive">public</span> <span class="type">void</span> reduce(Text key, <span class="predefined-type">Iterable</span>&lt;IntWritable&gt; values, <span class="predefined-type">Context</span> context) <span class="directive">throws</span> <span class="exception">IOException</span>, <span class="exception">InterruptedException</span> {
    <span class="type">int</span> i = <span class="integer">0</span>;
    <span class="keyword">for</span> (IntWritable val : values) {
      i += val.get();
    }
    context.write(key, <span class="keyword">new</span> IntWritable(i));
  }
}</code></pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="mapreduce.example.summary.noreducer"><a class="anchor" href="#mapreduce.example.summary.noreducer"></a> 52.6。HBase MapReduce摘要到不带减速器的HBase</h3>
<div class="paragraph">
<p>如果将HBase用作化简器，也可以不使用化简器执行摘要。</p>
</div>
<div class="paragraph">
<p>HBase目标表将需要存在以进行作业摘要。表格方法<code>incrementColumnValue</code>将用于原子地递增值。从性能的角度来看，可能需要保留一个“值映射”，并为每个映射任务增加其值，并在执行过程中对每个键进行一次更新。 <code>cleanup</code>映射器的方法。但是，您的里程可能会有所不同，具体取决于要处理的行数和唯一键。</p>
</div>
<div class="paragraph">
<p>最后，汇总结果在HBase中。</p>
</div>
</div>
<div class="sect2">
<h3 id="mapreduce.example.summary.rdbms"><a class="anchor" href="#mapreduce.example.summary.rdbms"></a> 52.7。HBase MapReduce到RDBMS的摘要</h3>
<div class="paragraph">
<p>有时，为RDBMS生成摘要更为合适。对于这些情况，可以通过定制化简器直接向RDBMS生成摘要。的<code>setup</code>方法可以连接到RDBMS（可以通过上下文中的自定义参数传递连接信息），并且清除方法可以关闭连接。</p>
</div>
<div class="paragraph">
<p>至关重要的是要了解该作业的减速器数量会影响汇总实现，因此您必须将其设计到减速器中。具体来说，它是设计为作为单例（一个减速器）运行还是作为多个减速器运行。对与错都取决于您的用例。认识到分配给作业的减速器越多，将创建到RDBMS的同时连接越多-这将扩展，但仅限于一点。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="directive">public</span> <span class="directive">static</span> <span class="type">class</span> <span class="class">MyRdbmsReducer</span> <span class="directive">extends</span> Reducer&lt;Text, IntWritable, Text, IntWritable&gt;  {

  <span class="directive">private</span> <span class="predefined-type">Connection</span> c = <span class="predefined-constant">null</span>;

  <span class="directive">public</span> <span class="type">void</span> setup(<span class="predefined-type">Context</span> context) {
    <span class="comment">// create DB connection...</span>
  }

  <span class="directive">public</span> <span class="type">void</span> reduce(Text key, <span class="predefined-type">Iterable</span>&lt;IntWritable&gt; values, <span class="predefined-type">Context</span> context) <span class="directive">throws</span> <span class="exception">IOException</span>, <span class="exception">InterruptedException</span> {
    <span class="comment">// do summarization</span>
    <span class="comment">// in this example the keys are Text, but this is just an example</span>
  }

  <span class="directive">public</span> <span class="type">void</span> cleanup(<span class="predefined-type">Context</span> context) {
    <span class="comment">// close db connection</span>
  }

}</code></pre>
</div>
</div>
<div class="paragraph">
<p>最后，汇总结果将写入您的RDBMS表。</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="mapreduce.htable.access"><a class="anchor" href="#mapreduce.htable.access"></a> 53。在MapReduce作业中访问其他HBase表</h2>
<div class="sectionbody">
<div class="paragraph">
<p>尽管该框架当前允许一个HBase表作为MapReduce作业的输入，但可以通过在Mapper的setup方法中创建一个Table实例在MapReduce作业中将其他HBase表作为查找表等进行访问。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="directive">public</span> <span class="type">class</span> <span class="class">MyMapper</span> <span class="directive">extends</span> TableMapper&lt;Text, LongWritable&gt; {
  <span class="directive">private</span> Table myOtherTable;

  <span class="directive">public</span> <span class="type">void</span> setup(<span class="predefined-type">Context</span> context) {
    <span class="comment">// In here create a Connection to the cluster and save it or use the Connection</span>
    <span class="comment">// from the existing table</span>
    myOtherTable = connection.getTable(<span class="string"><span class="delimiter">&quot;</span><span class="content">myOtherTable</span><span class="delimiter">&quot;</span></span>);
  }

  <span class="directive">public</span> <span class="type">void</span> map(ImmutableBytesWritable row, <span class="predefined-type">Result</span> value, <span class="predefined-type">Context</span> context) <span class="directive">throws</span> <span class="exception">IOException</span>, <span class="exception">InterruptedException</span> {
    <span class="comment">// process Result...</span>
    <span class="comment">// use 'myOtherTable' for lookups</span>
  }</code></pre>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="mapreduce.specex"><a class="anchor" href="#mapreduce.specex"></a> 54。投机执行</h2>
<div class="sectionbody">
<div class="paragraph">
<p>对于使用HBase作为源的MapReduce作业，通常建议关闭推测执行。可以在整个群集上通过属性逐个作业地完成此操作。特别是对于长时间运行的作业，推测性执行将创建重复的映射任务，这会将您的数据双重写入HBase。这可能不是您想要的。</p>
</div>
<div class="paragraph">
<p>有关更多信息，请参见<a href="#spec.ex">spec.ex。</a></p>
</div>
</div>
</div>
<h1 id="security" class="sect0"><a class="anchor" href="#security"></a>保护Apache HBase</h1>
<div class="openblock partintro">
<div class="content">
<div class="admonitionblock important">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-important" title="重要"></i>
</td>
<td class="content">
<div class="title">报告安全漏洞</div>
<div class="admonitionblock note">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-note" title="注意"></i>
</td>
<td class="content">为了保护现有的HBase安装不受攻击，请<strong>不要</strong>使用JIRA报告与安全性有关的错误。而是将您的报告发送到邮件列表<a href="mailto:private@apache.org">private@apache.org</a> ，该列表允许任何人发送消息，但限制了可以读取消息的人。该列表中的某人将与您联系以跟进您的报告。
</td>
</tr>
</tbody></table>
</div>
<div class="paragraph">
<p>HBase遵守Apache Software Foundation关于已报告漏洞的政策，该政策可从<a href="http://apache.org/security/" class="bare">http://apache.org/security/获得</a> 。</p>
</div>
<div class="paragraph">
<p>如果您希望发送加密的报告，则可以使用为常规ASF安全列表提供的GPG详细信息。这可能会增加对报告的响应时间。</p>
</div>
</td>
</tr>
</tbody></table>
</div>
<div class="paragraph">
<p>HBase提供了一些机制来保护HBase的各个组件和方面以及它与Hadoop基础架构的其余部分以及Hadoop外部的客户端和资源之间的关系。</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_using_secure_http_https_for_the_web_ui"><a class="anchor" href="#_using_secure_http_https_for_the_web_ui"></a> 55。将安全HTTP（HTTPS）用于Web UI</h2>
<div class="sectionbody">
<div class="paragraph">
<p>默认的HBase安装会为主服务器和区域服务器的Web UI使用不安全的HTTP连接。要改为启用安全HTTP（HTTPS）连接，请设置<code>hadoop.ssl.enabled</code>至<code>true</code>在<em>hbase-site.xml中</em> 。这不会更改Web UI使用的端口。要更改给定HBase组件的Web UI的端口，请在hbase-site.xml中配置该端口的设置。这些设置是：</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>hbase.master.info.port</code></p>
</li>
<li>
<p><code>hbase.regionserver.info.port</code></p>
</li>
</ul>
</div>
<div class="admonitionblock note">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-note" title="注意"></i>
</td>
<td class="content">
<div class="title">如果启用HTTPS，客户端应避免使用非安全的HTTP连接。</div>
<div class="paragraph">
<p>如果启用安全HTTP，则客户端应使用以下命令连接到HBase： <code>https://</code>网址。客户使用<code>http://</code> URL将收到HTTP响应<code>200</code> ，但不会接收任何数据。记录以下异常：</p>
</div>
<div class="listingblock">
<div class="content">
<pre>javax.net.ssl.SSLException: Unrecognized SSL message, plaintext connection?</pre>
</div>
</div>
<div class="paragraph">
<p>这是因为同一端口用于HTTP和HTTPS。</p>
</div>
<div class="paragraph">
<p>HBase将Jetty用于Web UI。如果不修改Jetty本身，似乎无法配置Jetty将一个端口重定向到同一主机上的另一个端口。有关更多信息，请参见Nick Dimiduk在此<a href="http://stackoverflow.com/questions/20611815/redirect-from-http-to-https-in-jetty">Stack Overflow</a>线程上的贡献。如果您知道如何解决此问题而又不为HTTPS打开第二个端口，那么不胜感激。</p>
</div>
</td>
</tr>
</tbody></table>
</div>
</div>
</div>
<div class="sect1">
<h2 id="hbase.secure.spnego.ui"><a class="anchor" href="#hbase.secure.spnego.ui"></a> 56。使用SPNEGO通过Web UI进行Kerberos身份验证</h2>
<div class="sectionbody">
<div class="paragraph">
<p>可以通过使用以下命令配置SPNEGO来启用对HBase Web UI的Kerberos身份验证： <code>hbase.security.authentication.ui</code> <em>hbase-site.xml中的</em>属性。启用此身份验证需要将HBase也配置为对RPC使用Kerberos身份验证（例如<code>hbase.security.authentication</code> = <code>kerberos</code> ）。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="xml"><span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>hbase.security.authentication.ui<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>kerberos<span class="tag">&lt;/value&gt;</span>
  <span class="tag">&lt;description&gt;</span>Controls what kind of authentication should be used for the HBase web UIs.<span class="tag">&lt;/description&gt;</span>
<span class="tag">&lt;/property&gt;</span>
<span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>hbase.security.authentication<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>kerberos<span class="tag">&lt;/value&gt;</span>
  <span class="tag">&lt;description&gt;</span>The Kerberos keytab file to use for SPNEGO authentication by the web server.<span class="tag">&lt;/description&gt;</span>
<span class="tag">&lt;/property&gt;</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>存在许多属性，可以为Web服务器配置SPNEGO身份验证：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="xml"><span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>hbase.security.authentication.spnego.kerberos.principal<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>HTTP/_HOST@EXAMPLE.COM<span class="tag">&lt;/value&gt;</span>
  <span class="tag">&lt;description&gt;</span>Required for SPNEGO, the Kerberos principal to use for SPNEGO authentication by the
  web server. The _HOST keyword will be automatically substituted with the node's
  hostname.<span class="tag">&lt;/description&gt;</span>
<span class="tag">&lt;/property&gt;</span>
<span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>hbase.security.authentication.spnego.kerberos.keytab<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>/etc/security/keytabs/spnego.service.keytab<span class="tag">&lt;/value&gt;</span>
  <span class="tag">&lt;description&gt;</span>Required for SPNEGO, the Kerberos keytab file to use for SPNEGO authentication by the
  web server.<span class="tag">&lt;/description&gt;</span>
<span class="tag">&lt;/property&gt;</span>
<span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>hbase.security.authentication.spnego.kerberos.name.rules<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span><span class="tag">&lt;/value&gt;</span>
  <span class="tag">&lt;description&gt;</span>Optional, Hadoop-style `auth_to_local` rules which will be parsed and used in the
  handling of Kerberos principals<span class="tag">&lt;/description&gt;</span>
<span class="tag">&lt;/property&gt;</span>
<span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>hbase.security.authentication.signature.secret.file<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span><span class="tag">&lt;/value&gt;</span>
  <span class="tag">&lt;description&gt;</span>Optional, a file whose contents will be used as a secret to sign the HTTP cookies
  as a part of the SPNEGO authentication handshake. If this is not provided, Java's `Random` library
  will be used for the secret.<span class="tag">&lt;/description&gt;</span>
<span class="tag">&lt;/property&gt;</span></code></pre>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="hbase.secure.configuration"><a class="anchor" href="#hbase.secure.configuration"></a> 57。安全的客户端访问Apache HBase</h2>
<div class="sectionbody">
<div class="paragraph">
<p>较新的Apache HBase版本（> = 0.92）支持客户端的可选SASL身份验证。另请参见Matteo Bertozzi的文章， <a href="http://www.cloudera.com/blog/2012/09/understanding-user-authentication-and-authorization-in-apache-hbase/">了解Apache HBase中的用户身份验证和授权</a> 。</p>
</div>
<div class="paragraph">
<p>这说明了如何设置Apache HBase和客户端以连接到安全的HBase资源。</p>
</div>
<div class="sect2">
<h3 id="security.prerequisites"><a class="anchor" href="#security.prerequisites"></a> 57.1。先决条件</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Hadoop身份验证配置</dt>
<dd>
<p>要使用强身份验证运行HBase RPC，必须设置<code>hbase.security.authentication</code>至<code>kerberos</code> 。在这种情况下，您还必须设置<code>hadoop.security.authentication</code>至<code>kerberos</code>在core-site.xml中。否则，您将对HBase使用强身份验证，而不对基础HDFS使用强身份验证，这将抵消任何好处。</p>
</dd>
<dt class="hdlist1">Kerberos KDC</dt>
<dd>
<p>您需要有一个有效的Kerberos KDC。</p>
</dd>
</dl>
</div>
</div>
<div class="sect2">
<h3 id="_server_side_configuration_for_secure_operation"><a class="anchor" href="#_server_side_configuration_for_secure_operation"></a> 57.2。服务器端配置以确保安全运行</h3>
<div class="paragraph">
<p>首先，请参阅<a href="#security.prerequisites">security.prerequisites，</a>并确保基础HDFS配置是安全的。</p>
</div>
<div class="paragraph">
<p>将以下内容添加到<code>hbase-site.xml</code>群集中每台服务器计算机上的文件：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="xml"><span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>hbase.security.authentication<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>kerberos<span class="tag">&lt;/value&gt;</span>
<span class="tag">&lt;/property&gt;</span>
<span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>hbase.security.authorization<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>true<span class="tag">&lt;/value&gt;</span>
<span class="tag">&lt;/property&gt;</span>
<span class="tag">&lt;property&gt;</span>
<span class="tag">&lt;name&gt;</span>hbase.coprocessor.region.classes<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>org.apache.hadoop.hbase.security.token.TokenProvider<span class="tag">&lt;/value&gt;</span>
<span class="tag">&lt;/property&gt;</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>部署这些配置更改时，需要完全关闭并重新启动HBase服务。</p>
</div>
</div>
<div class="sect2">
<h3 id="_client_side_configuration_for_secure_operation"><a class="anchor" href="#_client_side_configuration_for_secure_operation"></a> 57.3。客户端配置以确保安全运行</h3>
<div class="paragraph">
<p>首先，请参阅<a href="#security.prerequisites">先决条件，</a>并确保基础HDFS配置是安全的。</p>
</div>
<div class="paragraph">
<p>将以下内容添加到<code>hbase-site.xml</code>在每个客户端上归档：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="xml"><span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>hbase.security.authentication<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>kerberos<span class="tag">&lt;/value&gt;</span>
<span class="tag">&lt;/property&gt;</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>客户端环境必须通过以下方式从KDC或keytab登录到Kerberos： <code>kinit</code>在与HBase群集进行通信之前，可以使用该命令。</p>
</div>
<div class="paragraph">
<p>请注意，如果<code>hbase.security.authentication</code>如果客户端和服务器端站点文件不匹配，则客户端将无法与群集进行通信。</p>
</div>
<div class="paragraph">
<p>一旦为安全RPC配置了HBase，就可以选择配置加密通信。为此，请将以下内容添加到<code>hbase-site.xml</code>在每个客户端上归档：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="xml"><span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>hbase.rpc.protection<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>privacy<span class="tag">&lt;/value&gt;</span>
<span class="tag">&lt;/property&gt;</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>也可以在每个连接的基础上设置此配置属性。将其设置在<code>Configuration</code>提供给<code>Table</code> ：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="predefined-type">Configuration</span> conf = HBaseConfiguration.create();
<span class="predefined-type">Connection</span> connection = ConnectionFactory.createConnection(conf);
conf.set(<span class="string"><span class="delimiter">&quot;</span><span class="content">hbase.rpc.protection</span><span class="delimiter">&quot;</span></span>, <span class="string"><span class="delimiter">&quot;</span><span class="content">privacy</span><span class="delimiter">&quot;</span></span>);
<span class="keyword">try</span> (<span class="predefined-type">Connection</span> connection = ConnectionFactory.createConnection(conf)) {
  <span class="keyword">try</span> (Table table = connection.getTable(TableName.valueOf(tablename)) {
  .... do your stuff
  }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>预计加密通信的性能会降低约10％。</p>
</div>
</div>
<div class="sect2">
<h3 id="security.client.thrift"><a class="anchor" href="#security.client.thrift"></a> 57.4。用于安全操作的客户端配置-Thrift Gateway</h3>
<div class="paragraph">
<p>将以下内容添加到<code>hbase-site.xml</code>每个Thrift网关的文件：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="xml"><span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>hbase.thrift.keytab.file<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>/etc/hbase/conf/hbase.keytab<span class="tag">&lt;/value&gt;</span>
<span class="tag">&lt;/property&gt;</span>
<span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>hbase.thrift.kerberos.principal<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>$USER/_HOST@HADOOP.LOCALDOMAIN<span class="tag">&lt;/value&gt;</span>
  <span class="comment">&lt;!-- TODO: This may need to be  HTTP/_HOST@&lt;REALM&gt; and _HOST may not work.
   You may have  to put the concrete full hostname.
   --&gt;</span>
<span class="tag">&lt;/property&gt;</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>分别用适当的凭据和<em>$</em> keytab替换<em>$ USER</em>和<em>$ KEYTAB</em> 。</p>
</div>
<div class="paragraph">
<p>为了使用Thrift API主体与HBase进行交互，还必须添加<code>hbase.thrift.kerberos.principal</code>到<code><em>acl</em></code>表。例如，要提供Thrift API主体， <code>thrift_server</code> ，管理访问权限，这样的命令就足够了：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="sql"><span class="class">grant</span> <span class="string"><span class="delimiter">'</span><span class="content">thrift_server</span><span class="delimiter">'</span></span>, <span class="string"><span class="delimiter">'</span><span class="content">RWCA</span><span class="delimiter">'</span></span></code></pre>
</div>
</div>
<div class="paragraph">
<p>有关ACL的更多信息，请参见<a href="#hbase.accesscontrol.configuration">访问控制标签（ACL）</a>部分。</p>
</div>
<div class="paragraph">
<p>Thrift网关将使用提供的凭据向HBase进行身份验证。Thrift网关本身不会执行任何身份验证。所有通过Thrift网关的客户端访问都将使用Thrift网关的凭据并拥有其特权。</p>
</div>
</div>
<div class="sect2">
<h3 id="security.gateway.thrift"><a class="anchor" href="#security.gateway.thrift"></a> 57.5。配置Thrift Gateway以代表客户端进行身份验证</h3>
<div class="paragraph">
<p><a href="#security.client.thrift">安全操作的客户端配置-Thrift网关</a>介绍了如何使用固定用户向HBase认证Thrift客户端。或者，您可以配置Thrift网关代表客户端对HBase进行身份验证，并使用代理用户访问HBase。这在实施<a href="https://issues.apache.org/jira/browse/HBASE-11349">HBASE-11349</a>为节俭1，和<a href="https://issues.apache.org/jira/browse/HBASE-11474">HBASE-11474</a>为节俭2。</p>
</div>
<div class="admonitionblock note">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-note" title="注意"></i>
</td>
<td class="content">
<div class="title">节俭式框架运输的局限性</div>
<div class="paragraph">
<p>如果您使用框架传输，则您将无法利用此功能，因为SASL目前不适用于Thrift框架传输。</p>
</div>
</td>
</tr>
</tbody></table>
</div>
<div class="paragraph">
<p>要启用它，请执行以下操作。</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>通过遵循<a href="#security.client.thrift">安全操作客户端配置-Thrift Gateway中</a>描述的过程，确保Thrift在安全模式下运行。</p>
</li>
<li>
<p>确保将HBase配置为允许代理用户，如<a href="#security.rest.gateway">REST网关模拟配置中所述</a> 。</p>
</li>
<li>
<p>在每个运行Thrift网关的集群节点的<em>hbase-site.xml</em>中，设置属性<code>hbase.thrift.security.qop</code>为以下三个值之一：</p>
<div class="ulist">
<ul>
<li>
<p><code>privacy</code> -身份验证，完整性和机密性检查。</p>
</li>
<li>
<p><code>integrity</code> -身份验证和完整性检查</p>
</li>
<li>
<p><code>authentication</code> -仅验证检查</p>
</li>
</ul>
</div>
</li>
<li>
<p>重新启动Thrift网关进程以使更改生效。如果节点正在运行Thrift，则输出<code>jps</code>命令将列出一个<code>ThriftServer</code>处理。要在节点上停止Thrift，请运行以下命令<code>bin/hbase-daemon.sh stop thrift</code> 。要在节点上启动Thrift，请运行以下命令<code>bin/hbase-daemon.sh start thrift</code> 。</p>
</li>
</ol>
</div>
</div>
<div class="sect2">
<h3 id="security.gateway.thrift.doas"><a class="anchor" href="#security.gateway.thrift.doas"></a> 57.6。配置Thrift网关以使用<code>doAs</code>特征</h3>
<div class="paragraph">
<p><a href="#security.gateway.thrift">配置Thrift网关代表客户端进行身份验证</a>介绍如何配置Thrift网关代表客户端对HBase进行身份验证以及如何使用代理用户访问HBase。此方法的局限性在于，在使用特定的一组凭据初始化客户端之后，它无法在会话期间更改这些凭据。的<code>doAs</code>功能提供了一种灵活的方式来使用同一客户端模拟多个主体。此功能已在<a href="https://issues.apache.org/jira/browse/HBASE-12640">HBASE-12640中</a>为Thrift 1实现，但当前不适用于Thrift 2。</p>
</div>
<div class="paragraph">
<p><strong>要允许代理用户</strong> ，请将以下内容添加到每个HBase节点的<em>hbase-site.xml</em>文件中：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="xml"><span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>hadoop.security.authorization<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>true<span class="tag">&lt;/value&gt;</span>
<span class="tag">&lt;/property&gt;</span>
<span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>hadoop.proxyuser.$USER.groups<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>$GROUPS<span class="tag">&lt;/value&gt;</span>
<span class="tag">&lt;/property&gt;</span>
<span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>hadoop.proxyuser.$USER.hosts<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>$GROUPS<span class="tag">&lt;/value&gt;</span>
<span class="tag">&lt;/property&gt;</span></code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>要启用<code>doAs</code>功能</strong> ，为每个Thrift网关在<em>hbase-site.xml</em>文件中添加以下内容：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="xml"><span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>hbase.regionserver.thrift.http<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>true<span class="tag">&lt;/value&gt;</span>
<span class="tag">&lt;/property&gt;</span>
<span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>hbase.thrift.support.proxyuser<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>true/value<span class="error">&gt;</span>
<span class="tag">&lt;/property&gt;</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>查看<a href="https://github.com/apache/hbase/blob/master/hbase-examples/src/main/java/org/apache/hadoop/hbase/thrift/HttpDoAsClient.java">演示客户端</a> ，以全面了解如何在客户端中使用此功能。</p>
</div>
</div>
<div class="sect2">
<h3 id="_client_side_configuration_for_secure_operation_rest_gateway"><a class="anchor" href="#_client_side_configuration_for_secure_operation_rest_gateway"></a> 57.7。用于安全操作的客户端配置-REST网关</h3>
<div class="paragraph">
<p>将以下内容添加到<code>hbase-site.xml</code>每个REST网关的文件：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="xml"><span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>hbase.rest.keytab.file<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>$KEYTAB<span class="tag">&lt;/value&gt;</span>
<span class="tag">&lt;/property&gt;</span>
<span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>hbase.rest.kerberos.principal<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>$USER/_HOST@HADOOP.LOCALDOMAIN<span class="tag">&lt;/value&gt;</span>
<span class="tag">&lt;/property&gt;</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>分别用适当的凭据和<em>$</em> keytab替换<em>$ USER</em>和<em>$ KEYTAB</em> 。</p>
</div>
<div class="paragraph">
<p>REST网关将使用提供的凭据对HBase进行身份验证。</p>
</div>
<div class="paragraph">
<p>为了使用REST API主体与HBase进行交互，还必须添加<code>hbase.rest.kerberos.principal</code>到<code><em>acl</em></code>表。例如，要提供REST API主体， <code>rest_server</code> ，管理访问权限，这样的命令就足够了：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="sql"><span class="class">grant</span> <span class="string"><span class="delimiter">'</span><span class="content">rest_server</span><span class="delimiter">'</span></span>, <span class="string"><span class="delimiter">'</span><span class="content">RWCA</span><span class="delimiter">'</span></span></code></pre>
</div>
</div>
<div class="paragraph">
<p>有关ACL的更多信息，请参见<a href="#hbase.accesscontrol.configuration">访问控制标签（ACL）</a>部分。</p>
</div>
<div class="paragraph">
<p>HBase REST网关支持<a href="http://hadoop.apache.org/docs/stable/hadoop-auth/index.html">SPNEGO HTTP身份验证</a> ，以使客户端可以访问网关。要为客户端访问启用REST网关Kerberos身份验证，请将以下内容添加到<code>hbase-site.xml</code>每个REST网关的文件。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="xml"><span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>hbase.rest.authentication.type<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>kerberos<span class="tag">&lt;/value&gt;</span>
<span class="tag">&lt;/property&gt;</span>
<span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>hbase.rest.authentication.kerberos.principal<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>HTTP/_HOST@HADOOP.LOCALDOMAIN<span class="tag">&lt;/value&gt;</span>
<span class="tag">&lt;/property&gt;</span>
<span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>hbase.rest.authentication.kerberos.keytab<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>$KEYTAB<span class="tag">&lt;/value&gt;</span>
<span class="tag">&lt;/property&gt;</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>用keytab代替<em>$ KEYTAB的</em> HTTP。</p>
</div>
<div class="paragraph">
<p>HBase REST网关支持不同的“ hbase.rest.authentication.type”：简单，kerberos。您还可以通过实现Hadoop AuthenticationHandler来实现自定义身份验证，然后将完整的类名称指定为“ hbase.rest.authentication.type”值。有关更多信息，请参阅<a href="http://hadoop.apache.org/docs/stable/hadoop-auth/index.html">SPNEGO HTTP身份验证</a> 。</p>
</div>
</div>
<div class="sect2">
<h3 id="security.rest.gateway"><a class="anchor" href="#security.rest.gateway"></a> 57.8。REST网关模拟配置</h3>
<div class="paragraph">
<p>默认情况下，REST网关不支持模拟。它以上一节中配置的用户身份代表客户端访问HBase。对于HBase服务器，所有请求均来自REST网关用户。实际用户未知。您可以打开模拟支持。通过模拟，REST网关用户是代理用户。HBase服务器知道每个请求的实际/实际用户。因此，它可以应用适当的授权。</p>
</div>
<div class="paragraph">
<p>要打开REST网关模拟，我们需要配置HBase服务器（主服务器和区域服务器）以允许代理用户。配置REST网关以启用模拟。</p>
</div>
<div class="paragraph">
<p>要允许代理用户，请将以下内容添加到<code>hbase-site.xml</code>每个HBase服务器的文件：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="xml"><span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>hadoop.security.authorization<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>true<span class="tag">&lt;/value&gt;</span>
<span class="tag">&lt;/property&gt;</span>
<span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>hadoop.proxyuser.$USER.groups<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>$GROUPS<span class="tag">&lt;/value&gt;</span>
<span class="tag">&lt;/property&gt;</span>
<span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>hadoop.proxyuser.$USER.hosts<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>$GROUPS<span class="tag">&lt;/value&gt;</span>
<span class="tag">&lt;/property&gt;</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>将REST网关代理用户替换为<em>$ USER</em> ，并将允许的组列表替换为<em>$ GROUPS</em> 。</p>
</div>
<div class="paragraph">
<p>要启用REST网关模拟，请将以下内容添加到<code>hbase-site.xml</code>每个REST网关的文件。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="xml"><span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>hbase.rest.authentication.type<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>kerberos<span class="tag">&lt;/value&gt;</span>
<span class="tag">&lt;/property&gt;</span>
<span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>hbase.rest.authentication.kerberos.principal<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>HTTP/_HOST@HADOOP.LOCALDOMAIN<span class="tag">&lt;/value&gt;</span>
<span class="tag">&lt;/property&gt;</span>
<span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>hbase.rest.authentication.kerberos.keytab<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>$KEYTAB<span class="tag">&lt;/value&gt;</span>
<span class="tag">&lt;/property&gt;</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>用keytab代替<em>$ KEYTAB的</em> HTTP。</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="hbase.secure.simpleconfiguration"><a class="anchor" href="#hbase.secure.simpleconfiguration"></a> 58。简单的用户访问Apache HBase</h2>
<div class="sectionbody">
<div class="paragraph">
<p>较新的Apache HBase版本（> = 0.92）支持客户端的可选SASL身份验证。另请参见Matteo Bertozzi的文章， <a href="http://www.cloudera.com/blog/2012/09/understanding-user-authentication-and-authorization-in-apache-hbase/">了解Apache HBase中的用户身份验证和授权</a> 。</p>
</div>
<div class="paragraph">
<p>这描述了如何设置Apache HBase和客户端以简化用户对HBase资源的访问。</p>
</div>
<div class="sect2">
<h3 id="_simple_versus_secure_access"><a class="anchor" href="#_simple_versus_secure_access"></a> 58.1。简单访问与安全访问</h3>
<div class="paragraph">
<p>以下部分显示了如何设置简单的用户访问。简单的用户访问不是操作HBase的安全方法。此方法用于防止用户犯错误。它可以用来模拟在开发系统上使用的访问控制，而无需设置Kerberos。</p>
</div>
<div class="paragraph">
<p>此方法不用于防止恶意或黑客攻击尝试。要使HBase抵御这些类型的攻击，必须将HBase配置为安全操作。请参阅“ <a href="#hbase.secure.configuration">对Apache HBase的安全客户端访问</a> ”部分<a href="#hbase.secure.configuration">，</a>并完成此处描述的所有步骤。</p>
</div>
</div>
<div class="sect2">
<h3 id="_prerequisites"><a class="anchor" href="#_prerequisites"></a> 58.2。先决条件</h3>
<div class="paragraph">
<p>没有</p>
</div>
</div>
<div class="sect2">
<h3 id="_server_side_configuration_for_simple_user_access_operation"><a class="anchor" href="#_server_side_configuration_for_simple_user_access_operation"></a> 58.3。服务器端配置，用于简单的用户访问操作</h3>
<div class="paragraph">
<p>将以下内容添加到<code>hbase-site.xml</code>群集中每台服务器计算机上的文件：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="xml"><span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>hbase.security.authentication<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>simple<span class="tag">&lt;/value&gt;</span>
<span class="tag">&lt;/property&gt;</span>
<span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>hbase.security.authorization<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>true<span class="tag">&lt;/value&gt;</span>
<span class="tag">&lt;/property&gt;</span>
<span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>hbase.coprocessor.master.classes<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>org.apache.hadoop.hbase.security.access.AccessController<span class="tag">&lt;/value&gt;</span>
<span class="tag">&lt;/property&gt;</span>
<span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>hbase.coprocessor.region.classes<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>org.apache.hadoop.hbase.security.access.AccessController<span class="tag">&lt;/value&gt;</span>
<span class="tag">&lt;/property&gt;</span>
<span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>hbase.coprocessor.regionserver.classes<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>org.apache.hadoop.hbase.security.access.AccessController<span class="tag">&lt;/value&gt;</span>
<span class="tag">&lt;/property&gt;</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>对于0.94，请将以下内容添加到<code>hbase-site.xml</code>群集中每台服务器计算机上的文件：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="xml"><span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>hbase.rpc.engine<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>org.apache.hadoop.hbase.ipc.SecureRpcEngine<span class="tag">&lt;/value&gt;</span>
<span class="tag">&lt;/property&gt;</span>
<span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>hbase.coprocessor.master.classes<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>org.apache.hadoop.hbase.security.access.AccessController<span class="tag">&lt;/value&gt;</span>
<span class="tag">&lt;/property&gt;</span>
<span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>hbase.coprocessor.region.classes<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>org.apache.hadoop.hbase.security.access.AccessController<span class="tag">&lt;/value&gt;</span>
<span class="tag">&lt;/property&gt;</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>部署这些配置更改时，需要完全关闭并重新启动HBase服务。</p>
</div>
</div>
<div class="sect2">
<h3 id="_client_side_configuration_for_simple_user_access_operation"><a class="anchor" href="#_client_side_configuration_for_simple_user_access_operation"></a> 58.4。客户端配置，用于简单的用户访问操作</h3>
<div class="paragraph">
<p>将以下内容添加到<code>hbase-site.xml</code>在每个客户端上归档：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="xml"><span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>hbase.security.authentication<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>simple<span class="tag">&lt;/value&gt;</span>
<span class="tag">&lt;/property&gt;</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>对于0.94，请将以下内容添加到<code>hbase-site.xml</code>群集中每台服务器计算机上的文件：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="xml"><span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>hbase.rpc.engine<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>org.apache.hadoop.hbase.ipc.SecureRpcEngine<span class="tag">&lt;/value&gt;</span>
<span class="tag">&lt;/property&gt;</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>请注意，如果<code>hbase.security.authentication</code>如果客户端和服务器端站点文件不匹配，则客户端将无法与群集进行通信。</p>
</div>
<div class="sect3">
<h4 id="_client_side_configuration_for_simple_user_access_operation_thrift_gateway"><a class="anchor" href="#_client_side_configuration_for_simple_user_access_operation_thrift_gateway"></a> 58.4.1。简单用户访问操作的客户端配置-Thrift Gateway</h4>
<div class="paragraph">
<p>Thrift网关用户将需要访问。例如，要给Thrift API用户， <code>thrift_server</code> ，管理访问权限，这样的命令就足够了：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="sql"><span class="class">grant</span> <span class="string"><span class="delimiter">'</span><span class="content">thrift_server</span><span class="delimiter">'</span></span>, <span class="string"><span class="delimiter">'</span><span class="content">RWCA</span><span class="delimiter">'</span></span></code></pre>
</div>
</div>
<div class="paragraph">
<p>有关ACL的更多信息，请参见<a href="#hbase.accesscontrol.configuration">访问控制标签（ACL）</a>部分。</p>
</div>
<div class="paragraph">
<p>Thrift网关将使用提供的凭据向HBase进行身份验证。Thrift网关本身不会执行任何身份验证。所有通过Thrift网关的客户端访问都将使用Thrift网关的凭据并拥有其特权。</p>
</div>
</div>
<div class="sect3">
<h4 id="_client_side_configuration_for_simple_user_access_operation_rest_gateway"><a class="anchor" href="#_client_side_configuration_for_simple_user_access_operation_rest_gateway"></a> 58.4.2。用于简单用户访问操作的客户端配置-REST网关</h4>
<div class="paragraph">
<p>REST网关将使用提供的凭据对HBase进行身份验证。REST网关本身不会执行任何身份验证。通过REST网关进行的所有客户端访问都将使用REST网关的凭据，并具有其特权。</p>
</div>
<div class="paragraph">
<p>REST网关用户将需要访问。例如，要给REST API用户， <code>rest_server</code> ，管理访问权限，这样的命令就足够了：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="sql"><span class="class">grant</span> <span class="string"><span class="delimiter">'</span><span class="content">rest_server</span><span class="delimiter">'</span></span>, <span class="string"><span class="delimiter">'</span><span class="content">RWCA</span><span class="delimiter">'</span></span></code></pre>
</div>
</div>
<div class="paragraph">
<p>有关ACL的更多信息，请参见<a href="#hbase.accesscontrol.configuration">访问控制标签（ACL）</a>部分。</p>
</div>
<div class="paragraph">
<p>客户端应该可以通过SPNEGO HTTP身份验证通过REST网关通过HBase群集进行身份验证。这是未来的工作。</p>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_securing_access_to_hdfs_and_zookeeper"><a class="anchor" href="#_securing_access_to_hdfs_and_zookeeper"></a> 59。确保对HDFS和ZooKeeper的访问</h2>
<div class="sectionbody">
<div class="paragraph">
<p>安全的HBase需要安全的ZooKeeper和HDFS，以便用户无法从HBase下访问和/或修改元数据和数据。HBase使用HDFS（或配置的文件系统）来保留其数据文件以及预写日志（WAL）和其他数据。HBase使用ZooKeeper来存储一些用于操作的元数据（主地址，表锁，恢复状态等）。</p>
</div>
<div class="sect2">
<h3 id="_securing_zookeeper_data"><a class="anchor" href="#_securing_zookeeper_data"></a> 59.1。保护ZooKeeper数据</h3>
<div class="paragraph">
<p>ZooKeeper具有可插入的身份验证机制，以允许使用不同方法从客户端进行访问。ZooKeeper甚至可以同时允许经过身份验证和未经身份验证的客户端。可以通过为每个znode提供访问控制列表（ACL）来限制对znode的访问。ACL包含两个组件，身份验证方法和主体。ACL不是分层实施的。有关详细信息，请参见<a href="https://zookeeper.apache.org/doc/r3.3.6/zookeeperProgrammers.html#sc_ZooKeeperPluggableAuthentication">ZooKeeper程序员指南</a> 。</p>
</div>
<div class="paragraph">
<p>HBase守护程序通过SASL和kerberos向ZooKeeper进行<a href="#zk.sasl.auth">身份验证</a> （请参阅<a href="#zk.sasl.auth">使用ZooKeeper的SASL身份验证</a> ）。HBase设置znode ACL，以便仅HBase用户和配置的hbase超级用户（ <code>hbase.superuser</code> ）可以访问和修改数据。在将ZooKeeper用于服务发现或与客户端共享状态的情况下，由HBase创建的znode也将允许任何人（无论身份验证如何）读取这些znode（clusterId，主地址，元位置等），但只能读取HBase。用户可以修改它们。</p>
</div>
</div>
<div class="sect2">
<h3 id="_securing_file_system_hdfs_data"><a class="anchor" href="#_securing_file_system_hdfs_data"></a> 59.2。保护文件系统（HDFS）数据</h3>
<div class="paragraph">
<p>所有管理的数据都保存在文件系统的根目录下（ <code>hbase.rootdir</code> ）。应该限制对文件系统中数据和WAL文件的访问，以使用户无法绕过HBase层，并可以窥视文件系统中的基础数据文件。HBase假定使用的文件系统（HDFS或其他文件系统）强制执行权限。如果没有提供足够的文件系统保护（包括授权和身份验证），则HBase级别的授权控制（ACL，可见性标签等）将毫无意义，因为用户始终可以从文件系统访问数据。</p>
</div>
<div class="paragraph">
<p>HBase强制执行类似posix的权限700（ <code>rwx------</code> ）到其根目录。这意味着只有HBase用户可以读取或写入FS中的文件。可以通过配置更改默认设置<code>hbase.rootdir.perms</code>在hbase-site.xml中。需要重新启动活动主服务器，以便更改使用的权限。对于1.2.0之前的版本，您可以检查是否提交了HBASE-13780，如果没有提交，则可以根据需要手动设置根目录的权限。使用HDFS，命令将是：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">sudo -u hdfs hadoop fs -chmod 700 /hbase</code></pre>
</div>
</div>
<div class="paragraph">
<p>你应该改变<code>/hbase</code>如果您使用其他<code>hbase.rootdir</code> 。</p>
</div>
<div class="paragraph">
<p>在安全模式下，应配置SecureBulkLoadEndpoint并将其用于正确地将从MR作业创建的用户文件移交给HBase守护程序和HBase用户。分布式文件系统中的暂存目录，用于大容量加载（ <code>hbase.bulkload.staging.dir</code> ，默认为<code>/tmp/hbase-staging</code> ）应具有（模式711，或<code>rwx—​x—​x</code> ），以便用户可以访问在该父目录下创建的登台目录，但不能执行任何其他操作。有关如何配置SecureBulkLoadEndPoint的信息，请参阅<a href="#hbase.secure.bulkload">安全大容量加载</a> 。</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_securing_access_to_your_data"><a class="anchor" href="#_securing_access_to_your_data"></a> 60保护对您数据的访问</h2>
<div class="sectionbody">
<div class="paragraph">
<p>在HBase客户端与服务器进程和网关之间配置了安全身份验证之后，需要考虑数据本身的安全性。HBase提供了几种保护数据的策略：</p>
</div>
<div class="ulist">
<ul>
<li>
<p>基于角色的访问控制（RBAC）使用熟悉的角色范例控制哪些用户或组可以读写给定的HBase资源或执行协处理器端点。</p>
</li>
<li>
<p>可见性标签使您可以标记单元格并控制对标记单元格的访问，以进一步限制谁可以读取或写入数据的某些子集。可见性标签存储为标签。有关更多信息，请参见<a href="#hbase.tags">hbase.tags</a> 。</p>
</li>
<li>
<p>HFiles和WAL中基础文件系统上静态数据的透明加密。这样可以保护您的静态数据免受攻击者的攻击，而这些攻击者可以访问基础文件系统，而无需更改客户端的实现。它还可以防止因磁盘放置不当而造成的数据泄漏，这对于法律和法规遵从性很重要。</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>下面讨论了每个功能的服务器端配置，管理和实现细节，以及所有性能折衷。最后给出了一个示例安全配置，以显示所有这些功能一起使用，就像它们在现实世界中一样。</p>
</div>
<div class="admonitionblock caution">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-caution" title="警告"></i>
</td>
<td class="content">HBase中安全性的各个方面都在积极开发中，并且发展迅速。您为数据安全性采用的任何策略都应进行彻底测试。此外，其中一些功能仍处于试验开发阶段。要利用其中的许多功能，您必须正在运行HBase 0.98+并使用HFile v3文件格式。
</td>
</tr>
</tbody></table>
</div>
<div class="admonitionblock warning">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-warning" title="警告"></i>
</td>
<td class="content">
<div class="title">保护敏感文件</div>
<div class="paragraph">
<p>本节中的一些过程要求您在群集节点之间复制文件。复制密钥，配置文件或其他包含敏感字符串的文件时，请使用安全方法，例如<code>ssh</code> ，以避免泄漏敏感数据。</p>
</div>
</td>
</tr>
</tbody></table>
</div>
<div class="olist arabic">
<div class="title">过程：基本服务器端配置</div>
<ol class="arabic">
<li>
<p>通过设置启用HFile v3 <code>hfile.format.version</code>到3在<em>hbase-site.xml中</em> 。这是HBase 1.0和更高版本的默认设置。</p>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="xml"><span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>hfile.format.version<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>3<span class="tag">&lt;/value&gt;</span>
<span class="tag">&lt;/property&gt;</span></code></pre>
</div>
</div>
</li>
<li>
<p>启用RPC和ZooKeeper的SASL和Kerberos身份验证，如<a href="#security.prerequisites">security.prerequisites</a>和<a href="#zk.sasl.auth">使用ZooKeeper的SASL身份验证中</a>所述。</p>
</li>
</ol>
</div>
<div class="sect2">
<h3 id="hbase.tags"><a class="anchor" href="#hbase.tags"></a> 60.1。标签</h3>
<div class="paragraph">
<p><em class="firstterm">标签</em>是HFile v3的功能。标签是一部分元数据，它是单元的一部分，与键，值和版本分开。标签是实现细节，它为其他与安全相关的功能（例如单元级ACL和可见性标签）奠定了基础。标记存储在HFiles本身中。将来可能会使用标签来实现其他HBase功能。您不需要对标签了解太多，就可以使用它们启用的安全功能。</p>
</div>
<div class="sect3">
<h4 id="_implementation_details"><a class="anchor" href="#_implementation_details"></a> 60.1.1。实施细节</h4>
<div class="paragraph">
<p>每个单元格可以具有零个或多个标签。每个标签都有一个类型和实际的标签字节数组。</p>
</div>
<div class="paragraph">
<p>正如可以对行键，列族，限定符和值进行编码（请参阅<a href="#data.block.encoding.types">data.block.encoding.types</a> ）一样，也可以对标签进行编码。您可以在列族级别启用或禁用标记编码，并且默认情况下启用。使用<code>HColumnDescriptor#setCompressionTags(boolean compressTags)</code>在列族上管理编码设置的方法。您还需要为列系列启用DataBlockEncoder，以使标签编码生效。</p>
</div>
<div class="paragraph">
<p>如果还启用了WAL压缩，则可以通过设置WAL的值来启用WAL中每个标签的压缩<code>hbase.regionserver.wal.tags.enablecompression</code>至<code>true</code>在<em>hbase-site.xml中</em> 。标签压缩使用字典编码。</p>
</div>
<div class="paragraph">
<p>使用WAL加密时，不支持标签压缩。</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="hbase.accesscontrol.configuration"><a class="anchor" href="#hbase.accesscontrol.configuration"></a> 60.2。访问控制标签（ACL）</h3>
<div class="sect3">
<h4 id="_how_it_works"><a class="anchor" href="#_how_it_works"></a> 60.2.1。怎么运行的</h4>
<div class="paragraph">
<p>HBase中的ACL基于用户在组中的成员身份或从组中排除，以及给定的组访问给定资源的权限。ACL被实现为称为AccessController的协处理器。</p>
</div>
<div class="paragraph">
<p>HBase不维护私有组映射，而是依赖<em class="firstterm">Hadoop组映射器</em> ，该映射<em class="firstterm">器</em>在LDAP或Active Directory等目录中的实体与HBase用户之间进行映射。任何受支持的Hadoop组映射器都将起作用。然后，向用户授予针对资源（全局，名称空间，表，单元或端点）的特定权限（读取，写入，执行，创建，管理）。</p>
</div>
<div class="admonitionblock note">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-note" title="注意"></i>
</td>
<td class="content">启用Kerberos和访问控制后，将对客户端对HBase的访问进行身份验证，并且用户数据为私有数据，除非已明确授予访问权限。
</td>
</tr>
</tbody></table>
</div>
<div class="paragraph">
<p>HBase具有比关系数据库更简单的安全模型，尤其是在客户端操作方面。例如，插入（新记录）和更新（现有记录）之间没有区别，因为两者都折叠成Put。</p>
</div>
<div class="sect4">
<h5 id="_understanding_access_levels"><a class="anchor" href="#_understanding_access_levels"></a>了解访问级别</h5>
<div class="paragraph">
<p>HBase访问级别彼此独立授予，并允许在给定范围内进行不同类型的操作。</p>
</div>
<div class="ulist">
<ul>
<li>
<p><em>读取（R）</em> -可以读取给定范围的数据</p>
</li>
<li>
<p><em>写入（W）</em> -可以在给定范围内写入数据</p>
</li>
<li>
<p><em>执行（X）</em> -可以在给定范围内执行协处理器端点</p>
</li>
<li>
<p><em>创建（C）</em> -可以在给定范围内创建表或删除表（甚至包括未创建的表）</p>
</li>
<li>
<p><em>管理员（A）</em> -可以执行群集操作，例如平衡群集或在给定范围内分配区域</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>可能的范围是：</p>
</div>
<div class="ulist">
<ul>
<li>
<p><em>超级用户</em> -超级用户可以对任何资源执行HBase中可用的任何操作。在集群上运行HBase的用户是超级用户，分配给配置属性的任何主体也是如此<code>hbase.superuser</code>在<em>HMaster</em>上的hbase <em>-site.xml中</em> 。</p>
</li>
<li>
<p><em>全局</em> -在<em>全局</em>范围内授予的权限允许管理员对集群的所有表进行操作。</p>
</li>
<li>
<p><em>命名空间</em> -在<em>命名空间</em>范围内授予的权限适用于给定命名空间内的所有表。</p>
</li>
<li>
<p><em>表</em> -在<em>表</em>范围内授予的权限适用于给定表内的数据或元数据。</p>
</li>
<li>
<p><em>ColumnFamily-</em>在<em>ColumnFamily</em>范围内授予的权限适用于该ColumnFamily中的单元格。</p>
</li>
<li>
<p><em>单元格</em> -在<em>单元格</em>范围内授予的权限适用于该确切的单元格坐标（键，值，时间戳）。这允许策略与数据一起发展。</p>
<div class="paragraph">
<p>要更改特定单元格上的ACL，请将具有新ACL的更新后的单元格写入原始单元格的精确坐标。</p>
</div>
<div class="paragraph">
<p>如果您具有多版本架构，并且想要在所有可见版本上更新ACL，则需要为所有可见版本编写新的单元格。该应用程序可以完全控制策略的演变。</p>
</div>
<div class="paragraph">
<p>上述规则的例外是<code>append</code>和<code>increment</code>处理。追加和递增操作中可以携带ACL。如果该操作中包含一个，则它将应用于<code>append</code>要么<code>increment</code> 。否则，将保留要附加或递增的现有单元的ACL。</p>
</div>
</li>
</ul>
</div>
<div class="paragraph">
<p>访问级别和范围的组合创建了可以授予用户的可能访问级别的矩阵。在生产环境中，考虑完成特定工作所需的访问级别是很有用的。下表描述了一些常见类型的HBase用户的适当访问级别。重要的是，不要授予超出给定用户执行其所需任务所需权限的访问权限。</p>
</div>
<div class="ulist">
<ul>
<li>
<p><em>超级用户</em> -在生产系统中，只有HBase用户应具有超级用户访问权限。在开发环境中，管理员可能需要超级用户访问权限才能快速控制和管理集群。但是，这种类型的管理员通常应该是全局管理员，而不是超级用户。</p>
</li>
<li>
<p><em>全局管理员</em> -全局管理员可以执行任务并访问HBase中的每个表。在典型的生产环境中，管理员不应具有对表中数据的读取或写入权限。</p>
</li>
<li>
<p>具有管理员权限的全局管理员可以在群集上执行群集范围内的操作，例如平衡，分配或取消分配区域，或调用显式主要压缩。这是操作角色。</p>
</li>
<li>
<p>具有“创建”权限的全局管理员可以在HBase中创建或删除任何表。这更像是DBA类型的角色。</p>
<div class="paragraph">
<p>在生产环境中，不同的用户可能只有Admin和Create权限之一。</p>
</div>
<div class="admonitionblock warning">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-warning" title="警告"></i>
</td>
<td class="content">
<div class="paragraph">
<p>在当前实施中， <code>Admin</code>许可可以授予自己<code>Read</code>和<code>Write</code>对表的权限，并获得对该表数据的访问权限。因此，仅授予<code>Global Admin</code>实际需要信任用户的权限。</p>
</div>
<div class="paragraph">
<p>另请注意， <code>Global Admin</code>与<code>Create</code>权限可以执行<code>Put</code> ACL表上的操作，模拟<code>grant</code>要么<code>revoke</code>并绕过授权检查<code>Global Admin</code>权限。</p>
</div>
<div class="paragraph">
<p>由于这些问题，请谨慎授予<code>Global Admin</code>特权。</p>
</div>
</td>
</tr>
</tbody></table>
</div>
</li>
<li>
<p><em>命名空间管理员</em> -具有以下内容的命名空间管理员<code>Create</code>权限可以在该名称空间内创建或删除表，以及获取和还原快照。具有以下名称空间的管理员<code>Admin</code>权限可以对该名称空间内的表执行诸如拆分或主要压缩之类的操作。</p>
</li>
<li>
<p><em>表管理员</em> -表管理员只能在该表上执行管理操作。一个表管理员<code>Create</code>权限可以从该表创建快照或从快照还原该表。一个表管理员<code>Admin</code>权限可以对该表执行诸如拆分或主要压缩之类的操作。</p>
</li>
<li>
<p><em>用户</em> -用户可以读取或写入数据，或两者都有。用户也可以执行协处理器端点（如果有） <code>Executable</code>权限。</p>
</li>
</ul>
</div>
<table class="tableblock frame-all grid-all spread">
<caption class="title">表7。访问级别的真实示例</caption>
<colgroup>
<col style="width:25%">
<col style="width:25%">
<col style="width:25%">
<col style="width:25%">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">职称</th>
<th class="tableblock halign-left valign-top">范围</th>
<th class="tableblock halign-left valign-top">权限</th>
<th class="tableblock halign-left valign-top">描述</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">高级管理员</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">全球</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">访问，创建</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">管理集群并授予初级管理员访问权限。</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">初级管理员</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">全球</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">创建</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">创建表并授予表管理员访问权限。</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">表管理员</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">表</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">访问</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">从操作角度维护表。</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">数据分析师</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">表</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">读</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">根据HBase数据创建报告。</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Web应用程序</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">表</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">读，写</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">将数据放入HBase并使用HBase数据执行操作。</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<div class="title">ACL矩阵</div>
<p>有关ACL如何映射到特定HBase操作和任务的更多详细信息，请参见<a href="#appendix_acl_matrix">附录acl矩阵</a> 。</p>
</div>
</div>
<div class="sect4">
<h5 id="_implementation_details_2"><a class="anchor" href="#_implementation_details_2"></a>实施细节</h5>
<div class="paragraph">
<p>单元级ACL是使用标签实现的（请参见<a href="#hbase.tags">标签</a> ）。为了使用单元级别的ACL，必须使用HFile v3和HBase 0.98或更高版本。</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>由HBase创建的文件归运行HBase进程的操作系统用户所有。要与HBase文件进行交互，应使用API或批量加载工具。</p>
</li>
<li>
<p>HBase不在HBase内部对“角色”建模。而是可以授予组名权限。这允许通过组成员资格对角色进行外部建模。通过Hadoop组映射服务，可以在HBase的外部创建和操作组。</p>
</li>
</ol>
</div>
</div>
<div class="sect4">
<h5 id="_server_side_configuration"><a class="anchor" href="#_server_side_configuration"></a>服务器端配置</h5>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>作为前提条件，请执行<a href="#security.data.basic.server.side">[security.data.basic.server.side]中</a>的步骤。</p>
</li>
<li>
<p>通过在<em>hbase-site.xml中</em>设置以下属性来安装和配置AccessController协处理器。这些属性采用类列表。</p>
<div class="admonitionblock note">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-note" title="注意"></i>
</td>
<td class="content">如果将AccessController与VisibilityController一起使用，则AccessController必须在列表中排在第一位，因为在两个组件都处于活动状态的情况下，VisibilityController会将其系统表上的访问控制委托给AccessController。有关将两者一起使用的示例，请参阅“ <a href="#security.example.config">安全性配置示例”</a> 。
</td>
</tr>
</tbody></table>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="xml"> <span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>hbase.security.authorization<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>true<span class="tag">&lt;/value&gt;</span>
<span class="tag">&lt;/property&gt;</span>
<span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>hbase.coprocessor.region.classes<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>org.apache.hadoop.hbase.security.access.AccessController, org.apache.hadoop.hbase.security.token.TokenProvider<span class="tag">&lt;/value&gt;</span>
<span class="tag">&lt;/property&gt;</span>
<span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>hbase.coprocessor.master.classes<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>org.apache.hadoop.hbase.security.access.AccessController<span class="tag">&lt;/value&gt;</span>
<span class="tag">&lt;/property&gt;</span>
<span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>hbase.coprocessor.regionserver.classes<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>org.apache.hadoop.hbase.security.access.AccessController<span class="tag">&lt;/value&gt;</span>
<span class="tag">&lt;/property&gt;</span>
<span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>hbase.security.exec.permission.checks<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>true<span class="tag">&lt;/value&gt;</span>
<span class="tag">&lt;/property&gt;</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>（可选）您可以通过以下方式启用传输安全性： <code>hbase.rpc.protection</code>至<code>privacy</code> 。这需要HBase 0.98.4或更高版本。</p>
</div>
</li>
<li>
<p>在Hadoop名称节点的<em>core-site.xml中</em>设置Hadoop组映射器。这是Hadoop文件，而不是HBase文件。根据您的站点需求对其进行自定义。以下是一个示例。</p>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="xml"><span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>hadoop.security.group.mapping<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>org.apache.hadoop.security.LdapGroupsMapping<span class="tag">&lt;/value&gt;</span>
<span class="tag">&lt;/property&gt;</span>

<span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>hadoop.security.group.mapping.ldap.url<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>ldap://server<span class="tag">&lt;/value&gt;</span>
<span class="tag">&lt;/property&gt;</span>

<span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>hadoop.security.group.mapping.ldap.bind.user<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>Administrator@example-ad.local<span class="tag">&lt;/value&gt;</span>
<span class="tag">&lt;/property&gt;</span>

<span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>hadoop.security.group.mapping.ldap.bind.password<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>****<span class="tag">&lt;/value&gt;</span>
<span class="tag">&lt;/property&gt;</span>

<span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>hadoop.security.group.mapping.ldap.base<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>dc=example-ad,dc=local<span class="tag">&lt;/value&gt;</span>
<span class="tag">&lt;/property&gt;</span>

<span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>hadoop.security.group.mapping.ldap.search.filter.user<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>(<span class="entity">&amp;amp;</span>(objectClass=user)(sAMAccountName={0}))<span class="tag">&lt;/value&gt;</span>
<span class="tag">&lt;/property&gt;</span>

<span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>hadoop.security.group.mapping.ldap.search.filter.group<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>(objectClass=group)<span class="tag">&lt;/value&gt;</span>
<span class="tag">&lt;/property&gt;</span>

<span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>hadoop.security.group.mapping.ldap.search.attr.member<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>member<span class="tag">&lt;/value&gt;</span>
<span class="tag">&lt;/property&gt;</span>

<span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>hadoop.security.group.mapping.ldap.search.attr.group.name<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>cn<span class="tag">&lt;/value&gt;</span>
<span class="tag">&lt;/property&gt;</span></code></pre>
</div>
</div>
</li>
<li>
<p>（可选）启用提前评估策略。在HBase 0.98.0之前，如果未授予用户访问列系列或至少一个列限定符的权限，则将引发AccessDeniedException。HBase 0.98.0删除了此异常，以便允许单元级别的特殊授予。要恢复HBase 0.98.0-0.98.6中的旧行为，请设置<code>hbase.security.access.early_out</code>至<code>true</code>在<em>hbase-site.xml中</em> 。在HBase 0.98.6中，默认值已返回到<code>true</code> 。</p>
</li>
<li>
<p>分发配置并重新启动集群以使更改生效。</p>
</li>
<li>
<p>要测试您的配置，请以给定用户身份登录HBase Shell并使用<code>whoami</code>命令来报告用户所属的组。在此示例中，该用户被报告为该用户的成员<code>services</code>组。</p>
<div class="listingblock">
<div class="content">
<pre>hbase&gt; whoami
service (auth:KERBEROS)
    groups: services</pre>
</div>
</div>
</li>
</ol>
</div>
</div>
<div class="sect4">
<h5 id="_administration"><a class="anchor" href="#_administration"></a>管理</h5>
<div class="paragraph">
<p>可以从HBase Shell或通过API执行管理任务。</p>
</div>
<div class="admonitionblock caution">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-caution" title="警告"></i>
</td>
<td class="content">
<div class="title">API范例</div>
<div class="paragraph">
<p>以下许多API示例均来自源文件<em>hbase-server / src / test / java / org / apache / hadoop / hbase / security / access / TestAccessController.java</em>和<em>hbase-server / src / test / java / org / apache /hadoop/hbase/security/access/SecureTestUtil.java</em> 。</p>
</div>
<div class="paragraph">
<p>示例及其来源文件均不是公共HBase API的一部分，并且仅用于说明目的。有关使用说明，请参阅官方API。</p>
</div>
</td>
</tr>
</tbody></table>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>用户和组管理</p>
<div class="paragraph">
<p>用户和组在目录的HBase外部维护。</p>
</div>
</li>
<li>
<p>授予对命名空间，表，列族或单元格的访问权限</p>
<div class="paragraph">
<p>授予语句有几种不同类型的语法。第一个也是最熟悉的如下，表和列族是可选的：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="sql"><span class="class">grant</span> <span class="string"><span class="delimiter">'</span><span class="content">user</span><span class="delimiter">'</span></span>, <span class="string"><span class="delimiter">'</span><span class="content">RWXCA</span><span class="delimiter">'</span></span>, <span class="string"><span class="delimiter">'</span><span class="content">TABLE</span><span class="delimiter">'</span></span>, <span class="string"><span class="delimiter">'</span><span class="content">CF</span><span class="delimiter">'</span></span>, <span class="string"><span class="delimiter">'</span><span class="content">CQ</span><span class="delimiter">'</span></span></code></pre>
</div>
</div>
<div class="paragraph">
<p>授予组和用户访问权限的方式相同，但为组添加前缀<code>@</code>符号。以相同的方式，表和名称空间以相同的方式指定，但名称空间以<code>@</code>符号。</p>
</div>
<div class="paragraph">
<p>如本示例所示，还可以在单个语句中授予针对同一资源的多个权限。第一个子句将用户映射到ACL，第二个子句指定资源。</p>
</div>
<div class="admonitionblock note">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-note" title="注意"></i>
</td>
<td class="content">HBase Shell在单元级别授予和撤消访问的支持是用于测试和验证支持，不应用于生产用途，因为它不会将权限应用于尚不存在的单元。应用单元格级别权限的正确方法是在存储值时在应用程序代码中进行操作。
</td>
</tr>
</tbody></table>
</div>
<div class="paragraph">
<div class="title">ACL粒度和评估顺序</div>
<p>从最小粒度到最精细粒度对ACL进行评估，当达到授予许可的ACL时，评估将停止。这意味着单元ACL不会以较小的粒度覆盖ACL。</p>
</div>
<div class="exampleblock">
<div class="title">示例19HBase外壳</div>
<div class="content">
<div class="ulist">
<ul>
<li>
<p>全球：</p>
<div class="listingblock">
<div class="content">
<pre>hbase&gt; grant '@admins', 'RWXCA'</pre>
</div>
</div>
</li>
<li>
<p>命名空间：</p>
<div class="listingblock">
<div class="content">
<pre>hbase&gt; grant 'service', 'RWXCA', '@test-NS'</pre>
</div>
</div>
</li>
<li>
<p>表：</p>
<div class="listingblock">
<div class="content">
<pre>hbase&gt; grant 'service', 'RWXCA', 'user'</pre>
</div>
</div>
</li>
<li>
<p>列族：</p>
<div class="listingblock">
<div class="content">
<pre>hbase&gt; grant '@developers', 'RW', 'user', 'i'</pre>
</div>
</div>
</li>
<li>
<p>列限定符：</p>
<div class="listingblock">
<div class="content">
<pre>hbase&gt; grant 'service, 'RW', 'user', 'i', 'foo'</pre>
</div>
</div>
</li>
<li>
<p>细胞：</p>
<div class="paragraph">
<p>授予单元ACL的语法使用以下语法：</p>
</div>
<div class="listingblock">
<div class="content">
<pre>grant &lt;table&gt;, \
  { '&lt;user-or-group&gt;' =&gt; \
    '&lt;permissions&gt;', ... }, \
  { &lt;scanner-specification&gt; }</pre>
</div>
</div>
</li>
<li>
<p><em><user-or-group></user-or-group></em>是用户名或组名，前缀为<code>@</code>如果是一群人。</p>
</li>
<li>
<p><em><permissions></permissions></em>是包含任何或所有“ RWXCA”的字符串，尽管只有R和W在单元格范围内才有意义。</p>
</li>
<li>
<p><em><scanner-specification></scanner-specification></em>是'scan'shell命令使用的扫描仪规范语法和约定。有关扫描仪规格的一些示例，请发出以下HBase Shell命令。</p>
<div class="listingblock">
<div class="content">
<pre>hbase&gt; help "scan"</pre>
</div>
</div>
<div class="paragraph">
<p>此示例在与过滤器匹配的“ pii”列中的单元格上授予“ testuser”用户的读取访问权和对“ developers”组的读/写访问权限。</p>
</div>
<div class="listingblock">
<div class="content">
<pre>hbase&gt; grant 'user', \
  { '@developers' =&gt; 'RW', 'testuser' =&gt; 'R' }, \
  { COLUMNS =&gt; 'pii', FILTER =&gt; "(PrefixFilter ('test'))" }</pre>
</div>
</div>
<div class="paragraph">
<p>外壳程序将使用给定的标准运行扫描程序，用新的ACL重写找到的单元，然后将其存储回其精确坐标。</p>
</div>
</li>
</ul>
</div>
</div>
</div>
<div class="exampleblock">
<div class="title">示例20API</div>
<div class="content">
<div class="paragraph">
<p>下面的示例显示如何在表级别授予访问权限。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="directive">public</span> <span class="directive">static</span> <span class="type">void</span> grantOnTable(<span class="directive">final</span> HBaseTestingUtility util, <span class="directive">final</span> <span class="predefined-type">String</span> user,
    <span class="directive">final</span> TableName table, <span class="directive">final</span> <span class="type">byte</span><span class="type">[]</span> family, <span class="directive">final</span> <span class="type">byte</span><span class="type">[]</span> qualifier,
    <span class="directive">final</span> <span class="predefined-type">Permission</span>.Action... actions) <span class="directive">throws</span> <span class="exception">Exception</span> {
  SecureTestUtil.updateACLs(util, <span class="keyword">new</span> <span class="predefined-type">Callable</span>&lt;<span class="predefined-type">Void</span>&gt;() {
    <span class="annotation">@Override</span>
    <span class="directive">public</span> <span class="predefined-type">Void</span> call() <span class="directive">throws</span> <span class="exception">Exception</span> {
      <span class="predefined-type">Configuration</span> conf = HBaseConfiguration.create();
      <span class="predefined-type">Connection</span> connection = ConnectionFactory.createConnection(conf);
      <span class="keyword">try</span> (<span class="predefined-type">Connection</span> connection = ConnectionFactory.createConnection(conf)) {
        <span class="keyword">try</span> (Table table = connection.getTable(TableName.valueOf(tablename)) {
          AccessControlLists.ACL_TABLE_NAME);
          <span class="keyword">try</span> {
            BlockingRpcChannel service = acl.coprocessorService(HConstants.EMPTY_START_ROW);
            AccessControlService.BlockingInterface protocol =
                AccessControlService.newBlockingStub(service);
            ProtobufUtil.grant(protocol, user, table, family, qualifier, actions);
          } <span class="keyword">finally</span> {
            acl.close();
          }
          <span class="keyword">return</span> <span class="predefined-constant">null</span>;
        }
      }
    }
  }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>要在单元级别授予权限，您可以使用<code>Mutation.setACL</code>方法：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">Mutation.setACL(<span class="predefined-type">String</span> user, <span class="predefined-type">Permission</span> perms)
Mutation.setACL(<span class="predefined-type">Map</span>&lt;<span class="predefined-type">String</span>, <span class="predefined-type">Permission</span>&gt; perms)</code></pre>
</div>
</div>
<div class="paragraph">
<p>具体来说，此示例向名为的用户提供了读取权限<code>user1</code>在特定Put操作中包含的任何单元上：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">put.setACL(<span class="error">“</span>user1<span class="error">”</span>, <span class="keyword">new</span> <span class="predefined-type">Permission</span>(<span class="predefined-type">Permission</span>.Action.READ))</code></pre>
</div>
</div>
</div>
</div>
</li>
<li>
<p>撤消命名空间，表，列族或单元格中的访问控制</p>
<div class="paragraph">
<p>的<code>revoke</code> command和API是Grant命令和API的双胞胎，语法完全相同。唯一的例外是您不能撤消单元级别的权限。您只能撤消先前已授予的访问权限，并且<code>revoke</code>语句与显式拒绝资源不同。</p>
</div>
<div class="admonitionblock note">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-note" title="注意"></i>
</td>
<td class="content">HBase Shell对授予和撤消访问的支持是用于测试和验证支持，不应将其用于生产用途，因为它不会将权限应用于尚不存在的单元。应用单元格级别权限的正确方法是在存储值时在应用程序代码中进行操作。
</td>
</tr>
</tbody></table>
</div>
<div class="exampleblock">
<div class="title">示例21撤消对表的访问</div>
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="directive">public</span> <span class="directive">static</span> <span class="type">void</span> revokeFromTable(<span class="directive">final</span> HBaseTestingUtility util, <span class="directive">final</span> <span class="predefined-type">String</span> user,
    <span class="directive">final</span> TableName table, <span class="directive">final</span> <span class="type">byte</span><span class="type">[]</span> family, <span class="directive">final</span> <span class="type">byte</span><span class="type">[]</span> qualifier,
    <span class="directive">final</span> <span class="predefined-type">Permission</span>.Action... actions) <span class="directive">throws</span> <span class="exception">Exception</span> {
  SecureTestUtil.updateACLs(util, <span class="keyword">new</span> <span class="predefined-type">Callable</span>&lt;<span class="predefined-type">Void</span>&gt;() {
    <span class="annotation">@Override</span>
    <span class="directive">public</span> <span class="predefined-type">Void</span> call() <span class="directive">throws</span> <span class="exception">Exception</span> {
      <span class="predefined-type">Configuration</span> conf = HBaseConfiguration.create();
      <span class="predefined-type">Connection</span> connection = ConnectionFactory.createConnection(conf);
      Table acl = connection.getTable(util.getConfiguration(), AccessControlLists.ACL_TABLE_NAME);
      <span class="keyword">try</span> {
        BlockingRpcChannel service = acl.coprocessorService(HConstants.EMPTY_START_ROW);
        AccessControlService.BlockingInterface protocol =
            AccessControlService.newBlockingStub(service);
        ProtobufUtil.revoke(protocol, user, table, family, qualifier, actions);
      } <span class="keyword">finally</span> {
        acl.close();
      }
      <span class="keyword">return</span> <span class="predefined-constant">null</span>;
    }
  });
}</code></pre>
</div>
</div>
</div>
</div>
</li>
<li>
<p>显示用户的有效权限</p>
<div class="exampleblock">
<div class="title">示例22HBase外壳</div>
<div class="content">
<div class="listingblock">
<div class="content">
<pre>hbase&gt; user_permission 'user'

hbase&gt; user_permission '.*'

hbase&gt; user_permission JAVA_REGEX</pre>
</div>
</div>
</div>
</div>
</li>
</ol>
</div>
<div class="exampleblock">
<div class="title">示例23API</div>
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="directive">public</span> <span class="directive">static</span> <span class="type">void</span> verifyAllowed(User user, AccessTestAction action, <span class="type">int</span> count) <span class="directive">throws</span> <span class="exception">Exception</span> {
  <span class="keyword">try</span> {
    <span class="predefined-type">Object</span> obj = user.runAs(action);
    <span class="keyword">if</span> (obj != <span class="predefined-constant">null</span> &amp;&amp; obj <span class="keyword">instanceof</span> <span class="predefined-type">List</span>&amp;lt;?&amp;gt;) {
      <span class="predefined-type">List</span>&amp;lt;?&amp;gt; results = (<span class="predefined-type">List</span>&amp;lt;?&amp;gt;) obj;
      <span class="keyword">if</span> (results != <span class="predefined-constant">null</span> &amp;&amp; results.isEmpty()) {
        fail(<span class="string"><span class="delimiter">&quot;</span><span class="content">Empty non null results from action for user '</span><span class="delimiter">&quot;</span></span> <span class="error">`</span> user.getShortName() <span class="error">`</span> <span class="string"><span class="delimiter">&quot;</span><span class="content">'</span><span class="delimiter">&quot;</span></span>);
      }
      assertEquals(count, results.size());
    }
  } <span class="keyword">catch</span> (AccessDeniedException ade) {
    fail(<span class="string"><span class="delimiter">&quot;</span><span class="content">Expected action to pass for user '</span><span class="delimiter">&quot;</span></span> <span class="error">`</span> user.getShortName() <span class="error">`</span> <span class="string"><span class="delimiter">&quot;</span><span class="content">' but was denied</span><span class="delimiter">&quot;</span></span>);
  }
}</code></pre>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_visibility_labels"><a class="anchor" href="#_visibility_labels"></a> 60.3。可见性标签</h3>
<div class="paragraph">
<p>可见性标签控件只能用于允许与给定标签关联的用户或委托人读取或访问带有该标签的单元格。例如，您可以标记一个单元格<code>top-secret</code> ，并且仅将访问该标签的权限授予<code>managers</code>组。可见性标签是使用标签实现的，标签是HFile v3的功能，它允许您按单元存储元数据。标签是字符串，可以使用逻辑运算符（＆，|或！）并使用括号将标签组合成表达式。除了基本的格式正确之外，HBase不会对表达式进行任何形式的验证。可见性标签本身没有含义，可以用来表示敏感度级别，特权级别或任何其他任意语义。</p>
</div>
<div class="paragraph">
<p>如果用户的标签与单元格的标签或表达式不匹配，则拒绝用户访问该单元格。</p>
</div>
<div class="paragraph">
<p>在HBase 0.98.6和更高版本中，可见性标签和表达式支持UTF-8编码。使用创建标签时<code>addLabels(conf, labels)</code>提供的方法<code>org.apache.hadoop.hbase.security.visibility.VisibilityClient</code>类和通过Scan或Get传递“授权”中的标签，标签可以包含UTF-8字符以及可见性标签中通常使用的逻辑运算符，并带有普通的Java表示法，而无需任何转义方法。但是，当您通过Mutation传递CellVisibility表达式时，必须用<code>CellVisibility.quote()</code>如果您使用UTF-8字符或逻辑运算符，则使用此方法。看到<code>TestExpressionParser</code>以及源文件<em>hbase-client / src / test / java / org / apache / hadoop / hbase / client / TestScan.java</em> 。</p>
</div>
<div class="paragraph">
<p>用户在Put操作期间向单元格添加可见性表达式。在默认配置中，用户不需要访问标签即可为标签添加单元格。此行为由配置选项控制<code>hbase.security.visibility.mutations.checkauths</code> 。如果将此选项设置为<code>true</code> ，用户作为突变的一部分正在修改的标签必须与用户相关联，否则突变将失败。在“获取”或“扫描”过程中确定用户是否有权读取标记的单元格，并过滤掉不允许用户读取的结果。这将产生与返回结果相同的I / O损失，但是会减少网络上的负载。</p>
</div>
<div class="paragraph">
<p>还可以在“删除”操作期间指定可见性标签。有关可见性标签和删除的详细信息，请参见<a href="https://issues.apache.org/jira/browse/HBASE-10885">HBASE-10885</a> 。</p>
</div>
<div class="paragraph">
<p>当RegionServer首次接收到请求时，用户的有效标签集将建立在RPC上下文中。用户与标签关联的方式是可插入的。默认插件会通过添加到“获取”或“扫描”中的“授权”中指定的标签，并对照主叫用户的已认证标签列表检查这些标签。当客户端传递未经用户验证的标签时，默认插件会将其删除。您可以通过传递用户身份验证标签的子集<code>Get#setAuthorizations(Authorizations(String,…​))</code>和<code>Scan#setAuthorizations(Authorizations(String,…​));</code>方法。</p>
</div>
<div class="paragraph">
<p>可以向组授予与用户相同的可见性标签。组以@符号为前缀。当检查用户的可见性标签时，服务器将包括该用户所属的组的可见性标签以及用户自己的标签。使用API检索可见性标签时<code>VisibilityClient#getAuths</code>或Shell命令<code>get_auths</code>对于用户，我们将只返回专门为该用户添加的标签，而不是组级别标签。</p>
</div>
<div class="paragraph">
<p>可见性标签访问检查由VisibilityController协处理器执行。您可以使用界面<code>VisibilityLabelService</code>提供自定义实现和/或控制将可见性标签与单元格存储在一起的方式。有关一个<em>示例，</em>请参见源文件<em>hbase-server / src / test / java / org / apache / hadoop / hbase / security / visibility / TestVisibilityLabelsWithCustomVisLabService.java</em> 。</p>
</div>
<div class="paragraph">
<p>可见性标签可以与ACL结合使用。</p>
</div>
<div class="admonitionblock note">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-note" title="注意"></i>
</td>
<td class="content">必须先明确定义标签，然后才能在可见性标签中使用它们。请参阅以下示例，了解如何完成此操作。
</td>
</tr>
</tbody></table>
</div>
<div class="admonitionblock note">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-note" title="注意"></i>
</td>
<td class="content">当前无法确定已将哪些标签应用于单元格。有关详细信息，请参见<a href="https://issues.apache.org/jira/browse/HBASE-12470">HBASE-12470</a> 。
</td>
</tr>
</tbody></table>
</div>
<div class="admonitionblock note">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-note" title="注意"></i>
</td>
<td class="content">可见性标签当前不适用于超级用户。
</td>
</tr>
</tbody></table>
</div>
<table class="tableblock frame-all grid-all spread">
<caption class="title">表8。可见性表达示例</caption>
<colgroup>
<col style="width:50%">
<col style="width:50%">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">表达</th>
<th class="tableblock halign-left valign-top">解释</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><div class="literal"><pre>fulltime</pre></div></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">允许访问与全职标签关联的用户。</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><div class="literal"><pre>!public</pre></div></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">允许访问未与公共标签关联的用户。</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><div class="literal"><pre>( secret | topsecret ) &amp; !probationary</pre></div></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">允许访问与秘密或最高机密标签关联但与试用标签不关联的用户。</p></td>
</tr>
</tbody>
</table>
<div class="sect3">
<h4 id="_server_side_configuration_2"><a class="anchor" href="#_server_side_configuration_2"></a> 60.3.1。服务器端配置</h4>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>作为前提条件，请执行<a href="#security.data.basic.server.side">[security.data.basic.server.side]中</a>的步骤。</p>
</li>
<li>
<p>通过在<em>hbase-site.xml中</em>设置以下属性来安装和配置VisibilityController协处理器。这些属性采用类名列表。</p>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="xml"><span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>hbase.coprocessor.region.classes<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>org.apache.hadoop.hbase.security.visibility.VisibilityController<span class="tag">&lt;/value&gt;</span>
<span class="tag">&lt;/property&gt;</span>
<span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>hbase.coprocessor.master.classes<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>org.apache.hadoop.hbase.security.visibility.VisibilityController<span class="tag">&lt;/value&gt;</span>
<span class="tag">&lt;/property&gt;</span>
 <span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>hbase.security.authorization<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>true<span class="tag">&lt;/value&gt;</span>
<span class="tag">&lt;/property&gt;</span></code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-note" title="注意"></i>
</td>
<td class="content">如果同时使用AccessController和VisibilityController协处理器，则AccessController必须排在列表的首位，因为在两个组件都处于活动状态的情况下，VisibilityController会将其系统表上的访问控制委托给AccessController。
</td>
</tr>
</tbody></table>
</div>
</li>
<li>
<p>调整配置</p>
<div class="paragraph">
<p>默认情况下，用户可以使用任何标签来标记单元格，包括与它们不相关的标签，这意味着用户可以放置他无法读取的数据。例如，即使用户未与该标签关联，用户也可以使用（假设的）“最高机密”标签来标记该单元格。如果仅希望用户能够使用与其关联的标签来标记单元格，请设置<code>hbase.security.visibility.mutations.checkauths</code>至<code>true</code> 。在这种情况下，如果突变使用了用户未关联的标签，则它将失败。</p>
</div>
</li>
<li>
<p>分发配置并重新启动集群以使更改生效。</p>
</li>
</ol>
</div>
</div>
<div class="sect3">
<h4 id="_administration_2"><a class="anchor" href="#_administration_2"></a> 60.3.2。管理</h4>
<div class="paragraph">
<p>可以使用HBase Shell或Java API执行管理任务。为了定义可见性标签列表并将标签与用户相关联，HBase Shell可能更简单。</p>
</div>
<div class="admonitionblock caution">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-caution" title="警告"></i>
</td>
<td class="content">
<div class="title">API范例</div>
<div class="paragraph">
<p>本节中的许多Java API示例均来自源文件<em>hbase-server / src / test / java / org / apache / hadoop / hbase / security / visibility / TestVisibilityLabels.java</em> 。有关更多上下文，请参考该文件或API文档。</p>
</div>
<div class="paragraph">
<p>这些示例或它们的源文件均不是公共HBase API的一部分，并且仅用于说明目的。有关使用说明，请参阅官方API。</p>
</div>
</td>
</tr>
</tbody></table>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>定义可见性标签列表</p>
<div class="exampleblock">
<div class="title">示例24HBase外壳</div>
<div class="content">
<div class="listingblock">
<div class="content">
<pre>hbase&gt; add_labels [ 'admin', 'service', 'developer', 'test' ]</pre>
</div>
</div>
</div>
</div>
<div class="exampleblock">
<div class="title">示例25Java API</div>
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="directive">public</span> <span class="directive">static</span> <span class="type">void</span> addLabels() <span class="directive">throws</span> <span class="exception">Exception</span> {
  <span class="predefined-type">PrivilegedExceptionAction</span>&lt;VisibilityLabelsResponse&gt; action = <span class="keyword">new</span> <span class="predefined-type">PrivilegedExceptionAction</span>&lt;VisibilityLabelsResponse&gt;() {
    <span class="directive">public</span> VisibilityLabelsResponse run() <span class="directive">throws</span> <span class="exception">Exception</span> {
      <span class="predefined-type">String</span><span class="type">[]</span> labels = { SECRET, TOPSECRET, CONFIDENTIAL, PUBLIC, PRIVATE, COPYRIGHT, ACCENT,
          UNICODE_VIS_TAG, UC1, UC2 };
      <span class="keyword">try</span> {
        VisibilityClient.addLabels(conf, labels);
      } <span class="keyword">catch</span> (<span class="predefined-type">Throwable</span> t) {
        <span class="keyword">throw</span> <span class="keyword">new</span> <span class="exception">IOException</span>(t);
      }
      <span class="keyword">return</span> <span class="predefined-constant">null</span>;
    }
  };
  SUPERUSER.runAs(action);
}</code></pre>
</div>
</div>
</div>
</div>
</li>
<li>
<p>将标签与用户相关联</p>
<div class="exampleblock">
<div class="title">示例26。HBase外壳</div>
<div class="content">
<div class="listingblock">
<div class="content">
<pre>hbase&gt; set_auths 'service', [ 'service' ]</pre>
</div>
</div>
<div class="paragraph">
<p>+</p>
</div>
<div class="listingblock">
<div class="content">
<pre>hbase&gt; set_auths 'testuser', [ 'test' ]</pre>
</div>
</div>
<div class="paragraph">
<p>+</p>
</div>
<div class="listingblock">
<div class="content">
<pre>hbase&gt; set_auths 'qa', [ 'test', 'developer' ]</pre>
</div>
</div>
<div class="paragraph">
<p>+</p>
</div>
<div class="listingblock">
<div class="content">
<pre>hbase&gt; set_auths '@qagroup', [ 'test' ]</pre>
</div>
</div>
</div>
</div>
<div class="exampleblock">
<div class="title">示例27Java API</div>
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="directive">public</span> <span class="type">void</span> testSetAndGetUserAuths() <span class="directive">throws</span> <span class="predefined-type">Throwable</span> {
  <span class="directive">final</span> <span class="predefined-type">String</span> user = <span class="string"><span class="delimiter">&quot;</span><span class="content">user1</span><span class="delimiter">&quot;</span></span>;
  <span class="predefined-type">PrivilegedExceptionAction</span>&lt;<span class="predefined-type">Void</span>&gt; action = <span class="keyword">new</span> <span class="predefined-type">PrivilegedExceptionAction</span>&lt;<span class="predefined-type">Void</span>&gt;() {
    <span class="directive">public</span> <span class="predefined-type">Void</span> run() <span class="directive">throws</span> <span class="exception">Exception</span> {
      <span class="predefined-type">String</span><span class="type">[]</span> auths = { SECRET, CONFIDENTIAL };
      <span class="keyword">try</span> {
        VisibilityClient.setAuths(conf, auths, user);
      } <span class="keyword">catch</span> (<span class="predefined-type">Throwable</span> e) {
      }
      <span class="keyword">return</span> <span class="predefined-constant">null</span>;
    }
    ...</code></pre>
</div>
</div>
</div>
</div>
</li>
<li>
<p>清除用户标签</p>
<div class="exampleblock">
<div class="title">示例28。HBase外壳</div>
<div class="content">
<div class="listingblock">
<div class="content">
<pre>hbase&gt; clear_auths 'service', [ 'service' ]</pre>
</div>
</div>
<div class="paragraph">
<p>+</p>
</div>
<div class="listingblock">
<div class="content">
<pre>hbase&gt; clear_auths 'testuser', [ 'test' ]</pre>
</div>
</div>
<div class="paragraph">
<p>+</p>
</div>
<div class="listingblock">
<div class="content">
<pre>hbase&gt; clear_auths 'qa', [ 'test', 'developer' ]</pre>
</div>
</div>
<div class="paragraph">
<p>+</p>
</div>
<div class="listingblock">
<div class="content">
<pre>hbase&gt; clear_auths '@qagroup', [ 'test', 'developer' ]</pre>
</div>
</div>
</div>
</div>
<div class="exampleblock">
<div class="title">示例29。Java API</div>
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">...
auths = <span class="keyword">new</span> <span class="predefined-type">String</span><span class="type">[]</span> { SECRET, PUBLIC, CONFIDENTIAL };
VisibilityLabelsResponse response = <span class="predefined-constant">null</span>;
<span class="keyword">try</span> {
  response = VisibilityClient.clearAuths(conf, auths, user);
} <span class="keyword">catch</span> (<span class="predefined-type">Throwable</span> e) {
  fail(<span class="string"><span class="delimiter">&quot;</span><span class="content">Should not have failed</span><span class="delimiter">&quot;</span></span>);
  ...
}</code></pre>
</div>
</div>
</div>
</div>
</li>
<li>
<p>将标签或表达式应用于单元格</p>
<div class="paragraph">
<p>仅在写入数据时才应用标签。标签与单元的给定版本相关联。</p>
</div>
<div class="exampleblock">
<div class="title">示例30HBase外壳</div>
<div class="content">
<div class="listingblock">
<div class="content">
<pre>hbase&gt; set_visibility 'user', 'admin|service|developer', { COLUMNS =&gt; 'i' }</pre>
</div>
</div>
<div class="paragraph">
<p>+</p>
</div>
<div class="listingblock">
<div class="content">
<pre>hbase&gt; set_visibility 'user', 'admin|service', { COLUMNS =&gt; 'pii' }</pre>
</div>
</div>
<div class="paragraph">
<p>+</p>
</div>
<div class="listingblock">
<div class="content">
<pre>hbase&gt; set_visibility 'user', 'test', { COLUMNS =&gt; [ 'i', 'pii' ], FILTER =&gt; "(PrefixFilter ('test'))" }</pre>
</div>
</div>
</div>
</div>
<div class="admonitionblock note">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-note" title="注意"></i>
</td>
<td class="content">HBase Shell对将标签或权限应用于单元格的支持仅用于测试和验证支持，不应用于生产用途，因为它不会将标签应用于尚不存在的单元格。正确应用单元格级别标签的方法是在存储值时在应用程序代码中进行操作。
</td>
</tr>
</tbody></table>
</div>
<div class="exampleblock">
<div class="title">示例31。Java API</div>
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="directive">static</span> Table createTableAndWriteDataWithLabels(TableName tableName, <span class="predefined-type">String</span>... labelExps)
    <span class="directive">throws</span> <span class="exception">Exception</span> {
  <span class="predefined-type">Configuration</span> conf = HBaseConfiguration.create();
  <span class="predefined-type">Connection</span> connection = ConnectionFactory.createConnection(conf);
  Table table = NULL;
  <span class="keyword">try</span> {
    table = TEST_UTIL.createTable(tableName, fam);
    <span class="type">int</span> i = <span class="integer">1</span>;
    <span class="predefined-type">List</span>&lt;Put&gt; puts = <span class="keyword">new</span> <span class="predefined-type">ArrayList</span>&lt;Put&gt;();
    <span class="keyword">for</span> (<span class="predefined-type">String</span> labelExp : labelExps) {
      Put put = <span class="keyword">new</span> Put(Bytes.toBytes(<span class="string"><span class="delimiter">&quot;</span><span class="content">row</span><span class="delimiter">&quot;</span></span> + i));
      put.add(fam, qual, HConstants.LATEST_TIMESTAMP, value);
      put.setCellVisibility(<span class="keyword">new</span> CellVisibility(labelExp));
      puts.add(put);
      i++;
    }
    table.put(puts);
  } <span class="keyword">finally</span> {
    <span class="keyword">if</span> (table != <span class="predefined-constant">null</span>) {
      table.flushCommits();
    }
  }</code></pre>
</div>
</div>
</div>
</div>
</li>
</ol>
</div>
<div class="paragraph">
<p><a href="#reading_cells_with_labels">[reading_cells_with_labels]</a> ====读取带有标签的单元格发出“扫描”或“获取”时，HBase使用默认的授权集来过滤掉您无权访问的单元格。超级用户可以使用以下命令设置给定用户的默认授权集： <code>set_auths</code> HBase Shell命令或<a href="http://hbase.apache.org/devapidocs/org/apache/hadoop/hbase/security/visibility/VisibilityClient.html#setAuths(org.apache.hadoop.conf.Configuration, java.lang.String\">]，％20java.lang。字符串）[VisibilityClient.setAuths（）</a>方法。</p>
</div>
<div class="paragraph">
<p>您可以通过在HBase Shell中传递AUTHORIZATIONS选项或者在使用API的情况下通过<a href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/client/Scan.html#setAuthorizations%28org.apache.hadoop.hbase.security.visibility.Authorizations%29">setAuthorizations（）</a>方法来在“扫描”或“获取”期间指定其他授权。该授权将与您的默认设置结合在一起作为附加过滤器。它将进一步过滤您的结果，而不是授予您其他授权。</p>
</div>
<div class="exampleblock">
<div class="title">示例32HBase外壳</div>
<div class="content">
<div class="listingblock">
<div class="content">
<pre>hbase&gt; get_auths 'myUser'
hbase&gt; scan 'table1', AUTHORIZATIONS =&gt; ['private']</pre>
</div>
</div>
</div>
</div>
<div class="exampleblock">
<div class="title">例子33。Java API</div>
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">...
public <span class="predefined-type">Void</span> run() <span class="directive">throws</span> <span class="exception">Exception</span> {
  <span class="predefined-type">String</span><span class="type">[]</span> auths1 = { SECRET, CONFIDENTIAL };
  GetAuthsResponse authsResponse = <span class="predefined-constant">null</span>;
  <span class="keyword">try</span> {
    VisibilityClient.setAuths(conf, auths1, user);
    <span class="keyword">try</span> {
      authsResponse = VisibilityClient.getAuths(conf, user);
    } <span class="keyword">catch</span> (<span class="predefined-type">Throwable</span> e) {
      fail(<span class="string"><span class="delimiter">&quot;</span><span class="content">Should not have failed</span><span class="delimiter">&quot;</span></span>);
    }
  } <span class="keyword">catch</span> (<span class="predefined-type">Throwable</span> e) {
  }
  <span class="predefined-type">List</span>&lt;<span class="predefined-type">String</span>&gt; authsList = <span class="keyword">new</span> <span class="predefined-type">ArrayList</span>&lt;<span class="predefined-type">String</span>&gt;();
  <span class="keyword">for</span> (ByteString authBS : authsResponse.getAuthList()) {
    authsList.add(Bytes.toString(authBS.toByteArray()));
  }
  assertEquals(<span class="integer">2</span>, authsList.size());
  assertTrue(authsList.contains(SECRET));
  assertTrue(authsList.contains(CONFIDENTIAL));
  <span class="keyword">return</span> <span class="predefined-constant">null</span>;
}
...</code></pre>
</div>
</div>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_implementing_your_own_visibility_label_algorithm"><a class="anchor" href="#_implementing_your_own_visibility_label_algorithm"></a> 60.3.3。实施自己的可见性标签算法</h4>
<div class="paragraph">
<p>解释为给定的获取/扫描请求验证的标签是可插入的算法。</p>
</div>
<div class="paragraph">
<p>您可以使用属性指定一个或多个自定义插件<code>hbase.regionserver.scan.visibility.label.generator.class</code> 。第一个的输出<code>ScanLabelGenerator</code>将是下一个的输入，直到列表的末尾。</p>
</div>
<div class="paragraph">
<p>在<a href="https://issues.apache.org/jira/browse/HBASE-12466">HBASE-12466中</a>实现的默认实现会加载两个插件， <code>FeedUserAuthScanLabelGenerator</code>和<code>DefinedSetFilterScanLabelGenerator</code> 。参见<a href="#reading_cells_with_labels">[reading_cells_with_labels]</a> 。</p>
</div>
</div>
<div class="sect3">
<h4 id="_replicating_visibility_tags_as_strings"><a class="anchor" href="#_replicating_visibility_tags_as_strings"></a> 60.3.4。将可见性标签复制为字符串</h4>
<div class="paragraph">
<p>如以上各节所述，界面<code>VisibilityLabelService</code>可以用于实现在单元格中存储可见性表达式的另一种方式。启用复制的集群还必须将可见性表达式复制到对等集群。如果<code>DefaultVisibilityLabelServiceImpl</code>用作实现<code>VisibilityLabelService</code> ，所有可见性表达式都会根据标签表中存储的每个可见性标签的序号转换为相应的表达式。在复制过程中，可见细胞也将按顺序表达完整。对等群集可能不具有相同的<code>labels</code>可见性标签具有相同顺序映射的表格。在这种情况下，复制普通字母毫无意义。如果复制以字符串形式传输可见性表达式而进行复制会更好。要将可见性表达式作为字符串复制到对等集群，请创建一个<code>RegionServerObserver</code>配置的实现基于<code>VisibilityLabelService</code>接口。通过以下配置，可以将可见性表达式作为字符串复制到对等群集。有关更多详细信息，请参见<a href="https://issues.apache.org/jira/browse/HBASE-11639">HBASE-11639</a> 。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="xml"><span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>hbase.coprocessor.regionserver.classes<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>org.apache.hadoop.hbase.security.visibility.VisibilityController$VisibilityReplication<span class="tag">&lt;/value&gt;</span>
<span class="tag">&lt;/property&gt;</span></code></pre>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="hbase.encryption.server"><a class="anchor" href="#hbase.encryption.server"></a> 60.4。静态数据的透明加密</h3>
<div class="paragraph">
<p>HBase提供了一种保护位于HDFS或另一个分布式文件系统中的HFiles和WAL中的静态数据的机制。两层体系结构用于灵活和非侵入式密钥旋转。“透明”表示在客户端不需要更改任何实现。写入数据时，将对其进行加密。读取后，将按需解密。</p>
</div>
<div class="sect3">
<h4 id="_how_it_works_2"><a class="anchor" href="#_how_it_works_2"></a> 60.4.1。怎么运行的</h4>
<div class="paragraph">
<p>管理员为群集设置一个主密钥，该主密钥存储在密钥提供程序中，该密钥提供程序可用于每个受信任的HBase进程，包括管理工作站上的HMaster，RegionServers和客户端（例如HBase Shell）。默认密钥提供程序已与Java KeyStore API以及任何支持它的密钥管理系统集成在一起。其他自定义密钥提供程序实现也是可能的。密钥检索机制在<em>hbase-site.xml</em>配置文件中进行配置。主密钥可以存储在群集服务器上，受安全的KeyStore文件保护，也可以存储在外部密钥服务器上，或者存储在硬件安全模块中。HBase进程根据需要通过配置的密钥提供程序解析此主密钥。</p>
</div>
<div class="paragraph">
<p>接下来，可以通过创建或修改列描述符以包括两个附加属性，在模式中为每个列系列指定加密使用：加密算法的名称（当前仅支持“ AES”），以及可选的用集群主密钥包装（加密）的数据密钥。如果没有为ColumnFamily显式配置数据密钥，则HBase将为每个HFile创建一个随机数据密钥。与替代方案相比，这提供了安全性方面的增量改进。除非需要提供显式的数据密钥，例如在生成加密的HFile以使用给定的数据密钥批量导入的情况下，否则仅在ColumnFamily模式元数据中指定加密算法，然后让HBase根据需要创建数据密钥。每列族键可促进低冲击的增量键旋转，并减小键材料外部泄漏的范围。包装的数据密钥存储在ColumnFamily架构元数据中，并存储在Column Family的每个HFile中，并使用集群主密钥进行加密。配置列系列进行加密后，所有新的HFile将被写入加密状态。为确保对所有HFile进行加密，请在启用此功能后触发重大压缩。</p>
</div>
<div class="paragraph">
<p>打开HFile时，将从HFile中提取数据密钥，并使用集群主密钥解密该数据密钥，并将其用于解密HFile的其余部分。如果主密钥不可用，则HFile将不可读。如果远程用户由于HDFS权限的某些失效或从不当丢弃的媒体以某种方式获得了对HFile数据的访问权限，则将无法解密数据密钥或文件数据。</p>
</div>
<div class="paragraph">
<p>也可以对WAL进行加密。即使WAL是瞬态的，在底层文件系统遭到破坏的情况下，也有必要对WALEdits进行加密以避免对加密列族的HFile保护。启用WAL加密后，所有WAL都会被加密，无论相关的HFile是否已加密。</p>
</div>
</div>
<div class="sect3">
<h4 id="_server_side_configuration_3"><a class="anchor" href="#_server_side_configuration_3"></a> 60.4.2。服务器端配置</h4>
<div class="paragraph">
<p>此过程假定您正在使用默认的Java密钥库实现。如果您使用的是自定义实现，请检查其文档并进行相应调整。</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>使用以下命令，为AES加密创建适当长度的秘密密钥。 <code>keytool</code>效用。</p>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">$ keytool -keystore /path/to/hbase/conf/hbase.jks \
  -storetype jceks -storepass **** \
  -genseckey -keyalg AES -keysize 128 \
  -alias &lt;alias&gt;</code></pre>
</div>
</div>
<div class="paragraph">
<p>用密钥库文件的密码和<alias>HBase服务帐户的用户名或任意字符串替换<em class="replaceable">****</em> <alias>。如果使用任意字符串，则需要配置HBase以使用它，这将在下面介绍。指定适当的密钥大小。不要为密钥指定单独的密码，而是按<kbd>Return</kbd>提示时。</alias></alias></p>
</div>
</li>
<li>
<p>在密钥文件上设置适当的权限，并将其分发给所有HBase服务器。</p>
<div class="paragraph">
<p>上一条命令在HBase <em>conf /</em>目录中创建了一个名为<em>hbase.jks</em>的文件。对此文件设置权限和所有权，以便只有HBase服务帐户用户可以读取该文件，并将密钥安全地分发给所有HBase服务器。</p>
</div>
</li>
<li>
<p>配置HBase守护程序。</p>
<div class="paragraph">
<p>在区域服务器上的<em>hbase-site.xml中</em>设置以下属性，以配置HBase守护程序以使用由KeyStore文件支持的密钥提供者或检索集群主密钥。在下面的示例中，将<em class="replaceable">****</em>替换为密码。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="xml"><span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>hbase.crypto.keyprovider<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>org.apache.hadoop.hbase.io.crypto.KeyStoreKeyProvider<span class="tag">&lt;/value&gt;</span>
<span class="tag">&lt;/property&gt;</span>
<span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>hbase.crypto.keyprovider.parameters<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>jceks:///path/to/hbase/conf/hbase.jks?password=****<span class="tag">&lt;/value&gt;</span>
<span class="tag">&lt;/property&gt;</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>默认情况下，HBase服务帐户名将用于解析集群主密钥。但是，您可以将其存储为任意别名（在<code>keytool</code>命令）。在这种情况下，请将以下属性设置为您使用的别名。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="xml"><span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>hbase.crypto.master.key.name<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>my-alias<span class="tag">&lt;/value&gt;</span>
<span class="tag">&lt;/property&gt;</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>您还需要确保您的HFiles使用HFile v3，以便使用透明加密。这是HBase 1.0及更高版本的默认配置。对于以前的版本，请在<em>hbase-site.xml</em>文件中设置以下属性。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="xml"><span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>hfile.format.version<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>3<span class="tag">&lt;/value&gt;</span>
<span class="tag">&lt;/property&gt;</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>（可选）您可以使用其他密码提供程序，即Java密码学加密（JCE）算法提供程序或自定义HBase密码实现。</p>
</div>
<div class="ulist">
<ul>
<li>
<p>JCE：</p>
<div class="ulist">
<ul>
<li>
<p>安装签名的JCE提供程序（支持<code>AES/CTR/NoPadding</code>带有128位密钥的模式）</p>
</li>
<li>
<p>以最高优先级将其添加到JCE站点配置文件<em>$ JAVA_HOME / lib / security / java.security中</em> 。</p>
</li>
<li>
<p>更新资料<code>hbase.crypto.algorithm.aes.provider</code>和<code>hbase.crypto.algorithm.rng.provider</code> <em class="path">hbase-site.xml中的</em>选项。</p>
</li>
</ul>
</div>
</li>
<li>
<p>自定义HBase密码：</p>
<div class="ulist">
<ul>
<li>
<p>实行<code>org.apache.hadoop.hbase.io.crypto.CipherProvider</code> 。</p>
</li>
<li>
<p>将实现添加到服务器类路径。</p>
</li>
<li>
<p>更新资料<code>hbase.crypto.cipherprovider</code>在<em>hbase-site.xml中</em> 。</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</li>
<li>
<p>配置WAL加密。</p>
<div class="paragraph">
<p>通过设置以下属性，在每个RegionServer的<em>hbase-site.xml中</em>配置WAL加密。您也可以将它们包含在HMaster的<em>hbase-site.xml</em>中，但是HMaster没有WAL，因此不会使用它们。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="xml"><span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>hbase.regionserver.hlog.reader.impl<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>org.apache.hadoop.hbase.regionserver.wal.SecureProtobufLogReader<span class="tag">&lt;/value&gt;</span>
<span class="tag">&lt;/property&gt;</span>
<span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>hbase.regionserver.hlog.writer.impl<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>org.apache.hadoop.hbase.regionserver.wal.SecureProtobufLogWriter<span class="tag">&lt;/value&gt;</span>
<span class="tag">&lt;/property&gt;</span>
<span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>hbase.regionserver.wal.encryption<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>true<span class="tag">&lt;/value&gt;</span>
<span class="tag">&lt;/property&gt;</span></code></pre>
</div>
</div>
</li>
<li>
<p>在<em>hbase-site.xml</em>文件上配置权限。</p>
<div class="paragraph">
<p>由于密钥库密码存储在hbase-site.xml中，因此需要确保只有HBase用户才能使用文件所有权和权限来读取<em>hbase-site.xml</em>文件。</p>
</div>
</li>
<li>
<p>重新启动集群。</p>
<div class="paragraph">
<p>将新的配置文件分发到所有节点，然后重新启动集群。</p>
</div>
</li>
</ol>
</div>
</div>
<div class="sect3">
<h4 id="_administration_3"><a class="anchor" href="#_administration_3"></a> 60.4.3。管理</h4>
<div class="paragraph">
<p>可以在HBase Shell或Java API中执行管理任务。</p>
</div>
<div class="admonitionblock caution">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-caution" title="警告"></i>
</td>
<td class="content">
<div class="title">Java API</div>
<div class="paragraph">
<p>本节中的Java API示例摘自源文件<em>hbase-server / src / test / java / org / apache / hadoop / hbase / util / TestHBaseFsckEncryption.java</em> 。。</p>
</div>
<div class="paragraph">
<p>这些示例或它们的源文件均不是公共HBase API的一部分，并且仅用于说明目的。有关使用说明，请参阅官方API。</p>
</div>
</td>
</tr>
</tbody></table>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">在列族上启用加密</dt>
<dd>
<p>要对列族启用加密，可以使用HBase Shell或Java API。启用加密后，触发一次重大压缩。当主要压缩完成时，将对HFiles进行加密。</p>
</dd>
<dt class="hdlist1">旋转数据键</dt>
<dd>
<p>要旋转数据键，请首先更改列描述符中的ColumnFamily键，然后触发主要压缩。压缩完成后，将使用新的数据密钥重新加密所有HFile。在压缩完成之前，仍可以使用旧密钥读取旧的HFile。</p>
</dd>
<dt class="hdlist1">在使用随机数据密钥和指定密钥之间切换</dt>
<dd>
<p>如果您将列系列配置为使用特定键，并且想要返回使用对该列系列使用随机生成的键的默认行为，请使用Java API更改<code>HColumnDescriptor</code>这样密钥就不会发送任何值<code>ENCRYPTION_KEY</code> 。</p>
</dd>
<dt class="hdlist1">旋转万能钥匙</dt>
<dd>
<p>要旋转主密钥，请首先生成并分发新密钥。然后，更新密钥库以包含新的主密钥，并使用其他别名将旧的主密钥保留在密钥库中。接下来，将回退配置为<em>hbase-site.xml</em>文件中的<em>旧主</em>密钥。</p>
</dd>
<dt class="hdlist1"></dt>
</dl>
</div>
</div>
</div>
<div class="sect2">
<h3 id="hbase.secure.bulkload"><a class="anchor" href="#hbase.secure.bulkload"></a> 60.5。安全散装</h3>
<div class="paragraph">
<p>安全模式下的批量加载比普通设置要复杂得多，因为客户端必须将MapReduce作业生成的文件的所有权转移到HBase。安全批量加载由名为<a href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/security/access/SecureBulkLoadEndpoint.html">SecureBulkLoadEndpoint</a>的协处理器实现，该协处理器使用由配置属性配置的登台目录<code>hbase.bulkload.staging.dir</code> ，默认为<em>/ tmp / hbase-staging /</em> 。</p>
</div>
<div class="ulist">
<div class="title">安全批量加载算法</div>
<ul>
<li>
<p>仅一次，创建一个可在世界范围内遍历并由运行HBase的用户拥有的登台目录（模式711，或<code>rwx—​x—​x</code> ）。该目录的清单将类似于以下内容：</p>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">$ ls -ld /tmp/hbase-staging
drwx--x--x  2 hbase  hbase  68  3 Sep 14:54 /tmp/hbase-staging</code></pre>
</div>
</div>
</li>
<li>
<p>用户将数据写到该用户拥有的安全输出目录中。例如， <em>/ user / foo / data</em> 。</p>
</li>
<li>
<p>在内部，HBase创建一个可在全局范围内读取/写入的秘密登台目录（ <code>-rwxrwxrwx, 777</code> ）。例如， <em>/ tmp / hbase-staging / averylongandrandomdirectoryname</em> 。该目录的名称和位置不向用户公开。HBase管理此目录的创建和删除。</p>
</li>
<li>
<p>用户使数据可全球读取和写入，然后将其移动到随机暂存目录中，然后调用<code>SecureBulkLoadClient#bulkLoadHFiles</code>方法。</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>安全性的强度在于秘密目录的长度和随机性。</p>
</div>
<div class="paragraph">
<p>要启用安全的批量加载，请将以下属性添加到<em>hbase-site.xml</em> 。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="xml"><span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>hbase.bulkload.staging.dir<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>/tmp/hbase-staging<span class="tag">&lt;/value&gt;</span>
<span class="tag">&lt;/property&gt;</span>
<span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>hbase.coprocessor.region.classes<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>org.apache.hadoop.hbase.security.token.TokenProvider,
  org.apache.hadoop.hbase.security.access.AccessController,org.apache.hadoop.hbase.security.access.SecureBulkLoadEndpoint<span class="tag">&lt;/value&gt;</span>
<span class="tag">&lt;/property&gt;</span>
 <span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>hbase.security.authorization<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>true<span class="tag">&lt;/value&gt;</span>
<span class="tag">&lt;/property&gt;</span></code></pre>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="security.example.config"><a class="anchor" href="#security.example.config"></a> 61。安全配置示例</h2>
<div class="sectionbody">
<div class="paragraph">
<p>此配置示例包括对HFile v3，ACL，可见性标签的支持，以及对静态数据和WAL的透明加密。所有选项已在上面的部分中单独讨论。</p>
</div>
<div class="exampleblock">
<div class="title">示例34<em>hbase-site.xml中的</em>示例安全设置</div>
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="xml"><span class="comment">&lt;!-- HFile v3 Support --&gt;</span>
<span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>hfile.format.version<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>3<span class="tag">&lt;/value&gt;</span>
<span class="tag">&lt;/property&gt;</span>
<span class="comment">&lt;!-- HBase Superuser --&gt;</span>
<span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>hbase.superuser<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>hbase, admin<span class="tag">&lt;/value&gt;</span>
<span class="tag">&lt;/property&gt;</span>
<span class="comment">&lt;!-- Coprocessors for ACLs and Visibility Tags --&gt;</span>
<span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>hbase.coprocessor.region.classes<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>org.apache.hadoop.hbase.security.access.AccessController,
  org.apache.hadoop.hbase.security.visibility.VisibilityController,
  org.apache.hadoop.hbase.security.token.TokenProvider<span class="tag">&lt;/value&gt;</span>
<span class="tag">&lt;/property&gt;</span>
<span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>hbase.coprocessor.master.classes<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>org.apache.hadoop.hbase.security.access.AccessController,
  org.apache.hadoop.hbase.security.visibility.VisibilityController<span class="tag">&lt;/value&gt;</span>
<span class="tag">&lt;/property&gt;</span>
<span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>hbase.coprocessor.regionserver.classes<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>org.apache.hadoop/hbase.security.access.AccessController,
  org.apache.hadoop.hbase.security.access.VisibilityController<span class="tag">&lt;/value&gt;</span>
<span class="tag">&lt;/property&gt;</span>
<span class="comment">&lt;!-- Executable ACL for Coprocessor Endpoints --&gt;</span>
<span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>hbase.security.exec.permission.checks<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>true<span class="tag">&lt;/value&gt;</span>
<span class="tag">&lt;/property&gt;</span>
<span class="comment">&lt;!-- Whether a user needs authorization for a visibility tag to set it on a cell --&gt;</span>
<span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>hbase.security.visibility.mutations.checkauth<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>false<span class="tag">&lt;/value&gt;</span>
<span class="tag">&lt;/property&gt;</span>
<span class="comment">&lt;!-- Secure RPC Transport --&gt;</span>
<span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>hbase.rpc.protection<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>privacy<span class="tag">&lt;/value&gt;</span>
 <span class="tag">&lt;/property&gt;</span>
 <span class="comment">&lt;!-- Transparent Encryption --&gt;</span>
<span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>hbase.crypto.keyprovider<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>org.apache.hadoop.hbase.io.crypto.KeyStoreKeyProvider<span class="tag">&lt;/value&gt;</span>
<span class="tag">&lt;/property&gt;</span>
<span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>hbase.crypto.keyprovider.parameters<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>jceks:///path/to/hbase/conf/hbase.jks?password=***<span class="tag">&lt;/value&gt;</span>
<span class="tag">&lt;/property&gt;</span>
<span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>hbase.crypto.master.key.name<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>hbase<span class="tag">&lt;/value&gt;</span>
<span class="tag">&lt;/property&gt;</span>
<span class="comment">&lt;!-- WAL Encryption --&gt;</span>
<span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>hbase.regionserver.hlog.reader.impl<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>org.apache.hadoop.hbase.regionserver.wal.SecureProtobufLogReader<span class="tag">&lt;/value&gt;</span>
<span class="tag">&lt;/property&gt;</span>
<span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>hbase.regionserver.hlog.writer.impl<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>org.apache.hadoop.hbase.regionserver.wal.SecureProtobufLogWriter<span class="tag">&lt;/value&gt;</span>
<span class="tag">&lt;/property&gt;</span>
<span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>hbase.regionserver.wal.encryption<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>true<span class="tag">&lt;/value&gt;</span>
<span class="tag">&lt;/property&gt;</span>
<span class="comment">&lt;!-- For key rotation --&gt;</span>
<span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>hbase.crypto.master.alternate.key.name<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>hbase.old<span class="tag">&lt;/value&gt;</span>
<span class="tag">&lt;/property&gt;</span>
<span class="comment">&lt;!-- Secure Bulk Load --&gt;</span>
<span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>hbase.bulkload.staging.dir<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>/tmp/hbase-staging<span class="tag">&lt;/value&gt;</span>
<span class="tag">&lt;/property&gt;</span>
<span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>hbase.coprocessor.region.classes<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>org.apache.hadoop.hbase.security.token.TokenProvider,
  org.apache.hadoop.hbase.security.access.AccessController,org.apache.hadoop.hbase.security.access.SecureBulkLoadEndpoint<span class="tag">&lt;/value&gt;</span>
<span class="tag">&lt;/property&gt;</span>
 <span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>hbase.security.authorization<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>true<span class="tag">&lt;/value&gt;</span>
<span class="tag">&lt;/property&gt;</span></code></pre>
</div>
</div>
</div>
</div>
<div class="exampleblock">
<div class="title">示例35Hadoop <em>core-site.xml中的</em>示例组映射器</div>
<div class="content">
<div class="paragraph">
<p>调整这些设置以适合您的环境。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="xml"><span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>hadoop.security.group.mapping<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>org.apache.hadoop.security.LdapGroupsMapping<span class="tag">&lt;/value&gt;</span>
<span class="tag">&lt;/property&gt;</span>
<span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>hadoop.security.group.mapping.ldap.url<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>ldap://server<span class="tag">&lt;/value&gt;</span>
<span class="tag">&lt;/property&gt;</span>
<span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>hadoop.security.group.mapping.ldap.bind.user<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>Administrator@example-ad.local<span class="tag">&lt;/value&gt;</span>
<span class="tag">&lt;/property&gt;</span>
<span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>hadoop.security.group.mapping.ldap.bind.password<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>****<span class="tag">&lt;/value&gt;</span> <span class="comment">&lt;!-- Replace with the actual password --&gt;</span>
<span class="tag">&lt;/property&gt;</span>
<span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>hadoop.security.group.mapping.ldap.base<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>dc=example-ad,dc=local<span class="tag">&lt;/value&gt;</span>
<span class="tag">&lt;/property&gt;</span>
<span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>hadoop.security.group.mapping.ldap.search.filter.user<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>(<span class="entity">&amp;amp;</span>(objectClass=user)(sAMAccountName={0}))<span class="tag">&lt;/value&gt;</span>
<span class="tag">&lt;/property&gt;</span>
<span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>hadoop.security.group.mapping.ldap.search.filter.group<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>(objectClass=group)<span class="tag">&lt;/value&gt;</span>
<span class="tag">&lt;/property&gt;</span>
<span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>hadoop.security.group.mapping.ldap.search.attr.member<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>member<span class="tag">&lt;/value&gt;</span>
<span class="tag">&lt;/property&gt;</span>
<span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>hadoop.security.group.mapping.ldap.search.attr.group.name<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>cn<span class="tag">&lt;/value&gt;</span>
<span class="tag">&lt;/property&gt;</span></code></pre>
</div>
</div>
</div>
</div>
</div>
</div>
<h1 id="_architecture" class="sect0"><a class="anchor" href="#_architecture"></a>建筑</h1>
<div class="sect1">
<h2 id="arch.overview"><a class="anchor" href="#arch.overview"></a> 62。总览</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="arch.overview.nosql"><a class="anchor" href="#arch.overview.nosql"></a> 62.1NoSQL？</h3>
<div class="paragraph">
<p>HBase是一种“ NoSQL”数据库。“ NoSQL”是一个通用术语，表示该数据库不是支持SQL作为其主要访问语言的RDBMS，但是NoSQL数据库的类型很多：BerkeleyDB是本地NoSQL数据库的一个示例，而HBase在很大程度上分布式数据库。从技术上讲，HBase实际上比“数据库”更像是“数据存储”，因为它缺少您在RDBMS中发现的许多功能，例如类型化的列，二级索引，触发器和高级查询语言等。</p>
</div>
<div class="paragraph">
<p>但是，HBase具有支持线性和模块化缩放的许多功能。HBase群集通过添加在商品类服务器上托管的RegionServer来扩展。例如，如果一个群集从10个RegionServers扩展到20个，则它在存储和处理能力方面都会翻倍。RDBMS可以很好地扩展，但是只能扩展到一个点-特别是单个数据库服务器的大小-为了获得最佳性能，需要专用的硬件和存储设备。注意的HBase功能包括：</p>
</div>
<div class="ulist">
<ul>
<li>
<p>高度一致的读/写：HBase不是“最终一致”的数据存储。这使其非常适合诸如高速计数器聚合之类的任务。</p>
</li>
<li>
<p>自动分片：HBase表通过区域分布在群集上，并且随着数据的增长，区域会自动拆分和重新分布。</p>
</li>
<li>
<p>自动RegionServer故障转移</p>
</li>
<li>
<p>Hadoop / HDFS集成：HBase开箱即用地支持HDFS作为其分布式文件系统。</p>
</li>
<li>
<p>MapReduce：HBase支持通过MapReduce大规模并行化处理，以将HBase用作源和接收器。</p>
</li>
<li>
<p>Java客户端API：HBase支持易于使用的Java API进行编程访问。</p>
</li>
<li>
<p>Thrift / REST API：HBase还为非Java前端支持Thrift和REST。</p>
</li>
<li>
<p>块缓存和布隆过滤器：HBase支持块缓存和布隆过滤器，以进行大量查询优化。</p>
</li>
<li>
<p>运营管理：HBase提供了内置的网页，以提供运营见解以及JMX指标。</p>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="arch.overview.when"><a class="anchor" href="#arch.overview.when"></a> 62.2。什么时候应该使用HBase？</h3>
<div class="paragraph">
<p>HBase并不适合所有问题。</p>
</div>
<div class="paragraph">
<p>首先，请确保您有足够的数据。如果您有数亿或数十亿行，那么HBase是一个很好的选择。如果您只有数千行/百万行，那么使用传统的RDBMS可能是一个更好的选择，原因是您的所有数据可能会在一个（或两个）节点上结束，而集群的其余部分可能都处于等待状态闲。</p>
</div>
<div class="paragraph">
<p>其次，确保您可以在没有RDBMS提供的所有额外功能的情况下生存（例如，键入的列，二级索引，事务，高级查询语言等）。例如，仅通过更改JDBC驱动程序，就不能将基于RDBMS构建的应用程序“移植”到HBase。考虑从RDBMS迁移到HBase，作为与端口相对的完整重新设计。</p>
</div>
<div class="paragraph">
<p>第三，确保您有足够的硬件。即使少于5个DataNode（由于诸如HDFS块复制（默认值为3）之类的东西）以及一个NameNode，HDFS也不能很好地处理。</p>
</div>
<div class="paragraph">
<p>HBase在笔记本电脑上可以很好地独立运行-但这仅应视为开发配置。</p>
</div>
</div>
<div class="sect2">
<h3 id="arch.overview.hbasehdfs"><a class="anchor" href="#arch.overview.hbasehdfs"></a> 62.3。HBase与Hadoop / HDFS有什么区别？</h3>
<div class="paragraph">
<p><a href="http://hadoop.apache.org/hdfs/">HDFS</a>是一个分布式文件系统，非常适合存储大文件。它的文档指出，它不是通用文件系统，并且不提供文件中的快速个人记录查找。另一方面，HBase构建在HDFS之上，并为大型表提供快速记录查找（和更新）。有时这可能是概念上的混乱点。HBase在内部将数据放入HDFS上存在的索引“ StoreFiles”中，以进行高速查找。有关HBase如何实现其目标的更多信息，请参见<a href="#datamodel">数据模型</a>和本章的其余部分。</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="arch.catalog"><a class="anchor" href="#arch.catalog"></a> 63。目录表</h2>
<div class="sectionbody">
<div class="paragraph">
<p>目录表<code>hbase:meta</code>作为HBase表存在，并从HBase Shell的过滤掉<code>list</code>命令，但实际上是一个与其他表一样的表。</p>
</div>
<div class="sect2">
<h3 id="arch.catalog.root"><a class="anchor" href="#arch.catalog.root"></a> 63.1。 -根-</h3>
<div class="admonitionblock note">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-note" title="注意"></i>
</td>
<td class="content">的<code>-ROOT-</code>在HBase 0.96.0中删除了该表。这里的信息应视为历史信息。
</td>
</tr>
</tbody></table>
</div>
<div class="paragraph">
<p>的<code>-ROOT-</code>表格记录了位置<code>.META</code>表格（该表格的旧名称现在称为<code>hbase:meta</code> ）低于HBase 0.96。的<code>-ROOT-</code>表结构如下：</p>
</div>
<div class="ulist">
<div class="title">键</div>
<ul>
<li>
<p>。META。区域键（ <code>.META.,,1</code> ）</p>
</li>
</ul>
</div>
<div class="ulist">
<div class="title">价值观</div>
<ul>
<li>
<p><code>info:regioninfo</code> （的<a href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/HRegionInfo.html">HRegionInfo</a>序列化实例<code>hbase:meta</code> ）</p>
</li>
<li>
<p><code>info:server</code> （服务器：RegionServer所在端口<code>hbase:meta</code> ）</p>
</li>
<li>
<p><code>info:serverstartcode</code> （RegionServer进程的启动时间<code>hbase:meta</code> ）</p>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="arch.catalog.meta"><a class="anchor" href="#arch.catalog.meta"></a> 63.2。 hbase：元</h3>
<div class="paragraph">
<p>的<code>hbase:meta</code>表（以前称为<code>.META.</code> ）保留系统中所有区域的列表。的位置<code>hbase:meta</code>以前是在<code>-ROOT-</code>表，但现在存储在ZooKeeper中。</p>
</div>
<div class="paragraph">
<p>的<code>hbase:meta</code>表结构如下：</p>
</div>
<div class="ulist">
<div class="title">键</div>
<ul>
<li>
<p>格式的区域关键字（ <code>[table],[region start key],[region id]</code> ）</p>
</li>
</ul>
</div>
<div class="ulist">
<div class="title">价值观</div>
<ul>
<li>
<p><code>info:regioninfo</code> （此区域的序列化<a href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/HRegionInfo.html">HRegionInfo</a>实例）</p>
</li>
<li>
<p><code>info:server</code> （包含该区域的RegionServer的server：port）</p>
</li>
<li>
<p><code>info:serverstartcode</code> （包含该区域的RegionServer进程的开始时间）</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>当表正在拆分时，将创建另外两个列，称为<code>info:splitA</code>和<code>info:splitB</code> 。这些列代表两个子区域。这些列的值也是序列化的HRegionInfo实例。分割区域后，最终将删除此行。</p>
</div>
<div class="admonitionblock note">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-note" title="注意"></i>
</td>
<td class="content">
<div class="title">关于HRegionInfo的说明</div>
<div class="paragraph">
<p>空键用于表示表的开始和结束。起始键为空的区域是表中的第一个区域。如果一个区域同时具有空的开始键和空的结束键，则它是表中唯一的区域</p>
</div>
</td>
</tr>
</tbody></table>
</div>
<div class="paragraph">
<p>如果（需要不太可能）需要对目录元数据进行编程处理，请参见<a href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/util/Writables.html#getHRegionInfo%28byte" class="bare">http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/util/Writables.html#getHRegionInfo%28byte％29</a> [ [可写内容]实用程序。</p>
</div>
</div>
<div class="sect2">
<h3 id="arch.catalog.startup"><a class="anchor" href="#arch.catalog.startup"></a> 63.3。启动排序</h3>
<div class="paragraph">
<p>一，位置<code>hbase:meta</code>在ZooKeeper中查找。下一个， <code>hbase:meta</code>使用服务器和起始码值进行更新。</p>
</div>
<div class="paragraph">
<p>有关region-RegionServer分配的信息，请参见<a href="#regions.arch.assignment">Region-RegionServer分配</a> 。</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="architecture.client"><a class="anchor" href="#architecture.client"></a> 64。客户</h2>
<div class="sectionbody">
<div class="paragraph">
<p>HBase客户端找到正在服务的特定行范围的RegionServer。它通过查询<code>hbase:meta</code>表。有关详细信息，请参见<a href="#arch.catalog.meta">hbase：meta</a> 。找到所需的区域后，客户端将联系服务于该区域的RegionServer，而不是通过主服务器，并发出读取或写入请求。此信息被缓存在客户端中，因此后续请求无需经过查找过程。如果由主负载平衡器重新分配了区域，或者由于RegionServer已经失效，则客户端将重新查询目录表以确定用户区域的新位置。</p>
</div>
<div class="paragraph">
<p>有关主服务器对HBase客户端通信的<a href="#master.runtime">影响</a>的更多信息，请参见<a href="#master.runtime">运行时影响</a> 。</p>
</div>
<div class="paragraph">
<p>管理功能通过<a href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/client/Admin.html">Admin</a>实例完成</p>
</div>
<div class="sect2">
<h3 id="client.connections"><a class="anchor" href="#client.connections"></a> 64.1。集群连接</h3>
<div class="paragraph">
<p>API在HBase 1.0中已更改。有关连接配置的信息，请参阅<a href="#client_dependencies">连接到HBase群集的客户端配置和依赖项</a> 。</p>
</div>
<div class="sect3">
<h4 id="_api_as_of_hbase_1_0_0"><a class="anchor" href="#_api_as_of_hbase_1_0_0"></a> 64.1.1。自HBase 1.0.0起的API</h4>
<div class="paragraph">
<p>它已被清理，并且向用户返回了要使用的接口，而不是针对特定类型的接口。在HBase 1.0中，获取<code>Connection</code>来自的对象<code>ConnectionFactory</code>然后从中获取<code>Table</code> ， <code>Admin</code>和<code>RegionLocator</code>根据需要。完成后，关闭获得的实例。最后，请务必清理<code>Connection</code>实例退出之前。
<code>Connections</code>是重量级对象，但是线程安全的，因此您可以为应用程序创建一个对象并保留该实例。
<code>Table</code> ， <code>Admin</code>和<code>RegionLocator</code>实例是轻量级的。随心所欲创建，然后通过关闭它们立即放手。有关新HBase 1.0 API的示例用法，请参阅<a href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/client/package-summary.html">客户端软件包Javadoc说明</a> 。</p>
</div>
</div>
<div class="sect3">
<h4 id="_api_before_hbase_1_0_0"><a class="anchor" href="#_api_before_hbase_1_0_0"></a> 64.1.2。HBase 1.0.0之前的API</h4>
<div class="paragraph">
<p>的实例<code>HTable</code>是与1.0.0之前的HBase群集进行交互的方式。<em><a href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/client/Table.html">表</a>实例不是线程安全的</em> 。在任何给定时间，只有一个线程可以使用Table的实例。创建表实例时，建议使用相同的<a href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/HBaseConfiguration">HBaseConfiguration</a>实例。这将确保将ZooKeeper和套接字实例共享到RegionServer，这通常是您所需要的。例如，这是首选：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">HBaseConfiguration conf = HBaseConfiguration.create();
HTable table1 = <span class="keyword">new</span> HTable(conf, <span class="string"><span class="delimiter">&quot;</span><span class="content">myTable</span><span class="delimiter">&quot;</span></span>);
HTable table2 = <span class="keyword">new</span> HTable(conf, <span class="string"><span class="delimiter">&quot;</span><span class="content">myTable</span><span class="delimiter">&quot;</span></span>);</code></pre>
</div>
</div>
<div class="paragraph">
<p>与此相反：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">HBaseConfiguration conf1 = HBaseConfiguration.create();
HTable table1 = <span class="keyword">new</span> HTable(conf1, <span class="string"><span class="delimiter">&quot;</span><span class="content">myTable</span><span class="delimiter">&quot;</span></span>);
HBaseConfiguration conf2 = HBaseConfiguration.create();
HTable table2 = <span class="keyword">new</span> HTable(conf2, <span class="string"><span class="delimiter">&quot;</span><span class="content">myTable</span><span class="delimiter">&quot;</span></span>);</code></pre>
</div>
</div>
<div class="paragraph">
<p>有关如何在HBase客户端中处理连接的更多信息，请参见<a href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/client/ConnectionFactory.html">ConnectionFactory</a> 。</p>
</div>
<div class="sect4">
<h5 id="client.connection.pooling"><a class="anchor" href="#client.connection.pooling"></a>连接池</h5>
<div class="paragraph">
<p>对于需要高端多线程访问的应用程序（例如，可能在单个JVM中服务多个应用程序线程的Web服务器或应用程序服务器），您可以预先创建一个<code>Connection</code> ，如以下示例所示：</p>
</div>
<div class="exampleblock">
<div class="title">示例36。预创建一个<code>Connection</code></div>
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="comment">// Create a connection to the cluster.</span>
<span class="predefined-type">Configuration</span> conf = HBaseConfiguration.create();
<span class="keyword">try</span> (<span class="predefined-type">Connection</span> connection = ConnectionFactory.createConnection(conf)) {
  <span class="keyword">try</span> (Table table = connection.getTable(TableName.valueOf(tablename)) {
    <span class="comment">// use table as needed, the table returned is lightweight</span>
  }
}</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>构造HTableInterface实现非常轻巧，并且可以控制资源。</p>
</div>
<div class="admonitionblock warning">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-warning" title="警告"></i>
</td>
<td class="content">
<div class="title"><code>HTablePool</code>已弃用</div>
<div class="paragraph">
<p>讨论了本指南的先前版本<code>HTablePool</code> ，在HBase 0.94、0.95和0.96中已弃用，并在0.98.1中被<a href="https://issues.apache.org/jira/browse/HBASE-6580">HBASE-6500</a>删除，或者<code>HConnection</code> ，在HBase 1.0中已弃用<code>Connection</code> 。请改用<a href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/client/Connection.html">Connection</a> 。</p>
</div>
</td>
</tr>
</tbody></table>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="client.writebuffer"><a class="anchor" href="#client.writebuffer"></a> 64.2。WriteBuffer和批处理方法</h3>
<div class="paragraph">
<p>在HBase 1.0和更高版本中，不推荐使用<a href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/client/HTable.html">HTable，</a>而推荐使用<a href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/client/Table.html">Table</a> 。 <code>Table</code>不使用自动刷新。要进行缓冲写入，请使用BufferedMutator类。</p>
</div>
<div class="paragraph">
<p>之前<code>Table</code>要么<code>HTable</code>实例被丢弃，请调用<code>close()</code>要么<code>flushCommits()</code> ，因此`Put`不会丢失。</p>
</div>
<div class="paragraph">
<p>有关写持久性的其他信息，请查看<a href="../acid-semantics.html">ACID语义</a>页面。</p>
</div>
<div class="paragraph">
<p>用于细粒度控制配料<code>Put</code> s或<code>Delete</code> s，请参见表上的<a href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/client/Table.html#batch%28java.util.List%29">批处理</a>方法。</p>
</div>
</div>
<div class="sect2">
<h3 id="client.external"><a class="anchor" href="#client.external"></a> 64.3。外部客户</h3>
<div class="paragraph">
<p><a href="#external_apis">Apache HBase外部API</a>涵盖了有关非Java客户端和自定义协议的信息。</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="client.filter"><a class="anchor" href="#client.filter"></a> 65。客户请求过滤器</h2>
<div class="sectionbody">
<div class="paragraph">
<p>可以选择使用在RegionServer上应用的<a href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/filter/Filter.html">筛选器</a>来配置<a href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/client/Get.html">Get</a>和<a href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/client/Scan.html">Scan</a>实例。</p>
</div>
<div class="paragraph">
<p>过滤器可能会造成混乱，因为类型很多，最好通过了解过滤器功能组来进行过滤。</p>
</div>
<div class="sect2">
<h3 id="client.filter.structural"><a class="anchor" href="#client.filter.structural"></a> 65.1。结构性</h3>
<div class="paragraph">
<p>结构过滤器包含其他过滤器。</p>
</div>
<div class="sect3">
<h4 id="client.filter.structural.fl"><a class="anchor" href="#client.filter.structural.fl"></a> 65.1.1。筛选清单</h4>
<div class="paragraph">
<p><a href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/filter/FilterList.html">FilterList</a>表示具有以下关系的过滤器列表<code>FilterList.Operator.MUST_PASS_ALL</code>要么<code>FilterList.Operator.MUST_PASS_ONE</code>在过滤器之间。以下示例显示了两个过滤器之间的“或”（检查同一属性上的“我的值”或“我的其他值”）。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">FilterList list = <span class="keyword">new</span> FilterList(FilterList.Operator.MUST_PASS_ONE);
SingleColumnValueFilter filter1 = <span class="keyword">new</span> SingleColumnValueFilter(
  cf,
  column,
  CompareOp.EQUAL,
  Bytes.toBytes(<span class="string"><span class="delimiter">&quot;</span><span class="content">my value</span><span class="delimiter">&quot;</span></span>)
  );
list.add(filter1);
SingleColumnValueFilter filter2 = <span class="keyword">new</span> SingleColumnValueFilter(
  cf,
  column,
  CompareOp.EQUAL,
  Bytes.toBytes(<span class="string"><span class="delimiter">&quot;</span><span class="content">my other value</span><span class="delimiter">&quot;</span></span>)
  );
list.add(filter2);
scan.setFilter(list);</code></pre>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="client.filter.cv"><a class="anchor" href="#client.filter.cv"></a> 65.2。栏值</h3>
<div class="sect3">
<h4 id="client.filter.cv.scvf"><a class="anchor" href="#client.filter.cv.scvf"></a> 65.2.1。SingleColumnValueFilter</h4>
<div class="paragraph">
<p><a href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/filter/SingleColumnValueFilter.html">SingleColumnValueFilter</a>可用于测试列值是否相等（ <code>CompareOp.EQUAL</code> ），不平等（ <code>CompareOp.NOT_EQUAL</code> ）或范围（例如， <code>CompareOp.GREATER</code> ）。以下是测试将列与字符串值“ my value”等价的示例……</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">SingleColumnValueFilter filter = <span class="keyword">new</span> SingleColumnValueFilter(
  cf,
  column,
  CompareOp.EQUAL,
  Bytes.toBytes(<span class="string"><span class="delimiter">&quot;</span><span class="content">my value</span><span class="delimiter">&quot;</span></span>)
  );
scan.setFilter(filter);</code></pre>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="client.filter.cvp"><a class="anchor" href="#client.filter.cvp"></a> 65.3。列值比较器</h3>
<div class="paragraph">
<p>在Filter包中有几个Comparator类值得特别提及。这些比较器与其他过滤器（例如<a href="#client.filter.cv.scvf">SingleColumnValueFilter）一起使用</a> 。</p>
</div>
<div class="sect3">
<h4 id="client.filter.cvp.rcs"><a class="anchor" href="#client.filter.cvp.rcs"></a> 65.3.1。RegexStringComparator</h4>
<div class="paragraph">
<p><a href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/filter/RegexStringComparator.html">RegexStringComparator</a>支持用于值比较的正则表达式。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">RegexStringComparator comp = <span class="keyword">new</span> RegexStringComparator(<span class="string"><span class="delimiter">&quot;</span><span class="content">my.</span><span class="delimiter">&quot;</span></span>);   <span class="comment">// any value that starts with 'my'</span>
SingleColumnValueFilter filter = <span class="keyword">new</span> SingleColumnValueFilter(
  cf,
  column,
  CompareOp.EQUAL,
  comp
  );
scan.setFilter(filter);</code></pre>
</div>
</div>
<div class="paragraph">
<p>有关<a href="http://download.oracle.com/javase/6/docs/api/java/util/regex/Pattern.html">Java中受支持的RegEx模式的信息，</a>请参见Oracle JavaDoc。</p>
</div>
</div>
<div class="sect3">
<h4 id="client.filter.cvp.substringcomparator"><a class="anchor" href="#client.filter.cvp.substringcomparator"></a> 65.3.2。子串比较器</h4>
<div class="paragraph">
<p><a href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/filter/SubstringComparator.html">SubstringComparator</a>可用于确定值中是否存在给定的子字符串。比较不区分大小写。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">SubstringComparator comp = <span class="keyword">new</span> SubstringComparator(<span class="string"><span class="delimiter">&quot;</span><span class="content">y val</span><span class="delimiter">&quot;</span></span>);   <span class="comment">// looking for 'my value'</span>
SingleColumnValueFilter filter = <span class="keyword">new</span> SingleColumnValueFilter(
  cf,
  column,
  CompareOp.EQUAL,
  comp
  );
scan.setFilter(filter);</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="client.filter.cvp.bfp"><a class="anchor" href="#client.filter.cvp.bfp"></a> 65.3.3。BinaryPrefixComparator</h4>
<div class="paragraph">
<p>请参阅<a href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/filter/BinaryPrefixComparator.html">BinaryPrefixComparator</a> 。</p>
</div>
</div>
<div class="sect3">
<h4 id="client.filter.cvp.bc"><a class="anchor" href="#client.filter.cvp.bc"></a> 65.3.4。二进制比较器</h4>
<div class="paragraph">
<p>参见<a href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/filter/BinaryComparator.html">BinaryComparator</a> 。</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="client.filter.kvm"><a class="anchor" href="#client.filter.kvm"></a> 65.4。键值元数据</h3>
<div class="paragraph">
<p>由于HBase在内部将数据存储为键值对，因此键值元数据过滤器会评估行的键（即ColumnFamily：Column限定符）的存在，而不是上一节中的值。</p>
</div>
<div class="sect3">
<h4 id="client.filter.kvm.ff"><a class="anchor" href="#client.filter.kvm.ff"></a> 65.4.1。家庭过滤器</h4>
<div class="paragraph">
<p><a href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/filter/FamilyFilter.html">FamilyFilter</a>可用于对ColumnFamily进行过滤。通常，在“扫描”中选择ColumnFamilies比使用“过滤器”更好。</p>
</div>
</div>
<div class="sect3">
<h4 id="client.filter.kvm.qf"><a class="anchor" href="#client.filter.kvm.qf"></a> 65.4.2。QualifierFilter</h4>
<div class="paragraph">
<p><a href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/filter/QualifierFilter.html">QualifierFilter</a>可用于根据列（又称Qualifier）名称进行过滤。</p>
</div>
</div>
<div class="sect3">
<h4 id="client.filter.kvm.cpf"><a class="anchor" href="#client.filter.kvm.cpf"></a> 65.4.3。ColumnPrefixFilter</h4>
<div class="paragraph">
<p><a href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/filter/ColumnPrefixFilter.html">ColumnPrefixFilter</a>可用于基于Column（又名Qualifier）名称的前导部分进行过滤。</p>
</div>
<div class="paragraph">
<p>ColumnPrefixFilter在与每一行和每个涉及的列族匹配的前缀的第一列之前搜索。它可用于有效地获取非常宽的行中的列的子集。</p>
</div>
<div class="paragraph">
<p>注意：同一列限定符可用于不同的列族。该过滤器返回所有匹配的列。</p>
</div>
<div class="paragraph">
<p>示例：查找行和族中以“ abc”开头的所有列</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">HTableInterface t = ...;
<span class="type">byte</span><span class="type">[]</span> row = ...;
<span class="type">byte</span><span class="type">[]</span> family = ...;
<span class="type">byte</span><span class="type">[]</span> prefix = Bytes.toBytes(<span class="string"><span class="delimiter">&quot;</span><span class="content">abc</span><span class="delimiter">&quot;</span></span>);
Scan scan = <span class="keyword">new</span> Scan(row, row); <span class="comment">// (optional) limit to one row</span>
scan.addFamily(family); <span class="comment">// (optional) limit to one family</span>
<span class="predefined-type">Filter</span> f = <span class="keyword">new</span> ColumnPrefixFilter(prefix);
scan.setFilter(f);
scan.setBatch(<span class="integer">10</span>); <span class="comment">// set this if there could be many columns returned</span>
ResultScanner rs = t.getScanner(scan);
<span class="keyword">for</span> (<span class="predefined-type">Result</span> r = rs.next(); r != <span class="predefined-constant">null</span>; r = rs.next()) {
  <span class="keyword">for</span> (KeyValue kv : r.raw()) {
    <span class="comment">// each kv represents a column</span>
  }
}
rs.close();</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="client.filter.kvm.mcpf"><a class="anchor" href="#client.filter.kvm.mcpf"></a> 65.4.4。MultipleColumnPrefixFilter</h4>
<div class="paragraph">
<p><a href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/filter/MultipleColumnPrefixFilter.html">MultipleColumnPrefixFilter的</a>行为类似于ColumnPrefixFilter，但允许指定多个前缀。</p>
</div>
<div class="paragraph">
<p>与ColumnPrefixFilter一样，MultipleColumnPrefixFilter可以有效地搜索与最低前缀匹配的第一列，并且还可以搜索前缀之间的列的过去范围。它可用于有效地从非常宽的行中获取不连续的列集。</p>
</div>
<div class="paragraph">
<p>示例：查找行和族中以“ abc”或“ xyz”开头的所有列</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">HTableInterface t = ...;
<span class="type">byte</span><span class="type">[]</span> row = ...;
<span class="type">byte</span><span class="type">[]</span> family = ...;
<span class="type">byte</span><span class="type">[]</span><span class="type">[]</span> prefixes = <span class="keyword">new</span> <span class="type">byte</span><span class="type">[]</span><span class="type">[]</span> {Bytes.toBytes(<span class="string"><span class="delimiter">&quot;</span><span class="content">abc</span><span class="delimiter">&quot;</span></span>), Bytes.toBytes(<span class="string"><span class="delimiter">&quot;</span><span class="content">xyz</span><span class="delimiter">&quot;</span></span>)};
Scan scan = <span class="keyword">new</span> Scan(row, row); <span class="comment">// (optional) limit to one row</span>
scan.addFamily(family); <span class="comment">// (optional) limit to one family</span>
<span class="predefined-type">Filter</span> f = <span class="keyword">new</span> MultipleColumnPrefixFilter(prefixes);
scan.setFilter(f);
scan.setBatch(<span class="integer">10</span>); <span class="comment">// set this if there could be many columns returned</span>
ResultScanner rs = t.getScanner(scan);
<span class="keyword">for</span> (<span class="predefined-type">Result</span> r = rs.next(); r != <span class="predefined-constant">null</span>; r = rs.next()) {
  <span class="keyword">for</span> (KeyValue kv : r.raw()) {
    <span class="comment">// each kv represents a column</span>
  }
}
rs.close();</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="client.filter.kvm.crf"><a class="anchor" href="#client.filter.kvm.crf"></a> 65.4.5。ColumnRangeFilter</h4>
<div class="paragraph">
<p><a href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/filter/ColumnRangeFilter.html">ColumnRangeFilter</a>允许高效的行内扫描。</p>
</div>
<div class="paragraph">
<p>ColumnRangeFilter可以针对每个涉及的列族向前搜索第一个匹配列。它可以用于有效地获取非常宽的行的列的“切片”。也就是说，您连续有一百万列，但您只想查看bbbb-bbdd列。</p>
</div>
<div class="paragraph">
<p>注意：同一列限定符可用于不同的列族。该过滤器返回所有匹配的列。</p>
</div>
<div class="paragraph">
<p>示例：查找“ bbbb”（包括）和“ bbdd”（包括）之间的行和族的所有列</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">HTableInterface t = ...;
<span class="type">byte</span><span class="type">[]</span> row = ...;
<span class="type">byte</span><span class="type">[]</span> family = ...;
<span class="type">byte</span><span class="type">[]</span> startColumn = Bytes.toBytes(<span class="string"><span class="delimiter">&quot;</span><span class="content">bbbb</span><span class="delimiter">&quot;</span></span>);
<span class="type">byte</span><span class="type">[]</span> endColumn = Bytes.toBytes(<span class="string"><span class="delimiter">&quot;</span><span class="content">bbdd</span><span class="delimiter">&quot;</span></span>);
Scan scan = <span class="keyword">new</span> Scan(row, row); <span class="comment">// (optional) limit to one row</span>
scan.addFamily(family); <span class="comment">// (optional) limit to one family</span>
<span class="predefined-type">Filter</span> f = <span class="keyword">new</span> ColumnRangeFilter(startColumn, <span class="predefined-constant">true</span>, endColumn, <span class="predefined-constant">true</span>);
scan.setFilter(f);
scan.setBatch(<span class="integer">10</span>); <span class="comment">// set this if there could be many columns returned</span>
ResultScanner rs = t.getScanner(scan);
<span class="keyword">for</span> (<span class="predefined-type">Result</span> r = rs.next(); r != <span class="predefined-constant">null</span>; r = rs.next()) {
  <span class="keyword">for</span> (KeyValue kv : r.raw()) {
    <span class="comment">// each kv represents a column</span>
  }
}
rs.close();</code></pre>
</div>
</div>
<div class="paragraph">
<p>注意：在HBase 0.92中引入</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="client.filter.row"><a class="anchor" href="#client.filter.row"></a> 65.5。行键</h3>
<div class="sect3">
<h4 id="client.filter.row.rf"><a class="anchor" href="#client.filter.row.rf"></a> 65.5.1。行过滤器</h4>
<div class="paragraph">
<p>通常最好在Scan上使用startRow / stopRow方法进行行选择，但是也可以使用<a href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/filter/RowFilter.html">RowFilter</a> 。</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="client.filter.utility"><a class="anchor" href="#client.filter.utility"></a> 65.6。效用</h3>
<div class="sect3">
<h4 id="client.filter.utility.fkof"><a class="anchor" href="#client.filter.utility.fkof"></a> 65.6.1。FirstKeyOnlyFilter</h4>
<div class="paragraph">
<p>这主要用于行数作业。参见<a href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/filter/FirstKeyOnlyFilter.html">FirstKeyOnlyFilter</a> 。</p>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_master"><a class="anchor" href="#_master"></a> 66。主</h2>
<div class="sectionbody">
<div class="paragraph">
<p><code>HMaster</code>是主服务器的实施。主服务器负责监视群集中的所有RegionServer实例，并且是所有元数据更改的接口。在分布式群集中，主服务器通常在<a href="#arch.hdfs.nn">NameNode</a>上运行。J Mohamed Zahoor在此博客文章<a href="http://blog.zahoor.in/2012/08/hbase-hmaster-architecture/">HBase HMaster Architecture中</a>详细介绍了Master <a href="http://blog.zahoor.in/2012/08/hbase-hmaster-architecture/">Architecture</a> 。</p>
</div>
<div class="sect2">
<h3 id="master.startup"><a class="anchor" href="#master.startup"></a> 66.1。启动行为</h3>
<div class="paragraph">
<p>如果在多主服务器环境中运行，则所有主服务器都将竞争运行集群。如果活动的主服务器失去了在ZooKeeper中的租约（或主服务器关闭），则剩余的主服务器将争夺主服务器的角色。</p>
</div>
</div>
<div class="sect2">
<h3 id="master.runtime"><a class="anchor" href="#master.runtime"></a> 66.2。运行时影响</h3>
<div class="paragraph">
<p>常见的分发列表问题涉及当主服务器崩溃时，HBase群集会发生什么情况。因为HBase客户端直接与RegionServer通信，所以群集仍可以在“稳定状态”下运行。此外，根据<a href="#arch.catalog">目录表</a> ， <code>hbase:meta</code>作为HBase表存在，并且不驻留在主服务器中。但是，主服务器控制关键功能，例如RegionServer故障转移和完成区域划分。因此，尽管在没有Master的情况下群集仍可以短时间运行，但应该尽快重新启动Master。</p>
</div>
</div>
<div class="sect2">
<h3 id="master.api"><a class="anchor" href="#master.api"></a> 66.3。接口</h3>
<div class="paragraph">
<p>暴露的方法<code>HMasterInterface</code>主要是面向元数据的方法：</p>
</div>
<div class="ulist">
<ul>
<li>
<p>表（createTable，modifyTable，removeTable，启用，禁用）</p>
</li>
<li>
<p>ColumnFamily（addColumn，modifyColumn，removeColumn）</p>
</li>
<li>
<p>区域（移动，分配，取消分配），例如，当<code>Admin</code>方法<code>disableTable</code>被调用，由主服务器提供服务。</p>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="master.processes"><a class="anchor" href="#master.processes"></a> 66.4。工艺流程</h3>
<div class="paragraph">
<p>主服务器运行几个后台线程：</p>
</div>
<div class="sect3">
<h4 id="master.processes.loadbalancer"><a class="anchor" href="#master.processes.loadbalancer"></a> 66.4.1。负载均衡器</h4>
<div class="paragraph">
<p>周期性地，当没有过渡区域时，负载均衡器将运行并移动区域以平衡集群的负载。请参阅<a href="#balancer_config">平衡器</a>以配置此属性。</p>
</div>
<div class="paragraph">
<p>有关<a href="#regions.arch.assignment">区域分配</a>的更多信息，请参见<a href="#regions.arch.assignment">Region-RegionServer分配</a> 。</p>
</div>
</div>
<div class="sect3">
<h4 id="master.processes.catalog"><a class="anchor" href="#master.processes.catalog"></a> 66.4.2。目录管理员</h4>
<div class="paragraph">
<p>定期检查并清理<code>hbase:meta</code>表。有关<arch.catalog.meta>元表的更多信息，</arch.catalog.meta>请参见<arch.catalog.meta>>。</arch.catalog.meta></p>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="regionserver.arch"><a class="anchor" href="#regionserver.arch"></a> 67。区域服务器</h2>
<div class="sectionbody">
<div class="paragraph">
<p><code>HRegionServer</code>是RegionServer实现。它负责服务和管理区域。在分布式群集中，RegionServer在<a href="#arch.hdfs.dn">DataNode</a>上运行。</p>
</div>
<div class="sect2">
<h3 id="regionserver.arch.api"><a class="anchor" href="#regionserver.arch.api"></a> 67.1。接口</h3>
<div class="paragraph">
<p>暴露的方法<code>HRegionRegionInterface</code>包含面向数据和区域维护方法：</p>
</div>
<div class="ulist">
<ul>
<li>
<p>数据（获取，放置，删除，下一个等）</p>
</li>
<li>
<p>区域（splitRegion，compactRegion等）例如，当<code>Admin</code>方法<code>majorCompact</code>如果在表上调用，则客户端实际上会遍历指定表的所有区域，并直接向每个区域请求大压缩。</p>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="regionserver.arch.processes"><a class="anchor" href="#regionserver.arch.processes"></a> 67.2。工艺流程</h3>
<div class="paragraph">
<p>RegionServer运行各种后台线程：</p>
</div>
<div class="sect3">
<h4 id="regionserver.arch.processes.compactsplit"><a class="anchor" href="#regionserver.arch.processes.compactsplit"></a> 67.2.1。CompactSplitThread</h4>
<div class="paragraph">
<p>检查是否有裂痕并处理较小的压实。</p>
</div>
</div>
<div class="sect3">
<h4 id="regionserver.arch.processes.majorcompact"><a class="anchor" href="#regionserver.arch.processes.majorcompact"></a> 67.2.2。MajorCompactionChecker</h4>
<div class="paragraph">
<p>检查重大压实。</p>
</div>
</div>
<div class="sect3">
<h4 id="regionserver.arch.processes.memstore"><a class="anchor" href="#regionserver.arch.processes.memstore"></a> 67.2.3。MemStoreFlusher</h4>
<div class="paragraph">
<p>定期将MemStore中的内存中写入刷新到StoreFiles。</p>
</div>
</div>
<div class="sect3">
<h4 id="regionserver.arch.processes.log"><a class="anchor" href="#regionserver.arch.processes.log"></a> 67.2.4。LogRoller</h4>
<div class="paragraph">
<p>定期检查RegionServer的WAL。</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_coprocessors"><a class="anchor" href="#_coprocessors"></a> 67.3。协处理器</h3>
<div class="paragraph">
<p>在0.92中添加了协处理器。已发布了<a href="https://blogs.apache.org/hbase/entry/coprocessor_introduction">有关协处理器</a>的详尽<a href="https://blogs.apache.org/hbase/entry/coprocessor_introduction">博客概述</a> 。文档最终将移至该参考指南，但是博客是当前可用的最新信息。</p>
</div>
</div>
<div class="sect2">
<h3 id="block.cache"><a class="anchor" href="#block.cache"></a> 67.4。块缓存</h3>
<div class="paragraph">
<p>HBase提供了两种不同的BlockCache实现：默认的堆上<code>LruBlockCache</code>和<code>BucketCache</code> ，（通常）是堆外的。本节讨论每种实现的优缺点，如何选择适当的选项以及每种实现的配置选项。</p>
</div>
<div class="admonitionblock note">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-note" title="注意"></i>
</td>
<td class="content">
<div class="title">块缓存报告：UI</div>
<div class="paragraph">
<p>有关缓存部署的详细信息，请参见RegionServer UI。自HBase 0.98.4起，“块缓存”详细信息已得到显着扩展，显示了配置，大小，当前使用情况，缓存时间，甚至有关块计数和类型的详细信息。</p>
</div>
</td>
</tr>
</tbody></table>
</div>
<div class="sect3">
<h4 id="_cache_choices"><a class="anchor" href="#_cache_choices"></a> 67.4.1。缓存选择</h4>
<div class="paragraph">
<p><code>LruBlockCache</code>是原始的实现，并且完全在Java堆中。 <code>BucketCache</code>尽管主要用于保持块缓存数据的堆外状态， <code>BucketCache</code>还可以将数据保留在堆上，并从文件支持的缓存中提供服务。</p>
</div>
<div class="admonitionblock note">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-note" title="注意"></i>
</td>
<td class="content">
<div class="title">自HBase 0.98.6起，BucketCache已投入生产</div>
<div class="paragraph">
<p>要与BucketCache一起运行，您需要HBASE-11678。这包括在0.98.6中。</p>
</div>
</td>
</tr>
</tbody></table>
</div>
<div class="paragraph">
<p>与本地堆上的LruBlockCache相比，从BucketCache进行获取时，获取总是比较慢。但是，随着时间的流逝，延迟往往不太规律，因为使用BucketCache时，由于它管理的是BlockCache分配而不是GC，因此垃圾收集较少。如果以非堆模式部署BucketCache，则此内存完全不受GC管理。这就是为什么要使用BucketCache的原因，因此延迟较小，可以减少GC和堆碎片。请参阅Nick Dimiduk的<a href="http://www.n10k.com/blog/blockcache-101/">BlockCache 101，</a>以进行堆上和堆外测试的比较。另请参阅<a href="http://people.apache.org/~stack/bc/">比较BlockCache部署</a> ，该发现发现如果您的数据集适合您的LruBlockCache部署，请使用它，否则，如果您遇到缓存混乱（或者您希望缓存存在于Java GC的可变范围之外），请使用BucketCache。</p>
</div>
<div class="paragraph">
<p>启用BucketCache时，将启用两层缓存系统，即由LruBlockCache实例实现的L1缓存和由BucketCache实现的堆外L2缓存。这两个层的管理以及指示块之间如何移动的策略是通过以下方式完成的： <code>CombinedBlockCache</code> 。它将所有DATA块保留在L2 BucketCache中，将meta块（INDEX和BLOOM块）保留在L1上<code>LruBlockCache</code> 。有关<a href="#offheap.blockcache">脱堆</a>的更多详细信息，请参见<a href="#offheap.blockcache">堆外块缓存</a> 。</p>
</div>
</div>
<div class="sect3">
<h4 id="cache.configurations"><a class="anchor" href="#cache.configurations"></a> 67.4.2。常规缓存配置</h4>
<div class="paragraph">
<p>除了缓存实现本身之外，您还可以设置一些常规配置选项来控制缓存的执行方式。请参阅<a href="http://hbase.apache.org/devapidocs/org/apache/hadoop/hbase/io/hfile/CacheConfig.html" class="bare">http://hbase.apache.org/devapidocs/org/apache/hadoop/hbase/io/hfile/CacheConfig.html</a> 。设置任何这些选项之后，请重新启动或滚动重新启动群集以使配置生效。检查日志中是否有错误或意外行为。</p>
</div>
<div class="paragraph">
<p>另请参见<a href="#blockcache.prefetch">块缓存的预取选项</a> ，它讨论了<a href="https://issues.apache.org/jira/browse/HBASE-9857">HBASE-9857中</a>引入的新选项。</p>
</div>
</div>
<div class="sect3">
<h4 id="block.cache.design"><a class="anchor" href="#block.cache.design"></a> 67.4.3。LruBlockCache设计</h4>
<div class="paragraph">
<p>LruBlockCache是一个LRU缓存，其中包含三个级别的块优先级，以允许进行扫描抵抗和内存中的ColumnFamilies：</p>
</div>
<div class="ulist">
<ul>
<li>
<p>单一访问优先级：第一次从HDFS加载块时，它通常具有此优先级，它将成为驱逐期间要考虑的第一个组的一部分。优点是，与使用率更高的块相比，扫描的块更有可能被驱逐。</p>
</li>
<li>
<p>多路访问优先级：如果再次访问先前优先级组中的块，则会升级到该优先级。因此，它是驱逐期间考虑的第二组的一部分。</p>
</li>
<li>
<p>内存中访问优先级：如果将块的族配置为“内存中”，则无论访问该对象的次数如何，它都是该优先级的一部分。目录表的配置如下。该小组是驱逐期间考虑的最后一个小组。</p>
<div class="paragraph">
<p>要将列族标记为内存中，请调用</p>
</div>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">HColumnDescriptor.setInMemory(<span class="predefined-constant">true</span>);</code></pre>
</div>
</div>
<div class="paragraph">
<p>如果从Java创建表，或设置<code>IN_MEMORY ⇒ true</code>在外壳中创建或更改表时：例如</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">hbase(main):<span class="octal">003</span>:<span class="integer">0</span>&gt; create  <span class="string"><span class="delimiter">'</span><span class="content">t</span><span class="delimiter">'</span></span>, {NAME =&gt; <span class="string"><span class="delimiter">'</span><span class="content">f</span><span class="delimiter">'</span></span>, IN_MEMORY =&gt; <span class="string"><span class="delimiter">'</span><span class="content">true</span><span class="delimiter">'</span></span>}</code></pre>
</div>
</div>
<div class="paragraph">
<p>有关更多信息，请参见<a href="http://hbase.apache.org/xref/org/apache/hadoop/hbase/io/hfile/LruBlockCache.html">LruBlockCache源。</a></p>
</div>
</div>
<div class="sect3">
<h4 id="block.cache.usage"><a class="anchor" href="#block.cache.usage"></a> 67.4.4。LruBlockCache的使用</h4>
<div class="paragraph">
<p>默认情况下，所有用户表都启用块缓存，这意味着任何读取操作都将加载LRU缓存。这对于许多用例而言可能是好的，但是通常需要进行进一步调整才能获得更好的性能。一个重要的概念是<a href="http://en.wikipedia.org/wiki/Working_set_size">工作集大小</a>或WSS，即：“计算问题答案所需的内存量”。对于网站，这是在短时间内回答查询所需的数据。</p>
</div>
<div class="paragraph">
<p>计算HBase中可用于缓存的内存量的方法是：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">number of region servers * heap size * hfile.block.cache.size * <span class="float">0.99</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>块高速缓存的默认值为0.25，占可用堆的25％。最后一个值（99％）是LRU缓存中默认的可接受的加载因子，在此之后开始逐出。之所以将它包含在此等式中，是因为说有可能使用100％的可用内存是不切实际的，因为这会使进程从加载新块的位置开始阻塞。这里有些例子：</p>
</div>
<div class="ulist">
<ul>
<li>
<p>一台将堆大小设置为1 GB并且默认块高速缓存大小的区域服务器将具有253 MB的块高速缓存可用。</p>
</li>
<li>
<p>20个区域服务器（堆大小设置为8 GB）和默认块高速缓存大小将具有39.6的块高速缓存。</p>
</li>
<li>
<p>100个区域服务器（堆大小设置为24 GB，块缓存大小为0.5）将具有约1.16 TB的块缓存。</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>您的数据不是块缓存的唯一居民。以下是您可能需要考虑的其他事项：</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">目录表</dt>
<dd>
<p>的<code>-ROOT-</code> （在HBase 0.96之前，请参见<a href="#arch.catalog.root">arch.catalog.root</a> ）和<code>hbase:meta</code>表被强制进入块缓存并具有内存中优先级，这意味着它们更难于退出。前者使用的字节永远不会超过几百个字节，而后者则可以占用几个MB（取决于区域的数量）。</p>
</dd>
<dt class="hdlist1">HFiles索引</dt>
<dd>
<p><em>HFile</em>是HBase用于在HDFS中存储数据的文件格式。它包含一个多层索引，该索引使HBase无需读取整个文件即可查找数据。这些索引的大小是块大小（默认为64KB），键的大小和要存储的数据量的因素。对于大数据集，每个区域服务器大约有1GB的数据是很常见的，尽管并非所有数据都将存储在缓存中，因为LRU会驱逐未使用的索引。</p>
</dd>
<dt class="hdlist1">按键</dt>
<dd>
<p>存储的值仅是图片的一半，因为每个值都与其键（行键，家庭限定符和时间戳记）一起存储。请参阅<a href="#keysize">尝试最小化行和列的大小</a> 。</p>
</dd>
<dt class="hdlist1">布隆过滤器</dt>
<dd>
<p>就像HFile索引一样，那些数据结构（启用时）也存储在LRU中。</p>
</dd>
</dl>
</div>
<div class="paragraph">
<p>当前，推荐的衡量HFile索引和Bloom过滤器大小的方法是查看区域服务器Web UI并签出相关指标。对于密钥，可以使用HFile命令行工具进行采样并查找平均密钥大小度量标准。从HBase 0.98.3开始，您可以在UI的特殊“块缓存”部分中查看有关BlockCache统计信息和指标的详细信息。</p>
</div>
<div class="paragraph">
<p>当WSS不能容纳在内存中时，通常使用块缓存是很糟糕的。例如，当您在所有区域服务器的块缓存中都有40GB的可用空间，但需要处理1TB的数据时，就是这种情况。原因之一是驱逐产生的流失将不必要地触发更多垃圾收集。这是两个用例：</p>
</div>
<div class="ulist">
<ul>
<li>
<p>完全随机读取模式：在这种情况下，您几乎不会在短时间内访问同一行两次，因此命中缓存块的机会接近0。在这样的表上设置块缓存会浪费内存和CPU周期，从而浪费更多资源，因此它将生成更多垃圾以供JVM处理。有关监视GC的更多信息，请参阅《 <a href="#trouble.log.gc">JVM垃圾收集日志》</a> 。</p>
</li>
<li>
<p>映射表：在典型的MapReduce作业中，输入一个表，每行将只读取一次，因此无需将其放入块缓存中。扫描对象可以选择通过setCaching方法将其关闭（将其设置为false）。如果您需要快速的随机读取访问权限，则仍可以在此表上保持块缓存打开状态。一个例子是计算服务于实时流量的表中的行数，缓存该表的每个块都会造成巨大的客户流失，并且肯定会逐出当前正在使用的数据。</p>
</li>
</ul>
</div>
<div class="sect4">
<h5 id="data.blocks.in.fscache"><a class="anchor" href="#data.blocks.in.fscache"></a>仅缓存META块（fscache中的DATA块）</h5>
<div class="paragraph">
<p>一种有趣的设置是仅缓存META块，并在每次访问时读取DATA块。如果DATA块适合fscache内，则当跨非常大的数据集进行完全随机访问时，此替代方法可能有意义。要启用此设置，请更改表和每个列族集<code>BLOCKCACHE ⇒ 'false'</code> 。您仅针对此列系列“禁用” BlockCache。您永远不能禁用META块的缓存。由于<a href="https://issues.apache.org/jira/browse/HBASE-4683">HBASE-4683始终缓存索引块和Bloom块</a> ，因此即使禁用BlockCache，我们也将缓存META块。</p>
</div>
</div>
</div>
<div class="sect3">
<h4 id="offheap.blockcache"><a class="anchor" href="#offheap.blockcache"></a> 67.4.5。堆外块缓存</h4>
<div class="sect4">
<h5 id="enable.bucketcache"><a class="anchor" href="#enable.bucketcache"></a>如何启用BucketCache</h5>
<div class="paragraph">
<p>BucketCache的通常部署是通过管理类进行的，该管理类设置了两个缓存层：由LruBlockCache实现的L1堆上缓存和由BucketCache实现的第二个L2缓存。默认情况下，管理类为<a href="http://hbase.apache.org/devapidocs/org/apache/hadoop/hbase/io/hfile/CombinedBlockCache.html">CombinedBlockCache</a> 。前面的链接描述了CombinedBlockCache实现的缓存“策略”。简而言之，它通过将元数据块（INDEX和BLOOM保留在L1堆上的LruBlockCache层中）而工作，并将DATA数据块保留在L2的BucketCache层中。从版本1.0开始，可以在HBase中修改此行为，并要求列族通过设置将列和元数据块同时托管在L1层中<code>cacheDataInL1</code>通过<code>(HColumnDescriptor.setCacheDataInL1(true)</code>或在外壳中创建或修改列族设置<code>CACHE_DATA_IN_L1</code>变为真实：例如</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">hbase(main):<span class="octal">003</span>:<span class="integer">0</span>&gt; create <span class="string"><span class="delimiter">'</span><span class="content">t</span><span class="delimiter">'</span></span>, {NAME =&gt; <span class="string"><span class="delimiter">'</span><span class="content">t</span><span class="delimiter">'</span></span>, CONFIGURATION =&gt; {CACHE_DATA_IN_L1 =&gt; <span class="string"><span class="delimiter">'</span><span class="content">true</span><span class="delimiter">'</span></span>}}</code></pre>
</div>
</div>
<div class="paragraph">
<p>BucketCache块缓存可以部署在堆上，堆外或基于文件的位置。您可以通过设置<code>hbase.bucketcache.ioengine</code>设置。设置为<code>heap</code>将在分配的Java堆中部署BucketCache。设置为<code>offheap</code>将让BucketCache进行堆外分配，并将ioengine设置为<code>file:PATH_TO_FILE</code>会指示BucketCache使用文件缓存（尤其是当您在盒子上连接了一些快速I / O（例如SSD）时，该选项特别有用）。</p>
</div>
<div class="paragraph">
<p>可以部署L1 + L2设置，在此我们绕过CombinedBlockCache策略，并让BucketCache充当L1 LruBlockCache的严格L2缓存。对于这样的设置，设置<code>CacheConfig.BUCKET_CACHE_COMBINED_KEY</code>至<code>false</code> 。在此模式下，从L1逐出时，块进入L2。缓存块时，首先将其缓存在L1中。当我们寻找缓存的块时，我们首先在L1中查找，如果找不到，则搜索L2。让我们将此部署格式称为<em>Raw L1 + L2</em> 。</p>
</div>
<div class="paragraph">
<p>其他BucketCache配置包括：指定一个位置，以在重新启动后将缓存持久化，使用多少个线程来写入缓存，等等。有关配置选项和描述，请参见<a href="https://hbase.apache.org/apidocs/org/apache/hadoop/hbase/io/hfile/CacheConfig.html">CacheConfig.html</a>类。</p>
</div>
<div class="sect5">
<h6 id="_bucketcache_example_configuration"><a class="anchor" href="#_bucketcache_example_configuration"></a> BucketCache示例配置</h6>
<div class="paragraph">
<p>此示例提供了4 GB的堆外BucketCache和1 GB的堆上高速缓存的配置。</p>
</div>
<div class="paragraph">
<p>配置在RegionServer上执行。</p>
</div>
<div class="paragraph">
<p>设置<code>hbase.bucketcache.ioengine</code>和<code>hbase.bucketcache.size</code> > 0启用<code>CombinedBlockCache</code> 。让我们假设RegionServer已设置为与5G堆一起运行： <code>HBASE_HEAPSIZE=5g</code> 。</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>首先，编辑RegionServer的<em>hbase-env.sh</em>并设置<code>HBASE_OFFHEAPSIZE</code>值要大于所需的堆外大小，在这种情况下为4 GB（表示为4G）。让我们将其设置为5G。对于我们的堆外缓存，这将是4G，而对于堆外内存的任何其他用途，它将是1G（除BlockCache之外，还有其他堆外内存用户；例如，RegionServer中的DFSClient可以使用堆外内存）。请参见<a href="#direct.memory">HBase中的直接内存使用</a> 。</p>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">HBASE_OFFHEAPSIZE=<span class="integer">5</span>G</code></pre>
</div>
</div>
</li>
<li>
<p>接下来，将以下配置添加到RegionServer的<em>hbase-site.xml中</em> 。</p>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="xml"><span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>hbase.bucketcache.ioengine<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>offheap<span class="tag">&lt;/value&gt;</span>
<span class="tag">&lt;/property&gt;</span>
<span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>hfile.block.cache.size<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>0.2<span class="tag">&lt;/value&gt;</span>
<span class="tag">&lt;/property&gt;</span>
<span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>hbase.bucketcache.size<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>4196<span class="tag">&lt;/value&gt;</span>
<span class="tag">&lt;/property&gt;</span></code></pre>
</div>
</div>
</li>
<li>
<p>重新启动或滚动重新启动群集，并检查日志中是否有任何问题。</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>在上面，我们将BucketCache设置为4G。我们将堆上的LruBlockCache配置为具有RegionServer堆大小的20％（0.2）（0.2 * 5G = 1G）。换句话说，您可以像通常那样配置L1 LruBlockCache（就像没有L2缓存一样）。</p>
</div>
<div class="paragraph">
<p><a href="https://issues.apache.org/jira/browse/HBASE-10641">HBASE-10641</a>引入了在HBase 0.98及更高版本中为BucketCache的存储桶配置多个大小的功能。要配置多个存储桶大小，请配置新属性<code>hfile.block.cache.sizes</code> （代替<code>hfile.block.cache.size</code> ）以逗号分隔的块大小列表，从最小到最大顺序排列，没有空格。目的是根据您的数据访问模式优化存储桶大小。以下示例配置了大小为4096和8192的存储桶。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="xml"><span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>hfile.block.cache.sizes<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>4096,8192<span class="tag">&lt;/value&gt;</span>
<span class="tag">&lt;/property&gt;</span></code></pre>
</div>
</div>
<div id="direct.memory" class="admonitionblock note">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-note" title="注意"></i>
</td>
<td class="content">
<div class="title">HBase中的直接内存使用情况</div>
<div class="paragraph">
<p>默认最大直接内存因JVM而异。传统上，它是64M或与分配堆大小（-Xmx）有某种关系，或者根本没有限制（显然是JDK7）。HBase服务器使用直接内存，特别是短路读取，托管的DFSClient将分配直接内存缓冲区。如果进行堆外块缓存，则将使用直接内存。启动JVM，确保<code>-XX:MaxDirectMemorySize</code> <em>conf / hbase-env.sh</em>中的设置被设置为某个值，该值高于分配给堆外BlockCache的值（ <code>hbase.bucketcache.size</code> ）。它应该大于堆外块缓存，然后大于DFSClient的使用量（DFSClient使用多少并不容易量化；它是打开的HFiles的数量* <code>hbase.dfs.client.read.shortcircuit.buffer.size</code>哪里<code>hbase.dfs.client.read.shortcircuit.buffer.size</code>在HBase中设置为128k（请参阅<em>hbase-default.xml</em>默认配置）。直接内存是Java进程堆的一部分，与-Xmx分配的对象堆是分开的。分配的值<code>MaxDirectMemorySize</code>不得超过物理RAM，并且由于其他内存要求和系统限制，可能会小于可用的总RAM。</p>
</div>
<div class="paragraph">
<p>您可以通过查看UI中的“ <em>服务器度量标准：内存”</em>选项卡，查看将RegionServer配置为使用堆上和堆外/直接的内存量，以及在任何时候使用的<em>内存量</em> 。也可以通过JMX获得。特别是可以在服务器上找到服务器当前使用的直接内存。 <code>java.nio.type=BufferPool,name=direct</code>豆。Terracotta在使用Java中的堆外内存方面<a href="http://terracotta.org/documentation/4.0/bigmemorygo/configuration/storage-options">写得很好</a> 。它是针对其产品BigMemory的，但是提到的许多问题通常都适用于任何试图摆脱困境的尝试。看看这个。</p>
</div>
</td>
</tr>
</tbody></table>
</div>
<div class="admonitionblock note">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-note" title="注意"></i>
</td>
<td class="content">
<div class="title">hbase.bucketcache.percentage.in.combinedcache</div>
<div class="paragraph">
<p>这是HBase 1.0之前的配置已删除，因为它令人困惑。您可以将其设置为介于0.0和1.0之间的一个浮点数。默认值为0.9。如果部署使用的是CombinedBlockCache，则计算得出LruBlockCache L1的大小为<code>(1 - hbase.bucketcache.percentage.in.combinedcache) * size-of-bucketcache</code>而BucketCache的大小为<code>hbase.bucketcache.percentage.in.combinedcache * size-of-bucket-cache</code> 。桶缓存大小本身是配置的值<code>hbase.bucketcache.size</code>如果指定为兆字节或<code>hbase.bucketcache.size</code> * <code>-XX:MaxDirectMemorySize</code>如果<code>hbase.bucketcache.size</code>在0到1.0之间。</p>
</div>
<div class="paragraph">
<p>在1.0中，它应该更简单。使用以下命令将L1 LruBlockCache大小设置为Java堆的一部分<code>hfile.block.cache.size setting</code> （不是最佳名称），L2的设置单位为绝对兆字节或分配的最大直接内存的一部分。</p>
</div>
</td>
</tr>
</tbody></table>
</div>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_compressed_blockcache"><a class="anchor" href="#_compressed_blockcache"></a> 67.4.6。压缩块缓存</h4>
<div class="paragraph">
<p><a href="https://issues.apache.org/jira/browse/HBASE-11331">HBASE-</a> 11331引入了惰性BlockCache解压缩，简称为压缩BlockCache。启用压缩的BlockCache后，数据和编码的数据块将以其磁盘上的格式缓存在BlockCache中，而不是在缓存之前进行解压缩和解密。</p>
</div>
<div class="paragraph">
<p>对于承载超过缓存容量的更多数据的RegionServer，使用SNAPPY压缩启用此功能已显示出将吞吐量提高50％，平均延迟提高30％，同时将垃圾收集增加80％，并将总CPU负载增加30％。 2％。有关如何衡量和实现性能的更多详细信息，请参见HBASE-11331。对于托管可以舒适地容纳在缓存中的数据的RegionServer，或者如果您的工作负载对额外的CPU或垃圾收集负载敏感，则可能会收到较少的收益。</p>
</div>
<div class="paragraph">
<p>默认情况下，压缩的BlockCache是禁用的。要启用它，请设置<code>hbase.block.data.cachecompressed</code>至<code>true</code>在所有RegionServer上的<em>hbase-site.xml中</em> 。</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="regionserver_splitting_implementation"><a class="anchor" href="#regionserver_splitting_implementation"></a> 67.5。RegionServer拆分实施</h3>
<div class="paragraph">
<p>当写入请求由区域服务器处理时，它们会累积在称为<em>memstore</em>的内存存储系统中。内存存储填满后，其内容将作为其他存储文件写入磁盘。此事件称为<em>内存存储刷新</em> 。随着存储文件的累积，RegionServer将把它们<a href="#compaction">压缩</a>为更少，更大的文件。每次刷新或压缩完成后，该区域中存储的数据量已更改。RegionServer会查询区域拆分策略，以确定该区域是否太大或由于其他特定于策略的原因而应拆分。如果策略建议，则将区域划分请求加入队列。</p>
</div>
<div class="paragraph">
<p>从逻辑上讲，分割区域的过程很简单。我们在区域的键空间中找到一个合适的点，该区域应将区域分成两半，然后在该点将区域的数据分为两个新区域。但是，该过程的细节并不简单。发生拆分时，新创建的<em>子区域</em>不会立即将所有数据重写到新文件中。相反，它们创建类似于符号链接文件的小文件，称为<a href="http://www.google.com/url?q=http%3A%2F%2Fhbase.apache.org%2Fapidocs%2Forg%2Fapache%2Fhadoop%2Fhbase%2Fio%2FReference.html&sa=D&sntz=1&usg=AFQjCNEkCbADZ3CgKHTtGYI8bJVwp663CA">参考文件</a> ，该文件根据拆分点指向父存储文件的顶部或底部。参考文件的使用与常规数据文件一样，但是只考虑了一半的记录。仅当没有更多对父区域的不可变数据文件的引用时，才可以分割区域。这些参考文件将通过压缩逐步清除，因此该区域将停止引用其父文件，并且可以进一步拆分。</p>
</div>
<div class="paragraph">
<p>尽管分割区域是RegionServer做出的本地决定，但是分割过程本身必须与许多参与者协调。RegionServer在拆分之前和之后通知Master，更新<code>.META.</code>表，以便客户端可以发现新的子区域，并在HDFS中重新排列目录结构和数据文件。拆分是一个多任务过程。为了在发生错误的情况下启用回滚，RegionServer会在内存中保留有关执行状态的日志。<a href="#regionserver_split_process_image">RegionServer拆分过程</a>中说明了<a href="#regionserver_split_process_image">RegionServer</a>执行拆分的步骤。每个步骤均标有其步骤编号。来自RegionServers或Master的操作以红色显示，而来自客户端的操作以绿色显示。</p>
</div>
<div id="regionserver_split_process_image" class="imageblock">
<div class="content">
<img src="images/region_split_process.png" alt="区域分割过程">
</div>
<div class="title">图1。RegionServer拆分过程</div>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>RegionServer在本地决定分割区域，并准备分割。<strong>分割交易开始。</strong>第一步，RegionServer获取表上的共享读取锁，以防止在拆分过程中修改架构。然后在Zookeeper下创建一个znode <code>/hbase/region-in-transition/region-name</code> ，并将znode的状态设置为<code>SPLITTING</code> 。</p>
</li>
<li>
<p>主节点了解此znode，因为它具有父节点的观察者<code>region-in-transition</code> znode。</p>
</li>
<li>
<p>RegionServer创建一个名为<code>.splits</code>在父母的下<code>region</code> HDFS中的目录。</p>
</li>
<li>
<p>RegionServer关闭父区域，并在其本地数据结构中将该区域标记为脱机。<strong>分割区域现在离线。</strong>这时，到达父区域的客户请求将抛出<code>NotServingRegionException</code> 。客户端将重试一些退避。关闭区域被冲洗。</p>
</li>
<li>
<p>RegionServer在以下位置创建区域目录<code>.splits</code>目录，用于子区域A和B，并创建必要的数据结构。然后，它将拆分存储文件，这意味着它会在父区域中为每个存储文件创建两个<a href="http://www.google.com/url?q=http%3A%2F%2Fhbase.apache.org%2Fapidocs%2Forg%2Fapache%2Fhadoop%2Fhbase%2Fio%2FReference.html&sa=D&sntz=1&usg=AFQjCNEkCbADZ3CgKHTtGYI8bJVwp663CA">参考</a>文件。这些参考文件将指向父区域的文件。</p>
</li>
<li>
<p>RegionServer在HDFS中创建实际的区域目录，并移动每个子级的参考文件。</p>
</li>
<li>
<p>RegionServer发送一个<code>Put</code>要求<code>.META.</code>表中，将父级设置为脱机<code>.META.</code>表并添加有关子区域的信息。在这一点上，将不会有单独的条目<code>.META.</code>给女儿们客户端扫描后会看到父区域已拆分<code>.META.</code> ，但直到他们出现在女儿那里，他们才知道<code>.META.</code> 。另外，如果这<code>Put</code>至<code>.META</code> 。成功后，父母将被有效分割。如果RegionServer在此RPC成功之前失败，则Master和下一个打开该区域的Region Server将清除有关区域拆分的脏状态。之后<code>.META.</code>不过，更新后，区域划分将由Master进行前滚。</p>
</li>
<li>
<p>RegionServer并行打开子节点A和B。</p>
</li>
<li>
<p>RegionServer将子项A和B添加到<code>.META.</code> ，以及托管区域的信息。<strong>分割区域（参考父母的女儿）现在在线。</strong>此后，客户可以发现新区域并向他们发出请求。客户端缓存<code>.META.</code>本地条目，但是当它们向RegionServer发出请求时<code>.META.</code> ，其缓存将失效，并且他们将从中了解新区域<code>.META.</code> 。</p>
</li>
<li>
<p>RegionServer更新znode <code>/hbase/region-in-transition/region-name</code>在ZooKeeper中陈述<code>SPLIT</code> ，以便大师可以了解它。必要时，平衡器可以将子区域自由地重新分配给其他区域服务器。<strong>现在已完成拆分交易。</strong></p>
</li>
<li>
<p>分裂之后<code>.META.</code>并且HDFS仍将包含对父区域的引用。当子区域中的压缩重写数据文件时，这些引用将被删除。主服务器中的垃圾收集任务会定期检查子区域是否仍引用父区域的文件。否则，父区域将被删除。</p>
</li>
</ol>
</div>
</div>
<div class="sect2">
<h3 id="wal"><a class="anchor" href="#wal"></a> 67.6。预写日志（WAL）</h3>
<div class="sect3">
<h4 id="purpose.wal"><a class="anchor" href="#purpose.wal"></a> 67.6.1。目的</h4>
<div class="paragraph">
<p><em>预写日志（WAL）</em>将对HBase中数据的所有更改记录到基于文件的存储中。在正常操作下，由于数据更改从MemStore移到StoreFiles，因此不需要WAL。但是，如果在刷新MemStore之前RegionServer崩溃或变得不可用，则WAL确保可以重放对数据的更改。如果写入WAL失败，则修改数据的整个操作将失败。</p>
</div>
<div class="paragraph">
<p>HBase使用<a href="http://hbase.apache.org/devapidocs/org/apache/hadoop/hbase/wal/WAL.html">WAL</a>接口的实现。通常，每个RegionServer仅存在一个WAL实例。RegionServer会在其中记录<a href="#store.memstore">放置</a>和删除，然后再将它们记录到受影响的<a href="#store">[store]</a>的<a href="#store.memstore">MemStore</a>中。</p>
</div>
<div class="admonitionblock note">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-note" title="注意"></i>
</td>
<td class="content">
<div class="title">HLog</div>
<div class="paragraph">
<p>在2.0之前的版本中，HBase中的WAL接口被命名为<code>HLog</code> 。在0.94中，HLog是WAL实施的名称。您可能会在针对这些较早版本量身定制的文档中找到对HLog的引用。</p>
</div>
</td>
</tr>
</tbody></table>
</div>
<div class="paragraph">
<p>WAL驻留在<em>/ hbase / WALs /</em>目录中的HDFS中（在HBase 0.94之前，它们存储在<em>/hbase/.logs/中</em> ），每个区域都有子目录。</p>
</div>
<div class="paragraph">
<p>有关<a href="http://en.wikipedia.org/wiki/Write-ahead_logging">预</a>写日志概念的更多常规信息，请参阅Wikipedia <a href="http://en.wikipedia.org/wiki/Write-ahead_logging">预写日志</a>文章。</p>
</div>
</div>
<div class="sect3">
<h4 id="_multiwal"><a class="anchor" href="#_multiwal"></a> 67.6.2。多沃尔</h4>
<div class="paragraph">
<p>每个RegionServer使用单个WAL，RegionServer必须串行写入WAL，因为HDFS文件必须是顺序的。这导致WAL成为性能瓶颈。</p>
</div>
<div class="paragraph">
<p>HBase 1.0在<a href="https://issues.apache.org/jira/browse/HBASE-5699">HBASE-5699中</a>引入了对MultiWal的支持。MultiWAL允许RegionServer通过在基础HDFS实例中使用多个管道来并行写入多个WAL流，这将增加写入期间的总吞吐量。并行化是通过按区域对传入编辑进行分区来完成的。因此，当前的实现将无助于增加单个区域的吞吐量。</p>
</div>
<div class="paragraph">
<p>使用原始WAL实现的RegionServer和使用MultiWAL实现的RegionServer都可以处理任意一组WAL的恢复，因此可以通过滚动重启来实现零停机配置更新。</p>
</div>
<div class="paragraph">
<div class="title">配置MultiWAL</div>
<p>要为RegionServer配置MultiWAL，请设置属性的值<code>hbase.wal.provider</code>至<code>multiwal</code>通过粘贴以下XML：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="xml"><span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>hbase.wal.provider<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>multiwal<span class="tag">&lt;/value&gt;</span>
<span class="tag">&lt;/property&gt;</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>重新启动RegionServer，以使更改生效。</p>
</div>
<div class="paragraph">
<p>要为RegionServer禁用MultiWAL，请取消设置该属性，然后重新启动RegionServer。</p>
</div>
</div>
<div class="sect3">
<h4 id="wal_flush"><a class="anchor" href="#wal_flush"></a> 67.6.3。沃尔冲洗</h4>
<div class="paragraph">
<p>TODO（描述）。</p>
</div>
</div>
<div class="sect3">
<h4 id="_wal_splitting"><a class="anchor" href="#_wal_splitting"></a> 67.6.4。沃尔玛分裂</h4>
<div class="paragraph">
<p>RegionServer服务于许多区域。区域服务器中的所有区域共享相同的活动WAL文件。WAL文件中的每个编辑都包含有关它属于哪个区域的信息。当打开一个区域时，需要重播WAL文件中属于该区域的编辑。因此，必须按区域对WAL文件中的编辑进行分组，以便可以重放特定的集以重新生成特定区域中的数据。将WAL编辑按区域分组的过程称为<em>日志拆分</em> 。如果区域服务器发生故障，这是恢复数据的关键过程。</p>
</div>
<div class="paragraph">
<p>日志拆分是由HMaster在群集启动期间完成的，或者由ServerShutdownHandler在区域服务器关闭时完成的。为了保证一致性，在恢复数据之前受影响的区域将不可用。必须恢复并重放所有WAL编辑，然后才能再次使给定区域可用。结果，受日志拆分影响的区域将不可用，直到该过程完成。</p>
</div>
<div class="olist arabic">
<div class="title">过程：逐步拆分日志</div>
<ol class="arabic">
<li>
<p><em>/ hbase / WALs / <host><port>， <startcode></startcode></port></host></em>目录已重命名。</p>
<div class="paragraph">
<p>重命名目录很重要，因为即使HMaster认为它已关闭，RegionServer可能仍处于启动状态并接受请求。如果RegionServer没有立即响应并且没有对其ZooKeeper会话进行心跳检测，则HMaster可能会将其解释为RegionServer故障。重命名日志目录可确保不会被意外写入处于活动状态但繁忙的RegionServer的现有有效WAL文件。</p>
</div>
<div class="paragraph">
<p>新目录根据以下模式命名：</p>
</div>
<div class="listingblock">
<div class="content">
<pre>/hbase/WALs/&lt;host&gt;,&lt;port&gt;,&lt;startcode&gt;-splitting</pre>
</div>
</div>
<div class="paragraph">
<p>此类重命名目录的示例可能如下所示：</p>
</div>
<div class="listingblock">
<div class="content">
<pre>/hbase/WALs/srv.example.com,60020,1254173957298-splitting</pre>
</div>
</div>
</li>
<li>
<p>每个日志文件被拆分，一次一个。</p>
<div class="paragraph">
<p>日志拆分器一次读取日志文件中的一个编辑条目，并将每个编辑条目放入与该编辑区域相对应的缓冲区中。同时，拆分器启动多个写程序线程。编写器线程拾取相应的缓冲区，并将缓冲区中的编辑条目写入到临时恢复的编辑文件中。临时编辑文件使用以下命名模式存储到磁盘：</p>
</div>
<div class="listingblock">
<div class="content">
<pre>/hbase/&lt;table_name&gt;/&lt;region_id&gt;/recovered.edits/.temp</pre>
</div>
</div>
<div class="paragraph">
<p>该文件用于将所有编辑存储在该区域的WAL日志中。日志拆分完成后， <em>.temp</em>文件将重命名为写入该文件的第一个日志的序列ID。</p>
</div>
<div class="paragraph">
<p>为了确定是否已写入所有编辑，将序列ID与最后写入HFile的编辑序列进行比较。如果上次编辑的序列大于或等于文件名中包含的序列ID，则很明显，已完成对编辑文件的所有写操作。</p>
</div>
</li>
<li>
<p>日志拆分完成后，将每个受影响的区域分配给RegionServer。</p>
<div class="paragraph">
<p>当区域被打开，文件夹是检查<em>recovered.edits</em>恢复编辑文件。如果存在任何此类文件，则通过阅读编辑并将它们保存到MemStore来重放它们。重放所有编辑文件后，会将MemStore的内容写入磁盘（HFile），然后删除编辑文件。</p>
</div>
</li>
</ol>
</div>
<div class="sect4">
<h5 id="_handling_of_errors_during_log_splitting"><a class="anchor" href="#_handling_of_errors_during_log_splitting"></a>日志拆分过程中的错误处理</h5>
<div class="paragraph">
<p>如果您设定<code>hbase.hlog.split.skip.errors</code>选择<code>true</code> ，错误的处理方式如下：</p>
</div>
<div class="ulist">
<ul>
<li>
<p>分割期间遇到的任何错误都将被记录。</p>
</li>
<li>
<p>有问题的WAL日志将移至<em>hbase</em>下的.corrupt目录中<code>rootdir</code> ，</p>
</li>
<li>
<p>WAL的处理将继续</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>如果<code>hbase.hlog.split.skip.errors</code>选项设置为<code>false</code> ，默认情况下，将传播异常，并且拆分将记录为失败。请参见<a href="https://issues.apache.org/jira/browse/HBASE-2958">HBASE-2958。如果将hbase.hlog.split.skip.errors设置为false，则分割失败，仅此而已</a> 。如果设置了此标志，我们需要做的不仅仅是失败分割。</p>
</div>
<div class="sect5">
<h6 id="_how_eofexceptions_are_treated_when_splitting_a_crashed_regionserver_s_wals"><a class="anchor" href="#_how_eofexceptions_are_treated_when_splitting_a_crashed_regionserver_s_wals"></a>拆分崩溃的RegionServer的WAL时如何处理EOFException</h6>
<div class="paragraph">
<p>如果在分割日志时发生EOFException，则即使<code>hbase.hlog.split.skip.errors</code>被设定为<code>false</code> 。在读取要拆分的文件集中的最后一个日志时，可能会出现EOFException，因为RegionServer可能在崩溃时正在写入记录。有关背景，请参阅<a href="https://issues.apache.org/jira/browse/HBASE-2643">HBASE-2643。图如何处理eof拆分日志</a></p>
</div>
</div>
</div>
<div class="sect4">
<h5 id="_performance_improvements_during_log_splitting"><a class="anchor" href="#_performance_improvements_during_log_splitting"></a>日志拆分期间的性能改进</h5>
<div class="paragraph">
<p>WAL日志的拆分和恢复可能会占用大量资源，并且会花费很长时间，具体取决于崩溃中涉及的RegionServer的数量和区域的大小。<a href="#distributed.log.splitting">开发了分布式日志拆分</a>和<a href="#distributed.log.replay">分布式日志重播</a>以提高日志拆分期间的性能。</p>
</div>
<div class="sect5">
<h6 id="distributed.log.splitting"><a class="anchor" href="#distributed.log.splitting"></a>分布式日志拆分</h6>
<div class="paragraph">
<p>Facebook的Prakash Khemani在HBase版本0.92（ <a href="https://issues.apache.org/jira/browse/HBASE-1364">HBASE-1364</a> ）中添加了<em>分布式日志拆分</em> 。它大大减少了完成日志拆分的时间，从而提高了区域和表的可用性。例如，使用单线程日志拆分，恢复崩溃的群集大约需要9个小时，而使用分布式日志拆分，则仅花费大约6分钟。</p>
</div>
<div class="paragraph">
<p>本节中的信息来自Jimmy Xiang的博客文章， <a href="http://blog.cloudera.com/blog/2012/07/hbase-log-splitting/" class="bare">网址</a>为<a href="http://blog.cloudera.com/blog/2012/07/hbase-log-splitting/" class="bare">http://blog.cloudera.com/blog/2012/07/hbase-log-splitting/</a> 。</p>
</div>
<div class="paragraph">
<div class="title">启用或禁用分布式日志拆分</div>
<p>从HBase 0.92开始，默认情况下启用分布式日志处理。该设置由<code>hbase.master.distributed.log.splitting</code>属性，可以设置为<code>true</code>要么<code>false</code> ，但默认为<code>true</code> 。</p>
</div>
<div id="log.splitting.step.by.step" class="paragraph">
<div class="title">分布式日志拆分，分步进行</div>
<p>配置分布式日志拆分后，HMaster控制该过程。HMaster在日志拆分过程中注册每个RegionServer，拆分日志的实际工作由RegionServer完成。<a href="#log.splitting.step.by.step">分布式日志拆分（分步进行）中</a>描述的常规日志拆分过程仍在此处适用。</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>如果启用了分布式日志处理，则在启动群集时，HMaster将创建一个<em>拆分日志管理器</em>实例。</p>
<div class="olist loweralpha">
<ol class="loweralpha" type="a">
<li>
<p>拆分日志管理器管理所有需要扫描和拆分的日志文件。</p>
</li>
<li>
<p>拆分日志管理器将所有日志作为任务放入ZooKeeper拆分日志节点（ <em>/ hbase / splitlog</em> ）。</p>
</li>
<li>
<p>您可以通过发出以下命令来查看splitlog的内容<code>zkCli</code>命令。显示示例输出。</p>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">ls /hbase/splitlog
[hdfs%3A%2F%2Fhost2.sample.com%3A56020%2Fhbase%2F.logs%2Fhost8.sample.com%2C57020%2C1340474893275-splitting%2Fhost8.sample.com%253A57020.1340474893900,
hdfs%3A%2F%2Fhost2.sample.com%3A56020%2Fhbase%2F.logs%2Fhost3.sample.com%2C57020%2C1340474893299-splitting%2Fhost3.sample.com%253A57020.1340474893931,
hdfs%3A%2F%2Fhost2.sample.com%3A56020%2Fhbase%2F.logs%2Fhost4.sample.com%2C57020%2C1340474893287-splitting%2Fhost4.sample.com%253A57020.1340474893946]</code></pre>
</div>
</div>
<div class="paragraph">
<p>输出包含一些非ASCII字符。解码后，它看起来要简单得多：</p>
</div>
<div class="listingblock">
<div class="content">
<pre>[hdfs://host2.sample.com:56020/hbase/.logs
/host8.sample.com,57020,1340474893275-splitting
/host8.sample.com%3A57020.1340474893900,
hdfs://host2.sample.com:56020/hbase/.logs
/host3.sample.com,57020,1340474893299-splitting
/host3.sample.com%3A57020.1340474893931,
hdfs://host2.sample.com:56020/hbase/.logs
/host4.sample.com,57020,1340474893287-splitting
/host4.sample.com%3A57020.1340474893946]</pre>
</div>
</div>
<div class="paragraph">
<p>该清单表示要扫描和拆分的WAL文件名，这是日志拆分任务的列表。</p>
</div>
</li>
</ol>
</div>
</li>
<li>
<p>拆分日志管理器监视日志拆分任务和工作程序。</p>
<div class="paragraph">
<p>拆分日志管理器负责以下正在进行的任务：</p>
</div>
<div class="ulist">
<ul>
<li>
<p>一旦拆分日志管理器将所有任务发布到splitlog znode，它就会监视这些任务节点并等待它们被处理。</p>
</li>
<li>
<p>检查是否有排队等待死的拆分日志工作程序。如果发现未响应的工作人员主张任务，它将重新提交这些任务。如果由于某些ZooKeeper异常而导致重新提交失败，则已死亡的工作程序将再次排队等待重试。</p>
</li>
<li>
<p>检查是否有未分配的任务。如果发现任何错误，它将创建一个临时重新扫描节点，以便每个拆分日志工作程序通过通知重新扫描未分配的任务。 <code>nodeChildrenChanged</code> ZooKeeper事件。</p>
</li>
<li>
<p>检查已分配但已过期的任务。如果找到任何内容，则将它们移回至<code>TASK_UNASSIGNED</code>再次声明，以便可以重试。这些任务有可能分配给了慢工，或者它们可能已经完成。这不是问题，因为日志拆分任务具有幂等性。换句话说，同一日志拆分任务可以多次处理而不会引起任何问题。</p>
</li>
<li>
<p>拆分日志管理器不断监视HBase拆分日志znode。如果任何拆分日志任务节点数据已更改，则拆分日志管理器将检索节点数据。节点数据包含任务的当前状态。您可以使用<code>zkCli</code><code>get</code>命令以检索任务的当前状态。在下面的示例输出中，输出的第一行显示当前未分配任务。</p>
<div class="listingblock">
<div class="content">
<pre>get /hbase/splitlog/hdfs%3A%2F%2Fhost2.sample.com%3A56020%2Fhbase%2F.logs%2Fhost6.sample.com%2C57020%2C1340474893287-splitting%2Fhost6.sample.com%253A57020.1340474893945

unassigned host2.sample.com:57000
cZxid = 0×7115
ctime = Sat Jun 23 11:13:40 PDT 2012
...</pre>
</div>
</div>
<div class="paragraph">
<p>根据数据已更改的任务的状态，拆分日志管理器执行以下操作之一：</p>
</div>
</li>
<li>
<p>如果任务未分配，请重新提交</p>
</li>
<li>
<p>对任务执行心跳（如果已分配）</p>
</li>
<li>
<p>重新提交或使任务失败（如果任务已辞职）（请参阅<a href="#distributed.log.replay.failure.reasons">任务失败的原因</a> ）</p>
</li>
<li>
<p>如果错误完成任务，则重新提交或使任务失败（请参阅<a href="#distributed.log.replay.failure.reasons">任务失败的原因</a> ）</p>
</li>
<li>
<p>如果由于错误而无法完成任务，请重新提交或使任务失败（请参阅<a href="#distributed.log.replay.failure.reasons">任务失败的原因</a> ）</p>
</li>
<li>
<p>如果任务成功完成或失败，则将其删除</p>
<div id="distributed.log.replay.failure.reasons" class="admonitionblock note">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-note" title="注意"></i>
</td>
<td class="content">
<div class="title">任务失败的原因</div>
<div class="ulist">
<ul>
<li>
<p>任务已被删除。</p>
</li>
<li>
<p>该节点不再存在。</p>
</li>
<li>
<p>日志状态管理器无法将任务状态移至<code>TASK_UNASSIGNED</code> 。</p>
</li>
<li>
<p>重新提交的次数超过了重新提交的阈值。</p>
</li>
</ul>
</div>
</td>
</tr>
</tbody></table>
</div>
</li>
</ul>
</div>
</li>
<li>
<p>每个RegionServer的拆分日志工作器都执行日志拆分任务。</p>
<div class="paragraph">
<p>每个RegionServer都运行一个名为<em>split log worker</em>的守护程序线程，该线程负责<em>拆分</em>日志。守护程序线程在RegionServer启动时启动，并注册自己以监视HBase znode。如果任何splitlog znode子级发生更改，它将通知正在睡眠的工作线程唤醒并抓取更多任务。如果某个工作程序的当前任务的节点数据已更改，则该工作程序会检查该任务是否已由另一工作程序执行。如果是这样，工作线程将停止当前任务的工作。</p>
</div>
<div class="paragraph">
<p>工作程序会持续监视splitlog znode。当出现新任务时，拆分日志工作程序将检索任务路径并检查每个路径，直到找到未声明的任务并尝试声明该任务。如果声明成功，它将尝试执行任务并更新任务的<code>state</code>属性根据分割结果。此时，拆分日志工作程序将扫描另一个无人认领的任务。</p>
</div>
<div class="ulist">
<div class="title">拆分日志工作程序如何处理任务</div>
<ul>
<li>
<p>它查询任务状态，并且仅在任务处于“ TASK_UNASSIGNED”状态时才采取措施。</p>
</li>
<li>
<p>如果任务在<code>TASK_UNASSIGNED</code>状态，工作人员尝试将状态设置为<code>TASK_OWNED</code>通过它自己。如果无法设置状态，则其他工作人员将尝试获取它。如果任务仍未分配，则拆分日志管理器还将要求所有工作人员稍后重新扫描。</p>
</li>
<li>
<p>如果工作人员成功获得任务的所有权，它将尝试再次获取任务状态，以确保它确实是异步获取的。同时，它启动一个拆分任务执行器来执行实际工作：</p>
<div class="ulist">
<ul>
<li>
<p>获取HBase根文件夹，在根目录下创建一个temp文件夹，然后将日志文件拆分到temp文件夹。</p>
</li>
<li>
<p>如果拆分成功，则任务执行器将任务设置为state <code>TASK_DONE</code> 。</p>
</li>
<li>
<p>如果工作程序捕获到意外的IOException，则将任务设置为state <code>TASK_ERR</code> 。</p>
</li>
<li>
<p>如果工作人员正在关闭，请将任务设置为state <code>TASK_RESIGNED</code> 。</p>
</li>
<li>
<p>如果任务是由其他工作人员执行的，则只需记录下来即可。</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</li>
<li>
<p>拆分日志管理器监视未完成的任务。</p>
<div class="paragraph">
<p>当所有任务成功完成时，拆分日志管理器将返回。如果所有任务均因某些失败而完成，则拆分日志管理器将引发异常，以便可以重试日志拆分。由于异步实现，在极少数情况下，拆分日志管理器无法跟踪某些已完成的任务。因此，它会定期检查其任务图中或ZooKeeper中是否还有未完成的任务。如果未找到，它将引发异常，以便可以立即重试日志拆分，而不必挂在这里等待不会发生的事情。</p>
</div>
</li>
</ol>
</div>
</div>
<div class="sect5">
<h6 id="distributed.log.replay"><a class="anchor" href="#distributed.log.replay"></a>分布式日志重播</h6>
<div class="paragraph">
<p>RegionServer发生故障之后，其失败的区域将分配给另一个RegionServer，在ZooKeeper中将其标记为“正在恢复”。拆分日志工作器直接将发生故障的RegionServer的WAL重放编辑到其新位置的区域。当区域处于“正在恢复”状态时，它可以接受写入但不能读取（包括追加和增量），区域拆分或合并。</p>
</div>
<div class="paragraph">
<p>分布式日志重播扩展了<a href="#distributed.log.splitting">分布式日志拆分</a>框架。它的工作原理通过直接重放WAL编辑另一个RegionServer的，而不是创建<em>recovered.edits</em>文件。与单独的分布式日志拆分相比，它具有以下优点：</p>
</div>
<div class="ulist">
<ul>
<li>
<p>它消除了写入和读取大量<em>restore.edits</em>文件的开销。在RegionServer恢复期间同时创建和写入数千个<em>restore.edits</em>文件并不罕见。许多小的随机写入会降低整体系统性能。</p>
</li>
<li>
<p>即使区域处于恢复状态，它也允许写入。恢复区域只需几秒钟即可再次接受写入。</p>
</li>
</ul>
</div>
<div class="paragraph">
<div class="title">启用分布式日志重播</div>
<p>要启用分布式日志重播，请设置<code>hbase.master.distributed.log.replay</code>至<code>true</code> 。这将是HBase 0.99（ <a href="https://issues.apache.org/jira/browse/HBASE-10888">HBASE-10888</a> ）的默认设置。</p>
</div>
<div class="paragraph">
<p>您还必须启用HFile版本3（这是从HBase 0.99开始的默认HFile格式。参见<a href="https://issues.apache.org/jira/browse/HBASE-10855">HBASE-10855</a> ）。分布式日志重播对于滚动升级是不安全的。</p>
</div>
</div>
</div>
</div>
<div class="sect3">
<h4 id="wal.disable"><a class="anchor" href="#wal.disable"></a> 67.6.5。禁用WAL</h4>
<div class="paragraph">
<p>可以禁用WAL，以提高某些特定情况下的性能。但是，禁用WAL会使您的数据处于危险之中。推荐这样做的唯一情况是在大负载期间。这是因为，如果出现问题，可以重新运行大容量负载，而不会丢失数据。</p>
</div>
<div class="paragraph">
<p>通过调用HBase客户端字段来禁用WAL <code>Mutation.writeToWAL(false)</code> 。使用<code>Mutation.setDurability(Durability.SKIP_WAL)</code>和Mutation.getDurability（）方法来设置和获取字段的值。无法仅对特定表禁用WAL。</p>
</div>
<div class="admonitionblock warning">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-warning" title="警告"></i>
</td>
<td class="content">如果对大容量负载以外的任何其他功能禁用WAL，则数据将受到威胁。
</td>
</tr>
</tbody></table>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="regions.arch"><a class="anchor" href="#regions.arch"></a> 68。地区</h2>
<div class="sectionbody">
<div class="paragraph">
<p>区域是表可用性和分布的基本元素，并且由每个列族的商店组成。对象的层次结构如下：</p>
</div>
<div class="listingblock">
<div class="content">
<pre>Table                    (HBase table)
    Region               (Regions for the table)
        Store            (Store per ColumnFamily for each Region for the table)
            MemStore     (MemStore for each Store for each Region for the table)
            StoreFile    (StoreFiles for each Store for each Region for the table)
                Block    (Blocks within a StoreFile within a Store for each Region for the table)</pre>
</div>
</div>
<div class="paragraph">
<p>有关写入HDFS时HBase文件的外观的说明，请参阅<a href="#trouble.namenode.hbase.objects">浏览HFS对象的HDFS</a> 。</p>
</div>
<div class="sect2">
<h3 id="arch.regions.size"><a class="anchor" href="#arch.regions.size"></a> 68.1。区域数量注意事项</h3>
<div class="paragraph">
<p>通常，HBase被设计为在每个服务器上以少量（20-200）个相对较大（5-20Gb）的区域运行。注意事项如下：</p>
</div>
<div class="sect3">
<h4 id="too_many_regions"><a class="anchor" href="#too_many_regions"></a> 68.1.1。我为什么要保持我的地区计数低？</h4>
<div class="paragraph">
<p>通常，出于多种原因，您希望在HBase上保持较低的区域计数。通常，每个RegionServer大约100个区域产生了最佳结果。以下是一些使区域计数保持较低的原因：</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>MSLAB（MemStore本地分配缓冲区）每个MemStore需要2MB（每个区域每个家庭2MB）。 1000个具有2个系列的区域使用3.9GB的堆，甚至还没有存储数据。注意：2MB值是可配置的。</p>
</li>
<li>
<p>如果您以几乎相同的速率填充所有区域，则全局内存使用情况会导致当您拥有太多区域时会强制进行微小刷新，进而生成压缩。您想要做的最后一件事就是重写相同的数据数十次。一个示例是平均填充1000个区域（一个家庭），让我们考虑一下5GB的全局MemStore使用量的下限（区域服务器将有很大的堆）。一旦达到5GB，它将强制刷新最大的区域，这时他们几乎应该都拥有约5MB的数据，以便刷新该数量。稍后插入5MB，它将刷新另一个区域，该区域现在将有5MB以上的数据，依此类推。当前，这是限制区域数量的主要因素。有关详细公式，请参见<a href="#ops.capacity.regions.count">每个RS的区域数-上限</a> 。</p>
</li>
<li>
<p>主人对很多地区都过敏，将需要大量时间分配它们并分批移动它们。原因是它在ZK的使用上很繁重，并且目前还不是很同步（可以真正改进-在0.96 HBase中已经进行了很多改进）。</p>
</li>
<li>
<p>在旧版本的HBase（HFile v2之前的版本，0.90和更低版本）中，少数几个RS上的大量区域会导致存储文件索引增加，从而增加堆使用率，并可能在RS上造成内存压力或OOME</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>另一个问题是区域数量对MapReduce作业的影响。每个HBase区域通常有一个映射器。因此，每个RS仅托管5个区域可能不足以为MapReduce作业获得足够数量的任务，而1000个区域将生成太多任务。</p>
</div>
<div class="paragraph">
<p>有关配置准则，请参阅<a href="#ops.capacity.regions">确定区域数和大小</a> 。</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="regions.arch.assignment"><a class="anchor" href="#regions.arch.assignment"></a> 68.2。区域-区域服务器分配</h3>
<div class="paragraph">
<p>本节介绍如何将区域分配给RegionServers。</p>
</div>
<div class="sect3">
<h4 id="regions.arch.assignment.startup"><a class="anchor" href="#regions.arch.assignment.startup"></a> 68.2.1。启动</h4>
<div class="paragraph">
<p>HBase启动时，区域分配如下（简短版本）：</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>主人调用<code>AssignmentManager</code>启动时。</p>
</li>
<li>
<p>的<code>AssignmentManager</code>查看现有的区域分配<code>hbase:meta</code> 。</p>
</li>
<li>
<p>如果区域分配仍然有效（即，如果RegionServer仍然在线），则保留该分配。</p>
</li>
<li>
<p>如果分配无效，则<code>LoadBalancerFactory</code>调用以分配区域。负载均衡器（ <code>StochasticLoadBalancer</code>默认情况下，在HBase 1.0中）将区域分配给RegionServer。</p>
</li>
<li>
<p><code>hbase:meta</code>在RegionServer打开区域时，将使用RegionServer分配（如果需要）和RegionServer起始代码（RegionServer进程的开始时间）来更新。</p>
</li>
</ol>
</div>
</div>
<div class="sect3">
<h4 id="regions.arch.assignment.failover"><a class="anchor" href="#regions.arch.assignment.failover"></a> 68.2.2。故障转移</h4>
<div class="paragraph">
<p>当RegionServer发生故障时：</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>由于RegionServer已关闭，因此这些区域立即变得不可用。</p>
</li>
<li>
<p>主服务器将检测到RegionServer发生故障。</p>
</li>
<li>
<p>区域分配将被视为无效，并将像启动顺序一样重新分配。</p>
</li>
<li>
<p>机上查询将重试，并且不会丢失。</p>
</li>
<li>
<p>在以下时间内，操作将切换到新的RegionServer：</p>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">ZooKeeper session timeout + split time + assignment/replay time</code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
<div class="sect3">
<h4 id="regions.arch.balancer"><a class="anchor" href="#regions.arch.balancer"></a> 68.2.3。区域负载平衡</h4>
<div class="paragraph">
<p>可以通过<a href="#master.processes.loadbalancer">LoadBalancer</a>定期移动区域。</p>
</div>
</div>
<div class="sect3">
<h4 id="regions.arch.states"><a class="anchor" href="#regions.arch.states"></a> 68.2.4。区域状态转换</h4>
<div class="paragraph">
<p>HBase为每个区域维护一个状态，并在<code>hbase:meta</code> 。的状态<code>hbase:meta</code>该区域本身保留在ZooKeeper中。您可以在Master Web UI中查看过渡区域的状态。以下是可能的区域状态列表。</p>
</div>
<div class="ulist">
<div class="title">可能的区域州</div>
<ul>
<li>
<p><code>OFFLINE</code> ：该地区离线且未开放</p>
</li>
<li>
<p><code>OPENING</code> ：该地区正在开放中</p>
</li>
<li>
<p><code>OPEN</code> ：区域是开放的，RegionServer已通知主服务器</p>
</li>
<li>
<p><code>FAILED_OPEN</code> ：RegionServer无法打开区域</p>
</li>
<li>
<p><code>CLOSING</code> ：该地区正在关闭中</p>
</li>
<li>
<p><code>CLOSED</code> ：RegionServer已关闭区域并通知主服务器</p>
</li>
<li>
<p><code>FAILED_CLOSE</code> ：RegionServer无法关闭区域</p>
</li>
<li>
<p><code>SPLITTING</code> ：RegionServer通知主服务器该区域正在拆分</p>
</li>
<li>
<p><code>SPLIT</code> ：RegionServer通知主服务器该区域已完成分割</p>
</li>
<li>
<p><code>SPLITTING_NEW</code> ：此区域是由正在进行的拆分创建的</p>
</li>
<li>
<p><code>MERGING</code> ：RegionServer通知主服务器该区域正在与另一个区域合并</p>
</li>
<li>
<p><code>MERGED</code> ：RegionServer通知主服务器该区域已被合并</p>
</li>
<li>
<p><code>MERGING_NEW</code> ：此区域由两个区域合并而成</p>
</li>
</ul>
</div>
<div class="imageblock">
<div class="content">
<img src="images/region_states.png" alt="区域州">
</div>
<div class="title">图2。区域状态转换</div>
</div>
<div class="ulist">
<div class="title">图例</div>
<ul>
<li>
<p>棕色：离线状态，一种特殊的状态，可以是瞬态的（在打开之前先关闭后），终端的状态（禁用表的区域）或初始的状态（新创建的表的区域）</p>
</li>
<li>
<p>Palegreen：在线状态表明区域可以满足请求</p>
</li>
<li>
<p>浅蓝色：瞬态</p>
</li>
<li>
<p>红色：故障状态需要OPS注意</p>
</li>
<li>
<p>黄金：地区的最终状态已拆分/合并</p>
</li>
<li>
<p>灰色：通过拆分/合并创建的区域的初始状态</p>
</li>
</ul>
</div>
<div class="olist arabic">
<div class="title">过渡状态说明</div>
<ol class="arabic">
<li>
<p>主人将区域从<code>OFFLINE</code>至<code>OPENING</code>状态并尝试将区域分配给RegionServer。RegionServer可能会或可能未收到开放区域请求。主服务器重试将打开的区域请求发送到RegionServer，直到RPC通过或主服务器用尽重试。RegionServer收到打开区域请求后，RegionServer开始打开区域。</p>
</li>
<li>
<p>如果主服务器用尽了重试时间，则主服务器通过将区域移至来阻止RegionServer打开区域。 <code>CLOSING</code>状态并尝试关闭它，即使RegionServer开始打开区域。</p>
</li>
<li>
<p>RegionServer打开区域后，它将继续尝试通知主服务器，直到主服务器将区域移动到<code>OPEN</code>状态并通知RegionServer。该地区现已开放。</p>
</li>
<li>
<p>如果RegionServer无法打开区域，则会通知主服务器。主人将区域移动到<code>CLOSED</code>状态并尝试在其他RegionServer上打开区域。</p>
</li>
<li>
<p>如果母版无法在特定数量的区域中的任何一个上打开该区域，则它将区域移动到<code>FAILED_OPEN</code>状态，直到操作员从HBase Shell介入或服务器死机之前，不采取任何其他措施。</p>
</li>
<li>
<p>主人将区域从<code>OPEN</code>至<code>CLOSING</code>州。保留该区域的RegionServer可能已收到或未收到关闭区域请求。主服务器重试将关闭请求发送到服务器，直到RPC通过或主服务器用尽重试。</p>
</li>
<li>
<p>如果RegionServer不在线或抛出<code>NotServingRegionException</code> ，主人将区域移至<code>OFFLINE</code>状态，并将其重新分配给其他RegionServer。</p>
</li>
<li>
<p>如果RegionServer处于联机状态，但在主服务器用尽重试后仍无法访问，则主服务器将区域移至<code>FAILED_CLOSE</code>状态，并且直到操作员从HBase Shell进行干预或服务器已死机之前，不采取任何其他措施。</p>
</li>
<li>
<p>如果RegionServer得到关闭区域请求，它将关闭区域并通知主服务器。主人将区域移动到<code>CLOSED</code>状态，并将其重新分配给其他RegionServer。</p>
</li>
<li>
<p>在分配区域之前，母版将区域移动到<code>OFFLINE</code>如果它处于自动状态<code>CLOSED</code>州。</p>
</li>
<li>
<p>当RegionServer即将分割区域时，它将通知主服务器。母版移动要分割的区域<code>OPEN</code>至<code>SPLITTING</code>状态并将两个要创建的新区域添加到RegionServer。这两个地区在<code>SPLITING_NEW</code>最初状态。</p>
</li>
<li>
<p>通知主服务器后，RegionServer开始分割区域。一旦超过了无法返回的地步，RegionServer会再次通知主服务器，以便主服务器可以更新<code>hbase:meta</code>表。但是，主服务器不会更新区域状态，直到服务器通知它已完成拆分为止。如果拆分成功，则将拆分区域从<code>SPLITTING</code>至<code>SPLIT</code>州和两个新区域从<code>SPLITTING_NEW</code>至<code>OPEN</code>州。</p>
</li>
<li>
<p>如果分割失败，则将分割区域从<code>SPLITTING</code>回到<code>OPEN</code>状态，并且将创建的两个新区域从<code>SPLITTING_NEW</code>至<code>OFFLINE</code>州。</p>
</li>
<li>
<p>当RegionServer要合并两个区域时，它将首先通知主服务器。母版将两个要合并的区域从<code>OPEN</code>至<code>MERGING</code>状态，然后将将合并区域区域内容保存到RegionServer的新区域。新地区在<code>MERGING_NEW</code>最初状态。</p>
</li>
<li>
<p>通知主服务器后，RegionServer开始合并两个区域。一旦超过了不可返回的点，RegionServer将再次通知主服务器，以便主服务器可以更新META。但是，在RegionServer通知其合并已完成之前，主服务器不会更新区域状态。如果合并成功，则将两个合并区域从<code>MERGING</code>至<code>MERGED</code>状态，新的地区从<code>MERGING_NEW</code>至<code>OPEN</code>州。</p>
</li>
<li>
<p>如果合并失败，则将两个合并区域从<code>MERGING</code>回到<code>OPEN</code>状态，并将创建用于保存合并区域内容的新区域从<code>MERGING_NEW</code>至<code>OFFLINE</code>州。</p>
</li>
<li>
<p>对于中的地区<code>FAILED_OPEN</code>要么<code>FAILED_CLOSE</code>状态时，当操作员通过HBase Shell重新分配它们时，主机尝试再次关闭它们。</p>
</li>
</ol>
</div>
</div>
</div>
<div class="sect2">
<h3 id="regions.arch.locality"><a class="anchor" href="#regions.arch.locality"></a> 68.3。区域服务器区域</h3>
<div class="paragraph">
<p>随着时间的流逝，Region-RegionServer的本地性是通过HDFS块复制来实现的。在选择写入副本的位置时，HDFS客户端默认情况下会执行以下操作：</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>第一个副本写入本地节点</p>
</li>
<li>
<p>将第二个副本写入另一个机架上的随机节点</p>
</li>
<li>
<p>第三个副本与第二个副本位于相同的机架上，但在随机选择的不同节点上</p>
</li>
<li>
<p>后续副本将写入集群中的随机节点上。请参阅此页面上的<em>副本位置：“第一步之初”</em> ： <a href="http://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-hdfs/HdfsDesign.html">HDFS体系结构</a></p>
</li>
</ol>
</div>
<div class="paragraph">
<p>因此，在冲洗或压实之后，HBase最终实现了区域的局部性。在RegionServer故障转移情况下，可能会为RegionServer分配具有非本地StoreFiles的区域（因为所有副本都不是本地的），但是当在该区域中写入新数据或压缩表并重新编写StoreFiles时，它们将成为RegionServer的“本地”。</p>
</div>
<div class="paragraph">
<p>有关更多信息，请参见本页上的<em>副本位置：第一个婴儿步骤</em> ： <a href="http://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-hdfs/HdfsDesign.html">HDFS体系结构</a>以及Lars George的<a href="http://www.larsgeorge.com/2010/05/hbase-file-locality-in-hdfs.html">HBase和HDFS本地性</a>博客。</p>
</div>
</div>
<div class="sect2">
<h3 id="arch.region.splits"><a class="anchor" href="#arch.region.splits"></a> 68.4。区域分割</h3>
<div class="paragraph">
<p>区域达到配置的阈值时会分裂。下面我们简短地讨论该主题。有关更详细的说明，请参见我们的Enis Soztutar撰写的<a href="http://hortonworks.com/blog/apache-hbase-region-splitting-and-merging/">Apache HBase区域拆分和合并</a> 。</p>
</div>
<div class="paragraph">
<p>拆分在RegionServer上独立运行；即大师不参加。RegionServer分割一个区域，使分割的区域脱机，然后将子区域添加到<code>hbase:meta</code> ，在父级托管的RegionServer上打开子级，然后将拆分报告给主级。请参阅<a href="#disable.splitting">托管拆分，</a>以了解如何手动管理拆分（以及为什么这样做的原因）。</p>
</div>
<div class="sect3">
<h4 id="_custom_split_policies"><a class="anchor" href="#_custom_split_policies"></a> 68.4.1。自定义拆分策略</h4>
<div class="paragraph">
<p>您可以使用自定义<a href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/regionserver/RegionSplitPolicy.html">RegionSplitPolicy</a> （HBase 0.94+）覆盖默认的拆分策略。通常，自定义拆分策略应扩展HBase的默认拆分策略： <a href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/regionserver/IncreasingToUpperBoundRegionSplitPolicy.html">IncreasingToUpperBoundRegionSplitPolicy</a> 。</p>
</div>
<div class="paragraph">
<p>该策略可以通过HBase配置全局设置，也可以基于每个表设置。</p>
</div>
<div class="listingblock">
<div class="title">在<em>hbase-site.xml中</em>全局配置拆分策略</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="xml"><span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>hbase.regionserver.region.split.policy<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>org.apache.hadoop.hbase.regionserver.IncreasingToUpperBoundRegionSplitPolicy<span class="tag">&lt;/value&gt;</span>
<span class="tag">&lt;/property&gt;</span></code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">使用Java API在表上配置拆分策略</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">HTableDescriptor tableDesc = <span class="keyword">new</span> HTableDescriptor(<span class="string"><span class="delimiter">&quot;</span><span class="content">test</span><span class="delimiter">&quot;</span></span>);
tableDesc.setValue(HTableDescriptor.SPLIT_POLICY, ConstantSizeRegionSplitPolicy.class.getName());
tableDesc.addFamily(<span class="keyword">new</span> HColumnDescriptor(Bytes.toBytes(<span class="string"><span class="delimiter">&quot;</span><span class="content">cf1</span><span class="delimiter">&quot;</span></span>)));
admin.createTable(tableDesc);
----</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">使用HBase Shell在表上配置拆分策略</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">hbase&gt; create <span class="string"><span class="delimiter">'</span><span class="content">test</span><span class="delimiter">'</span></span>, {METHOD =&gt; <span class="string"><span class="delimiter">'</span><span class="content">table_att</span><span class="delimiter">'</span></span>, CONFIG =&gt; {<span class="string"><span class="delimiter">'</span><span class="content">SPLIT_POLICY</span><span class="delimiter">'</span></span> =&gt; <span class="string"><span class="delimiter">'</span><span class="content">org.apache.hadoop.hbase.regionserver.ConstantSizeRegionSplitPolicy</span><span class="delimiter">'</span></span>}},
{NAME =&gt; <span class="string"><span class="delimiter">'</span><span class="content">cf1</span><span class="delimiter">'</span></span>}</code></pre>
</div>
</div>
<div class="paragraph">
<p>可以使用自定义<a href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/regionserver/RegionSplitPolicy.html">RegionSplitPolicy（HBase 0.94+）</a>覆盖默认的拆分策略。通常，自定义拆分策略应扩展HBase的默认拆分策略： <a href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/regionserver/ConstantSizeRegionSplitPolicy.html">ConstantSizeRegionSplitPolicy</a> 。</p>
</div>
<div class="paragraph">
<p>可以通过使用的HBaseConfiguration或在每个表的基础上全局设置策略：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">HTableDescriptor myHtd = ...;
myHtd.setValue(HTableDescriptor.SPLIT_POLICY, MyCustomSplitPolicy.class.getName());</code></pre>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="manual_region_splitting_decisions"><a class="anchor" href="#manual_region_splitting_decisions"></a> 68.5。手动区域分割</h3>
<div class="paragraph">
<p>可以在表创建（预分割）时或以后作为管理操作手动分割表。您可能由于以下一个或多个原因而选择拆分区域。可能还有其他合理的原因，但是需要手动拆分表也可能会导致方案设计出现问题。</p>
</div>
<div class="ulist">
<div class="title">手动拆分表的原因</div>
<ul>
<li>
<p>您的数据按时间序列或其他类似的算法排序，该算法在表末尾对新数据进行排序。这意味着保存最后一个区域的区域服务器始终处于负载状态，而其他区域服务器则处于空闲状态或大部分处于空闲状态。另请参见<a href="#timeseries">单调增加行键/时间序列数据</a> 。</p>
</li>
<li>
<p>您在表的一个区域中建立了一个意外的热点。例如，如果有名人的新闻出现，那么跟踪名人搜索的应用可能会被名人的大量搜索淹没。有关此特定方案的更多讨论，请参见<a href="#perf.one.region">perf.one.region</a> 。</p>
</li>
<li>
<p>在群集中的RegionServer数量大大增加之后，可以快速分散负载。</p>
</li>
<li>
<p>散装之前，这可能会导致跨区域的异常负载和不均匀负载。</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>有关完全手动管理拆分的危险和潜在好处的讨论，请参阅<a href="#disable.splitting">托管拆分</a> 。</p>
</div>
<div class="sect3">
<h4 id="_determining_split_points"><a class="anchor" href="#_determining_split_points"></a> 68.5.1。确定分割点</h4>
<div class="paragraph">
<p>手动拆分表的目的是在仅凭好的行键设计无法解决问题的情况下，提高在整个群集之间平衡负载的机会。请记住，划分区域的方式非常取决于数据的特征。可能是您已经知道拆分表的最佳方法。如果不是，则拆分表的方式取决于键的类型。</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">字母数字行键</dt>
<dd>
<p>如果您的行键以字母或数字开头，则可以在字母或数字边界处拆分表。例如，以下命令创建一个表，该表具有在每个元音处分开的区域，因此第一个区域具有AD，第二个区域具有EH，第三个区域具有IN，第四个区域具有OV，第五个区域具有UZ。</p>
</dd>
<dt class="hdlist1">使用自定义算法</dt>
<dd>
<p>HBase提供了RegionSplitter工具，并使用<em>SplitAlgorithm</em>为您确定分割点。作为参数，您给它提供算法，所需的区域数和列族。它包括三种拆分算法。首先是<code><a href="https://hbase.apache.org/devapidocs/org/apache/hadoop/hbase/util/RegionSplitter.HexStringSplit.html">HexStringSplit</a></code>该算法假定行键是十六进制字符串。第二个是<code><a href="https://hbase.apache.org/devapidocs/org/apache/hadoop/hbase/util/RegionSplitter.DecimalStringSplit.html">DecimalStringSplit</a></code>该算法假定行键是000000000到99999999之间的十进制字符串。第三， <code><a href="https://hbase.apache.org/devapidocs/org/apache/hadoop/hbase/util/RegionSplitter.UniformSplit.html">UniformSplit</a></code> ，假设行键是随机字节数组。您可能需要开发自己的<code><a href="https://hbase.apache.org/devapidocs/org/apache/hadoop/hbase/util/RegionSplitter.SplitAlgorithm.html">SplitAlgorithm</a></code> ，使用提供的模型作为模型。</p>
</dd>
</dl>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_online_region_merges"><a class="anchor" href="#_online_region_merges"></a> 68.6。在线区域合并</h3>
<div class="paragraph">
<p>Master和RegionServer都参与在线区域合并的事件。客户端将合并的RPC发送到主服务器，然后主服务器将区域一起移动到RegionServer，在该服务器中负载较重的区域驻留在该服务器上。最终，主服务器将合并请求发送到此RegionServer，然后运行该合并。与区域拆分过程相似，区域合并作为RegionServer上的本地事务运行。它使区域脱机，然后合并文件系统上的两个区域，从中原子删除合并区域<code>hbase:meta</code>并将合并的区域添加到<code>hbase:meta</code> ，在RegionServer上打开合并的区域，然后将合并报告给主服务器。</p>
</div>
<div class="paragraph">
<p>HBase Shell中区域合并的示例</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bourne">$ hbase&gt; merge_region 'ENCODED_REGIONNAME', 'ENCODED_REGIONNAME'
$ hbase&gt; merge_region 'ENCODED_REGIONNAME', 'ENCODED_REGIONNAME', true</code></pre>
</div>
</div>
<div class="paragraph">
<p>这是一个异步操作，调用会立即返回，而无需等待合并完成。通过<code>true</code>因为可选的第三个参数将强制合并。通常，只有相邻区域可以合并。的<code>force</code>参数将覆盖此行为，并且仅供专家使用。</p>
</div>
</div>
<div class="sect2">
<h3 id="_store"><a class="anchor" href="#_store"></a> 68.7。商店</h3>
<div class="paragraph">
<p>一个商店托管一个MemStore和0个或多个StoreFiles（HFiles）。商店对应于给定区域的表的列族。</p>
</div>
<div class="sect3">
<h4 id="store.memstore"><a class="anchor" href="#store.memstore"></a> 68.7.1。记忆库</h4>
<div class="paragraph">
<p>MemStore保留对Store的内存中修改。修改是单元格/键值。当请求刷新时，当前的MemStore将移至快照并被清除。HBase继续从新的MemStore和备份快照提供编辑，直到刷新程序报告刷新成功为止。此时，快照将被丢弃。请注意，发生刷新时，属于同一区域的MemStores将全部被刷新。</p>
</div>
</div>
<div class="sect3">
<h4 id="_memstore_flush"><a class="anchor" href="#_memstore_flush"></a> 68.7.2。MemStore冲洗</h4>
<div class="paragraph">
<p>可以在下面列出的任何条件下触发MemStore刷新。最小刷新单位是每个区域，而不是单个MemStore级别。</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>当MemStore达到指定的大小时<code>hbase.hregion.memstore.flush.size</code> ，则属于其区域的所有MemStores将被刷新到磁盘。</p>
</li>
<li>
<p>当MemStore的整体使用量达到由<code>hbase.regionserver.global.memstore.upperLimit</code> ，来自各个区域的MemStore将被刷新到磁盘上，以减少RegionServer中的整体MemStore使用情况。刷新顺序基于区域的MemStore使用量的降序。区域将刷新其MemStore，直到整体MemStore使用量降至或略低于<code>hbase.regionserver.global.memstore.lowerLimit</code> 。</p>
</li>
<li>
<p>当每个区域服务器的WAL数量达到在中指定的值时<code>hbase.regionserver.max.logs</code> ，来自不同区域的MemStores将被刷新到磁盘以减少WAL计数。刷新顺序基于时间。具有最旧MemStores的区域将首先刷新，直到WAL计数降至以下<code>hbase.regionserver.max.logs</code> 。</p>
</li>
</ol>
</div>
</div>
<div class="sect3">
<h4 id="hregion.scans"><a class="anchor" href="#hregion.scans"></a> 68.7.3。扫瞄</h4>
<div class="ulist">
<ul>
<li>
<p>当客户端对表进行扫描时，HBase会生成<code>RegionScanner</code>对象（每个区域一个）来满足扫描请求。</p>
</li>
<li>
<p>的<code>RegionScanner</code>对象包含一个列表<code>StoreScanner</code>对象，每个列族一个。</p>
</li>
<li>
<p>每<code>StoreScanner</code>对象还包含一个列表<code>StoreFileScanner</code>对象，分别对应于相应列族的每个StoreFile和HFile，以及<code>KeyValueScanner</code> MemStore的对象。</p>
</li>
<li>
<p>这两个列表合并为一个，然后按升序排序，列表末尾有MemStore的扫描对象。</p>
</li>
<li>
<p>当一个<code>StoreFileScanner</code>对象被构造，它与一个<code>MultiVersionConcurrencyControl</code>读取点，即当前<code>memstoreTS</code> ，过滤掉超出读取点的所有新更新。</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="hfile"><a class="anchor" href="#hfile"></a> 68.7.4。StoreFile（HFile）</h4>
<div class="paragraph">
<p>StoreFiles是数据存放的地方。</p>
</div>
<div class="sect4">
<h5 id="_hfile_format"><a class="anchor" href="#_hfile_format"></a> HFile格式</h5>
<div class="paragraph">
<p><em>HFile</em>文件格式基于<a href="http://research.google.com/archive/bigtable.html">BigTable [2006</a> ]论文中描述的SSTable文件和Hadoop的<a href="http://hadoop.apache.org/common/docs/current/api/org/apache/hadoop/io/file/tfile/TFile.html">TFile</a> （单元测试套件和压缩工具直接取自TFile）。Schubert Zhang的<a href="http://cloudepr.blogspot.com/2009/09/hfile-block-indexed-file-format-to.html">HFile</a>博客文章<a href="http://cloudepr.blogspot.com/2009/09/hfile-block-indexed-file-format-to.html">：存储有序键-值对的块索引文件格式，对</a> HBase的HFile进行了全面介绍。Matteo Bertozzi还提出了一个有用的描述，即<a href="http://th30z.blogspot.com/2011/02/hbase-io-hfile.html?spref=tw">HBase I / O：HFile</a> 。</p>
</div>
<div class="paragraph">
<p>有关更多信息，请参见<a href="http://hbase.apache.org/xref/org/apache/hadoop/hbase/io/hfile/HFile.html">HFile源代码</a> 。另请参阅<a href="#hfilev2">带有内联块的HBase文件格式（版本2）</a>以获取有关0.92中包含的HFile v2格式的信息。</p>
</div>
</div>
<div class="sect4">
<h5 id="_hfile_tool"><a class="anchor" href="#_hfile_tool"></a> HFile工具</h5>
<div class="paragraph">
<p>要查看HFile内容的文本版本，您可以使用<code>org.apache.hadoop.hbase.io.hfile.HFile</code>工具。输入以下内容以查看用法：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">$ ${HBASE_HOME}/bin/hbase org.apache.hadoop.hbase.io.hfile.HFile</code></pre>
</div>
</div>
<div class="paragraph">
<p>例如，要查看文件<em>hdfs：//10.81.47.41：8020 / hbase / TEST / 1418428042 / DSMP / 4759508618286845475的内容</em> ，请键入以下内容：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash"> $ ${HBASE_HOME}/bin/hbase org.apache.hadoop.hbase.io.hfile.HFile -v -f hdfs://10.81.47.41:8020/hbase/TEST/1418428042/DSMP/4759508618286845475</code></pre>
</div>
</div>
<div class="paragraph">
<p>如果不选择-v，则仅在HFile上看到摘要。请参阅用法以了解与<code>HFile</code>工具。</p>
</div>
</div>
<div class="sect4">
<h5 id="store.file.dir"><a class="anchor" href="#store.file.dir"></a> HDFS上的StoreFile目录结构</h5>
<div class="paragraph">
<p>有关与目录结构有关的HDFS上StoreFiles外观的详细信息，请参阅<a href="#trouble.namenode.hbase.objects">浏览</a> HFS <a href="#trouble.namenode.hbase.objects">对象的HDFS</a> 。</p>
</div>
</div>
</div>
<div class="sect3">
<h4 id="hfile.blocks"><a class="anchor" href="#hfile.blocks"></a> 68.7.5。积木</h4>
<div class="paragraph">
<p>StoreFiles由块组成。块大小基于每个ColumnFamily配置。</p>
</div>
<div class="paragraph">
<p>压缩发生在StoreFiles中的块级别。有关压缩的更多信息，请参见<a href="#compression">HBase中的压缩和数据块编码</a> 。</p>
</div>
<div class="paragraph">
<p>有关块的更多信息，请参见<a href="http://hbase.apache.org/xref/org/apache/hadoop/hbase/io/hfile/HFileBlock.html">HFileBlock源代码</a> 。</p>
</div>
</div>
<div class="sect3">
<h4 id="_keyvalue"><a class="anchor" href="#_keyvalue"></a> 68.7.6。核心价值</h4>
<div class="paragraph">
<p>KeyValue类是HBase中数据存储的核心。KeyValue包装一个字节数组，并将偏移量和长度放入传递的数组中，该数组指定从何处开始将内容解释为KeyValue。</p>
</div>
<div class="paragraph">
<p>字节数组中的KeyValue格式为：</p>
</div>
<div class="ulist">
<ul>
<li>
<p>密钥长度</p>
</li>
<li>
<p>价值长度</p>
</li>
<li>
<p>键</p>
</li>
<li>
<p>值</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>密钥进一步分解为：</p>
</div>
<div class="ulist">
<ul>
<li>
<p>行长</p>
</li>
<li>
<p>行（即行键）</p>
</li>
<li>
<p>列族长度</p>
</li>
<li>
<p>专栏家庭</p>
</li>
<li>
<p>列限定符</p>
</li>
<li>
<p>时间戳记</p>
</li>
<li>
<p>键类型（例如，Put，Delete，DeleteColumn，DeleteFamily）</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>KeyValue实例<em>不</em>跨块拆分。例如，如果有一个8 MB的键值，则即使块大小为64kb，该键值也将作为连贯的块读入。有关更多信息，请参见<a href="http://hbase.apache.org/xref/org/apache/hadoop/hbase/KeyValue.html">KeyValue源代码</a> 。</p>
</div>
<div class="sect4">
<h5 id="keyvalue.example"><a class="anchor" href="#keyvalue.example"></a>例</h5>
<div class="paragraph">
<p>为了强调以上几点，请检查同一行的两个不同列的两次看跌期权的处理情况：</p>
</div>
<div class="ulist">
<ul>
<li>
<p>放置＃1：<code>rowkey=row1, cf:attr1=value1</code></p>
</li>
<li>
<p>放置＃2：<code>rowkey=row1, cf:attr2=value2</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>即使这些用于同一行，也会为每列创建一个KeyValue：</p>
</div>
<div class="paragraph">
<p>推杆1的关键部分：</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>rowlength -----------→ 4</code></p>
</li>
<li>
<p><code>row -----------------→ row1</code></p>
</li>
<li>
<p><code>columnfamilylength --→ 2</code></p>
</li>
<li>
<p><code>columnfamily --------→ cf</code></p>
</li>
<li>
<p><code>columnqualifier -----→ attr1</code></p>
</li>
<li>
<p><code>timestamp -----------→ server time of Put</code></p>
</li>
<li>
<p><code>keytype -------------→ Put</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>推杆2的关键部分：</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>rowlength -----------→ 4</code></p>
</li>
<li>
<p><code>row -----------------→ row1</code></p>
</li>
<li>
<p><code>columnfamilylength --→ 2</code></p>
</li>
<li>
<p><code>columnfamily --------→ cf</code></p>
</li>
<li>
<p><code>columnqualifier -----→ attr2</code></p>
</li>
<li>
<p><code>timestamp -----------→ server time of Put</code></p>
</li>
<li>
<p><code>keytype -------------→ Put</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>了解行键，ColumnFamily和列（也称为columnqualifier）嵌入在KeyValue实例中非常重要。这些标识符越长，则KeyValue越大。</p>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_compaction"><a class="anchor" href="#_compaction"></a> 68.7.7。压实</h4>
<div class="ulist">
<div class="title">术语不明确</div>
<ul>
<li>
<p><em>StoreFile</em>是<em>HFile</em>的外观。在压缩方面，StoreFile的使用似乎在过去很盛行。</p>
</li>
<li>
<p><em>商店</em>与ColumnFamily是同一件事。StoreFiles与商店或ColumnFamily相关。</p>
</li>
<li>
<p>如果要了解有关StoreFiles和HFiles以及Stores和ColumnFamilies的更多信息，请参阅<a href="https://issues.apache.org/jira/browse/HBASE-11316">HBASE-11316</a> 。</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>当MemStore达到指定大小时（ <code>hbase.hregion.memstore.flush.size</code> ），将其内容刷新到StoreFile。存储中的StoreFiles数量随时间增加。<em>压缩</em>是一种通过合并存储来减少存储中StoreFile数量的操作，以提高读取操作的性能。压缩可能会占用大量资源，并且取决于许多因素，压缩可能会帮助或阻碍性能。</p>
</div>
<div class="paragraph">
<p>压实分为两类：次要和主要。次要和主要压实在以下方面有所不同。</p>
</div>
<div class="paragraph">
<p><em>小型压缩</em>通常会选择少量的较小的相邻StoreFile，然后将它们重写为单个StoreFile。由于潜在的副作用，较小的压缩不会丢弃（过滤掉）删除或过期的版本。有关如何处理与压缩有关的删除和版本的信息，请参见<a href="#compaction.and.deletes">[compaction.and.deletes]</a>和<a href="#compaction.and.versions">[compaction.and.versions]</a> 。较小压缩的最终结果是给定商店的StoreFiles更少，更大。</p>
</div>
<div class="paragraph">
<p><em>重大压缩</em>的最终结果是每个商店一个StoreFile。大型压缩还处理删除标记和最大版本。有关如何处理与压缩有关的删除和版本的信息，请参见<a href="#compaction.and.deletes">[compaction.and.deletes]</a>和<a href="#compaction.and.versions">[compaction.and.versions]</a> 。</p>
</div>
<div class="paragraph">
<div class="title">压缩和删除</div>
<p>在HBase中发生显式删除时，实际上不会删除数据。相反，将写入一个<em>墓碑</em>标记。逻辑删除标记可防止查询返回数据。在大型压缩期间，实际上会删除数据，并从StoreFile中删除逻辑删除标记。如果由于TTL过期而导致删除，则不会创建逻辑删除。而是，过期的数据将被过滤掉，并且不会写回到压缩的StoreFile中。</p>
</div>
<div class="paragraph">
<div class="title">压缩和版本</div>
<p>创建列族时，可以通过指定以下内容来指定要保留的最大版本数： <code>HColumnDescriptor.setMaxVersions(int versions)</code> 。默认值为<code>3</code> 。如果存在的版本超过指定的最大值，则多余的版本将被滤除，并且不会写回到压缩的StoreFile中。</p>
</div>
<div class="admonitionblock note">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-note" title="注意"></i>
</td>
<td class="content">
<div class="title">重大压缩可能会影响查询结果</div>
<div class="paragraph">
<p>在某些情况下，如果明确删除较新的版本，则可能会无意中恢复较旧的版本。有关更深入的说明，请参见<a href="#major.compactions.change.query.results">主要压缩更改查询结果</a> 。这种情况只有在压实完成之前才有可能。</p>
</div>
</td>
</tr>
</tbody></table>
</div>
<div class="paragraph">
<p>从理论上讲，大型压实可以提高性能。但是，在高负载的系统上，大型压缩可能需要不适当数量的资源，并对性能产生不利影响。在默认配置中，大型压缩将自动计划为每7天运行一次。有时这不适用于生产中的系统。您可以手动管理主要压缩。请参阅<a href="#managed.compactions">托管压缩</a> 。</p>
</div>
<div class="paragraph">
<p>压缩不执行区域合并。有关区域合并的更多信息，请参见<a href="#ops.regionmgt.merge">合并</a> 。</p>
</div>
<div class="paragraph">
<div class="title">压实开关</div>
<p>我们可以在区域服务器上打开和关闭压缩。关闭压缩还会中断任何当前正在进行的压缩。可以使用hbase shell中的“ compaction_switch”命令动态完成此操作。如果从命令行完成，则此设置将在服务器重新启动时丢失。要保留跨区域服务器的更改，请修改hbase-site.xml中的配置hbase.regionserver .compaction.enabled并重新启动HBase。</p>
</div>
<div class="sect4">
<h5 id="compaction.file.selection"><a class="anchor" href="#compaction.file.selection"></a>压缩策略-HBase 0.96.x和更高版本</h5>
<div class="paragraph">
<p>压缩大型StoreFiles或一次压缩太多StoreFiles可能会导致更多的IO负载，而群集无法处理而又不会造成性能问题。HBase选择要包含在压缩中的StoreFiles（以及压缩是次要压缩还是次要压缩）的方法称为<em>压缩策略</em> 。</p>
</div>
<div class="paragraph">
<p>在HBase 0.96.x之前，只有一种压缩策略。该原始压缩策略仍可用于<code>RatioBasedCompactionPolicy</code> 。新的压缩默认策略称为<code>ExploringCompactionPolicy</code> ，随后被反向移植到HBase 0.94和HBase 0.95，并且是HBase 0.96和更高版本中的默认设置。它在<a href="https://issues.apache.org/jira/browse/HBASE-7842">HBASE-7842中实现</a> 。简而言之， <code>ExploringCompactionPolicy</code>尝试选择最佳的StoreFiles集合以最少的工作量进行压缩，而<code>RatioBasedCompactionPolicy</code>选择符合条件的第一组。</p>
</div>
<div class="paragraph">
<p>无论使用哪种压缩策略，文件选择都由几个可配置的参数控制，并且以多步方法进行。这些参数将在上下文中进行说明，然后在一个表中给出，该表显示了它们的描述，默认值以及更改它们的含义。</p>
</div>
<div class="sect5">
<h6 id="compaction.being.stuck"><a class="anchor" href="#compaction.being.stuck"></a>被卡住</h6>
<div class="paragraph">
<p>当MemStore太大时，需要将其内容刷新到StoreFile。但是，商店只能具有<code>hbase.hstore.blockingStoreFiles</code>文件，因此MemStore需要等待一次或多次压缩减少StoreFile的数量。但是，如果MemStore大于<code>hbase.hregion.memstore.flush.size</code> ，则无法将其内容刷新到StoreFile。如果MemStore太大并且StoreFiles的数量也太多，则该算法被称为“卡住”。压缩算法会检查这种“卡住”情况，并提供缓解机制。</p>
</div>
</div>
<div class="sect5">
<h6 id="exploringcompaction.policy"><a class="anchor" href="#exploringcompaction.policy"></a> ExploringCompactPolicy算法</h6>
<div class="paragraph">
<p>ExploringCompactionPolicy算法在选择压缩最有利的位置之前，先考虑相邻StoreFiles的每个可能的位置。</p>
</div>
<div class="paragraph">
<p>ExploringCompactionPolicy效果特别好的一种情况是，当您批量加载数据并且批量加载创建的StoreFiles比StoreFiles更大时，StoreFiles保存的数据比批量加载的数据还早。每次需要压缩时，这都会“欺骗” HBase选择执行大型压缩，并导致大量额外开销。借助ExploringCompactionPolicy，大型压缩的发生频率要低得多，因为小型压缩更为有效。</p>
</div>
<div class="paragraph">
<p>通常，ExploringCompactionPolicy是大多数情况的正确选择，因此是默认的压缩策略。您还可以将ExploringCompactionPolicy与<a href="#ops.stripe">实验：条带压缩</a>一起使用。</p>
</div>
<div class="paragraph">
<p>可以在<em><a href="http://hbase.apache.org/xref/org/apache/hadoop/hbase/regionserver/compactions/ExploringCompactionPolicy.html">hbase-server / src / main / java / org / apache / hadoop / hbase / regionserver / compactions / ExploringCompactionPolicy.java中</a></em>检查此策略的逻辑。以下是ExploringCompactionPolicy的逻辑的逐步介绍。</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>列出商店中所有现有的StoreFiles。该算法的其余部分将过滤此列表，以提供将被选择进行压缩的HFiles子集。</p>
</li>
<li>
<p>如果这是用户请求的压缩，请尝试执行请求的压缩类型，而不管通常选择哪种压缩类型。注意，即使用户请求进行大压缩，也可能无法进行大压缩。这可能是因为并非列族中的所有StoreFile都可以压缩，或者是因为列族中的存储太多。</p>
</li>
<li>
<p>某些StoreFiles会自动排除在考虑范围之外。这些包括：</p>
<div class="ulist">
<ul>
<li>
<p>大于的StoreFiles<code>hbase.hstore.compaction.max.size</code></p>
</li>
<li>
<p>由批量加载操作创建的StoreFiles，该操作明确排除了压缩。您可以决定从压缩中排除批量加载产生的StoreFiles。为此，请指定<code>hbase.mapreduce.hfileoutputformat.compaction.exclude</code>大容量加载操作期间的参数。</p>
</li>
</ul>
</div>
</li>
<li>
<p>遍历第1步中的列表，并列出所有可能的StoreFiles集以压缩在一起。潜在集是<code>hbase.hstore.compaction.min</code>列表中的连续StoreFiles。对于每个集合，执行一些完整性检查，找出这是否是可以完成的最佳压缩：</p>
<div class="ulist">
<ul>
<li>
<p>如果此集中的StoreFiles数量（不是StoreFiles的大小）小于<code>hbase.hstore.compaction.min</code>或以上<code>hbase.hstore.compaction.max</code> ，请忽略它。</p>
</li>
<li>
<p>将这组StoreFiles的大小与到目前为止在列表中找到的最小压缩的大小进行比较。如果这组StoreFiles的大小代表可以完成的最小压缩，则在算法“卡住”的情况下存储它以用作备用，否则将不选择任何StoreFiles。见<a href="#compaction.being.stuck">被卡住</a> 。</p>
</li>
<li>
<p>对这组StoreFiles中的每个StoreFile进行基于大小的完整性检查。</p>
<div class="ulist">
<ul>
<li>
<p>如果此StoreFile的大小大于<code>hbase.hstore.compaction.max.size</code> ，请忽略它。</p>
</li>
<li>
<p>如果大小大于或等于<code>hbase.hstore.compaction.min.size</code> ，根据文件比例检查它的完整性，以查看它是否太大而无法考虑。</p>
<div class="paragraph">
<p>在以下情况下，完整性检查成功：</p>
</div>
</li>
<li>
<p>此集合中只有一个StoreFile，或者</p>
</li>
<li>
<p>对于每个StoreFile，其大小乘以<code>hbase.hstore.compaction.ratio</code> （要么<code>hbase.hstore.compaction.ratio.offpeak</code> （如果配置了非高峰时间，并且是在非高峰时间）小于集合中其他HFile大小的总和。</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</li>
<li>
<p>如果仍在考虑这组StoreFiles，请将其与先前选择的最佳压缩方式进行比较。如果更好，请用此替代以前选择的最佳压实。</p>
</li>
<li>
<p>处理完所有可能的压实列表后，执行发现的最佳压实。如果没有选择要压缩的StoreFiles，但是有多个StoreFiles，则假定算法被卡住（请参阅Betting <a href="#compaction.being.stuck">Stuck</a> ），如果是，则执行在步骤3中发现的最小压缩。</p>
</li>
</ol>
</div>
</div>
<div class="sect5">
<h6 id="compaction.ratiobasedcompactionpolicy.algorithm"><a class="anchor" href="#compaction.ratiobasedcompactionpolicy.algorithm"></a>基于比率的压缩策略算法</h6>
<div class="paragraph">
<p>RatioBasedCompactionPolicy是HBase 0.96之前的唯一压缩策略，尽管ExploringCompactionPolicy现在已反向移植到HBase 0.94和0.95。要使用RatioBasedCompactionPolicy而不是ExploringCompactionPolicy，请设置<code>hbase.hstore.defaultengine.compactionpolicy.class</code>至<code>RatioBasedCompactionPolicy</code>在<em>hbase-site.xml</em>文件中。要切换回ExploringCompactionPolicy，请从<em>hbase-site.xml中</em>删除设置。</p>
</div>
<div class="paragraph">
<p>下一节将向您介绍用于在RatioBasedCompactionPolicy中选择要压缩的StoreFiles的算法。</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>第一阶段是创建所有候选压缩列表。将创建一个列表，列出所有尚未在压缩队列中的StoreFiles，以及所有比当前正在压缩的最新文件新的StoreFiles。此StoreFiles列表按序列ID排序。序列ID在将Put附加到预写日志（WAL）时生成，并存储在HFile的元数据中。</p>
</li>
<li>
<p>检查算法是否被卡住（请参阅<a href="#compaction.being.stuck">被卡住</a> ，如果是，则强行进行大压缩。这是一个关键领域，在<a href="#exploringcompaction.policy">其中ExploringCompactionPolicy算法</a>通常比RatioBasedCompactionPolicy更好。</p>
</li>
<li>
<p>如果压缩是用户请求的，请尝试执行请求的压缩类型。请注意，如果并非所有HFile都不能进行压缩，或者存在太多StoreFile（超过<code>hbase.hstore.compaction.max</code> ）。</p>
</li>
<li>
<p>某些StoreFiles会自动排除在考虑范围之外。这些包括：</p>
<div class="ulist">
<ul>
<li>
<p>大于的StoreFiles<code>hbase.hstore.compaction.max.size</code></p>
</li>
<li>
<p>由批量加载操作创建的StoreFiles，该操作明确排除了压缩。您可以决定从压缩中排除批量加载产生的StoreFiles。为此，请指定<code>hbase.mapreduce.hfileoutputformat.compaction.exclude</code>大容量加载操作期间的参数。</p>
</li>
</ul>
</div>
</li>
<li>
<p>大型压缩中允许的最大StoreFiles数由<code>hbase.hstore.compaction.max</code>参数。如果列表包含的存储文件数量超过了此数目，则将执行次要压缩，即使原本会进行次要压缩也是如此。但是，即使有超过<code>hbase.hstore.compaction.max</code>将StoreFiles压缩。</p>
</li>
<li>
<p>如果列表包含少于<code>hbase.hstore.compaction.min</code> StoreFiles进行压缩，轻微压缩将中止。请注意，可以在单个HFile上执行主要压缩。它的功能是删除删除和过期的版本，并重置StoreFile上的位置。</p>
</li>
<li>
<p>的价值<code>hbase.hstore.compaction.ratio</code>参数乘以小于给定文件的StoreFiles之和，以确定在次压缩期间是否选择了StoreFile进行压缩。例如，如果hbase.hstore.compaction.ratio为1.2，则FileX为5MB，FileY为2MB，FileZ为3MB：</p>
<div class="listingblock">
<div class="content">
<pre>5 &lt;= 1.2 x (2 + 3)            or            5 &lt;= 6</pre>
</div>
</div>
<div class="paragraph">
<p>在这种情况下，FileX可以进行较小的压缩。如果FileX为7MB，则不适合进行小型压缩。此比率有利于较小的StoreFile。您可以使用参数为非高峰时段配置其他比率<code>hbase.hstore.compaction.ratio.offpeak</code> ，如果您还配置<code>hbase.offpeak.start.hour</code>和<code>hbase.offpeak.end.hour</code> 。</p>
</div>
</li>
<li>
<p>如果上一次大型压缩的时间太久了，并且要压缩的StoreFile不止一个，那么将运行一次大型压缩，即使原本可能是次要的压缩也是如此。默认情况下，两次大夯之间的最大时间为7天，加上或减去4.8小时，并在这些参数内随机确定。在HBase 0.96之前，主要压实时间为24小时。看到<code>hbase.hregion.majorcompaction</code>在下表中调整或禁用基于时间的主要压缩。</p>
</li>
</ol>
</div>
</div>
<div class="sect5">
<h6 id="compaction.parameters"><a class="anchor" href="#compaction.parameters"></a>压缩算法使用的参数</h6>
<div class="paragraph">
<p>该表包含用于压缩的主要配置参数。此列表并不详尽。要从默认值调整这些参数，请编辑<em>hbase-default.xml</em>文件。有关所有可用配置参数的完整列表，请参见<a href="#config.files">config.files</a></p>
</div>
<table class="tableblock frame-all grid-all spread">
<colgroup>
<col style="width:33%">
<col style="width:33%">
<col style="width:33%">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">参数</th>
<th class="tableblock halign-left valign-top">描述</th>
<th class="tableblock halign-left valign-top">默认</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>hbase.hstore.compaction.min</code></p></td>
<td class="tableblock halign-left valign-top"><div><div id="toc" class="toc">
<div id="toctitle">内容</div>

</div>
<div class="paragraph">
<p>运行压缩之前必须符合压缩条件的最小StoreFiles数。调整的目标<code>hbase.hstore.compaction.min</code>是为了避免最终产生太多无法压缩的微小StoreFiles。每次在存储中有两个StoreFiles时，将此值设置为2都会导致较小的压缩，这可能不合适。如果将此值设置得太高，则所有其他值都需要相应地进行调整。在大多数情况下，默认值为适当。在以前的HBase版本中，参数hbase.hstore.compaction.min被调用<code>hbase.hstore.compactionThreshold</code> 。</p>
</div></div></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">3</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>hbase.hstore.compaction.max</code></p></td>
<td class="tableblock halign-left valign-top"><div><div id="toc" class="toc">
<div id="toctitle">内容</div>

</div>
<div class="paragraph">
<p>无论合格的StoreFiles数量如何，一次较小的压缩都会选择的StoreFiles的最大数量。实际上，hbase.hstore.compaction.max的值控制完成一次压缩的时间长度。将其设置为更大意味着压缩中将包含更多StoreFiles。在大多数情况下，默认值为适当。</p>
</div></div></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">10</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>hbase.hstore.compaction.min.size</code></p></td>
<td class="tableblock halign-left valign-top"><div><div id="toc" class="toc">
<div id="toctitle">内容</div>

</div>
<div class="paragraph">
<p>小于此大小的StoreFile将始终有资格进行较小的压缩。大于或等于此大小的StoreFiles由<code>hbase.hstore.compaction.ratio</code>确定他们是否符合条件。因为此限制表示小于此值的所有StoreFiles的“自动包含”限制，所以在需要大量写入1-2 MB范围的文件的写繁重环境中，可能需要减小此值，因为每个StoreFile都将作为目标。进行压缩，生成的StoreFiles可能仍小于最小大小，需要进一步压缩。如果降低此参数，比率检查将更快地触发。这解决了早期版本的HBase中遇到的一些问题，但是在大多数情况下不再需要更改此参数。</p>
</div></div></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">128兆字节</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>hbase.hstore.compaction.max.size</code></p></td>
<td class="tableblock halign-left valign-top"><div><div id="toc" class="toc">
<div id="toctitle">内容</div>

</div>
<div class="paragraph">
<p>大于此大小的StoreFile将从压缩中排除。养育的效果<code>hbase.hstore.compaction.max.size</code>较少，较大的StoreFiles不会经常压缩。如果您认为压缩过于频繁而没有太多好处，则可以尝试提高此值。</p>
</div></div></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>Long.MAX_VALUE</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>hbase.hstore.compaction.ratio</code></p></td>
<td class="tableblock halign-left valign-top"><div><div id="toc" class="toc">
<div id="toctitle">内容</div>

</div>
<div class="paragraph">
<p>对于较小的压缩，此比率用于确定给定的StoreFile是否大于<code>hbase.hstore.compaction.min.size</code>有资格进行压实。它的作用是限制大型StoreFile的压缩。的价值<code>hbase.hstore.compaction.ratio</code>用浮点十进制表示。</p>
</div>
<div class="ulist">
<ul>
<li>
<p>很大的比例（例如10）将产生一个巨大的StoreFile。相反，值.25将产生类似于BigTable压缩算法的行为，从而产生四个StoreFiles。</p>
</li>
<li>
<p>建议在1.0到1.4之间使用一个中等值。调整此值时，您要平衡写入成本和读取成本。将值提高（到1.4之类）会增加写入成本，因为您将压缩更大的StoreFiles。但是，在读取期间，HBase将需要搜索较少的StoreFiles来完成读取。如果您不能利用<a href="#bloom">[bloom]，</a>请考虑使用这种方法。</p>
</li>
<li>
<p>或者，您可以将此值降低到1.0之类，以减少写入的背景成本，并用于限制读取期间接触的StoreFiles的数量。在大多数情况下，默认值为适当。</p>
</li>
</ul>
</div></div></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1.2F</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>hbase.hstore.compaction.ratio.offpeak</code></p></td>
<td class="tableblock halign-left valign-top"><div><div id="toc" class="toc">
<div id="toctitle">内容</div>

</div>
<div class="paragraph">
<p>如果还配置了非高峰时间，则在非高峰压实期间使用的压实率（请参见下文）。表示为浮点小数。这样可以使攻击力更强（如果设置得比<code>hbase.hstore.compaction.ratio</code> ）在设定的时间段内压实。如果禁用了非高峰则忽略（默认）。这与hbase.hstore.compaction.ratio相同。</p>
</div></div></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>5.0F</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>hbase.offpeak.start.hour</code></p></td>
<td class="tableblock halign-left valign-top"><div><div id="toc" class="toc">
<div id="toctitle">内容</div>

</div>
<div class="paragraph">
<p>非高峰时间的开始，表示为0到23之间的一个整数（包括0和23）。设置为-1以禁用非峰值。</p>
</div></div></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>-1</code> （已禁用）</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>hbase.offpeak.end.hour</code></p></td>
<td class="tableblock halign-left valign-top"><div><div id="toc" class="toc">
<div id="toctitle">内容</div>

</div>
<div class="paragraph">
<p>非高峰时间的结束时间，以0到23之间的整数表示（包括0和23）。设置为-1以禁用非峰值。</p>
</div></div></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>-1</code> （已禁用）</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>hbase.regionserver.thread.compaction.throttle</code></p></td>
<td class="tableblock halign-left valign-top"><div><div id="toc" class="toc">
<div id="toctitle">内容</div>

</div>
<div class="paragraph">
<p>有两种不同的线程池用于压缩，一种用于大压缩，另一种用于小压缩。这有助于保持精简表的压缩（例如<code>hbase:meta</code> ）快速。如果压缩大于此阈值，它将进入大型压缩池。在大多数情况下，默认值为适当。</p>
</div></div></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>2 x hbase.hstore.compaction.max x hbase.hregion.memstore.flush.size</code> （默认为<code>128</code> ）</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>hbase.hregion.majorcompaction</code></p></td>
<td class="tableblock halign-left valign-top"><div><div id="toc" class="toc">
<div id="toctitle">内容</div>

</div>
<div class="paragraph">
<p>两次大压实之间的时间，以毫秒为单位。设置为0将禁用基于时间的自动专业压缩。用户请求的基于大小的大型压缩仍将运行。该值乘以<code>hbase.hregion.majorcompaction.jitter</code>使压实在给定的时间范围内在某个随机时间开始。</p>
</div></div></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">7天 （ <code>604800000</code>毫秒）</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>hbase.hregion.majorcompaction.jitter</code></p></td>
<td class="tableblock halign-left valign-top"><div><div id="toc" class="toc">
<div id="toctitle">内容</div>

</div>
<div class="paragraph">
<p>应用于hbase.hregion.majorcompaction的乘数，使压缩发生在给定时间的两侧<code>hbase.hregion.majorcompaction</code> 。数量越小，压实就越紧密<code>hbase.hregion.majorcompaction</code>间隔。表示为浮点小数。</p>
</div></div></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>.50F</code></p></td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="sect4">
<h5 id="compaction.file.selection.old"><a class="anchor" href="#compaction.file.selection.old"></a>压缩文件选择</h5>
<div class="admonitionblock note">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-note" title="注意"></i>
</td>
<td class="content">
<div class="title">旧版资讯</div>
<div class="paragraph">
<p>由于历史原因保留了本节的内容，并涉及在HBase 0.96.x之前进行压缩的方式。如果启用<a href="#compaction.ratiobasedcompactionpolicy.algorithm">RatioBasedCompactionPolicy Algorithm，</a>则仍然可以使用此行为。有关压缩在HBase 0.96.x及更高版本中的工作方式的信息，请参见<a href="#compaction">[compaction]</a> 。</p>
</div>
</td>
</tr>
</tbody></table>
</div>
<div class="paragraph">
<p>要了解选择StoreFile的核心算法， <a href="http://hbase.apache.org/xref/org/apache/hadoop/hbase/regionserver/Store.html#836">Store源代码</a>中有一些ASCII技巧可以用作参考。</p>
</div>
<div class="paragraph">
<p>它已被复制到下面：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="comment">/* normal skew:
 *
 *         older ----&gt; newer
 *     _
 *    | |   _
 *    | |  | |   _
 *  --|-|- |-|- |-|---_-------_-------  minCompactSize
 *    | |  | |  | |  | |  _  | |
 *    | |  | |  | |  | | | | | |
 *    | |  | |  | |  | | | | | |
 */</span></code></pre>
</div>
</div>
<div class="ulist">
<div class="title">重要旋钮：</div>
<ul>
<li>
<p><code>hbase.hstore.compaction.ratio</code>压缩文件选择算法中使用的比率（默认为1.2f）。</p>
</li>
<li>
<p><code>hbase.hstore.compaction.min</code> （在HBase v 0.90中，这称为<code>hbase.hstore.compactionThreshold</code> ）（文件）为进行压缩而选择的每个商店的最小StoreFiles数量（默认为2）。</p>
</li>
<li>
<p><code>hbase.hstore.compaction.max</code> （文件）每个次要压缩要压缩的StoreFiles的最大数目（默认为10）。</p>
</li>
<li>
<p><code>hbase.hstore.compaction.min.size</code> （字节）小于此设置的任何StoreFile都会自动成为压缩对象。默认为<code>hbase.hregion.memstore.flush.size</code> （128 mb）。</p>
</li>
<li>
<p><code>hbase.hstore.compaction.max.size</code> （.92）（字节）大于此设置且自动排除的任何StoreFile（默认为Long。MAX_VALUE）。</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>次要压缩StoreFile选择逻辑基于大小，并在压缩文件时选择文件进行压缩<code>file ⇐ sum(smaller_files) * hbase.hstore.compaction.ratio</code> 。</p>
</div>
<div class="sect5">
<h6 id="compaction.file.selection.example1"><a class="anchor" href="#compaction.file.selection.example1"></a>次要压缩文件选择-示例1（基本示例）</h6>
<div class="paragraph">
<p>此示例反映了单元测试中的示例<code>TestCompactSelection</code> 。</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>hbase.hstore.compaction.ratio</code> = 1.0f</p>
</li>
<li>
<p><code>hbase.hstore.compaction.min</code> = 3（文件）</p>
</li>
<li>
<p><code>hbase.hstore.compaction.max</code> = 5（文件）</p>
</li>
<li>
<p><code>hbase.hstore.compaction.min.size</code> = 10（字节）</p>
</li>
<li>
<p><code>hbase.hstore.compaction.max.size</code> = 1000（字节）</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>存在以下StoreFiles：每个100、50、23、12和12个字节（最旧到最新）。使用上述参数，将选择进行次压缩的文件为23、12和12。</p>
</div>
<div class="paragraph">
<p>为什么？</p>
</div>
<div class="ulist">
<ul>
<li>
<p>100→不，因为sum（50，23，12，12）* 1.0 = 97。</p>
</li>
<li>
<p>50→否，因为sum（23，12，12）* 1.0 = 47。</p>
</li>
<li>
<p>23→是，因为sum（12，12）* 1.0 = 24。</p>
</li>
<li>
<p>12→是，因为已包含上一个文件，并且没有超过最大文件数限制5</p>
</li>
<li>
<p>12→是，因为已包含上一个文件，并且没有超过最大文件数限制5。</p>
</li>
</ul>
</div>
</div>
<div class="sect5">
<h6 id="compaction.file.selection.example2"><a class="anchor" href="#compaction.file.selection.example2"></a>次要压缩文件的选择-示例2（压缩文件不足）</h6>
<div class="paragraph">
<p>此示例反映了单元测试中的示例<code>TestCompactSelection</code> 。</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>hbase.hstore.compaction.ratio</code> = 1.0f</p>
</li>
<li>
<p><code>hbase.hstore.compaction.min</code> = 3（文件）</p>
</li>
<li>
<p><code>hbase.hstore.compaction.max</code> = 5（文件）</p>
</li>
<li>
<p><code>hbase.hstore.compaction.min.size</code> = 10（字节）</p>
</li>
<li>
<p><code>hbase.hstore.compaction.max.size</code> = 1000（字节）</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>存在以下StoreFiles：每个100、25、12和12个字节（最旧到最新）。使用以上参数，将不会开始压缩。</p>
</div>
<div class="paragraph">
<p>为什么？</p>
</div>
<div class="ulist">
<ul>
<li>
<p>100→不，因为sum（25，12，12）* 1.0 = 47</p>
</li>
<li>
<p>25→否，因为sum（12，12）* 1.0 = 24</p>
</li>
<li>
<p>12→否。因为sum（12）* 1.0 = 12，所以只有2个要压缩的文件小于3个阈值</p>
</li>
<li>
<p>12→否。因为以前的StoreFile是候选文件，但是没有足够的文件要压缩</p>
</li>
</ul>
</div>
</div>
<div class="sect5">
<h6 id="compaction.file.selection.example3"><a class="anchor" href="#compaction.file.selection.example3"></a>次压缩文件选择-示例3（将文件限制为压缩）</h6>
<div class="paragraph">
<p>此示例反映了单元测试中的示例<code>TestCompactSelection</code> 。</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>hbase.hstore.compaction.ratio</code> = 1.0f</p>
</li>
<li>
<p><code>hbase.hstore.compaction.min</code> = 3（文件）</p>
</li>
<li>
<p><code>hbase.hstore.compaction.max</code> = 5（文件）</p>
</li>
<li>
<p><code>hbase.hstore.compaction.min.size</code> = 10（字节）</p>
</li>
<li>
<p><code>hbase.hstore.compaction.max.size</code> = 1000（字节）</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>存在以下StoreFiles：每个7、6、5、4、3、2和1个字节（最旧到最新）。使用以上参数，将选择进行次压缩的文件为7、6、5、4、3。</p>
</div>
<div class="paragraph">
<p>为什么？</p>
</div>
<div class="ulist">
<ul>
<li>
<p>7→是，因为sum（6，5，4，3，2，1）* 1.0 = 21。此外，7小于最小大小</p>
</li>
<li>
<p>6→是，因为sum（5，4，3，2，1）* 1.0 = 15。此外，6小于最小大小。</p>
</li>
<li>
<p>5→是，因为sum（4，3，2，1）* 1.0 = 10。另外，5小于最小大小。</p>
</li>
<li>
<p>4→是，因为sum（3，2，1）* 1.0 = 6。另外，4小于最小大小。</p>
</li>
<li>
<p>3→是，因为sum（2，1）* 1.0 = 3。此外，3小于最小大小。</p>
</li>
<li>
<p>2→否。因为已选择上一个文件，并且2小于最小大小，但已达到要压缩的最大文件数，因此为候选。</p>
</li>
<li>
<p>1→No.候选，因为选择了上一个文件，并且1小于最小大小，但已达到要压缩的最大文件数。</p>
</li>
</ul>
</div>
<div id="compaction.config.impact" class="admonitionblock note">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-note" title="注意"></i>
</td>
<td class="content">
<div class="title">关键配置选项的影响</div>现在，此信息包含在<a href="#compaction.configuration.parameters">[compaction.configuration.parameters]</a>中的配置参数表中。
</td>
</tr>
</tbody></table>
</div>
</div>
</div>
<div class="sect4">
<h5 id="ops.stripe"><a class="anchor" href="#ops.stripe"></a>实验：条带压缩</h5>
<div class="paragraph">
<p>条纹压缩是HBase 0.98中添加的一项实验功能，旨在改善大区域或不均匀分布的行键的压缩。为了实现更小和/或更详细的压缩，区域内的StoreFiles分别针对该区域的几个行键子范围或“条”进行维护。条带对其余的HBase透明，因此对HFiles或数据的其他操作无需修改即可工作。</p>
</div>
<div class="paragraph">
<p>条带压缩会更改HFile布局，从而在区域内创建子区域。这些次区域更容易压实，应减少主要压实。这种方法减轻了较大区域的挑战。</p>
</div>
<div class="paragraph">
<p>条带压缩与<a href="#compaction">[compaction]</a>完全兼容，并且可以与ExploringCompactionPolicy或RatioBasedCompactionPolicy结合使用。可以为现有表启用它，并且如果以后禁用该表，该表将继续正常运行。</p>
</div>
</div>
<div class="sect4">
<h5 id="ops.stripe.when"><a class="anchor" href="#ops.stripe.when"></a>何时使用条带压缩</h5>
<div class="paragraph">
<p>如果满足以下任一条件，请考虑使用条带压缩：</p>
</div>
<div class="ulist">
<ul>
<li>
<p>大区域。您可以获得较小区域的积极影响，而无需增加MemStore的额外开销和区域管理开销。</p>
</li>
<li>
<p>非统一密钥，例如密钥中的时间维度。只有接收新密钥的条带才需要压缩。如果有的话，旧数据将不会经常压缩</p>
</li>
</ul>
</div>
<div class="paragraph">
<div class="title">性能改进</div>
<p>性能测试表明，读取的性能有所提高，并且读取和写入的性能差异大大降低。在较大的非均匀行键区域（例如哈希前缀的时间戳键）上，可以看到总体的长期性能改进。在已经很大的桌子上，这些性能提升最为明显。性能改进可能会扩展到区域拆分。</p>
</div>
<div class="sect5">
<h6 id="ops.stripe.enable"><a class="anchor" href="#ops.stripe.enable"></a>启用条带压缩</h6>
<div class="paragraph">
<p>您可以通过设置表或列族的条带压缩来启用条带压缩<code>hbase.hstore.engine.class</code>至<code>org.apache.hadoop.hbase.regionserver.StripeStoreEngine</code> 。您还需要设置<code>hbase.hstore.blockingStoreFiles</code>设置为高数，例如100（而不是默认值10）。</p>
</div>
<div class="olist arabic">
<div class="title">过程：启用条带压缩</div>
<ol class="arabic">
<li>
<p>如果该表已经存在，请禁用该表。</p>
</li>
<li>
<p>在HBase Shell中运行以下命令之一。替换表名<code>orders_table</code>表的名称。</p>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="sql"><span class="class">alter</span> <span class="string"><span class="delimiter">'</span><span class="content">orders_table</span><span class="delimiter">'</span></span>, CONFIGURATION =&gt; {<span class="string"><span class="delimiter">'</span><span class="content">hbase.hstore.engine.class</span><span class="delimiter">'</span></span> =&gt; <span class="string"><span class="delimiter">'</span><span class="content">org.apache.hadoop.hbase.regionserver.StripeStoreEngine</span><span class="delimiter">'</span></span>, <span class="string"><span class="delimiter">'</span><span class="content">hbase.hstore.blockingStoreFiles</span><span class="delimiter">'</span></span> =&gt; <span class="string"><span class="delimiter">'</span><span class="content">100</span><span class="delimiter">'</span></span>}
<span class="class">alter</span> <span class="string"><span class="delimiter">'</span><span class="content">orders_table</span><span class="delimiter">'</span></span>, {NAME =&gt; <span class="string"><span class="delimiter">'</span><span class="content">blobs_cf</span><span class="delimiter">'</span></span>, CONFIGURATION =&gt; {<span class="string"><span class="delimiter">'</span><span class="content">hbase.hstore.engine.class</span><span class="delimiter">'</span></span> =&gt; <span class="string"><span class="delimiter">'</span><span class="content">org.apache.hadoop.hbase.regionserver.StripeStoreEngine</span><span class="delimiter">'</span></span>, <span class="string"><span class="delimiter">'</span><span class="content">hbase.hstore.blockingStoreFiles</span><span class="delimiter">'</span></span> =&gt; <span class="string"><span class="delimiter">'</span><span class="content">100</span><span class="delimiter">'</span></span>}}
<span class="class">create</span> <span class="string"><span class="delimiter">'</span><span class="content">orders_table</span><span class="delimiter">'</span></span>, <span class="string"><span class="delimiter">'</span><span class="content">blobs_cf</span><span class="delimiter">'</span></span>, CONFIGURATION =&gt; {<span class="string"><span class="delimiter">'</span><span class="content">hbase.hstore.engine.class</span><span class="delimiter">'</span></span> =&gt; <span class="string"><span class="delimiter">'</span><span class="content">org.apache.hadoop.hbase.regionserver.StripeStoreEngine</span><span class="delimiter">'</span></span>, <span class="string"><span class="delimiter">'</span><span class="content">hbase.hstore.blockingStoreFiles</span><span class="delimiter">'</span></span> =&gt; <span class="string"><span class="delimiter">'</span><span class="content">100</span><span class="delimiter">'</span></span>}</code></pre>
</div>
</div>
</li>
<li>
<p>如果需要，配置其他选项。有关更多信息，请参阅<a href="#ops.stripe.config">配置条带压缩</a> 。</p>
</li>
<li>
<p>启用表格。</p>
</li>
</ol>
</div>
<div class="olist arabic">
<div class="title">过程：禁用条带压缩</div>
<ol class="arabic">
<li>
<p>禁用表格。</p>
</li>
<li>
<p>设置<code>hbase.hstore.engine.class</code>选择为nil或<code>org.apache.hadoop.hbase.regionserver.DefaultStoreEngine</code> 。两种选择都具有相同的效果。</p>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="sql"><span class="class">alter</span> <span class="string"><span class="delimiter">'</span><span class="content">orders_table</span><span class="delimiter">'</span></span>, CONFIGURATION =&gt; {<span class="string"><span class="delimiter">'</span><span class="content">hbase.hstore.engine.class</span><span class="delimiter">'</span></span> =&gt; <span class="string"><span class="delimiter">'</span><span class="content">rg.apache.hadoop.hbase.regionserver.DefaultStoreEngine</span><span class="delimiter">'</span></span>}</code></pre>
</div>
</div>
</li>
<li>
<p>启用表格。</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>在以任何一种方式更改存储引擎之后启用大表时，可能会在大多数区域上执行大型压缩。在新表上不需要这样做。</p>
</div>
</div>
<div class="sect5">
<h6 id="ops.stripe.config"><a class="anchor" href="#ops.stripe.config"></a>配置条带压缩</h6>
<div class="paragraph">
<p>禁用表后，应在表或列系列中配置条带压缩的每个设置。如果使用HBase Shell，则常规命令模式如下：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="sql"><span class="class">alter</span> <span class="string"><span class="delimiter">'</span><span class="content">orders_table</span><span class="delimiter">'</span></span>, CONFIGURATION =&gt; {<span class="string"><span class="delimiter">'</span><span class="content">key</span><span class="delimiter">'</span></span> =&gt; <span class="string"><span class="delimiter">'</span><span class="content">value</span><span class="delimiter">'</span></span>, ..., <span class="string"><span class="delimiter">'</span><span class="content">key</span><span class="delimiter">'</span></span> =&gt; <span class="string"><span class="delimiter">'</span><span class="content">value</span><span class="delimiter">'</span></span>}}</code></pre>
</div>
</div>
<div id="ops.stripe.config.sizing" class="paragraph">
<div class="title">区域和条纹大小</div>
<p>您可以根据区域大小来配置条带大小。默认情况下，您的新区域将从一个条纹开始。在条带变得太大（16 x MemStore刷新大小）之后的下一次压缩中，将其分成两个条带。条带分裂随着区域的增长而继续，直到该区域大到足以分裂为止。</p>
</div>
<div class="paragraph">
<p>您可以针对自己的数据改进此模式。一个好的规则是，目标是至少1 GB的条带大小，对于统一的行键，大约8-12条带。例如，如果您的区域为30 GB，则可能需要12 x 2.5 GB的条带。</p>
</div>
<table class="tableblock frame-all grid-all spread">
<caption class="title">表9。条纹大小设置</caption>
<colgroup>
<col style="width:50%">
<col style="width:50%">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">设置</th>
<th class="tableblock halign-left valign-top">笔记</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>hbase.store.stripe.initialStripeCount</code></p></td>
<td class="tableblock halign-left valign-top"><div><div id="toc" class="toc">
<div id="toctitle">内容</div>

</div>
<div class="paragraph">
<p>启用条带压缩时要创建的条带数量。您可以按以下方式使用它：</p>
</div>
<div class="ulist">
<ul>
<li>
<p>对于相对统一的行键，如果您从上面知道了大致的目标条带数量，则可以通过从几个条带（2、5、10 ...）开始避免开销的分散。如果早期数据不能代表整个行密钥分配，那么效率将不那么高。</p>
</li>
<li>
<p>对于具有大量数据的现有表，此设置将有效地预先分割条带。</p>
</li>
<li>
<p>对于像哈希前缀的连续密钥这样的密钥，每个区域有一个以上的哈希前缀，预分割可能是有意义的。</p>
</li>
</ul>
</div></div></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>hbase.store.stripe.sizeToSplit</code></p></td>
<td class="tableblock halign-left valign-top"><div><div id="toc" class="toc">
<div id="toctitle">内容</div>

</div>
<div class="paragraph">
<p>条带在分裂前增长的最大大小。结合使用<code>hbase.store.stripe.splitPartCount</code>控制目标条带大小（ <code>sizeToSplit = splitPartsCount * target stripe size</code> ），请根据上述大小注意事项。</p>
</div></div></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>hbase.store.stripe.splitPartCount</code></p></td>
<td class="tableblock halign-left valign-top"><div><div id="toc" class="toc">
<div id="toctitle">内容</div>

</div>
<div class="paragraph">
<p>分割条带时要创建的新条带数。默认值为2，适用于大多数情况。对于非一致的行键，您可以尝试将数字增加到3或4，以将到达的更新隔离到该区域的较窄切片中，而无需进行其他拆分。</p>
</div></div></td>
</tr>
</tbody>
</table>
<div id="ops.stripe.config.memstore" class="paragraph">
<div class="title">MemStore大小设置</div>
<p>默认情况下，刷新会根据现有的条带边界和要刷新的行键从一个MemStore创建多个文件。这种方法最大程度地减少了写放大，但是如果MemStore很小并且有很多条带，则可能不希望这样做，因为文件太小了。</p>
</div>
<div class="paragraph">
<p>在这种情况下，您可以设置<code>hbase.store.stripe.compaction.flushToL0</code>至<code>true</code> 。这将导致MemStore刷新创建单个文件。至少在<code>hbase.store.stripe.compaction.minFilesL0</code>此类文件（默认情况下为4）会累积，将被压缩为带状文件。</p>
</div>
<div id="ops.stripe.config.compact" class="paragraph">
<div class="title">常规压缩配置和条带压缩</div>
<p>适用于常规压缩的所有设置（请参阅<a href="#compaction.configuration.parameters">[compaction.configuration.parameters]</a> ）都适用于条带压缩。最小和最大文件数是个例外，默认情况下将其设置为较高的值，因为带区中的文件较小。要控制这些以进行条带压缩，请使用<code>hbase.store.stripe.compaction.minFiles</code>和<code>hbase.store.stripe.compaction.maxFiles</code> ， 而不是<code>hbase.hstore.compaction.min</code>和<code>hbase.hstore.compaction.max</code> 。</p>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="arch.bulk.load"><a class="anchor" href="#arch.bulk.load"></a> 69。批量装载</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="arch.bulk.load.overview"><a class="anchor" href="#arch.bulk.load.overview"></a> 69.1。总览</h3>
<div class="paragraph">
<p>HBase包括几种将数据加载到表中的方法。最直接的方法是使用<code>TableOutputFormat</code>类从MapReduce作业，或使用常规客户端API；但是，这些方法并不总是最有效的方法。</p>
</div>
<div class="paragraph">
<p>批量加载功能使用MapReduce作业以HBase的内部数据格式输出表数据，然后将生成的StoreFiles直接加载到正在运行的集群中。与仅使用HBase API相比，使用大容量加载将占用更少的CPU和网络资源。</p>
</div>
</div>
<div class="sect2">
<h3 id="arch.bulk.load.limitations"><a class="anchor" href="#arch.bulk.load.limitations"></a> 69.2。批量负荷限制</h3>
<div class="paragraph">
<p>由于批量加载绕过了写入路径，因此WAL不会作为该过程的一部分被写入。复制是通过读取WAL文件来进行的，因此它不会看到批量加载的数据-使用的编辑内容也是如此<code>Put.setDurability(SKIP_WAL)</code> 。一种处理方法是将原始文件或HFile运送到另一个群集，并在那里进行其他处理。</p>
</div>
</div>
<div class="sect2">
<h3 id="arch.bulk.load.arch"><a class="anchor" href="#arch.bulk.load.arch"></a> 69.3。批量加载架构</h3>
<div class="paragraph">
<p>HBase批量加载过程包括两个主要步骤。</p>
</div>
<div class="sect3">
<h4 id="arch.bulk.load.prep"><a class="anchor" href="#arch.bulk.load.prep"></a> 69.3.1。通过MapReduce作业准备数据</h4>
<div class="paragraph">
<p>批量加载的第一步是使用MapReduce作业生成HBase数据文件（StoreFiles） <code>HFileOutputFormat2</code> 。此输出格式以HBase的内部存储格式写出数据，以便以后可以将它们非常有效地加载到群集中。</p>
</div>
<div class="paragraph">
<p>为了有效运作， <code>HFileOutputFormat2</code>必须配置为使每个输出HFile都适合单个区域。为此，其输出将被批量加载到HBase中的作业使用Hadoop的<code>TotalOrderPartitioner</code>类将映射输出划分为键空间的不相交范围，该范围与表中区域的键范围相对应。</p>
</div>
<div class="paragraph">
<p><code>HFileOutputFormat2</code>包括便利功能， <code>configureIncrementalLoad()</code> ，它会自动设置一个<code>TotalOrderPartitioner</code>基于表的当前区域边界。</p>
</div>
</div>
<div class="sect3">
<h4 id="arch.bulk.load.complete"><a class="anchor" href="#arch.bulk.load.complete"></a> 69.3.2。完成数据加载</h4>
<div class="paragraph">
<p>准备好数据导入后，可以使用<code>importtsv</code>带有“ importtsv.bulk.output”选项的工具，或通过使用<code>HFileOutputFormat</code> ， <code>completebulkload</code>该工具用于将数据导入到正在运行的群集中。此命令行工具遍历准备好的数据文件，并为每个文件确定文件所属的区域。然后，它与采用HFile的适当RegionServer联系，将其移入其存储目录并将数据提供给客户端。</p>
</div>
<div class="paragraph">
<p>如果在大荷载准备过程中或准备和完成步骤之间区域边界发生了变化，则<code>completebulkload</code>实用程序将自动将数据文件拆分为与新边界相对应的片段。此过程的效率不是最佳，因此用户应注意最大程度地减少准备大容量负载和将其导入群集之间的延迟，尤其是在其他客户端通过其他方式同时加载数据时。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">$ hadoop jar hbase-server-VERSION.jar completebulkload [-c /path/to/hbase/config/hbase-site.xml] /user/todd/myoutput mytable</code></pre>
</div>
</div>
<div class="paragraph">
<p>的<code>-c config-file</code>如果CLASSPATH中尚未提供该选项，则该选项可用于指定包含适当hbase参数的文件（例如，hbase-site.xml）（此外，如果未管理zookeeper，则CLASSPATH必须包含具有zookeeper配置文件的目录。由HBase）。</p>
</div>
<div class="admonitionblock note">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-note" title="注意"></i>
</td>
<td class="content">如果目标表在HBase中尚不存在，则此工具将自动创建表。
</td>
</tr>
</tbody></table>
</div>
</div>
</div>
<div class="sect2">
<h3 id="arch.bulk.load.also"><a class="anchor" href="#arch.bulk.load.also"></a> 69.4。也可以看看</h3>
<div class="paragraph">
<p>有关引用的实用程序的更多信息，请参见<a href="#importtsv">[importtsv]</a>和<a href="#completebulkload">[completebulkload]</a> 。</p>
</div>
<div class="paragraph">
<p>请参阅<a href="http://blog.cloudera.com/blog/2013/09/how-to-use-hbase-bulk-loading-and-why/">操作方法：使用HBase批量加载，以及</a>有关最近关于批量加载当前状态的博客的原因。</p>
</div>
</div>
<div class="sect2">
<h3 id="arch.bulk.load.adv"><a class="anchor" href="#arch.bulk.load.adv"></a> 69.5。高级用法</h3>
<div class="paragraph">
<p>虽然<code>importtsv</code>该工具在许多情况下很有用，高级用户可能希望以编程方式生成数据，或从其他格式导入数据。要开始这样做，请深入研究<code>ImportTsv.java</code>并检查JavaDoc for HFileOutputFormat。</p>
</div>
<div class="paragraph">
<p>批量加载的导入步骤也可以通过编程完成。见<code>LoadIncrementalHFiles</code>类以获取更多信息。</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="arch.hdfs"><a class="anchor" href="#arch.hdfs"></a> 70HDFS</h2>
<div class="sectionbody">
<div class="paragraph">
<p>由于HBase在HDFS上运行（并且每个StoreFile都作为文件写在HDFS上），因此重要的是了解HDFS体系结构，尤其是在如何存储文件，处理故障转移和复制块方面。</p>
</div>
<div class="paragraph">
<p>有关更多信息，请参阅<a href="http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/HdfsDesign.html">HDFS体系结构</a>上的Hadoop文档。</p>
</div>
<div class="sect2">
<h3 id="arch.hdfs.nn"><a class="anchor" href="#arch.hdfs.nn"></a> 70.1。名称节点</h3>
<div class="paragraph">
<p>NameNode负责维护文件系统元数据。有关更多信息，请参见上面的HDFS体系结构链接。</p>
</div>
</div>
<div class="sect2">
<h3 id="arch.hdfs.dn"><a class="anchor" href="#arch.hdfs.dn"></a> 70.2。数据节点</h3>
<div class="paragraph">
<p>数据节点负责存储HDFS块。有关更多信息，请参见上面的HDFS体系结构链接。</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="arch.timelineconsistent.reads"><a class="anchor" href="#arch.timelineconsistent.reads"></a> 71。时间轴一致的高可用读取</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="casestudies.timelineconsistent.intro"><a class="anchor" href="#casestudies.timelineconsistent.intro"></a> 71.1。介绍</h3>
<div class="paragraph">
<p>从结构上讲，HBase从一开始就始终具有强大的一致性保证。所有读取和写入均通过单个区域服务器进行路由，以确保所有写入均按顺序进行，并且所有读取都看到最新提交的数据。</p>
</div>
<div class="paragraph">
<p>但是，由于将读取单次归位到单个位置，因此如果服务器不可用，则托管在区域服务器中的表的区域在一段时间内将变得不可用。区域恢复过程分为三个阶段-检测，分配和恢复。其中，检测时间通常最长，根据ZooKeeper会话超时，当前检测时间约为20-30秒。在这段时间内和恢复完成之前，客户端将无法读取区域数据。</p>
</div>
<div class="paragraph">
<p>但是，对于某些用例，数据可以是只读的，或者可以接受对某些陈旧数据的读取。借助时间轴一致的高可用读取，HBase可以用于这类对延迟敏感的用例，在这些用例中，应用程序预期在读取完成上有时间限制。</p>
</div>
<div class="paragraph">
<p>为了实现读取的高可用性，HBase提供了一种称为<em>区域复制</em>的功能。在此模型中，对于表的每个区域，将在不同的RegionServers中打开多个副本。默认情况下，区域复制设置为1，因此仅部署一个区域副本，并且与原始模型不会有任何更改。如果将区域复制设置为2或更多，则主服务器将分配表区域的副本。负载平衡器可确保区域副本不会共同托管在同一区域服务器和同一机架中（如果可能）。</p>
</div>
<div class="paragraph">
<p>单个区域的所有副本将具有一个唯一的copy_id，从0开始。复制副本ID = = 0的区域副本称为主要区域，其他<em>次要区域</em>或次要<em>区域</em> 。只有主服务器可以接受来自客户端的写入，并且主服务器将始终包含最新的更改。由于所有写操作仍必须经过主要区域，因此这些写操作不是高度可用（这意味着如果该区域不可用，它们可能会阻塞一段时间）。</p>
</div>
</div>
<div class="sect2">
<h3 id="_timeline_consistency"><a class="anchor" href="#_timeline_consistency"></a> 71.2。时间线一致性</h3>
<div class="paragraph">
<p>HBase通过此功能引入了一致性定义，可以为每个读取操作（获取或扫描）提供一致性定义。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="directive">public</span> <span class="type">enum</span> Consistency {
    STRONG,
    TIMELINE
}</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>Consistency.STRONG</code>是HBase提供的默认一致性模型。如果表的区域复制= 1，或者在具有区域副本的表中，但是读取是在这种一致性下进行的，则读取始终由主要区域执行，因此与先前的行为不会有任何变化，并且客户总是观察最新数据。</p>
</div>
<div class="paragraph">
<p>如果用<code>Consistency.TIMELINE</code> ，然后读取的RPC将首先发送到主要区域服务器。短暂间隔后（ <code>hbase.client.primaryCallTimeout.get</code> ，默认情况下为10毫秒），如果主区域未响应，则也会发送用于辅助区域副本的并行RPC。此后，从首先完成的RPC中返回结果。如果响应是从主区域副本返回的，则我们始终可以知道数据是最新的。为此，已添加Result.isStale（）API以检查过时性。如果结果来自辅助区域，则Result.isStale（）将设置为true。然后，用户可以检查该字段以可能推断出数据。</p>
</div>
<div class="paragraph">
<p>在语义方面，由HBase实现的TIMELINE一致性在以下方面不同于纯粹的最终一致性：</p>
</div>
<div class="ulist">
<ul>
<li>
<p>单一归宿和有序更新：无论是否进行区域复制，在写入方面，仍然只有1个定义的副本（主副本）可以接受写入。此副本负责命令编辑并防止冲突。这样可以确保不同的副本不会同时提交两次不同的写入，并且数据会发散。这样，就无需进行读取修复或上次时间戳获胜的冲突解决方案。</p>
</li>
<li>
<p>辅助节点还按照主要节点提交编辑的顺序来应用编辑。这样，辅助数据库将在任何时间点包含主数据库数据的快照。这类似于RDBMS复制，甚至类似于HBase自己的多数据中心复制，但是在单个群集中。</p>
</li>
<li>
<p>在读取方面，客户端可以检测读取是来自最新数据还是陈旧数据。此外，客户端可以在每次操作的基础上发出具有不同一致性要求的读取，以确保其自身的语义保证。</p>
</li>
<li>
<p>如果客户端首先观察到一个二级副本的读取，然后观察另一个二级副本的读取，则客户端仍然可以无序观察编辑，并且可以及时返回。区域副本没有粘性，也没有基于交易ID的保证。如果需要，可以稍后执行。</p>
</li>
</ul>
</div>
<div class="imageblock">
<div class="content">
<img src="images/timeline_consistency.png" alt="时间线一致性">
</div>
<div class="title">图3。时间线一致性</div>
</div>
<div class="paragraph">
<p>为了更好地理解TIMELINE语义，让我们看一下上面的图。可以说有两个客户端，第一个客户端首先写x = 1，然后写x = 2，然后写x = 3。如上所述，所有写操作均由主区域副本处理。写入将保存在预写日志（WAL）中，并异步复制到其他副本。在上图中，请注意，replica_id = 1接收了2个更新，并且其数据显示x = 2，而replica_id = 2仅接收了一个更新，并且其数据显示x = 1。</p>
</div>
<div class="paragraph">
<p>如果client1以STRONG一致性读取，则它只会与copy_id = 0对话，因此可以保证观察到x = 3的最新值。如果客户端发出TIMELINE一致性读取，则RPC将转到所有副本（在主超时后），并且第一个响应的结果将返回。因此，客户可以将1、2或3视为x的值。假设主要区域发生故障，并且日志复制无法持续一段时间。如果客户端以TIMELINE一致性进行多次读取，则她可以先观察x = 2，然后观察x = 1，依此类推。</p>
</div>
</div>
<div class="sect2">
<h3 id="_tradeoffs"><a class="anchor" href="#_tradeoffs"></a> 71.3权衡</h3>
<div class="paragraph">
<p>托管二级区域以实现读取可用性会带来一些折衷，应根据每个用例仔细评估。以下是优点和缺点。</p>
</div>
<div class="ulist">
<div class="title">好处</div>
<ul>
<li>
<p>只读表的高可用性</p>
</li>
<li>
<p>高可用性的陈旧读取</p>
</li>
<li>
<p>能够以非常高的百分位数（99.9％+）延迟进行非常低延迟的读取，以实现陈旧的读取</p>
</li>
</ul>
</div>
<div class="ulist">
<div class="title">缺点</div>
<ul>
<li>
<p>区域复制> 1的表的Double / Triple MemStore用法（取决于区域复制计数）</p>
</li>
<li>
<p>增加的块缓存使用率</p>
</li>
<li>
<p>用于日志复制的额外网络流量</p>
</li>
<li>
<p>副本的额外备份RPC</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>为了提供来自多个副本的区域数据，HBase在区域服务器中以辅助模式打开区域。在辅助模式下打开的区域将与主区域副本共享相同的数据文件，但是每个辅助区域副本将具有其自己的MemStore以保留未刷新的数据（仅主区域可以进行刷新）。另外，为了服务于来自次级区域的读取，数据文件的块也可以被高速缓存在用于次级区域的块高速缓存中。</p>
</div>
</div>
<div class="sect2">
<h3 id="_where_is_the_code"><a class="anchor" href="#_where_is_the_code"></a> 71.4。代码在哪里</h3>
<div class="paragraph">
<p>此功能分两个阶段（阶段1和2）提供。对于HBase-1.0.0发行，第一阶段已及时完成。意味着使用HBase-1.0.x，可以使用标记为阶段1的所有功能。在HBase-1.1.0中提交了阶段2，这意味着1.1.0之后的所有HBase版本都应包含阶段2项。</p>
</div>
</div>
<div class="sect2">
<h3 id="_propagating_writes_to_region_replicas"><a class="anchor" href="#_propagating_writes_to_region_replicas"></a> 71.5。将写入传播到区域副本</h3>
<div class="paragraph">
<p>如上所述，写入仅转到主要区域副本。为了将写操作从主要区域副本传播到辅助区域，有两种不同的机制。对于只读表，您不需要使用以下任何方法。禁用和启用该表应使数据在所有区域副本中均可用。对于可变表，您<strong>仅需</strong>使用以下机制之一：存储文件刷新器或异步wal复制。建议后者。</p>
</div>
<div class="sect3">
<h4 id="_storefile_refresher"><a class="anchor" href="#_storefile_refresher"></a> 71.5.1。StoreFile刷新器</h4>
<div class="paragraph">
<p>第一种机制是HBase-1.0 +中引入的存储文件刷新器。存储文件刷新器是每个区域服务器的一个线程，该线程定期运行，并对辅助区域副本的主区域的存储文件执行刷新操作。如果启用，刷新器将确保辅助区域副本及时从主区域中看到新的已刷新，压缩或批量加载的文件。但是，这意味着只能从辅助区域副本中读取刷新的数据，并且在运行刷新器之后，使辅助数据库在较长时间内落后于主数据库。</p>
</div>
<div class="paragraph">
<p>要启用此功能，您应该配置<code>hbase.regionserver.storefile.refresh.period</code>设置为非零值。请参阅下面的“配置”部分。</p>
</div>
</div>
<div class="sect3">
<h4 id="_asnyc_wal_replication"><a class="anchor" href="#_asnyc_wal_replication"></a> 71.5.2。Asnyc WAL复制</h4>
<div class="paragraph">
<p>第二种机制是通过“异步WAL复制”功能完成的，用于传播对次要对象的写操作，并且仅在HBase-1.1 +中可用。这类似于HBase的多数据中心复制，但是来自区域的数据被复制到辅助区域。每个辅助副本始终以与主要区域提交它们的顺序相同的顺序接收和观察写入。从某种意义上说，这种设计可以被认为是“集群内复制”，其中数据复制到辅助区域以使辅助区域的内存中状态保持最新，而不是复制到其他数据中心。数据文件在主区域和其他副本之间共享，因此没有额外的存储开销。但是，辅助区域的存储器中将有最近未刷新的数据，这会增加内存开销。主区域也将刷新，压缩和批量装入事件写入其WAL，这些事件也通过wal复制复制到辅助数据库。当他们观察到刷新/压缩或批量加载事件时，辅助区域将重播该事件以拾取新文件并删除旧文件。</p>
</div>
<div class="paragraph">
<p>以与主要区域相同的顺序提交写入操作可确保次区域不会与主要区域数据分开，但是由于日志复制是异步的，因此在次区域中数据仍可能是陈旧的。由于此功能充当复制端点，因此性能和等待时间特性预计与集群间复制类似。</p>
</div>
<div class="paragraph">
<p>默认情况下，异步WAL复制是<strong>禁用</strong>的。您可以通过设置启用此功能<code>hbase.region.replica.replication.enabled</code>至<code>true</code> 。Asyn WAL复制功能将添加一个名为<code>region_replica_replication</code>首次创建区域复制> 1的表时，将其作为复制对等体。启用后，如果要禁用此功能，则需要执行两个操作：*设置配置属性<code>hbase.region.replica.replication.enabled</code>虚假<code>hbase-site.xml</code> （请参阅下面的“配置”部分）*禁用名为<code>region_replica_replication</code>在集群中使用hbase shell或<code>ReplicationAdmin</code>类：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bourne">        hbase&gt; disable_peer 'region_replica_replication'</code></pre>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_store_file_ttl"><a class="anchor" href="#_store_file_ttl"></a> 71.6。存储文件TTL</h3>
<div class="paragraph">
<p>在上述两种写传播方法中，主数据库的存储文件将在与主区域无关的辅助数据库中打开。因此，对于主要压缩的文件，辅助文件可能仍会引用这些文件进行读取。这两个功能都使用HFileLinks来引用文件，但是（至今）没有任何保护措施可以保证不会过早删除文件。因此，作为警卫，您应该设置配置属性<code>hbase.master.hfilecleaner.ttl</code>设置为一个较大的值（例如1小时），以确保您不会收到去复本的请求的IOExceptions。</p>
</div>
</div>
<div class="sect2">
<h3 id="_region_replication_for_meta_table_s_region"><a class="anchor" href="#_region_replication_for_meta_table_s_region"></a> 71.7。META表的区域的区域复制</h3>
<div class="paragraph">
<p>当前，尚未对META表的WAL执行异步WAL复制。元表的辅助副本仍从持久性存储文件中刷新自身。因此<code>hbase.regionserver.meta.storefile.refresh.period</code>需要设置为某个非零值以刷新元存储文件。请注意，此配置的配置与<code>hbase.regionserver.storefile.refresh.period</code> 。</p>
</div>
</div>
<div class="sect2">
<h3 id="_memory_accounting"><a class="anchor" href="#_memory_accounting"></a> 71.8。内存记帐</h3>
<div class="paragraph">
<p>辅助区域副本引用主区域副本的数据文件，但是它们具有自己的内存存储区（在HBase-1.1 +中），并且还使用块缓存。但是，一个区别是，辅助区域副本在其内存存储存在内存压力时无法刷新数据。仅当主区域执行刷新并将此刷新复制到辅助区域时，它们才能释放内存存储内存。由于在区域服务器中托管某些区域的主副本，而在某些区域托管第二副本，因此这些副本可能导致对同一主机中主区域的额外刷新。在极端情况下，将没有内存可用于通过wal复制添加来自主数据库的新写入。为了消除这种情况（并且由于辅助节点无法自行刷新），允许辅助节点执行“存储文件刷新”，方法是执行文件系统列表操作以从主要节点拾取新文件，并可能删除其内存存储。仅当最大辅助区域副本的内存大小至少为2时，才执行此刷新<code>hbase.region.replica.storefile.refresh.memstore.multiplier</code> （默认值为4），比主副本的最大内存存储大。一个警告是，如果执行此操作，则辅助数据库可以观察到跨列族的部分行更新（因为列族是独立刷新的）。默认设置应该很好，不要经常执行此操作。您可以根据需要将此值设置为较大的值以禁用此功能，但是请注意，这可能会导致复制永久停止。</p>
</div>
</div>
<div class="sect2">
<h3 id="_secondary_replica_failover"><a class="anchor" href="#_secondary_replica_failover"></a> 71.9。辅助副本故障转移</h3>
<div class="paragraph">
<p>当辅助区域副本首次联机或进行故障转移时，它可能已从其内存存储中进行了一些编辑。由于辅助副本的恢复处理方式不同，因此辅助副本必须确保在分配后开始为请求提供服务之前，它不会及时返回。为此，辅助服务器等待直到观察到完整的刷新周期（开始刷新，提交刷新）或从主要服务器复制的“区域打开事件”。在这种情况发生之前，辅助区域副本将通过抛出IOException消息“该区域的读取已禁用”来拒绝所有读取请求。但是，其他副本可能仍然可以读取，因此不会对具有TIMELINE一致性的rpc造成任何影响。为了加快恢复速度，辅助区域在打开时将触发来自主要区域的刷新请求。配置属性<code>hbase.region.replica.wait.for.primary.flush</code> （默认情况下启用）（可根据需要使用）禁用此功能。</p>
</div>
</div>
<div class="sect2">
<h3 id="_configuration_properties"><a class="anchor" href="#_configuration_properties"></a> 71.10。配置属性</h3>
<div class="paragraph">
<p>要使用高可用性读物，您应该在<code>hbase-site.xml</code>文件。没有启用或禁用区域副本的特定配置。相反，您可以更改每个表的区域副本数，以在创建表或使用alter table时增加或减少。以下配置用于使用异步wal复制和3的元副本。</p>
</div>
<div class="sect3">
<h4 id="_server_side_properties"><a class="anchor" href="#_server_side_properties"></a> 71.10.1。服务器端属性</h4>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="xml"><span class="tag">&lt;property&gt;</span>
    <span class="tag">&lt;name&gt;</span>hbase.regionserver.storefile.refresh.period<span class="tag">&lt;/name&gt;</span>
    <span class="tag">&lt;value&gt;</span>0<span class="tag">&lt;/value&gt;</span>
    <span class="tag">&lt;description&gt;</span>
      The period (in milliseconds) for refreshing the store files for the secondary regions. 0 means this feature is disabled. Secondary regions sees new files (from flushes and compactions) from primary once the secondary region refreshes the list of files in the region (there is no notification mechanism). But too frequent refreshes might cause extra Namenode pressure. If the files cannot be refreshed for longer than HFile TTL (hbase.master.hfilecleaner.ttl) the requests are rejected. Configuring HFile TTL to a larger value is also recommended with this setting.
    <span class="tag">&lt;/description&gt;</span>
<span class="tag">&lt;/property&gt;</span>

<span class="tag">&lt;property&gt;</span>
    <span class="tag">&lt;name&gt;</span>hbase.regionserver.meta.storefile.refresh.period<span class="tag">&lt;/name&gt;</span>
    <span class="tag">&lt;value&gt;</span>300000<span class="tag">&lt;/value&gt;</span>
    <span class="tag">&lt;description&gt;</span>
      The period (in milliseconds) for refreshing the store files for the hbase:meta tables secondary regions. 0 means this feature is disabled. Secondary regions sees new files (from flushes and compactions) from primary once the secondary region refreshes the list of files in the region (there is no notification mechanism). But too frequent refreshes might cause extra Namenode pressure. If the files cannot be refreshed for longer than HFile TTL (hbase.master.hfilecleaner.ttl) the requests are rejected. Configuring HFile TTL to a larger value is also recommended with this setting. This should be a non-zero number if meta replicas are enabled (via hbase.meta.replica.count set to greater than 1).
    <span class="tag">&lt;/description&gt;</span>
<span class="tag">&lt;/property&gt;</span>

<span class="tag">&lt;property&gt;</span>
    <span class="tag">&lt;name&gt;</span>hbase.region.replica.replication.enabled<span class="tag">&lt;/name&gt;</span>
    <span class="tag">&lt;value&gt;</span>true<span class="tag">&lt;/value&gt;</span>
    <span class="tag">&lt;description&gt;</span>
      Whether asynchronous WAL replication to the secondary region replicas is enabled or not. If this is enabled, a replication peer named &quot;region_replica_replication&quot; will be created which will tail the logs and replicate the mutatations to region replicas for tables that have region replication <span class="error">&gt;</span> 1. If this is enabled once, disabling this replication also      requires disabling the replication peer using shell or ReplicationAdmin java class. Replication to secondary region replicas works over standard inter-cluster replication. So replication, if disabled explicitly, also has to be enabled by setting &quot;hbase.replication&quot;· to true for this feature to work.
    <span class="tag">&lt;/description&gt;</span>
<span class="tag">&lt;/property&gt;</span>
<span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>hbase.region.replica.replication.memstore.enabled<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>true<span class="tag">&lt;/value&gt;</span>
  <span class="tag">&lt;description&gt;</span>
    If you set this to `false`, replicas do not receive memstore updates from
    the primary RegionServer. If you set this to `true`, you can still disable
    memstore replication on a per-table basis, by setting the table's
    `REGION_MEMSTORE_REPLICATION` configuration property to `false`. If
    memstore replication is disabled, the secondaries will only receive
    updates for events like flushes and bulkloads, and will not have access to
    data which the primary has not yet flushed. This preserves the guarantee
    of row-level consistency, even when the read requests `Consistency.TIMELINE`.
  <span class="tag">&lt;/description&gt;</span>
<span class="tag">&lt;/property&gt;</span>

<span class="tag">&lt;property&gt;</span>
    <span class="tag">&lt;name&gt;</span>hbase.master.hfilecleaner.ttl<span class="tag">&lt;/name&gt;</span>
    <span class="tag">&lt;value&gt;</span>3600000<span class="tag">&lt;/value&gt;</span>
    <span class="tag">&lt;description&gt;</span>
      The period (in milliseconds) to keep store files in the archive folder before deleting them from the file system.<span class="tag">&lt;/description&gt;</span>
<span class="tag">&lt;/property&gt;</span>

<span class="tag">&lt;property&gt;</span>
    <span class="tag">&lt;name&gt;</span>hbase.meta.replica.count<span class="tag">&lt;/name&gt;</span>
    <span class="tag">&lt;value&gt;</span>3<span class="tag">&lt;/value&gt;</span>
    <span class="tag">&lt;description&gt;</span>
      Region replication count for the meta regions. Defaults to 1.
    <span class="tag">&lt;/description&gt;</span>
<span class="tag">&lt;/property&gt;</span>


<span class="tag">&lt;property&gt;</span>
    <span class="tag">&lt;name&gt;</span>hbase.region.replica.storefile.refresh.memstore.multiplier<span class="tag">&lt;/name&gt;</span>
    <span class="tag">&lt;value&gt;</span>4<span class="tag">&lt;/value&gt;</span>
    <span class="tag">&lt;description&gt;</span>
      The multiplier for a “store file refresh” operation for the secondary region replica. If a region server has memory pressure, the secondary region will refresh it’s store files if the memstore size of the biggest secondary replica is bigger this many times than the memstore size of the biggest primary replica. Set this to a very big value to disable this feature (not recommended).
    <span class="tag">&lt;/description&gt;</span>
<span class="tag">&lt;/property&gt;</span>

<span class="tag">&lt;property&gt;</span>
 <span class="tag">&lt;name&gt;</span>hbase.region.replica.wait.for.primary.flush<span class="tag">&lt;/name&gt;</span>
    <span class="tag">&lt;value&gt;</span>true<span class="tag">&lt;/value&gt;</span>
    <span class="tag">&lt;description&gt;</span>
      Whether to wait for observing a full flush cycle from the primary before start serving data in a secondary. Disabling this might cause the secondary region replicas to go back in time for reads between region movements.
    <span class="tag">&lt;/description&gt;</span>
<span class="tag">&lt;/property&gt;</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>还要记住的一件事是，区域副本放置策略仅由<code>StochasticLoadBalancer</code>这是默认的平衡器。如果您在hbase-site.xml中使用自定义负载均衡器属性， <code>hbase.master.loadbalancer.class</code> ）区域的副本可能最终会托管在同一服务器中。</p>
</div>
</div>
<div class="sect3">
<h4 id="_client_side_properties"><a class="anchor" href="#_client_side_properties"></a> 71.10.2。客户端属性</h4>
<div class="paragraph">
<p>确保为将使用区域副本的所有客户端（和服务器）设置以下内容。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="xml"><span class="tag">&lt;property&gt;</span>
    <span class="tag">&lt;name&gt;</span>hbase.ipc.client.specificThreadForWriting<span class="tag">&lt;/name&gt;</span>
    <span class="tag">&lt;value&gt;</span>true<span class="tag">&lt;/value&gt;</span>
    <span class="tag">&lt;description&gt;</span>
      Whether to enable interruption of RPC threads at the client side. This is required for region replicas with fallback RPC’s to secondary regions.
    <span class="tag">&lt;/description&gt;</span>
<span class="tag">&lt;/property&gt;</span>
<span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>hbase.client.primaryCallTimeout.get<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>10000<span class="tag">&lt;/value&gt;</span>
  <span class="tag">&lt;description&gt;</span>
    The timeout (in microseconds), before secondary fallback RPC’s are submitted for get requests with Consistency.TIMELINE to the secondary replicas of the regions. Defaults to 10ms. Setting this lower will increase the number of RPC’s, but will lower the p99 latencies.
  <span class="tag">&lt;/description&gt;</span>
<span class="tag">&lt;/property&gt;</span>
<span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>hbase.client.primaryCallTimeout.multiget<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>10000<span class="tag">&lt;/value&gt;</span>
  <span class="tag">&lt;description&gt;</span>
      The timeout (in microseconds), before secondary fallback RPC’s are submitted for multi-get requests (Table.get(List<span class="tag">&lt;Get&gt;</span>)) with Consistency.TIMELINE to the secondary replicas of the regions. Defaults to 10ms. Setting this lower will increase the number of RPC’s, but will lower the p99 latencies.
  <span class="tag">&lt;/description&gt;</span>
<span class="tag">&lt;/property&gt;</span>
<span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>hbase.client.replicaCallTimeout.scan<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>1000000<span class="tag">&lt;/value&gt;</span>
  <span class="tag">&lt;description&gt;</span>
    The timeout (in microseconds), before secondary fallback RPC’s are submitted for scan requests with Consistency.TIMELINE to the secondary replicas of the regions. Defaults to 1 sec. Setting this lower will increase the number of RPC’s, but will lower the p99 latencies.
  <span class="tag">&lt;/description&gt;</span>
<span class="tag">&lt;/property&gt;</span>
<span class="tag">&lt;property&gt;</span>
    <span class="tag">&lt;name&gt;</span>hbase.meta.replicas.use<span class="tag">&lt;/name&gt;</span>
    <span class="tag">&lt;value&gt;</span>true<span class="tag">&lt;/value&gt;</span>
    <span class="tag">&lt;description&gt;</span>
      Whether to use meta table replicas or not. Default is false.
    <span class="tag">&lt;/description&gt;</span>
<span class="tag">&lt;/property&gt;</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>注意HBase-1.0.x用户应使用<code>hbase.ipc.client.allowsInterrupt</code>而不是<code>hbase.ipc.client.specificThreadForWriting</code> 。</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_user_interface"><a class="anchor" href="#_user_interface"></a> 71.11。用户界面</h3>
<div class="paragraph">
<p>在主用户界面中，还显示了表的区域副本以及主要区域。您会注意到，区域的副本将共享相同的开始键和结束键以及相同的区域名称前缀。唯一的区别是附加的restore_id（编码为十六进制），而区域编码的名称将不同。您还可以查看UI中明确显示的副本ID。</p>
</div>
</div>
<div class="sect2">
<h3 id="_creating_a_table_with_region_replication"><a class="anchor" href="#_creating_a_table_with_region_replication"></a> 71.12。使用区域复制创建表</h3>
<div class="paragraph">
<p>区域复制是每个表的属性。所有表都有<code>REGION_REPLICATION = 1</code>默认情况下，这意味着每个区域只有一个副本。您可以通过提供以下信息来设置和更改表的每个区域的副本数： <code>REGION_REPLICATION</code>表描述符中的属性。</p>
</div>
<div class="sect3">
<h4 id="_shell"><a class="anchor" href="#_shell"></a> 71.12.1。贝壳</h4>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">create <span class="string"><span class="delimiter">'</span><span class="content">t1</span><span class="delimiter">'</span></span>, <span class="string"><span class="delimiter">'</span><span class="content">f1</span><span class="delimiter">'</span></span>, {REGION_REPLICATION =&gt; <span class="integer">2</span>}

describe <span class="string"><span class="delimiter">'</span><span class="content">t1</span><span class="delimiter">'</span></span>
<span class="keyword">for</span> i in <span class="integer">1</span>.<span class="float">.100</span>
put <span class="string"><span class="delimiter">'</span><span class="content">t1</span><span class="delimiter">'</span></span>, <span class="string"><span class="delimiter">&quot;</span><span class="content">r#{i}</span><span class="delimiter">&quot;</span></span>, <span class="string"><span class="delimiter">'</span><span class="content">f1:c1</span><span class="delimiter">'</span></span>, i
end
flush <span class="string"><span class="delimiter">'</span><span class="content">t1</span><span class="delimiter">'</span></span></code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_java"><a class="anchor" href="#_java"></a> 71.12.2。爪哇</h4>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">HTableDescriptor htd = <span class="keyword">new</span> HTableDescriptor(TableName.valueOf(<span class="error">“</span>test_table<span class="error">”</span>));
htd.setRegionReplication(<span class="integer">2</span>);
...
admin.createTable(htd);</code></pre>
</div>
</div>
<div class="paragraph">
<p>您也可以使用<code>setRegionReplication()</code>并更改表以增加，减少表的区域复制。</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_read_api_and_usage"><a class="anchor" href="#_read_api_and_usage"></a> 71.13。阅读API和用法</h3>
<div class="sect3">
<h4 id="_shell_2"><a class="anchor" href="#_shell_2"></a> 71.13.1。贝壳</h4>
<div class="paragraph">
<p>您可以使用Consistency在Shell中进行读取。TIMELINE语义如下</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">hbase(main):<span class="octal">001</span>:<span class="integer">0</span>&gt; get <span class="string"><span class="delimiter">'</span><span class="content">t1</span><span class="delimiter">'</span></span>,<span class="string"><span class="delimiter">'</span><span class="content">r6</span><span class="delimiter">'</span></span>, {CONSISTENCY =&gt; <span class="string"><span class="delimiter">&quot;</span><span class="content">TIMELINE</span><span class="delimiter">&quot;</span></span>}</code></pre>
</div>
</div>
<div class="paragraph">
<p>您可以模拟区域服务器暂停或变得不可用，并从辅助副本进行读取：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">$ kill -STOP &lt;pid or primary region server&gt;

hbase(main):001:0&gt; get 't1','r6', {CONSISTENCY =&gt; &quot;TIMELINE&quot;}</code></pre>
</div>
</div>
<div class="paragraph">
<p>使用扫描也很相似</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">hbase&gt; scan <span class="string"><span class="delimiter">'</span><span class="content">t1</span><span class="delimiter">'</span></span>, {CONSISTENCY =&gt; <span class="string"><span class="delimiter">'</span><span class="content">TIMELINE</span><span class="delimiter">'</span></span>}</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_java_2"><a class="anchor" href="#_java_2"></a> 71.13.2。爪哇</h4>
<div class="paragraph">
<p>您可以设置“获取”和“扫描”的一致性，并执行请求，如下所示。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">Get get = <span class="keyword">new</span> Get(row);
get.setConsistency(Consistency.TIMELINE);
...
Result result = table.get(get);</code></pre>
</div>
</div>
<div class="paragraph">
<p>您还可以传递多个获取：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">Get get1 = <span class="keyword">new</span> Get(row);
get1.setConsistency(Consistency.TIMELINE);
...
ArrayList&lt;Get&gt; gets = <span class="keyword">new</span> <span class="predefined-type">ArrayList</span>&lt;Get&gt;();
gets.add(get1);
...
Result<span class="type">[]</span> results = table.get(gets);</code></pre>
</div>
</div>
<div class="paragraph">
<p>并扫描：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">Scan scan = <span class="keyword">new</span> Scan();
scan.setConsistency(Consistency.TIMELINE);
...
ResultScanner scanner = table.getScanner(scan);</code></pre>
</div>
</div>
<div class="paragraph">
<p>您可以通过以下方法检查结果是否来自主要地区： <code>Result.isStale()</code>方法：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="predefined-type">Result</span> result = table.get(get);
<span class="keyword">if</span> (result.isStale()) {
  ...
}</code></pre>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_resources"><a class="anchor" href="#_resources"></a> 71.14。资源资源</h3>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>有关设计和实现的更多信息，请参见jira问题： <a href="https://issues.apache.org/jira/browse/HBASE-10070">HBASE-10070</a></p>
</li>
<li>
<p>HBaseCon 2014 <a href="http://hbasecon.com/sessions/#session15">演讲</a>还包含一些详细信息和<a href="http://www.slideshare.net/enissoz/hbase-high-availability-for-reads-with-time">幻灯片</a> 。</p>
</li>
</ol>
</div>
</div>
</div>
</div>
<h1 id="hbase_apis" class="sect0"><a class="anchor" href="#hbase_apis"></a> Apache HBase API</h1>
<div class="openblock partintro">
<div class="content">
<div class="paragraph">
<p>本章提供有关使用HBase本机API执行操作的信息。该信息并非详尽无遗，除了<a href="http://hbase.apache.org/apidocs/index.html">User API Reference</a>之外，还提供了快速<a href="http://hbase.apache.org/apidocs/index.html">参考</a> 。此处的示例并不全面或不完整，应仅用于说明目的。</p>
</div>
<div class="paragraph">
<p>Apache HBase还可以使用多个外部API。有关更多信息，请参见<a href="#external_apis">Apache HBase外部API</a> 。</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_examples"><a class="anchor" href="#_examples"></a> 72。例子</h2>
<div class="sectionbody">
<div class="exampleblock">
<div class="title">示例37。使用Java创建，修改和删除表</div>
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="keyword">package</span> <span class="namespace">com.example.hbase.admin</span>;

<span class="keyword">package</span> <span class="namespace">util</span>;

<span class="keyword">import</span> <span class="include">java.io.IOException</span>;

<span class="keyword">import</span> <span class="include">org.apache.hadoop.conf.Configuration</span>;
<span class="keyword">import</span> <span class="include">org.apache.hadoop.fs.Path</span>;
<span class="keyword">import</span> <span class="include">org.apache.hadoop.hbase.HBaseConfiguration</span>;
<span class="keyword">import</span> <span class="include">org.apache.hadoop.hbase.HColumnDescriptor</span>;
<span class="keyword">import</span> <span class="include">org.apache.hadoop.hbase.HConstants</span>;
<span class="keyword">import</span> <span class="include">org.apache.hadoop.hbase.HTableDescriptor</span>;
<span class="keyword">import</span> <span class="include">org.apache.hadoop.hbase.TableName</span>;
<span class="keyword">import</span> <span class="include">org.apache.hadoop.hbase.client.Admin</span>;
<span class="keyword">import</span> <span class="include">org.apache.hadoop.hbase.client.Connection</span>;
<span class="keyword">import</span> <span class="include">org.apache.hadoop.hbase.client.ConnectionFactory</span>;
<span class="keyword">import</span> <span class="include">org.apache.hadoop.hbase.io.compress.Compression.Algorithm</span>;

<span class="directive">public</span> <span class="type">class</span> <span class="class">Example</span> {

  <span class="directive">private</span> <span class="directive">static</span> <span class="directive">final</span> <span class="predefined-type">String</span> TABLE_NAME = <span class="string"><span class="delimiter">&quot;</span><span class="content">MY_TABLE_NAME_TOO</span><span class="delimiter">&quot;</span></span>;
  <span class="directive">private</span> <span class="directive">static</span> <span class="directive">final</span> <span class="predefined-type">String</span> CF_DEFAULT = <span class="string"><span class="delimiter">&quot;</span><span class="content">DEFAULT_COLUMN_FAMILY</span><span class="delimiter">&quot;</span></span>;

  <span class="directive">public</span> <span class="directive">static</span> <span class="type">void</span> createOrOverwrite(Admin admin, HTableDescriptor table) <span class="directive">throws</span> <span class="exception">IOException</span> {
    <span class="keyword">if</span> (admin.tableExists(table.getTableName())) {
      admin.disableTable(table.getTableName());
      admin.deleteTable(table.getTableName());
    }
    admin.createTable(table);
  }

  <span class="directive">public</span> <span class="directive">static</span> <span class="type">void</span> createSchemaTables(<span class="predefined-type">Configuration</span> config) <span class="directive">throws</span> <span class="exception">IOException</span> {
    <span class="keyword">try</span> (<span class="predefined-type">Connection</span> connection = ConnectionFactory.createConnection(config);
         Admin admin = connection.getAdmin()) {

      HTableDescriptor table = <span class="keyword">new</span> HTableDescriptor(TableName.valueOf(TABLE_NAME));
      table.addFamily(<span class="keyword">new</span> HColumnDescriptor(CF_DEFAULT).setCompressionType(Algorithm.SNAPPY));

      <span class="predefined-type">System</span>.out.print(<span class="string"><span class="delimiter">&quot;</span><span class="content">Creating table. </span><span class="delimiter">&quot;</span></span>);
      createOrOverwrite(admin, table);
      <span class="predefined-type">System</span>.out.println(<span class="string"><span class="delimiter">&quot;</span><span class="content"> Done.</span><span class="delimiter">&quot;</span></span>);
    }
  }

  <span class="directive">public</span> <span class="directive">static</span> <span class="type">void</span> modifySchema (<span class="predefined-type">Configuration</span> config) <span class="directive">throws</span> <span class="exception">IOException</span> {
    <span class="keyword">try</span> (<span class="predefined-type">Connection</span> connection = ConnectionFactory.createConnection(config);
         Admin admin = connection.getAdmin()) {

      TableName tableName = TableName.valueOf(TABLE_NAME);
      <span class="keyword">if</span> (admin.tableExists(tableName)) {
        <span class="predefined-type">System</span>.out.println(<span class="string"><span class="delimiter">&quot;</span><span class="content">Table does not exist.</span><span class="delimiter">&quot;</span></span>);
        <span class="predefined-type">System</span>.exit(-<span class="integer">1</span>);
      }

      HTableDescriptor table = <span class="keyword">new</span> HTableDescriptor(tableName);

      <span class="comment">// Update existing table</span>
      HColumnDescriptor newColumn = <span class="keyword">new</span> HColumnDescriptor(<span class="string"><span class="delimiter">&quot;</span><span class="content">NEWCF</span><span class="delimiter">&quot;</span></span>);
      newColumn.setCompactionCompressionType(Algorithm.GZ);
      newColumn.setMaxVersions(HConstants.ALL_VERSIONS);
      admin.addColumn(tableName, newColumn);

      <span class="comment">// Update existing column family</span>
      HColumnDescriptor existingColumn = <span class="keyword">new</span> HColumnDescriptor(CF_DEFAULT);
      existingColumn.setCompactionCompressionType(Algorithm.GZ);
      existingColumn.setMaxVersions(HConstants.ALL_VERSIONS);
      table.modifyFamily(existingColumn);
      admin.modifyTable(tableName, table);

      <span class="comment">// Disable an existing table</span>
      admin.disableTable(tableName);

      <span class="comment">// Delete an existing column family</span>
      admin.deleteColumn(tableName, CF_DEFAULT.getBytes(<span class="string"><span class="delimiter">&quot;</span><span class="content">UTF-8</span><span class="delimiter">&quot;</span></span>));

      <span class="comment">// Delete a table (Need to be disabled first)</span>
      admin.deleteTable(tableName);
    }
  }

  <span class="directive">public</span> <span class="directive">static</span> <span class="type">void</span> main(<span class="predefined-type">String</span>... args) <span class="directive">throws</span> <span class="exception">IOException</span> {
    <span class="predefined-type">Configuration</span> config = HBaseConfiguration.create();

    <span class="comment">//Add any necessary configuration files (hbase-site.xml, core-site.xml)</span>
    config.addResource(<span class="keyword">new</span> Path(<span class="predefined-type">System</span>.getenv(<span class="string"><span class="delimiter">&quot;</span><span class="content">HBASE_CONF_DIR</span><span class="delimiter">&quot;</span></span>), <span class="string"><span class="delimiter">&quot;</span><span class="content">hbase-site.xml</span><span class="delimiter">&quot;</span></span>));
    config.addResource(<span class="keyword">new</span> Path(<span class="predefined-type">System</span>.getenv(<span class="string"><span class="delimiter">&quot;</span><span class="content">HADOOP_CONF_DIR</span><span class="delimiter">&quot;</span></span>), <span class="string"><span class="delimiter">&quot;</span><span class="content">core-site.xml</span><span class="delimiter">&quot;</span></span>));
    createSchemaTables(config);
    modifySchema(config);
  }
}</code></pre>
</div>
</div>
</div>
</div>
</div>
</div>
<h1 id="external_apis" class="sect0"><a class="anchor" href="#external_apis"></a> Apache HBase外部API</h1>
<div class="openblock partintro">
<div class="content">本章将介绍通过非Java语言或通过自定义协议对Apache HBase的访问。有关使用本机HBase API的信息，请参阅《 <a href="http://hbase.apache.org/apidocs/index.html">用户API参考》</a>和新的《 <a href="#hbase_apis">HBase API》</a>一章。
</div>
</div>
<div class="sect1">
<h2 id="nonjava.jvm"><a class="anchor" href="#nonjava.jvm"></a> 73。非Java语言与JVM对话</h2>
<div class="sectionbody">
<div class="paragraph">
<p>当前，有关此主题的文档位于<a href="http://wiki.apache.org/hadoop/Hbase">Apache HBase Wiki中</a> 。另请参见<a href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/thrift/package-summary.html#package_description">Thrift API Javadoc</a> 。</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_rest"><a class="anchor" href="#_rest"></a> 74。休息</h2>
<div class="sectionbody">
<div class="paragraph">
<p>当前，大多数有关REST的文档都存在于REST上的<a href="http://wiki.apache.org/hadoop/Hbase/Stargate">Apache HBase Wiki中</a> （REST网关以前称为“ Stargate”）。关于<a href="http://blog.cloudera.com/blog/2013/03/how-to-use-the-apache-hbase-rest-interface-part-1/">如何使用方法，</a>也有很多不错的博客<a href="http://blog.cloudera.com/blog/2013/03/how-to-use-the-apache-hbase-rest-interface-part-1/">：</a> Jesse Anderson <a href="http://blog.cloudera.com/blog/2013/03/how-to-use-the-apache-hbase-rest-interface-part-1/">撰写的使用Apache HBase REST接口</a> 。</p>
</div>
<div class="paragraph">
<p>要在SSL下运行REST服务器，请设置<code>hbase.rest.ssl.enabled</code>至<code>true</code>并在启动REST服务器时设置以下配置：（请参阅<a href="#jmx_config">JMX config中的</a>示例命令）</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">hbase.rest.ssl.keystore.store
hbase.rest.ssl.keystore.password
hbase.rest.ssl.keystore.keypassword</code></pre>
</div>
</div>
<div class="paragraph">
<p>HBase附带了一个简单的REST客户端，有关详细信息，请参阅<a href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/rest/client/package-summary.html">REST客户端</a>软件包。要为此启用SSL支持，还请将您的证书导入本地java cacerts密钥库：</p>
</div>
<div class="listingblock">
<div class="content">
<pre>keytool -import -trustcacerts -file /home/user/restserver.cert -keystore $JAVA_HOME/jre/lib/security/cacerts</pre>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_thrift"><a class="anchor" href="#_thrift"></a> 75。节约</h2>
<div class="sectionbody">
<div class="paragraph">
<p>有关Thrift的文档已移至<a href="#thrift">Thrift API和过滤器语言</a> 。</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="c"><a class="anchor" href="#c"></a> 76。C / C ++ Apache HBase客户端</h2>
<div class="sectionbody">
<div class="paragraph">
<p>FB的Chip Turner编写了一个纯C / C ++客户端。
<a href="https://github.com/facebook/native-cpp-hbase-client">检查一下</a> 。</p>
</div>
</div>
</div>
<h1 id="thrift" class="sect0"><a class="anchor" href="#thrift"></a>节俭API和过滤器语言</h1>
<div class="openblock partintro">
<div class="content">
<div class="paragraph">
<p>Apache <a href="http://thrift.apache.org/">Thrift</a>是一个跨平台，跨语言的开发框架。HBase包括Thrift API和过滤器语言。Thrift API依赖于客户端和服务器进程。有关HBase Thrift API的文档位于<a href="http://wiki.apache.org/hadoop/Hbase/ThriftApi" class="bare">http://wiki.apache.org/hadoop/Hbase/ThriftApi</a> 。</p>
</div>
<div class="paragraph">
<p>您可以按照<a href="#security.client.thrift">客户端安全操作</a> <a href="#security.gateway.thrift">配置</a> <a href="#security.client.thrift">-Thrift网关中的过程，</a>以及<a href="#security.gateway.thrift">配置Thrift网关代表客户端进行身份</a>验证，在服务器和客户端上配置Thrift以进行安全身份验证。</p>
</div>
<div class="paragraph">
<p>本章的其余部分讨论了Thrift API提供的过滤器语言。</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="thrift.filter_language"><a class="anchor" href="#thrift.filter_language"></a> 77。筛选语言</h2>
<div class="sectionbody">
<div class="paragraph">
<p>HBase 0.92中引入了节俭过滤器语言。通过Thrift或在HBase Shell中访问HBase时，它允许您执行服务器端过滤。您可以通过使用<code>scan help</code>在shell中执行命令。</p>
</div>
<div class="paragraph">
<p>您将过滤器指定为字符串，该字符串将在服务器上解析以构造过滤器。</p>
</div>
<div class="sect2">
<h3 id="general_syntax"><a class="anchor" href="#general_syntax"></a> 77.1。通用过滤器字符串语法</h3>
<div class="paragraph">
<p>一个简单的过滤器表达式表示为一个字符串：</p>
</div>
<div class="listingblock">
<div class="content">
<pre>“FilterName (argument, argument,... , argument)”</pre>
</div>
</div>
<div class="paragraph">
<p>请牢记以下语法准则。</p>
</div>
<div class="ulist">
<ul>
<li>
<p>指定过滤器的名称，然后在括号中指定逗号分隔的参数列表。</p>
</li>
<li>
<p>如果参数代表字符串，则应将其括在单引号（ <code>'</code> ）。</p>
</li>
<li>
<p>表示布尔值，整数或比较运算符（例如<，>或！=），不应该用引号引起来</p>
</li>
<li>
<p>过滤器名称必须是一个单词。允许使用所有ASCII字符，但空格，单引号和括号除外。</p>
</li>
<li>
<p>过滤器的参数可以包含任何ASCII字符。如果参数中包含单引号，则必须在前面加上一个附加的单引号。</p>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="_compound_filters_and_operators"><a class="anchor" href="#_compound_filters_and_operators"></a> 77.2。复合过滤器和运算符</h3>
<div class="dlist">
<div class="title">二元运算符</div>
<dl>
<dt class="hdlist1"><code>AND</code></dt>
<dd>
<p>如果<code>AND</code>使用运算符时，键值必须同时满足两个过滤条件。</p>
</dd>
<dt class="hdlist1"><code>OR</code></dt>
<dd>
<p>如果<code>OR</code>如果使用运算符，则键值必须满足至少一个过滤条件。</p>
</dd>
</dl>
</div>
<div class="dlist">
<div class="title">一元运算符</div>
<dl>
<dt class="hdlist1"><code>SKIP</code></dt>
<dd>
<p>对于特定行，如果任何键值均未通过过滤条件，则将跳过整行。</p>
</dd>
<dt class="hdlist1"><code>WHILE</code></dt>
<dd>
<p>对于特定行，将发射键值，直到达到失败的过滤条件的键值为止。</p>
</dd>
</dl>
</div>
<div class="exampleblock">
<div class="title">示例38。复合运算符</div>
<div class="content">
<div class="paragraph">
<p>您可以组合多个运算符来创建过滤器层次结构，例如以下示例：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">(Filter1 AND Filter2) OR (Filter3 AND Filter4)</code></pre>
</div>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_order_of_evaluation"><a class="anchor" href="#_order_of_evaluation"></a> 77.3。评估顺序</h3>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>括号的优先级最高。</p>
</li>
<li>
<p>一元运算符<code>SKIP</code>和<code>WHILE</code>是下一个，并且具有相同的优先级。</p>
</li>
<li>
<p>二进制运算符跟随。 <code>AND</code>优先级最高，其次<code>OR</code> 。</p>
</li>
</ol>
</div>
<div class="exampleblock">
<div class="title">示例39。优先示例</div>
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">Filter1 AND Filter2 OR <span class="predefined-type">Filter</span>
is evaluated as
(Filter1 AND Filter2) OR Filter3</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">Filter1 AND SKIP Filter2 OR Filter3
is evaluated as
(Filter1 AND (SKIP Filter2)) OR Filter3</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>您可以使用括号显式控制评估的顺序。</p>
</div>
</div>
<div class="sect2">
<h3 id="_compare_operator"><a class="anchor" href="#_compare_operator"></a> 77.4。比较运算符</h3>
<div class="paragraph">
<p>提供了以下比较运算符：</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>少（<）</p>
</li>
<li>
<p>LESS_OR_EQUAL（⇐）</p>
</li>
<li>
<p>等于（=）</p>
</li>
<li>
<p>NOT_EQUAL（！=）</p>
</li>
<li>
<p>GREATER_OR_EQUAL（> =）</p>
</li>
<li>
<p>更大（>）</p>
</li>
<li>
<p>NO_OP（无操作）</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>客户应使用符号（<，⇐，=，！=，>，> =）表示比较运算符。</p>
</div>
</div>
<div class="sect2">
<h3 id="_comparator"><a class="anchor" href="#_comparator"></a> 77.5。比较器</h3>
<div class="paragraph">
<p>比较器可以是以下任意一个：</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><em>BinaryComparator-</em>使用Bytes.compareTo（byte []，byte []）在字典上与指定的字节数组进行比较</p>
</li>
<li>
<p><em>BinaryPrefixComparator-</em>在字典上与指定的字节数组进行比较。它仅比较该字节数组的长度。</p>
</li>
<li>
<p><em>RegexStringComparator-</em>使用给定的正则表达式将其与指定的字节数组进行比较。此比较器仅EQUAL和NOT_EQUAL比较有效</p>
</li>
<li>
<p><em>SubStringComparator-</em>测试给定的子字符串是否出现在指定的字节数组中。比较不区分大小写。此比较器仅EQUAL和NOT_EQUAL比较有效</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>比较器的一般语法为：<code>ComparatorType:ComparatorValue</code></p>
</div>
<div class="paragraph">
<p>各种比较器的ComparatorType如下：</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><em>BinaryComparator-</em>二进制</p>
</li>
<li>
<p><em>BinaryPrefixComparator</em> -binaryprefix</p>
</li>
<li>
<p><em>RegexStringComparator</em> -regexstring</p>
</li>
<li>
<p><em>SubStringComparator-</em>子字符串</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>ComparatorValue可以是任何值。</p>
</div>
<div class="olist arabic">
<div class="title">示例比较器值</div>
<ol class="arabic">
<li>
<p><code>binary:abc</code>将匹配在字典上大于“ abc”的所有内容</p>
</li>
<li>
<p><code>binaryprefix:abc</code>将匹配在字典上前三个字符等于“ abc”的所有字符</p>
</li>
<li>
<p><code>regexstring:ab*yz</code>将匹配所有不以“ ab”开头且以“ yz”结尾的内容</p>
</li>
<li>
<p><code>substring:abc123</code>将匹配以子字符串“ abc123”开头的所有内容</p>
</li>
</ol>
</div>
</div>
<div class="sect2">
<h3 id="examplephpclientprogram"><a class="anchor" href="#examplephpclientprogram"></a> 77.6。使用过滤器语言的示例PHP客户端程序</h3>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="php"><span class="inline-delimiter">&lt;?</span>
  <span class="predefined">$_SERVER</span>[<span class="string"><span class="delimiter">'</span><span class="content">PHP_ROOT</span><span class="delimiter">'</span></span>] = <span class="predefined">realpath</span>(<span class="predefined">dirname</span>(<span class="predefined-constant">__FILE__</span>).<span class="string"><span class="delimiter">'</span><span class="content">/..</span><span class="delimiter">'</span></span>);
  <span class="predefined">require_once</span> <span class="predefined">$_SERVER</span>[<span class="string"><span class="delimiter">'</span><span class="content">PHP_ROOT</span><span class="delimiter">'</span></span>].<span class="string"><span class="delimiter">'</span><span class="content">/flib/__flib.php</span><span class="delimiter">'</span></span>;
  flib_init(<span class="constant">FLIB_CONTEXT_SCRIPT</span>);
  require_module(<span class="string"><span class="delimiter">'</span><span class="content">storage/hbase</span><span class="delimiter">'</span></span>);
  <span class="local-variable">$hbase</span> = <span class="keyword">new</span> <span class="constant">HBase</span>(<span class="string"><span class="delimiter">'</span><span class="content">&lt;server_name_running_thrift_server&gt;</span><span class="delimiter">'</span></span>, &lt;port on which thrift server is running&gt;);
  <span class="local-variable">$hbase</span>-&gt;open();
  <span class="local-variable">$client</span> = <span class="local-variable">$hbase</span>-&gt;getClient();
  <span class="local-variable">$result</span> = <span class="local-variable">$client</span>-&gt;scannerOpenWithFilterString(<span class="string"><span class="delimiter">'</span><span class="content">table_name</span><span class="delimiter">'</span></span>, <span class="string"><span class="delimiter">&quot;</span><span class="content">(PrefixFilter ('row2') AND (QualifierFilter (&gt;=, 'binary:xyz'))) AND (TimestampsFilter ( 123, 456))</span><span class="delimiter">&quot;</span></span>);
  <span class="local-variable">$to_print</span> = <span class="local-variable">$client</span>-&gt;scannerGetList(<span class="local-variable">$result</span>,<span class="integer">1</span>);
  <span class="keyword">while</span> (<span class="local-variable">$to_print</span>) {
    <span class="predefined">print_r</span>(<span class="local-variable">$to_print</span>);
    <span class="local-variable">$to_print</span> = <span class="local-variable">$client</span>-&gt;scannerGetList(<span class="local-variable">$result</span>,<span class="integer">1</span>);
  }
  <span class="local-variable">$client</span>-&gt;scannerClose(<span class="local-variable">$result</span>);
<span class="inline-delimiter">?&gt;</span></code></pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_example_filter_strings"><a class="anchor" href="#_example_filter_strings"></a> 77.7。过滤字符串示例</h3>
<div class="ulist">
<ul>
<li>
<p><code>"PrefixFilter ('Row') AND PageFilter (1) AND FirstKeyOnlyFilter ()"</code>将返回符合以下条件的所有键值对：</p>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>包含键值的行应具有前缀<em>Row</em></p>
</li>
<li>
<p>键值必须位于表格的第一行</p>
</li>
<li>
<p>键值对必须是该行中的第一个键值</p>
</li>
</ol>
</div>
</li>
<li>
<p><code>"(RowFilter (=, 'binary:Row 1') AND TimeStampsFilter (74689, 89734)) OR ColumnRangeFilter ('abc', true, 'xyz', false))"</code>将返回符合以下两个条件的所有键值对：</p>
<div class="ulist">
<ul>
<li>
<p>键值位于具有行键<em>Row 1的行中</em></p>
</li>
<li>
<p>键值的时间戳记必须为74689或89734。</p>
</li>
<li>
<p>或者它必须满足以下条件：</p>
<div class="ulist">
<ul>
<li>
<p>键值对必须位于按字典顺序> = abc和<xyz的列中</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</li>
<li>
<p><code>"SKIP ValueFilter (0)"</code>如果该行中的任何值不为0，将跳过整行</p>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="individualfiltersyntax"><a class="anchor" href="#individualfiltersyntax"></a> 77.8。个别过滤器语法</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">KeyOnlyFilter</dt>
<dd>
<p>此过滤器不接受任何参数。它仅返回每个键值的键组成部分。</p>
</dd>
<dt class="hdlist1">FirstKeyOnlyFilter</dt>
<dd>
<p>此过滤器不接受任何参数。它仅返回每行的第一个键值。</p>
</dd>
<dt class="hdlist1">PrefixFilter</dt>
<dd>
<p>此过滤器采用一个参数–行键的前缀。它仅返回以指定行前缀开头的行中存在的那些键值</p>
</dd>
<dt class="hdlist1">ColumnPrefixFilter</dt>
<dd>
<p>该过滤器采用一个参数–列前缀。它仅返回存在于以指定列前缀开头的列中的那些键值。列前缀的格式必须为： <code>“qualifier”</code> 。</p>
</dd>
<dt class="hdlist1">MultipleColumnPrefixFilter</dt>
<dd>
<p>此过滤器采用列前缀列表。它返回存在于以任何指定列前缀开头的列中的键值。每个列前缀都必须采用以下格式： <code>“qualifier”</code> 。</p>
</dd>
<dt class="hdlist1">ColumnCountGetFilter</dt>
<dd>
<p>此过滤器采用一个参数-一个限制。它返回表中的第一个限制列数。</p>
</dd>
<dt class="hdlist1">页面过滤器</dt>
<dd>
<p>此过滤器采用一个参数–页面大小。它从表中返回页面大小的行数。</p>
</dd>
<dt class="hdlist1">ColumnPaginationFilter</dt>
<dd>
<p>该过滤器采用两个参数–限制和偏移量。在偏移列数之后返回限制列数。它为所有行执行此操作。</p>
</dd>
<dt class="hdlist1">InclusiveStopFilter</dt>
<dd>
<p>该过滤器采用一个参数–行键，停止扫描。它返回直到指定行为止（包括指定行）的所有键值。</p>
</dd>
<dt class="hdlist1">时间戳过滤器</dt>
<dd>
<p>该过滤器采用时间戳列表。它返回那些时间戳与任何指定时间戳匹配的键值。</p>
</dd>
<dt class="hdlist1">行过滤器</dt>
<dd>
<p>该过滤器带有一个比较运算符和一个比较器。它使用比较运算符将每个行键与比较器进行比较，如果比较返回true，则返回该行中的所有键值。</p>
</dd>
<dt class="hdlist1">家庭过滤器</dt>
<dd>
<p>该过滤器带有一个比较运算符和一个比较器。它使用比较运算符将每个限定符名称与比较器进行比较，如果比较返回true，则将返回该列中的所有键值。</p>
</dd>
<dt class="hdlist1">QualifierFilter</dt>
<dd>
<p>该过滤器带有一个比较运算符和一个比较器。它使用比较运算符将每个限定符名称与比较器进行比较，如果比较返回true，则将返回该列中的所有键值。</p>
</dd>
<dt class="hdlist1">值过滤器</dt>
<dd>
<p>该过滤器带有一个比较运算符和一个比较器。它使用比较运算符将每个值与比较器进行比较，如果比较返回true，则返回该键值。</p>
</dd>
<dt class="hdlist1">DependentColumnFilter</dt>
<dd>
<p>该过滤器接受两个参数-家庭和限定词。它尝试在每一行中定位此列，并返回该行中所有具有相同时间戳的键值。如果该行不包含指定的列-该行中的任何键值均不会返回。</p>
</dd>
<dt class="hdlist1">SingleColumnValueFilter</dt>
<dd>
<p>该过滤器包含一个列族，一个限定符，一个比较运算符和一个比较器。如果找不到指定的列，则将发射该行的所有列。如果找到该列，并且与比较器的比较返回true，则将发出该行的所有列。如果条件失败，则不会发出该行。</p>
</dd>
<dt class="hdlist1">SingleColumnValueExcludeFilter</dt>
<dd>
<p>该过滤器采用相同的参数，其行为与SingleColumnValueFilter相同–但是，如果找到该列并且条件通过，则将发射该行的所有列，但测试的列值除外。</p>
</dd>
<dt class="hdlist1">ColumnRangeFilter</dt>
<dd>
<p>此过滤器仅用于选择列在minColumn和maxColumn之间的键。它还需要两个布尔变量来指示是否包括minColumn和maxColumn。</p>
</dd>
</dl>
</div>
</div>
</div>
</div>
<h1 id="cp" class="sect0"><a class="anchor" href="#cp"></a> Apache HBase协处理器</h1>
<div class="openblock partintro">
<div class="content">
<div class="paragraph">
<p>HBase协处理器以Google BigTable（ <a href="http://www.scribd.com/doc/21631448/Dean-Keynote-Ladis2009" class="bare">http://www.scribd.com/doc/21631448/Dean-Keynote-Ladis2009</a> ，第66-67页）中的协处理器为模型。协处理器的功能类似于Linux内核模块。它们提供了一种对本地存储的数据运行服务器级代码的方法。它们提供的功能非常强大，但也带来很大的风险，并且可能会对操作系统级别的系统产生不利影响。本章中的信息主要来自赖明杰的博客， <a href="https://blogs.apache.org/hbase/entry/coprocessor_introduction" class="bare">网址</a>为<a href="https://blogs.apache.org/hbase/entry/coprocessor_introduction" class="bare">https://blogs.apache.org/hbase/entry/coprocessor_introduction</a> 。</p>
</div>
<div class="paragraph">
<p>协处理器不是为HBase的最终用户设计的，而是由需要向HBase添加专门功能的HBase开发人员使用的。使用协处理器的一个示例是可插拔压缩和扫描策略，它们在<a href="https://issues.apache.org/jira/browse/HBASE-6427">HBASE-6427中</a>作为协处理器提供。</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_coprocessor_framework"><a class="anchor" href="#_coprocessor_framework"></a> 78。协处理器框架</h2>
<div class="sectionbody">
<div class="paragraph">
<p>HBase协处理器的实现与BigTable实现不同。HBase框架提供了一个库和运行时环境，用于在HBase区域服务器和主进程中执行用户代码。</p>
</div>
<div class="paragraph">
<p><a href="https://hbase.apache.org/apidocs/org/apache/hadoop/hbase/coprocessor/package-summary.html">协处理器</a>程序包中提供了框架API。</p>
</div>
<div class="paragraph">
<p>框架根据其范围提供两种不同类型的协处理器。</p>
</div>
<div class="dlist">
<div class="title">协处理器的类型</div>
<dl>
<dt class="hdlist1">系统协处理器</dt>
<dd>
<p>系统协处理器全局加载在区域服务器托管的所有表和区域上。</p>
</dd>
<dt class="hdlist1">表协处理器</dt>
<dd>
<p>您可以按表指定应在表的所有区域上加载哪些协处理器。</p>
</dd>
</dl>
</div>
<div class="paragraph">
<p>该框架还提供了扩展的两个不同方面： <em>观察者</em>和<em>终结点</em> 。</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">观察员</dt>
<dd>
<p>观察者类似于常规数据库中的触发器。它们允许您通过覆盖协处理器框架提供的上行调用方法来插入用户代码。发生事件时，将从HBase核心代码执行回调函数。回调由框架处理，协处理器本身仅需要插入扩展功能或备用功能。</p>
</dd>
<dt class="hdlist1">端点（HBase 0.96.x和更高版本）</dt>
<dd>
<p>由于引入了协议缓冲区（protobufs）（ <a href="https://issues.apache.org/jira/browse/HBASE-5448">HBASE-5488</a> ），因此在HBase 0.96.x中，端点的实现发生了显着变化。如果在0.96.x之前创建端点，则需要重写它们。现在定义了端点并将其称为protobuf服务，而不是作为可写Blob传递的端点调用</p>
</dd>
<dt class="hdlist1">端点（HBase 0.94.x和更早版本）</dt>
<dd>
<p>动态RPC端点类似于存储过程。可以随时从客户端调用端点。调用它时，它将在一个或多个目标区域中远程执行，并将执行结果返回给客户端。</p>
</dd>
</dl>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_examples_2"><a class="anchor" href="#_examples_2"></a> 79。例子</h2>
<div class="sectionbody">
<div class="paragraph">
<p><em>hbase-examples / src / test / java / org / apache / hadoop / hbase / coprocessor / example / TestZooKeeperScanPolicyObserver.java中包含观察者的示例</em> 。同一目录中包含几个端点示例。</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_building_a_coprocessor"><a class="anchor" href="#_building_a_coprocessor"></a> 80。构建协处理器</h2>
<div class="sectionbody">
<div class="paragraph">
<p>在构建处理器之前，必须先将其开发，编译和打包为JAR文件。下一步是配置协处理器框架以使用您的协处理器。您可以从HBase配置中加载协处理器，以便协处理器以HBase开头，也可以从HBase Shell配置协处理器作为表属性，以便在打开或重新打开表时动态加载该协处理器。</p>
</div>
<div class="sect2">
<h3 id="_load_from_configuration"><a class="anchor" href="#_load_from_configuration"></a> 80.1。从配置加载</h3>
<div class="paragraph">
<p>若要配置要在HBase启动时加载的协处理器，请根据要配置的观察者的类型，修改RegionServer的<em>hbase-site.xml</em>并配置以下属性之一：</p>
</div>
<div class="ulist">
<ul>
<li>
<p>用于RegionObservers和端点的hbase.coprocessor.region.classes</p>
</li>
<li>
<p>WALObservers的hbase.coprocessor.wal.classes</p>
</li>
<li>
<p>MasterObservers的hbase.coprocessor.master.classes</p>
</li>
</ul>
</div>
<div class="exampleblock">
<div class="title">示例40示例RegionObserver配置</div>
<div class="content">
<div class="paragraph">
<p>在此示例中，为所有HBase表配置了一个RegionObserver。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="xml"><span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>hbase.coprocessor.region.classes<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>org.apache.hadoop.hbase.coprocessor.AggregateImplementation<span class="tag">&lt;/value&gt;</span>
<span class="tag">&lt;/property&gt;</span></code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>如果为加载指定了多个类别，则类别名称必须用逗号分隔。框架尝试使用默认的类加载器来加载所有配置的类。因此，jar文件必须驻留在服务器端HBase类路径上。</p>
</div>
<div class="paragraph">
<p>以这种方式加载的协处理器将在所有表的所有区域上处于活动状态。这些是前面介绍的系统协处理器。首先列出的协处理器将被分配优先级<code>Coprocessor.Priority.SYSTEM</code> 。列表中的每个后续协处理器将使其优先级值增加1（这会降低其优先级，因为优先级具有整数的自然排序顺序）。</p>
</div>
<div class="paragraph">
<p>当调用注册的观察者时，框架将按照其优先级的排序顺序执行其回调方法。领带被任意打破。</p>
</div>
</div>
<div class="sect2">
<h3 id="_load_from_the_hbase_shell"><a class="anchor" href="#_load_from_the_hbase_shell"></a> 80.2。从HBase Shell加载</h3>
<div class="paragraph">
<p>您可以通过表属性在特定表上加载协处理器。以下示例将加载<code>FooRegionObserver</code>观察者何时表<code>t1</code>被读取或重新读取。</p>
</div>
<div class="exampleblock">
<div class="title">示例41。使用HBase Shell在表上加载协处理器</div>
<div class="content">
<div class="listingblock">
<div class="content">
<pre>hbase(main):005:0&gt;  alter 't1', METHOD =&gt; 'table_att',
  'coprocessor'=&gt;'hdfs:///foo.jar|com.foo.FooRegionObserver|1001|arg1=1,arg2=2'
Updating all regions with the new schema...
1/1 regions updated.
Done.
0 row(s) in 1.0730 seconds

hbase(main):006:0&gt; describe 't1'
DESCRIPTION                                                        ENABLED
 {NAME =&gt; 't1', coprocessor$1 =&gt; 'hdfs:///foo.jar|com.foo.FooRegio false
 nObserver|1001|arg1=1,arg2=2', FAMILIES =&gt; [{NAME =&gt; 'c1', DATA_B
 LOCK_ENCODING =&gt; 'NONE', BLOOMFILTER =&gt; 'NONE', REPLICATION_SCOPE
  =&gt; '0', VERSIONS =&gt; '3', COMPRESSION =&gt; 'NONE', MIN_VERSIONS =&gt;
 '0', TTL =&gt; '2147483647', KEEP_DELETED_CELLS =&gt; 'false', BLOCKSIZ
 E =&gt; '65536', IN_MEMORY =&gt; 'false', ENCODE_ON_DISK =&gt; 'true', BLO
 CKCACHE =&gt; 'true'}, {NAME =&gt; 'f1', DATA_BLOCK_ENCODING =&gt; 'NONE',
  BLOOMFILTER =&gt; 'NONE', REPLICATION_SCOPE =&gt; '0', VERSIONS =&gt; '3'
 , COMPRESSION =&gt; 'NONE', MIN_VERSIONS =&gt; '0', TTL =&gt; '2147483647'
 , KEEP_DELETED_CELLS =&gt; 'false', BLOCKSIZE =&gt; '65536', IN_MEMORY
 =&gt; 'false', ENCODE_ON_DISK =&gt; 'true', BLOCKCACHE =&gt; 'true'}]}
1 row(s) in 0.0190 seconds</pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>协处理器框架将尝试从协处理器表属性值中读取类信息。该值包含四条信息，这些信息由<code>|</code>字符。</p>
</div>
<div class="ulist">
<ul>
<li>
<p>文件路径：包含协处理器实现的jar文件必须位于所有区域服务器都可以读取的位置。您可以将文件复制到每个区域服务器上的本地磁盘上，但是建议将其存储在HDFS中。</p>
</li>
<li>
<p>类名：协处理器的完整类名。</p>
</li>
<li>
<p>优先级：整数。框架将使用优先级确定在同一钩子上注册的所有已配置观察者的执行顺序。该字段可以留为空白。在这种情况下，框架将分配默认优先级值。</p>
</li>
<li>
<p>参数：此字段传递给协处理器实现。</p>
</li>
</ul>
</div>
<div class="exampleblock">
<div class="title">示例42。使用HBase Shell从表中卸载协处理器</div>
<div class="content">
<div class="listingblock">
<div class="content">
<pre>hbase(main):007:0&gt; alter 't1', METHOD =&gt; 'table_att_unset',
hbase(main):008:0*   NAME =&gt; 'coprocessor$1'
Updating all regions with the new schema...
1/1 regions updated.
Done.
0 row(s) in 1.1130 seconds

hbase(main):009:0&gt; describe 't1'
DESCRIPTION                                                        ENABLED
 {NAME =&gt; 't1', FAMILIES =&gt; [{NAME =&gt; 'c1', DATA_BLOCK_ENCODING =&gt; false
  'NONE', BLOOMFILTER =&gt; 'NONE', REPLICATION_SCOPE =&gt; '0', VERSION
 S =&gt; '3', COMPRESSION =&gt; 'NONE', MIN_VERSIONS =&gt; '0', TTL =&gt; '214
 7483647', KEEP_DELETED_CELLS =&gt; 'false', BLOCKSIZE =&gt; '65536', IN
 _MEMORY =&gt; 'false', ENCODE_ON_DISK =&gt; 'true', BLOCKCACHE =&gt; 'true
 '}, {NAME =&gt; 'f1', DATA_BLOCK_ENCODING =&gt; 'NONE', BLOOMFILTER =&gt;
 'NONE', REPLICATION_SCOPE =&gt; '0', VERSIONS =&gt; '3', COMPRESSION =&gt;
  'NONE', MIN_VERSIONS =&gt; '0', TTL =&gt; '2147483647', KEEP_DELETED_C
 ELLS =&gt; 'false', BLOCKSIZE =&gt; '65536', IN_MEMORY =&gt; 'false', ENCO
 DE_ON_DISK =&gt; 'true', BLOCKCACHE =&gt; 'true'}]}
1 row(s) in 0.0180 seconds</pre>
</div>
</div>
</div>
</div>
<div class="admonitionblock warning">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-warning" title="警告"></i>
</td>
<td class="content">无法保证框架会成功加载给定的协处理器。例如，shell命令既不能保证jar文件存在于特定位置，也不能验证给定的类是否实际上包含在jar文件中。
</td>
</tr>
</tbody></table>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_check_the_status_of_a_coprocessor"><a class="anchor" href="#_check_the_status_of_a_coprocessor"></a> 81。检查协处理器的状态</h2>
<div class="sectionbody">
<div class="paragraph">
<p>要在配置协处理器后检查其状态，请使用<code>status</code> HBase Shell命令。</p>
</div>
<div class="listingblock">
<div class="content">
<pre>hbase(main):020:0&gt; status 'detailed'
version 0.92-tm-6
0 regionsInTransition
master coprocessors: []
1 live servers
    localhost:52761 1328082515520
        requestsPerSecond=3, numberOfOnlineRegions=3, usedHeapMB=32, maxHeapMB=995
        -ROOT-,,0
            numberOfStores=1, numberOfStorefiles=1, storefileUncompressedSizeMB=0, storefileSizeMB=0, memstoreSizeMB=0,
storefileIndexSizeMB=0, readRequestsCount=54, writeRequestsCount=1, rootIndexSizeKB=0, totalStaticIndexSizeKB=0,
totalStaticBloomSizeKB=0, totalCompactingKVs=0, currentCompactedKVs=0, compactionProgressPct=NaN, coprocessors=[]
        .META.,,1
            numberOfStores=1, numberOfStorefiles=0, storefileUncompressedSizeMB=0, storefileSizeMB=0, memstoreSizeMB=0,
storefileIndexSizeMB=0, readRequestsCount=97, writeRequestsCount=4, rootIndexSizeKB=0, totalStaticIndexSizeKB=0,
totalStaticBloomSizeKB=0, totalCompactingKVs=0, currentCompactedKVs=0, compactionProgressPct=NaN, coprocessors=[]
        t1,,1328082575190.c0491168a27620ffe653ec6c04c9b4d1.
            numberOfStores=2, numberOfStorefiles=1, storefileUncompressedSizeMB=0, storefileSizeMB=0, memstoreSizeMB=0,
storefileIndexSizeMB=0, readRequestsCount=0, writeRequestsCount=0, rootIndexSizeKB=0, totalStaticIndexSizeKB=0,
totalStaticBloomSizeKB=0, totalCompactingKVs=0, currentCompactedKVs=0, compactionProgressPct=NaN,
coprocessors=[AggregateImplementation]
0 dead servers</pre>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_monitor_time_spent_in_coprocessors"><a class="anchor" href="#_monitor_time_spent_in_coprocessors"></a> 82。监视协处理器中花费的时间</h2>
<div class="sectionbody">
<div class="paragraph">
<p>HBase 0.98.5引入了监视某些统计信息的功能，该统计信息与执行给定协处理器所花费的时间有关。您可以通过HBase Metrics框架（通过<em>协处理器Metrics</em>选项卡查看给定的区域服务器的<a href="#hbase_metrics">[hbase_metrics]</a>或Web UI）查看这些统计信息。这些统计信息对于调试和确定给定协处理器对群集的性能影响非常有用。跟踪的统计信息包括最小值，最大值，平均值以及第90、95和99个百分位数。所有时间均以毫秒为单位。统计是根据报告间隔内记录的协处理器执行样本计算得出的，缺省情况下，间隔为10秒。指标采样率，如<a href="#hbase_metrics">[hbase_metrics]中所述</a> 。</p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/coprocessor_stats.png" alt="协处理器统计">
</div>
<div class="title">图4。协处理器指标UI</div>
</div>
</div>
</div>
<h1 id="performance" class="sect0"><a class="anchor" href="#performance"></a> Apache HBase性能调优</h1>
<div class="sect1">
<h2 id="perf.os"><a class="anchor" href="#perf.os"></a> 83。操作系统</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="perf.os.ram"><a class="anchor" href="#perf.os.ram"></a> 83.1。记忆</h3>
<div class="paragraph">
<p>RAM，RAM，RAM。不要饿死HBase。</p>
</div>
</div>
<div class="sect2">
<h3 id="perf.os.64"><a class="anchor" href="#perf.os.64"></a> 83.2。 64位</h3>
<div class="paragraph">
<p>使用64位平台（和64位JVM）。</p>
</div>
</div>
<div class="sect2">
<h3 id="perf.os.swap"><a class="anchor" href="#perf.os.swap"></a> 83.3。交换</h3>
<div class="paragraph">
<p>当心交换。组<code>swappiness</code>到0。</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="perf.network"><a class="anchor" href="#perf.network"></a> 84。网络</h2>
<div class="sectionbody">
<div class="paragraph">
<p>避免网络问题降低Hadoop和HBase性能的最重要因素可能是所使用的交换硬件，当您将群集大小增加一倍或两倍时，在项目范围内早期做出的决定可能会导致严重问题。</p>
</div>
<div class="paragraph">
<p>要考虑的重要事项：</p>
</div>
<div class="ulist">
<ul>
<li>
<p>设备的交换能力</p>
</li>
<li>
<p>连接的系统数</p>
</li>
<li>
<p>上行容量</p>
</li>
</ul>
</div>
<div class="sect2">
<h3 id="perf.network.1switch"><a class="anchor" href="#perf.network.1switch"></a> 84.1。单开关</h3>
<div class="paragraph">
<p>此配置中最重要的一个因素是硬件的交换能力能够处理由连接到交换机的所有系统所产生的流量。某些价格较低的商品硬件的交换容量可能会比完整交换机所使用的交换容量慢。</p>
</div>
</div>
<div class="sect2">
<h3 id="perf.network.2switch"><a class="anchor" href="#perf.network.2switch"></a> 84.2。多个开关</h3>
<div class="paragraph">
<p>多个交换机是架构中的潜在陷阱。价格较低的硬件最常见的配置是从一台交换机到另一台交换机的简单1Gbps上行链路。这个经常被忽略的瓶颈很容易成为集群通信的瓶颈。尤其是对于同时读取和写入大量数据的MapReduce作业，跨此上行链路的通信可能会饱和。</p>
</div>
<div class="paragraph">
<p>缓解此问题非常简单，可以通过多种方式实现：</p>
</div>
<div class="ulist">
<ul>
<li>
<p>对要构建的集群规模使用适当的硬件。</p>
</li>
<li>
<p>使用较大的单交换机配置，即单个48端口而不是2个24端口</p>
</li>
<li>
<p>为上行链路配置端口中继，以利用多个接口来增加跨交换机带宽。</p>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="perf.network.multirack"><a class="anchor" href="#perf.network.multirack"></a> 84.3。多个机架</h3>
<div class="paragraph">
<p>多个机架配置具有与多个交换机相同的潜在问题，并且可能在两个主要方面导致性能下降：</p>
</div>
<div class="ulist">
<ul>
<li>
<p>开关容量性能不佳</p>
</li>
<li>
<p>到另一个机架的上行链路不足</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>如果机架中的交换机具有适当的交换能力以全速处理所有主机，则下一个最可能出现的问题将是通过在机架中放置更多的群集而引起的。跨多个机架时避免问题的最简单方法是使用端口中继来创建到其他机架的绑定上行链路。但是，此方法的缺点是可能要使用的端口的开销。这样的一个例子是，创建一个从机架A到机架B的8Gbps端口通道，使用24个端口中的8个在机架之间进行通信会给您带来较差的ROI，但是使用的端口数太少可能意味着您没有从中获得最大的收益簇。</p>
</div>
<div class="paragraph">
<p>在机架之间使用10Gbe链接将大大提高性能，并且假设您的交换机支持10Gbe上行链路或允许使用扩展卡，则可以为上行链路分配机器的端口。</p>
</div>
</div>
<div class="sect2">
<h3 id="perf.network.ints"><a class="anchor" href="#perf.network.ints"></a> 84.4。网络接口</h3>
<div class="paragraph">
<p>所有网络接口是否正常运行？你确定吗？请参阅<a href="#casestudies.slownode">案例研究1（单个节点中的性能问题）中</a>的故障诊断案例研究。</p>
</div>
</div>
<div class="sect2">
<h3 id="perf.network.call_me_maybe"><a class="anchor" href="#perf.network.call_me_maybe"></a> 84.5。网络一致性和分区容限</h3>
<div class="paragraph">
<p><a href="http://en.wikipedia.org/wiki/CAP_theorem">CAP定理</a>指出，分布式系统可以维护以下三个特征中的两个：-* C *一致性-所有节点都可以看到相同的数据。-* A *可用性-每个请求都会收到有关成功还是失败的响应。-* P *定位公差-即使其中某些组件对其他组件不可用，系统仍将继续运行。</p>
</div>
<div class="paragraph">
<p>HBase支持一致性和分区容忍度，因此必须做出决定。Coda Hale在<a href="http://codahale.com/you-cant-sacrifice-partition-tolerance/" class="bare">http://codahale.com/you-cant-sacrifice-partition-tolerance/中</a>解释了为什么分区容忍如此重要。</p>
</div>
<div class="paragraph">
<p>罗伯特·约科塔（Robert Yokota）使用了一种名为<a href="https://aphyr.com/tags/jepsen">Jepson</a>的自动化测试框架，以Aphyr的<a href="https://aphyr.com/posts/281-call-me-maybe-carly-rae-jepsen-and-the-perils-of-network-partitions">Call Me Maybe</a>系列为模型，对HBase的网络分区容忍度进行了测试。结果以<a href="http://old.eng.yammer.com/call-me-maybe-hbase/">博客文章</a>和<a href="http://old.eng.yammer.com/call-me-maybe-hbase-addendum/">附录的形式</a>显示，表明HBase的性能正常。</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="jvm"><a class="anchor" href="#jvm"></a> 85。爪哇</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="gc"><a class="anchor" href="#gc"></a> 85.1。垃圾收集器和Apache HBase</h3>
<div class="sect3">
<h4 id="gcpause"><a class="anchor" href="#gcpause"></a> 85.1.1。GC长时间停顿</h4>
<div class="paragraph">
<p>在他的演讲“ <a href="http://www.slideshare.net/cloudera/hbase-hug-presentation">避免使用MemStore-Local分配缓冲区的完整GC”中</a> ，Todd Lipcon描述了HBase常见的两种情况，特别是在加载过程中； CMS的失败模式和旧的堆碎片带来了。</p>
</div>
<div class="paragraph">
<p>要解决第一个问题，请通过添加以下内容在默认情况下提前启动CMS： <code>-XX:CMSInitiatingOccupancyFraction</code>并将其设置为默认值。从60％或70％开始（降低阈值越低，完成GC越多，使用的CPU越多）。为了解决第二个碎片问题，托德补充实验设施（MSLAB），必须在Apache的HBase的0.90.x明确启用（它默认是<em>在</em> Apache的0.92.x HBase的）。组<code>hbase.hregion.memstore.mslab.enabled</code>对你的真实<code>Configuration</code> 。有关背景和详细信息，请参见引用的幻灯片。最新的JVM最好考虑碎片化，因此请确保您正在运行最新版本。阅读消息， <a href="http://osdir.com/ml/hotspot-gc-use/2011-11/msg00002.html">确定由碎片引起的并发模式故障</a> 。请注意，启用后，每个MemStore实例将至少占用一个MSLAB内存实例。如果您有成千上万个区域或许多区域，每个区域都有许多列族，则MSLAB的这种分配可能会占您堆分配的很大一部分，在极端情况下会导致您成为OOME。在这种情况下，请禁用MSLAB，或降低其使用的内存量，或使每台服务器的浮动区域更少。</p>
</div>
<div class="paragraph">
<p>如果您的工作量繁重，请查看<a href="https://issues.apache.org/jira/browse/HBASE-8163">HBASE-8163 MemStoreChunkPool：使用MSLAB时对JAVA GC的改进</a> 。它描述了在写重负载期间降低新GC数量的配置。如果您没有安装HBASE-8163，并且正在尝试缩短GC的使用时间，则可以考虑的一项技巧（由我们的Liang Xie提供）是设置GC配置。 <code>-XX:PretenureSizeThreshold</code>在<em>hbase-env.sh</em>中要小于<code>hbase.hregion.memstore.mslab.chunksize</code>因此，MSLAB分配直接发生在使用权空间中，而不是在年轻一代中首先发生。您之所以这样做，是因为这些MSLAB分配无论如何都可能会变成旧一代，而不是在伊甸园空间中支付s0和s1之间的副本的价格，然后在MSLAB拥有之后从年轻一代复制到老一代取得了足够的任期，节省了一些YGC流失并直接分配给了旧一代。</p>
</div>
<div class="paragraph">
<p>有关GC日志的更多信息，请参阅<a href="#trouble.log.gc">JVM垃圾收集日志</a> 。</p>
</div>
<div class="paragraph">
<p>考虑还启用堆外块缓存。已显示这可以减少GC暂停时间。请参阅<a href="#block.cache">块缓存</a></p>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="perf.configurations"><a class="anchor" href="#perf.configurations"></a> 86。HBase配置</h2>
<div class="sectionbody">
<div class="paragraph">
<p>参见<a href="#recommended_configurations">[recommended_configurations]</a> 。</p>
</div>
<div class="sect2">
<h3 id="perf.compactions.and.splits"><a class="anchor" href="#perf.compactions.and.splits"></a> 86.1。管理压实</h3>
<div class="paragraph">
<p>对于较大的系统，您可能需要考虑管理link：[compacts and splits]。</p>
</div>
</div>
<div class="sect2">
<h3 id="perf.handlers"><a class="anchor" href="#perf.handlers"></a> 86.2。<code>hbase.regionserver.handler.count</code></h3>
<div class="paragraph">
<p>请参阅<a href="#hbase.regionserver.handler.count">[hbase.regionserver.handler.count]</a> 。</p>
</div>
</div>
<div class="sect2">
<h3 id="perf.hfile.block.cache.size"><a class="anchor" href="#perf.hfile.block.cache.size"></a> 86.3。<code>hfile.block.cache.size</code></h3>
<div class="paragraph">
<p>参见<a href="#hfile.block.cache.size">[hfile.block.cache.size]</a> 。RegionServer进程的内存设置。</p>
</div>
</div>
<div class="sect2">
<h3 id="blockcache.prefetch"><a class="anchor" href="#blockcache.prefetch"></a> 86.4。块缓存的预取选项</h3>
<div class="paragraph">
<p>如果设置了Column family或RegionServer属性，则<a href="https://issues.apache.org/jira/browse/HBASE-9857">HBASE-9857</a>添加一个新选项以在打开BlockCache时预取HFile内容。此选项可用于HBase 0.98.3及更高版本。目的是使用内存中的表数据，在打开高速缓存后尽可能快地预热BlockCache，而不将预取视为高速缓存未命中。这对于快速读取非常有用，但是如果要预加载的数据不适合BlockCache，则不是一个好主意。对于调整预取的IO影响与所有数据块进入缓存之前的时间相比，这很有用。</p>
</div>
<div class="paragraph">
<p>要在给定的列族上启用预取，可以使用HBase Shell或API。</p>
</div>
<div class="exampleblock">
<div class="title">例子43。使用HBase Shell启用预取</div>
<div class="content">
<div class="listingblock">
<div class="content">
<pre>hbase&gt; create 'MyTable', { NAME =&gt; 'myCF', PREFETCH_BLOCKS_ON_OPEN =&gt; 'true' }</pre>
</div>
</div>
</div>
</div>
<div class="exampleblock">
<div class="title">例子44。使用API启用预取</div>
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="comment">// ...</span>
HTableDescriptor tableDesc = <span class="keyword">new</span> HTableDescriptor(<span class="string"><span class="delimiter">&quot;</span><span class="content">myTable</span><span class="delimiter">&quot;</span></span>);
HColumnDescriptor cfDesc = <span class="keyword">new</span> HColumnDescriptor(<span class="string"><span class="delimiter">&quot;</span><span class="content">myCF</span><span class="delimiter">&quot;</span></span>);
cfDesc.setPrefetchBlocksOnOpen(<span class="predefined-constant">true</span>);
tableDesc.addFamily(cfDesc);
<span class="comment">// ...</span></code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>请参阅<a href="https://hbase.apache.org/apidocs/org/apache/hadoop/hbase/io/hfile/CacheConfig.html">CacheConfig</a>的API文档。</p>
</div>
</div>
<div class="sect2">
<h3 id="perf.rs.memstore.size"><a class="anchor" href="#perf.rs.memstore.size"></a> 86.5。<code>hbase.regionserver.global.memstore.size</code></h3>
<div class="paragraph">
<p>请参阅<a href="#hbase.regionserver.global.memstore.size">[hbase.regionserver.global.memstore.size]</a> 。通常根据需要针对RegionServer进程调整此内存设置。</p>
</div>
</div>
<div class="sect2">
<h3 id="perf.rs.memstore.size.lower.limit"><a class="anchor" href="#perf.rs.memstore.size.lower.limit"></a> 86.6。<code>hbase.regionserver.global.memstore.size.lower.limit</code></h3>
<div class="paragraph">
<p>请参阅<a href="#hbase.regionserver.global.memstore.size.lower.limit">[hbase.regionserver.global.memstore.size.lower.limit]</a> 。通常根据需要针对RegionServer进程调整此内存设置。</p>
</div>
</div>
<div class="sect2">
<h3 id="perf.hstore.blockingstorefiles"><a class="anchor" href="#perf.hstore.blockingstorefiles"></a> 86.7。<code>hbase.hstore.blockingStoreFiles</code></h3>
<div class="paragraph">
<p>请参阅<a href="#hbase.hstore.blockingstorefiles">[hbase.hstore.blockingstorefiles]</a> 。如果RegionServer日志中存在阻塞，则增加该值可以有所帮助。</p>
</div>
</div>
<div class="sect2">
<h3 id="perf.hregion.memstore.block.multiplier"><a class="anchor" href="#perf.hregion.memstore.block.multiplier"></a> 86.8。<code>hbase.hregion.memstore.block.multiplier</code></h3>
<div class="paragraph">
<p>参见<a href="#hbase.hregion.memstore.block.multiplier">[hbase.hregion.memstore.block.multiplier]</a> 。如果有足够的RAM，增加存储空间会有所帮助。</p>
</div>
</div>
<div class="sect2">
<h3 id="hbase.regionserver.checksum.verify.performance"><a class="anchor" href="#hbase.regionserver.checksum.verify.performance"></a> 86.9。<code>hbase.regionserver.checksum.verify</code></h3>
<div class="paragraph">
<p>让HBase将校验和写入数据块，并在每次读取时省去执行校验和查找的麻烦。</p>
</div>
<div class="paragraph">
<p>请参阅<a href="#hbase.regionserver.checksum.verify">[hbase.regionserver.checksum.verify]</a> ， <a href="#hbase.hstore.bytes.per.checksum">[hbase.hstore.bytes.per.checksum]</a>和<a href="#hbase.hstore.checksum.algorithm">[hbase.hstore.checksum.algorithm]</a> 。有关更多信息，请参见<a href="https://issues.apache.org/jira/browse/HBASE-5074">HBase块缓存中</a>有关<a href="https://issues.apache.org/jira/browse/HBASE-5074">HBASE-5074支持校验和</a>的发行说明。</p>
</div>
</div>
<div class="sect2">
<h3 id="_tuning_code_callqueue_code_options"><a class="anchor" href="#_tuning_code_callqueue_code_options"></a> 86.10。调音<code>callQueue</code>选件</h3>
<div class="paragraph">
<p><a href="https://issues.apache.org/jira/browse/HBASE-11355">HBASE-</a> 11355引入了几种可以提高性能的callQueue调整机制。有关一些基准测试信息，请参见JIRA。</p>
</div>
<div class="paragraph">
<p>要增加呼叫队列的数量，请设置<code>hbase.ipc.server.num.callqueue</code>大于<code>1</code> 。要将呼叫队列拆分为单独的读写队列，请设置<code>hbase.ipc.server.callqueue.read.ratio</code>到之间的一个值<code>0</code>和<code>1</code> 。此因素将队列加权为写入（如果低于0.5）或读取（如果高于0.5）。另一种说法是，该因素决定了拆分队列中有多少百分比用于读取。以下示例说明了一些可能性。请注意，无论使用哪种设置，您始终至少有一个写队列。</p>
</div>
<div class="ulist">
<ul>
<li>
<p>的默认值<code>0</code>不拆分队列。</p>
</li>
<li>
<p>值<code>.3</code>将30％的队列用于读取，将60％的队列用于写入。给定值为<code>10</code>对于<code>hbase.ipc.server.num.callqueue</code> ，则将3个队列用于读取，将7个队列用于写入。</p>
</li>
<li>
<p>值<code>.5</code>使用相同数量的读取队列和写入队列。给定值为<code>10</code>对于<code>hbase.ipc.server.num.callqueue</code> ，则将5个队列用于读取，将5个队列用于写入。</p>
</li>
<li>
<p>值<code>.6</code>使用60％的队列进行读取，使用30％的队列进行读取。给定值为<code>10</code>对于<code>hbase.ipc.server.num.callqueue</code> ，将使用7个队列进行读取，将3个队列用于写入。</p>
</li>
<li>
<p>值<code>1.0</code>使用一个队列处理写请求，所有其他队列处理读请求。高于<code>1.0</code>与的值具有相同的作用<code>1.0</code> 。给定值为<code>10</code>对于<code>hbase.ipc.server.num.callqueue</code> ，将使用9个队列进行读取，使用1个队列进行写入。</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>您还可以拆分读取队列，以便通过设置以下选项将单独的队列用于短读（来自Get操作）和长读（来自Scan操作）。 <code>hbase.ipc.server.callqueue.scan.ratio</code>选项。此选项是介于0和1之间的因子，该因子确定用于“获取”和“扫描”的读取队列的比率。如果该值低于，则将更多队列用于Gets <code>.5</code>如果该值大于0，则更多用于扫描<code>.5</code> 。无论使用什么设置，至少一个读取队列都将用于Get操作。</p>
</div>
<div class="ulist">
<ul>
<li>
<p>值<code>0</code>不拆分读取队列。</p>
</li>
<li>
<p>值<code>.3</code>将60％的读取队列用于获取，将30％的扫描用于扫描。给定值为<code>20</code>对于<code>hbase.ipc.server.num.callqueue</code>和值为<code>.5</code>对于<code>hbase.ipc.server.callqueue.read.ratio</code> ，其中10个队列用于读取，在这10个队列中，有7个用于Gets，3个用于Scans。</p>
</li>
<li>
<p>值<code>.5</code>将读取队列的一半用于获取，将一半用于扫描。给定值为<code>20</code>对于<code>hbase.ipc.server.num.callqueue</code>和值为<code>.5</code>对于<code>hbase.ipc.server.callqueue.read.ratio</code> ，其中10个队列用于读取，在这10个队列中，有5个用于Gets，5个用于Scans。</p>
</li>
<li>
<p>值<code>.6</code>将30％的读取队列用于Gets，将60％的扫描用于Scans。给定值为<code>20</code>对于<code>hbase.ipc.server.num.callqueue</code>和值为<code>.5</code>对于<code>hbase.ipc.server.callqueue.read.ratio</code> ，其中10个队列用于读取，在这10个队列中，有3个用于Gets，7个用于Scans。</p>
</li>
<li>
<p>值<code>1.0</code>使用除读取队列之一以外的所有读取队列进行扫描。给定值为<code>20</code>对于<code>hbase.ipc.server.num.callqueue</code>的值为.5 <code>hbase.ipc.server.callqueue.read.ratio</code> ，其中10个队列用于读取，在这10个队列中，有1个用于Gets，9个用于Scans。</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>您可以使用新选项<code>hbase.ipc.server.callqueue.handler.factor</code>以编程方式调整队列数：</p>
</div>
<div class="ulist">
<ul>
<li>
<p>值<code>0</code>在所有处理程序之间使用单个共享队列。</p>
</li>
<li>
<p>值<code>1</code>为每个处理程序使用一个单独的队列。</p>
</li>
<li>
<p>介于<code>0</code>和<code>1</code>根据处理程序的数量调整队列的数量。例如，值为<code>.5</code>每两个处理程序之间共享一个队列。</p>
<div class="paragraph">
<p>具有更多队列，例如在每个处理程序只有一个队列的情况下，可以减少将任务添加到队列或从队列中选择任务时的争用。权衡是，如果您有一些队列中有长时间运行的任务，则处理程序可能最终会从该队列中等待执行，而不是处理另一个具有等待任务的队列。</p>
</div>
</li>
</ul>
</div>
<div class="paragraph">
<p>为了使这些值在给定的RegionServer上生效，必须重新启动RegionServer。这些参数仅用于测试目的，应谨慎使用。</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="perf.zookeeper"><a class="anchor" href="#perf.zookeeper"></a> 87。动物园管理员</h2>
<div class="sectionbody">
<div class="paragraph">
<p>请参阅<a href="#zookeeper">ZooKeeper，</a>以获取有关配置ZooKeeper的信息，并参阅有关拥有专用磁盘的部分。</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="perf.schema"><a class="anchor" href="#perf.schema"></a> 88。模式设计</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="perf.number.of.cfs"><a class="anchor" href="#perf.number.of.cfs"></a> 88.1。列族数</h3>
<div class="paragraph">
<p>请参见<a href="#number.of.cfs">关于列族数</a> 。</p>
</div>
</div>
<div class="sect2">
<h3 id="perf.schema.keys"><a class="anchor" href="#perf.schema.keys"></a> 88.2。键和属性长度</h3>
<div class="paragraph">
<p>请参阅<a href="#keysize">尝试最小化行和列的大小</a> 。又见<a href="#perf.compression.however">但是...</a>压缩注意事项。</p>
</div>
</div>
<div class="sect2">
<h3 id="schema.regionsize"><a class="anchor" href="#schema.regionsize"></a> 88.3。表区域大小</h3>
<div class="paragraph">
<p>可以通过以下方式在每个表的基础上设置区域大小<code>setFileSize</code>如果某些表要求的区域大小与配置的默认区域大小不同，则在<a href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/HTableDescriptor.html">HTableDescriptor</a>上<a href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/HTableDescriptor.html">启用</a> 。</p>
</div>
<div class="paragraph">
<p>有关更多信息，请参见<a href="#ops.capacity.regions">确定区域数和大小</a> 。</p>
</div>
</div>
<div class="sect2">
<h3 id="schema.bloom"><a class="anchor" href="#schema.bloom"></a> 88.4。布隆过滤器</h3>
<div class="paragraph">
<p>以其创建者Burton Howard Bloom命名的Bloom过滤器是一种数据结构，旨在预测给定元素是否为数据集的成员。布隆过滤器的肯定结果并不总是准确的，但肯定会得出负面结果。Bloom过滤器被设计为对于足够大的数据集“足够准确”，以至于常规的散列机制将是不切实际的。有关常规Bloom过滤器的更多信息，请参阅<a href="http://en.wikipedia.org/wiki/Bloom_filter" class="bare">http://en.wikipedia.org/wiki/Bloom_filter</a> 。</p>
</div>
<div class="paragraph">
<p>就HBase而言，Bloom筛选器提供了一种轻量级的内存结构，以减少给定Get操作（Bloom筛选器不适用于Scans）的磁盘读取次数，仅减少可能包含所需行的StoreFiles。潜在的性能增益随并行读取的数量而增加。</p>
</div>
<div class="paragraph">
<p>Bloom筛选器本身存储在每个HFile的元数据中，不需要更新。当由于将区域部署到RegionServer而打开HFile时，Bloom筛选器将加载到内存中。</p>
</div>
<div class="paragraph">
<p>HBase包括一些调整机制，用于折叠Bloom过滤器以减小尺寸并将假阳性率保持在所需范围内。</p>
</div>
<div class="paragraph">
<p>在<a href="https://issues.apache.org/jira/browse/HBASE-1200">HBASE-1200</a>中引入了Bloom过滤器。从HBase 0.96开始，默认情况下启用基于行的Bloom筛选器。（ <a href="https://issues.apache.org/jira/browse/HBASE-8450">HBASE-</a> ）</p>
</div>
<div class="paragraph">
<p>有关与HBase相关的<a href="#blooms">Bloom过滤器</a>的更多信息，请参见<a href="#blooms">Bloom过滤器</a>以获取更多信息，或进行以下Quora讨论： <a href="http://www.quora.com/How-are-bloom-filters-used-in-HBase">HBase中如何使用Bloom过滤器？</a> 。</p>
</div>
<div class="sect3">
<h4 id="bloom.filters.when"><a class="anchor" href="#bloom.filters.when"></a> 88.4.1。何时使用布隆过滤器</h4>
<div class="paragraph">
<p>从HBase 0.96开始，默认情况下启用基于行的Bloom筛选器。您可以选择禁用它们或更改某些表以使用行+列Bloom过滤器，具体取决于数据的特性以及如何将其加载到HBase中。</p>
</div>
<div class="paragraph">
<p>要确定Bloom过滤器是否会产生积极影响，请检查<code>blockCacheHitRatio</code>在RegionServer指标中。如果启用布隆过滤器，则<code>blockCacheHitRatio</code>应当增加，因为布隆过滤器正在过滤出绝对不需要的块。</p>
</div>
<div class="paragraph">
<p>您可以选择为行或行+列组合启用Bloom过滤器。如果通常扫描整个行，则行+列组合将不会提供任何好处。基于行的Bloom过滤器可以对行+列Get进行操作，但不能相反。但是，如果您有大量的列级Put，使得每个StoreFile中都可能存在一行，则基于行的过滤器将始终返回正结果，并且没有任何好处。除非每行有一列，否则行+列Bloom过滤器需要更多空间才能存储更多键。当每个数据条目的大小至少为几千字节时，Bloom过滤器最有效。</p>
</div>
<div class="paragraph">
<p>当您的数据存储在一些较大的StoreFiles中时，开销将减少，以避免在低级扫描找到特定的行期间出现额外的磁盘IO。</p>
</div>
<div class="paragraph">
<p>Bloom过滤器需要在删除时重新构建，因此可能不适用于具有大量删除操作的环境。</p>
</div>
</div>
<div class="sect3">
<h4 id="_enabling_bloom_filters"><a class="anchor" href="#_enabling_bloom_filters"></a> 88.4.2。启用布隆过滤器</h4>
<div class="paragraph">
<p>在列族上启用了布隆过滤器。您可以使用HColumnDescriptor的setBloomFilterType方法或使用HBase API来执行此操作。有效值为<code>NONE</code> （默认）， <code>ROW</code> ， 要么<code>ROWCOL</code> 。有关更多信息，请参见<a href="#bloom.filters.when">何时使用布隆过滤器</a> 。 <code>ROW</code>与<code>ROWCOL</code> 。另请参见<a href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/HColumnDescriptor.html">HColumnDescriptor</a>的API文档。</p>
</div>
<div class="paragraph">
<p>以下示例创建一个表，并在该表上启用ROWCOL Bloom过滤器<code>colfam1</code>列族。</p>
</div>
<div class="listingblock">
<div class="content">
<pre>hbase&gt; create 'mytable',{NAME =&gt; 'colfam1', BLOOMFILTER =&gt; 'ROWCOL'}</pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_configuring_server_wide_behavior_of_bloom_filters"><a class="anchor" href="#_configuring_server_wide_behavior_of_bloom_filters"></a> 88.4.3。配置布隆过滤器的服务器范围行为</h4>
<div class="paragraph">
<p>您可以在<em>hbase-site.xml中</em>配置以下设置。</p>
</div>
<table class="tableblock frame-all grid-all spread">
<colgroup>
<col style="width:33%">
<col style="width:33%">
<col style="width:33%">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">参数</th>
<th class="tableblock halign-left valign-top">默认</th>
<th class="tableblock halign-left valign-top">描述</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">io.hfile.bloom.enabled</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">是</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">设置为no可在出现问题时在服务器范围内终止Bloom过滤器</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">io.hfile.bloom.error.rate</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">.01</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">布隆过滤器的平均误报率。折叠用于维持误报率。用百分比的十进制表示形式表示。</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">io.hfile.bloom.max.fold</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">7</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">保证的最大折页率。不需要更改此设置，不建议这样做。</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">io.storefile.bloom.max.keys</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">128000000</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">对于默认（单块）Bloom过滤器，这指定了最大密钥数。</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">io.storefile.delete.family.bloom.enabled</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">真正</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">主开关启用“删除家族绽放”过滤器并将其存储在StoreFile中。</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">io.storefile.bloom.block.size</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">65536</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">目标Bloom块大小。大约此大小的布隆过滤器块与数据块交织。</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">hfile.block.bloom.cacheonwrite</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">假</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">为复合Bloom过滤器的内联块启用写时缓存。</p></td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="sect2">
<h3 id="schema.cf.blocksize"><a class="anchor" href="#schema.cf.blocksize"></a> 88.5。列家庭块大小</h3>
<div class="paragraph">
<p>可以为表中的每个ColumnFamily配置块大小，默认为64k。较大的像元值需要较大的块大小。块大小与生成的StoreFile索引之间存在反比关系（即，如果块大小加倍，则生成的索引应大致减半）。</p>
</div>
<div class="paragraph">
<p>有关更多信息，请参见<a href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/HColumnDescriptor.html">HColumnDescriptor</a>和<a href="#store">[store]</a> 。</p>
</div>
</div>
<div class="sect2">
<h3 id="cf.in.memory"><a class="anchor" href="#cf.in.memory"></a> 88.6。内存中列系列</h3>
<div class="paragraph">
<p>ColumnFamilies可以可选地定义为内存中。像其他任何ColumnFamily一样，数据仍保留在磁盘上。内存中的块在“ <a href="#block.cache">块缓存”中</a>具有最高优先级，但这不能保证整个表都将在内存中。</p>
</div>
<div class="paragraph">
<p>有关更多信息，请参见<a href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/HColumnDescriptor.html">HColumnDescriptor</a> 。</p>
</div>
</div>
<div class="sect2">
<h3 id="perf.compression"><a class="anchor" href="#perf.compression"></a> 88.7。压缩</h3>
<div class="paragraph">
<p>生产系统应在其ColumnFamily定义中使用压缩。有关更多信息，请参见<a href="#compression">HBase中的压缩和数据块编码</a> 。</p>
</div>
<div class="sect3">
<h4 id="perf.compression.however"><a class="anchor" href="#perf.compression.however"></a> 88.7.1。但是...</h4>
<div class="paragraph">
<p>压缩可以压缩<em>磁盘上的</em>数据。当它在内存中（例如，在MemStore中）或在线（例如，在RegionServer和Client之间传输）时，它会膨胀。因此，虽然使用ColumnFamily压缩是一种最佳实践，但是它并不能完全消除过大的键，过大的ColumnFamily名称或过大的列名称的影响。</p>
</div>
<div class="paragraph">
<p>有关架构设计技巧，请参见<a href="#keysize">尝试最小化行和列的大小</a> ；有关HBase内部存储数据的更多信息，请参见<a href="#keyvalue">[keyvalue]</a> 。</p>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="perf.general"><a class="anchor" href="#perf.general"></a> 89。HBase通用模式</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="perf.general.constants"><a class="anchor" href="#perf.general.constants"></a> 89.1。常数</h3>
<div class="paragraph">
<p>当人们开始使用HBase时，他们倾向于编写如下代码：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">Get get = <span class="keyword">new</span> Get(rowkey);
<span class="predefined-type">Result</span> r = table.get(get);
<span class="type">byte</span><span class="type">[]</span> b = r.getValue(Bytes.toBytes(<span class="string"><span class="delimiter">&quot;</span><span class="content">cf</span><span class="delimiter">&quot;</span></span>), Bytes.toBytes(<span class="string"><span class="delimiter">&quot;</span><span class="content">attr</span><span class="delimiter">&quot;</span></span>));  <span class="comment">// returns current version of value</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>但是，尤其是在内部循环（和MapReduce作业）中，将columnFamily和column-name反复转换为字节数组的代价令人惊讶。最好为字节数组使用常量，如下所示：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="directive">public</span> <span class="directive">static</span> <span class="directive">final</span> <span class="type">byte</span><span class="type">[]</span> CF = <span class="string"><span class="delimiter">&quot;</span><span class="content">cf</span><span class="delimiter">&quot;</span></span>.getBytes();
<span class="directive">public</span> <span class="directive">static</span> <span class="directive">final</span> <span class="type">byte</span><span class="type">[]</span> ATTR = <span class="string"><span class="delimiter">&quot;</span><span class="content">attr</span><span class="delimiter">&quot;</span></span>.getBytes();
...
Get get = <span class="keyword">new</span> Get(rowkey);
<span class="predefined-type">Result</span> r = table.get(get);
<span class="type">byte</span><span class="type">[]</span> b = r.getValue(CF, ATTR);  <span class="comment">// returns current version of value</span></code></pre>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="perf.writing"><a class="anchor" href="#perf.writing"></a> 90写入HBase</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="perf.batch.loading"><a class="anchor" href="#perf.batch.loading"></a> 90.1批量加载</h3>
<div class="paragraph">
<p>如果可以，请使用批量加载工具。请参阅<a href="#arch.bulk.load">批量加载</a> 。否则，请注意以下内容。</p>
</div>
</div>
<div class="sect2">
<h3 id="precreate.regions"><a class="anchor" href="#precreate.regions"></a> 90.2。表创建：预创建区域</h3>
<div class="paragraph">
<p>默认情况下，HBase中的表最初是使用一个区域创建的。对于批量导入，这意味着所有客户端都将写入同一区域，直到该区域足够大以进行拆分并在整个群集中分布为止。加快批量导入过程的一种有用模式是预先创建空白区域。在这方面要保守一些，因为太多区域实际上会降低性能。</p>
</div>
<div class="paragraph">
<p>有两种不同的方法可以预先创建分割。第一种方法是依靠默认<code>Admin</code>策略（在<code>Bytes.split</code> ）...</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="type">byte</span><span class="type">[]</span> startKey = ...;      <span class="comment">// your lowest key</span>
<span class="type">byte</span><span class="type">[]</span> endKey = ...;        <span class="comment">// your highest key</span>
<span class="type">int</span> numberOfRegions = ...;  <span class="comment">// # of regions to create</span>
admin.createTable(table, startKey, endKey, numberOfRegions);</code></pre>
</div>
</div>
<div class="paragraph">
<p>另一种方法是自己定义分割...</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="type">byte</span><span class="type">[]</span><span class="type">[]</span> splits = ...;   <span class="comment">// create your own splits</span>
admin.createTable(table, splits);</code></pre>
</div>
</div>
<div class="paragraph">
<p>有关与了解键空间和预创建区域有关的问题，请参见<a href="#rowkey.regionsplits">RowKey和Region Splits之间的关系</a> 。有关手动预分割区域的讨论，请参见<a href="#manual_region_splitting_decisions">手动区域分割决策</a> 。</p>
</div>
</div>
<div class="sect2">
<h3 id="def.log.flush"><a class="anchor" href="#def.log.flush"></a> 90.3。表创建：延迟日志刷新</h3>
<div class="paragraph">
<p>使用预写日志（WAL）的看跌期权的默认行为是<code>WAL</code>编辑将立即写入。如果使用了延迟日志刷新，则WAL编辑将保留在内存中，直到刷新周期。好处是聚合和异步<code>WAL</code> -写，但是潜在的缺点是，如果RegionServer崩溃，则尚未刷新的编辑将丢失。但是，与完全不使用Put一起使用WAL相比，这更安全。</p>
</div>
<div class="paragraph">
<p>可以通过<a href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/HTableDescriptor.html">HTableDescriptor</a>在表上配置延迟的日志刷新。的默认值<code>hbase.regionserver.optionallogflushinterval</code>是1000毫秒</p>
</div>
</div>
<div class="sect2">
<h3 id="perf.hbase.client.autoflush"><a class="anchor" href="#perf.hbase.client.autoflush"></a> 90.4。HBase客户端：自动刷新</h3>
<div class="paragraph">
<p>在执行大量Put时，请确保在<a href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/client/Table.html">Table</a>实例上将setAutoFlush设置为false。否则，看跌期权将一次发送到RegionServer。通过添加的看跌期权<code>table.add(Put)</code>和<code>table.add( <List> Put)</code>在同一个写缓冲区结束。如果<code>autoFlush = false</code> ，直到填充了写缓冲区后，才会发送这些消息。要显式刷新消息，请致电<code>flushCommits</code> 。呼唤<code>close</code>在<code>Table</code>实例将调用<code>flushCommits</code> 。</p>
</div>
</div>
<div class="sect2">
<h3 id="perf.hbase.client.putwal"><a class="anchor" href="#perf.hbase.client.putwal"></a> 90.5。HBase客户端：关闭看跌期权的WAL</h3>
<div class="paragraph">
<p>一个常见的请求是禁用WAL以提高看跌期权的性能。这仅适用于大容量加载，因为在区域服务器崩溃的情况下，通过删除WAL的保护会给您的数据带来风险。崩溃时可以重新运行大容量负载，数据丢失的风险很小。</p>
</div>
<div class="admonitionblock warning">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-warning" title="警告"></i>
</td>
<td class="content">如果对大容量负载以外的任何其他功能禁用WAL，则数据将受到威胁。
</td>
</tr>
</tbody></table>
</div>
<div class="paragraph">
<p>通常，最好将WAL用于看跌期权，而在需要考虑装载吞吐量的情况下，请使用批量装载技术。对于正常的看跌期权，您不太可能看到性能提高超过风险。要禁用WAL，请参阅<a href="#wal.disable">禁用WAL</a> 。</p>
</div>
</div>
<div class="sect2">
<h3 id="perf.hbase.client.regiongroup"><a class="anchor" href="#perf.hbase.client.regiongroup"></a> 90.6。HBase客户端：按RegionServer分组放置</h3>
<div class="paragraph">
<p>除了使用writeBuffer之外，分组<code>Put`s by RegionServer can reduce the number of client RPC calls per writeBuffer flush. There is a utility `HTableUtil</code>当前在TRUNK上执行此操作，但是您可以复制该文件或为仍在0.90.x或更早版本上的版本实现自己的版本。</p>
</div>
</div>
<div class="sect2">
<h3 id="perf.hbase.write.mr.reducer"><a class="anchor" href="#perf.hbase.write.mr.reducer"></a> 90.7。MapReduce：跳过Reducer</h3>
<div class="paragraph">
<p>当从MR作业（例如，使用<a href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/mapreduce/TableOutputFormat.html">TableOutputFormat</a> ）将大量数据写入HBase表时，尤其是从Mapper发出<a href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/mapreduce/TableOutputFormat.html">Put的</a>位置时，请跳过Reducer步骤。使用Reducer步骤时，Mapper的所有输出（Put）将被后台处理到磁盘，然后被排序/混编到其他很有可能不在节点上的Reducer。直接写入HBase效率更高。</p>
</div>
<div class="paragraph">
<p>对于将HBase用作源和接收器的汇总作业，则写入将来自Reducer步骤（例如，汇总值然后写出结果）。这是与上述情况不同的处理问题。</p>
</div>
</div>
<div class="sect2">
<h3 id="perf.one.region"><a class="anchor" href="#perf.one.region"></a> 90.8。反模式：一个热门地区</h3>
<div class="paragraph">
<p>如果您一次将所有数据都写入一个区域，请重新阅读有关处理时间序列数据的部分。</p>
</div>
<div class="paragraph">
<p>此外，如果您正在预分割区域，即使您的密钥没有单调增加，但所有数据<em>仍在</em>单个区域中整理，请确认您的密钥空间确实适用于分割策略。出于多种原因，区域可能看起来“很好地分开”，但不适用于您的数据。当HBase客户端直接与RegionServer通信时，可以通过<a href="javascript:void(0);" class="bare">hhttp：//hbase.apache.org/apidocs/org/apache/hadoop/hbase/client/Table.html#getRegionLocation（byte</a> ）[Table.getRegionLocation]获取。</p>
</div>
<div class="paragraph">
<p>请参阅<a href="#precreate.regions">表创建：预创建区域</a> ，以及<a href="#perf.configurations">HBase配置</a></p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="perf.reading"><a class="anchor" href="#perf.reading"></a> 91。从HBase读取</h2>
<div class="sectionbody">
<div class="paragraph">
<p>如果您遇到性能问题，邮件列表可以提供帮助。例如，以下是解决读取时间问题的一个不错的通用线程： <a href="http://search-hadoop.com/m/qOo2yyHtCC1">HBase随机读取延迟> 100ms</a></p>
</div>
<div class="sect2">
<h3 id="perf.hbase.client.caching"><a class="anchor" href="#perf.hbase.client.caching"></a> 91.1。扫描缓存</h3>
<div class="paragraph">
<p>例如，如果将HBase用作MapReduce作业的输入源，请确保MapReduce作业的输入<a href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/client/Scan.html">Scan</a>实例具有<code>setCaching</code>设置为大于默认值（1）的值。使用默认值意味着映射任务将为每个已处理的记录回调到区域服务器。例如，将此值设置为500，将一次将500行传输到要处理的客户端。拥有较大的缓存值是有成本/收益的，因为对于客户端和RegionServer而言，它在内存上的开销都更大，因此增大缓存值并不总是更好。</p>
</div>
<div class="sect3">
<h4 id="perf.hbase.client.caching.mr"><a class="anchor" href="#perf.hbase.client.caching.mr"></a> 91.1.1。扫描MapReduce作业中的缓存</h4>
<div class="paragraph">
<p>MapReduce作业中的扫描设置值得特别注意。如果在客户端返回RegionServer获取下一组数据之前需要花费更长的时间处理一批记录，则Map任务中可能会导致超时（例如，UnknownScannerException）。发生此问题的原因是每行都发生了非平凡的处理。如果您快速处理行，请设置更高的缓存。如果您处理行的速度较慢（例如，每行进行很多转换，写入），则将缓存设置得较低。</p>
</div>
<div class="paragraph">
<p>在非MapReduce用例中也可能发生超时（即，单线程HBase客户端执行扫描），但是MapReduce作业中经常执行的处理会加剧此问题。</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="perf.hbase.client.selection"><a class="anchor" href="#perf.hbase.client.selection"></a> 91.2。扫描属性选择</h3>
<div class="paragraph">
<p>每当使用扫描来处理大量行（尤其是用作MapReduce源）时，请注意选择了哪些属性。如果<code>scan.addFamily</code>调用后，指定ColumnFamily中的<em>所有</em>属性将返回给客户端。如果仅要处理少量可用属性，则应在输入扫描中仅指定那些属性，因为在大型数据集上，属性过度选择是不平凡的性能损失。</p>
</div>
</div>
<div class="sect2">
<h3 id="perf.hbase.client.seek"><a class="anchor" href="#perf.hbase.client.seek"></a> 91.3。避免扫描寻道</h3>
<div class="paragraph">
<p>当使用显式选择列时<code>scan.addColumn</code> ，HBase将安排搜索操作以在选定的列之间进行搜索。如果行中的列很少，而每列中只有几个版本，则效率可能很低。如果至少不搜索超过5-10列/版本或512-1024字节，则搜索操作通常会较慢。</p>
</div>
<div class="paragraph">
<p>为了有机会向前看一些列/版本，以查看是否可以在安排搜索操作之前以这种方式找到下一个列/版本，因此请添加一个新属性<code>Scan.HINT_LOOKAHEAD</code>可以设置扫描对象。下面的代码指示RegionServer在计划搜索之前尝试next的两次迭代：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">Scan scan = <span class="keyword">new</span> Scan();
scan.addColumn(...);
scan.setAttribute(Scan.HINT_LOOKAHEAD, Bytes.toBytes(<span class="integer">2</span>));
table.getScanner(scan);</code></pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="perf.hbase.mr.input"><a class="anchor" href="#perf.hbase.mr.input"></a> 91.4。MapReduce-输入分割</h3>
<div class="paragraph">
<p>对于使用HBase表作为源的MapReduce作业，如果存在一种模式，其中“慢速”地图任务似乎具有相同的输入拆分（即，由RegionServer提供数据），请参阅<a href="#casestudies.slownode">案例研究1中</a>的故障排除案例研究<a href="#casestudies.slownode">（单节点上的性能问题）</a> 。</p>
</div>
</div>
<div class="sect2">
<h3 id="perf.hbase.client.scannerclose"><a class="anchor" href="#perf.hbase.client.scannerclose"></a> 91.5。关闭结果扫描仪</h3>
<div class="paragraph">
<p>与其说提高性能，不如说是<em>避免</em>性能问题。如果您忘记关闭<a href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/client/ResultScanner.html">ResultScanners</a> ，可能会在RegionServers上引起问题。始终在try / catch块中包含ResultScanner处理。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">Scan scan = <span class="keyword">new</span> Scan();
<span class="comment">// set attrs...</span>
ResultScanner rs = table.getScanner(scan);
<span class="keyword">try</span> {
  <span class="keyword">for</span> (<span class="predefined-type">Result</span> r = rs.next(); r != <span class="predefined-constant">null</span>; r = rs.next()) {
  <span class="comment">// process result...</span>
} <span class="keyword">finally</span> {
  rs.close();  <span class="comment">// always close the ResultScanner!</span>
}
table.close();</code></pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="perf.hbase.client.blockcache"><a class="anchor" href="#perf.hbase.client.blockcache"></a> 91.6。块缓存</h3>
<div class="paragraph">
<p>可以通过以下方式将<a href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/client/Scan.html">扫描</a>实例设置为使用RegionServer中的块缓存： <code>setCacheBlocks</code>方法。对于输入扫描到MapReduce作业，应为<code>false</code> 。对于经常访问的行，建议使用块缓存。</p>
</div>
<div class="paragraph">
<p>通过将块缓存移到堆外来缓存更多数据。请参阅<a href="#offheap.blockcache">堆外块缓存</a></p>
</div>
</div>
<div class="sect2">
<h3 id="perf.hbase.client.rowkeyonly"><a class="anchor" href="#perf.hbase.client.rowkeyonly"></a> 91.7。行键的最佳加载</h3>
<div class="paragraph">
<p>当执行只需要行键的表<a href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/client/Scan.html">扫描时</a> （不需要族，限定符，值或时间戳），请添加带有<code>MUST_PASS_ALL</code>操作员使用<code>setFilter</code> 。过滤器列表应同时包含<a href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/filter/FirstKeyOnlyFilter.html">FirstKeyOnlyFilter</a>和<a href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/filter/KeyOnlyFilter.html">KeyOnlyFilter</a> 。使用此筛选器组合将导致在最坏的情况下，RegionServer从磁盘读取单个值，并且对于单行，到客户端的网络通信量最少。</p>
</div>
</div>
<div class="sect2">
<h3 id="perf.hbase.read.dist"><a class="anchor" href="#perf.hbase.read.dist"></a> 91.8。并发：监控数据传播</h3>
<div class="paragraph">
<p>当执行大量并发读取时，请监视目标表的数据传播。如果目标表的区域太少，则可能从太少的节点提供读取服务。</p>
</div>
<div class="paragraph">
<p>请参阅<a href="#precreate.regions">表创建：预创建区域</a> ，以及<a href="#perf.configurations">HBase配置</a></p>
</div>
</div>
<div class="sect2">
<h3 id="blooms"><a class="anchor" href="#blooms"></a> 91.9。布隆过滤器</h3>
<div class="paragraph">
<p>启用Bloom Filters可以节省您进入磁盘的时间，并有助于提高读取延迟。</p>
</div>
<div class="paragraph">
<p>在<a href="https://issues.apache.org/jira/browse/HBASE-1200">HBase-1200 Add Bloomfilters</a>中开发了<a href="http://en.wikipedia.org/wiki/Bloom_filter">Bloom过滤器</a> 。有关开发过程的说明（为什么是静态绽放而不是动态绽放）以及有关HBase中的绽放的独特属性的概述以及可能的未来方向，请参阅<a href="https://issues.apache.org/jira/browse/HBASE-1200">HBASE</a>附带的<a href="https://issues.apache.org/jira/browse/HBASE-1200">HBase</a>文档<a href="https://issues.apache.org/jira/secure/attachment/12444007/Bloom_Filters_in_HBase.pdf">BloomFilters</a>的“ <em>开发过程”</em>部分。 <a href="https://issues.apache.org/jira/browse/HBASE-1200">-1200</a> 。这里描述的Bloom过滤器实际上是HBase中Bloom的第二版。在高达0.19.x的版本中，HBase具有基于<a href="http://www.one-lab.org">欧盟委员会One-Lab项目034819</a>完成的工作的动态Bloom选项。HBase开花工作的核心后来被带入Hadoop以实现org.apache.hadoop.io。BloomMapFile。HBase Blooms的版本1从来没有那么好过。版本2是从头开始重写的，尽管它还是从一个实验室的工作开始。</p>
</div>
<div class="paragraph">
<p>另请参见<a href="#schema.bloom">Bloom过滤器</a> 。</p>
</div>
<div class="sect3">
<h4 id="bloom_footprint"><a class="anchor" href="#bloom_footprint"></a> 91.9.1。Bloom StoreFile占用空间</h4>
<div class="paragraph">
<p>布隆过滤器将条目添加到<code>StoreFile</code>一般<code>FileInfo</code>数据结构，然后再添加两个<code>StoreFile</code>元数据部分。</p>
</div>
<div class="sect4">
<h5 id="_bloomfilter_in_the_code_storefile_fileinfo_code_data_structure"><a class="anchor" href="#_bloomfilter_in_the_code_storefile_fileinfo_code_data_structure"></a>中的BloomFilter <code>StoreFile``FileInfo</code>数据结构</h5>
<div class="paragraph">
<p><code>FileInfo</code>有个<code>BLOOM_FILTER_TYPE</code>设置为<code>NONE</code> ， <code>ROW</code>要么<code>ROWCOL.</code></p>
</div>
</div>
<div class="sect4">
<h5 id="_bloomfilter_entries_in_code_storefile_code_metadata"><a class="anchor" href="#_bloomfilter_entries_in_code_storefile_code_metadata"></a>中的BloomFilter条目<code>StoreFile</code>元数据</h5>
<div class="paragraph">
<p><code>BLOOM_FILTER_META</code>保留Bloom大小，使用的Hash函数等。它很小，并缓存在<code>StoreFile.Reader</code>加载</p>
</div>
<div class="paragraph">
<p><code>BLOOM_FILTER_DATA</code>是实际的Bloomfilter数据。按需获取。存储在LRU缓存中（如果已启用）（默认情况下已启用）。</p>
</div>
</div>
</div>
<div class="sect3">
<h4 id="config.bloom"><a class="anchor" href="#config.bloom"></a> 91.9.2。布隆过滤器配置</h4>
<div class="sect4">
<h5 id="__code_io_hfile_bloom_enabled_code_global_kill_switch"><a class="anchor" href="#__code_io_hfile_bloom_enabled_code_global_kill_switch"></a><code>io.hfile.bloom.enabled</code>全局终止开关</h5>
<div class="paragraph">
<p><code>io.hfile.bloom.enabled</code>在<code>Configuration</code>用作万一出现问题的kill开关。默认值= <code>true</code> 。</p>
</div>
</div>
<div class="sect4">
<h5 id="__code_io_hfile_bloom_error_rate_code"><a class="anchor" href="#__code_io_hfile_bloom_error_rate_code"></a><code>io.hfile.bloom.error.rate</code></h5>
<div class="paragraph">
<p><code>io.hfile.bloom.error.rate</code> =平均误报率。默认值= 1％。每个bloom条目将速率降低1/2（例如降至0.5％）== +1位。</p>
</div>
</div>
<div class="sect4">
<h5 id="__code_io_hfile_bloom_max_fold_code"><a class="anchor" href="#__code_io_hfile_bloom_max_fold_code"></a><code>io.hfile.bloom.max.fold</code></h5>
<div class="paragraph">
<p><code>io.hfile.bloom.max.fold</code> =保证的最小折叠率。大多数人应该不要理会这个。默认值= 7，或者可以折叠至少为原始大小的1/128。有关此选项的含义，请参见<a href="https://issues.apache.org/jira/secure/attachment/12444007/Bloom_Filters_in_HBase.pdf">HBase</a>文档<a href="https://issues.apache.org/jira/secure/attachment/12444007/Bloom_Filters_in_HBase.pdf">BloomFilters</a>的“ <em>开发过程”</em>部分。</p>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_hedged_reads"><a class="anchor" href="#_hedged_reads"></a> 91.10。对冲读取</h3>
<div class="paragraph">
<p>对冲读取是<a href="https://issues.apache.org/jira/browse/HDFS-5776">HDFS-5776中</a>引入的<a href="https://issues.apache.org/jira/browse/HDFS-5776">HDFS的功能</a> 。通常，为每个读取请求生成一个线程。但是，如果启用了树篱读取，则客户端将等待一些可配置的时间，如果读取未返回，则客户端将针对相同数据的不同块副本生成第二个读取请求。使用第一个读取返回的对象，而另一个读取请求则被丢弃。在由于磁盘故障或网络连接不稳定等瞬时错误而导致罕见的缓慢读取的情况下，对冲读取会很有用。</p>
</div>
<div class="paragraph">
<p>由于HBase RegionServer是HDFS客户端，因此可以通过在RegionServer的hbase-site.xml中添加以下属性并调整值以适合您的环境来在HBase中启用对冲读取。</p>
</div>
<div class="ulist">
<div class="title">对冲读取的配置</div>
<ul>
<li>
<p><code>dfs.client.hedged.read.threadpool.size</code> -专用于服务被套期读取的线程数。如果将其设置为0（默认值），则会禁用树篱读取。</p>
</li>
<li>
<p><code>dfs.client.hedged.read.threshold.millis</code> -产生第二个读取线程之前要等待的毫秒数。</p>
</li>
</ul>
</div>
<div class="exampleblock">
<div class="title">示例45对冲读取配置示例</div>
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="xml"><span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>dfs.client.hedged.read.threadpool.size<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>20<span class="tag">&lt;/value&gt;</span>  <span class="comment">&lt;!-- 20 threads --&gt;</span>
<span class="tag">&lt;/property&gt;</span>
<span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>dfs.client.hedged.read.threshold.millis<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>10<span class="tag">&lt;/value&gt;</span>  <span class="comment">&lt;!-- 10 milliseconds --&gt;</span>
<span class="tag">&lt;/property&gt;</span></code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>使用以下指标来调整群集上对冲读取的设置。有关更多信息，请参见<a href="#hbase_metrics">[hbase_metrics]</a> 。</p>
</div>
<div class="ulist">
<div class="title">对冲读取的指标</div>
<ul>
<li>
<p>树篱读取操作-树篱读取线程已触发的次数。这可能表明读取请求通常很慢，或者套期读取触发得太快。</p>
</li>
<li>
<p>树篱ReadOpsWin-树篱读取线程比原始线程快的次数。这可能表明给定的RegionServer在处理请求时遇到了麻烦。</p>
</li>
</ul>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="perf.deleting"><a class="anchor" href="#perf.deleting"></a> 92。从HBase删除</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="perf.deleting.queue"><a class="anchor" href="#perf.deleting.queue"></a> 92.1。使用HBase表作为队列</h3>
<div class="paragraph">
<p>HBase表有时用作队列。在这种情况下，必须格外注意定期对以这种方式使用的桌子进行大夯实。如<a href="#datamodel">数据模型中所述</a> ，将行标记为已删除会创建其他StoreFile，然后需要在读取时对其进行处理。墓碑仅通过大压实清理。</p>
</div>
<div class="paragraph">
<p>另请参见<a href="#compaction">[compaction]</a>和<a href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/client/Admin.html#majorCompact%28java.lang.String%29">Admin.majorCompact</a> 。</p>
</div>
</div>
<div class="sect2">
<h3 id="perf.deleting.rpc"><a class="anchor" href="#perf.deleting.rpc"></a> 92.2。删除RPC行为</h3>
<div class="paragraph">
<p>意识到<code>Table.delete(Delete)</code>不使用writeBuffer。它将在每次调用时执行RegionServer RPC。对于大量删除，请考虑<code>Table.delete(List)</code> 。</p>
</div>
<div class="paragraph">
<p>请参阅<a href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/client/Table.html#delete%28org.apache.hadoop.hbase.client.Delete%29" class="bare">http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/client/Table.html#delete%28org.apache.hadoop.hbase.client.Delete%29</a></p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="perf.hdfs"><a class="anchor" href="#perf.hdfs"></a> 93。HDFS</h2>
<div class="sectionbody">
<div class="paragraph">
<p>因为HBase在<a href="#arch.hdfs">HDFS上</a>运行，所以重要的是要了解其工作方式以及它如何影响HBase。</p>
</div>
<div class="sect2">
<h3 id="perf.hdfs.curr"><a class="anchor" href="#perf.hdfs.curr"></a> 93.1。低延迟阅读的当前问题</h3>
<div class="paragraph">
<p>HDFS的原始用例是批处理。因此，从历史上看，低延迟读取并不是优先事项。随着对Apache HBase的越来越多的采用，这种情况正在改变，并且已经在进行一些改进。有关<a href="https://issues.apache.org/jira/browse/HDFS-1599">HBase的HDFS改进，</a>请参阅《 <a href="https://issues.apache.org/jira/browse/HDFS-1599">雨伞吉拉》门票</a> 。</p>
</div>
</div>
<div class="sect2">
<h3 id="perf.hdfs.configs.localread"><a class="anchor" href="#perf.hdfs.configs.localread"></a> 93.2。利用本地数据</h3>
<div class="paragraph">
<p>由于通过<a href="https://issues.apache.org/jira/browse/HDFS-2246">HDFS-2246的</a> Hadoop 1.0.0（以及0.22.1、0.23.1，CDH3u3和HDP 1.0），DFSClient可能会发生“短路”并直接从磁盘读取，而不是通过DataNode读取数据为本地时。对于HBase而言，这意味着RegionServer可以直接从其计算机的磁盘读取数据，而不必打开套接字来与DataNode进行通信，而后者通常要快得多。参见京东的<a href="http://files.meetup.com/1350427/hug_ebay_jdcryans.pdf">绩效演讲</a> 。另请参见<a href="http://search-hadoop.com/m/zV6dKrLCVh1">HBase，邮件＃dev-阅读短路</a>线程，以获取有关短路读取的更多讨论。</p>
</div>
<div class="paragraph">
<p>要启用“短路”读取，将取决于您的Hadoop版本。最初的短路读取补丁在<a href="https://issues.apache.org/jira/browse/HDFS-347">HDFS-347的</a> Hadoop 2中进行了很大的改进。有关两者之间差异的详细信息，请参见<a href="http://blog.cloudera.com/blog/2013/08/how-improved-short-circuit-local-reads-bring-better-performance-and-security-to-hadoop/" class="bare">http://blog.cloudera.com/blog/2013/08/how-improved-short-circuit-local-reads-bring-better-performance-and-security-to-hadoop/</a>旧的和新的实现。请参阅<a href="http://archive.cloudera.com/cdh4/cdh/4/hadoop/hadoop-project-dist/hadoop-hdfs/ShortCircuitLocalReads.html">Hadoop短路读取配置页，</a>以了解如何启用后者的更好的短路版本。例如，这是一个最小配置。启用添加到<em>hbase-site.xml</em>的短路读取：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="xml"><span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>dfs.client.read.shortcircuit<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>true<span class="tag">&lt;/value&gt;</span>
  <span class="tag">&lt;description&gt;</span>
    This configuration parameter turns on short-circuit local reads.
  <span class="tag">&lt;/description&gt;</span>
<span class="tag">&lt;/property&gt;</span>
<span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>dfs.domain.socket.path<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>/home/stack/sockets/short_circuit_read_socket_PORT<span class="tag">&lt;/value&gt;</span>
  <span class="tag">&lt;description&gt;</span>
    Optional.  This is a path to a UNIX domain socket that will be used for
    communication between the DataNode and local HDFS clients.
    If the string &quot;_PORT&quot; is present in this path, it will be replaced by the
    TCP port of the DataNode.
  <span class="tag">&lt;/description&gt;</span>
<span class="tag">&lt;/property&gt;</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>注意托管共享域套接字的目录的权限； dfsclient将向非hbase用户开放。</p>
</div>
<div class="paragraph">
<p>如果您在旧的Hadoop上运行，那么该旧Hadoop没有<a href="https://issues.apache.org/jira/browse/HDFS-347">HDFS-347</a>但具有<a href="https://issues.apache.org/jira/browse/HDFS-2246">HDFS-2246</a> ，则必须设置两个配置。首先，需要修改hdfs-site.xml。设置属性<code>dfs.block.local-path-access.user</code>成为<em>唯一</em>可以使用该快捷方式的用户。这必须是启动HBase的用户。然后在hbase-site.xml中设置<code>dfs.client.read.shortcircuit</code>成为<code>true</code></p>
</div>
<div class="paragraph">
<p>服务-至少是HBase RegionServers-将需要重新启动以选择新配置。</p>
</div>
<div class="admonitionblock note">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-note" title="注意"></i>
</td>
<td class="content">
<div class="title">dfs.client.read.shortcircuit.buffer.size</div>
<div class="paragraph">
<p>当在流量很高的HBase上运行时，此值的默认值太高。在HBase中，如果未设置此值，则将其从默认值1M设置为128k（自HBase 0.98.0和0.96.1起）。请参见<a href="https://issues.apache.org/jira/browse/HBASE-8143">Hadoop 2上的HBASE HBASE，具有本地短路读取（ssr）的原因是OOM</a> ）。HBase中的Hadoop DFSClient将为其打开的<em>每个</em>块分配此大小的直接字节缓冲区。鉴于HBase始终保持其HDFS文件打开，这可以快速累加。</p>
</div>
</td>
</tr>
</tbody></table>
</div>
</div>
<div class="sect2">
<h3 id="perf.hdfs.comp"><a class="anchor" href="#perf.hdfs.comp"></a> 93.3。HBase与HDFS的性能比较</h3>
<div class="paragraph">
<p>dist列表上的一个相当普遍的问题是，为什么HBase在批处理上下文中不如HDFS文件（例如，作为MapReduce源或接收器）那么出色。简短的答案是，HBase的性能要比HDFS好得多（例如，读取键值，返回最新行或指定的时间戳等），因此HBase在此处理上下文中比HDFS慢4-5倍。有改进的余地，随着时间的流逝，这种差距将不断缩小，但是在这种用例中，HDFS总是会更快。</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="perf.ec2"><a class="anchor" href="#perf.ec2"></a> 94。亚马逊EC2</h2>
<div class="sectionbody">
<div class="paragraph">
<p>性能问题在Amazon EC2环境中很常见，因为它是一个共享环境。您不会看到与专用服务器相同的吞吐量。就在EC2上运行测试而言，出于相同原因多次运行它们（即，它是一个共享环境，您不知道服务器上还发生了什么）。</p>
</div>
<div class="paragraph">
<p>如果您正在使用EC2并将性能问题发布到dist-list上，请预先声明这一事实，因为EC2问题实际上是一类单独的性能问题。</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="perf.hbase.mr.cluster"><a class="anchor" href="#perf.hbase.mr.cluster"></a> 95。并置HBase和MapReduce</h2>
<div class="sectionbody">
<div class="paragraph">
<p>通常建议对HBase和MapReduce使用不同的群集。一个更好的限定条件是：不要并置一个服务于具有大量MR工作负载的实时请求的HBase。OLTP和OLAP优化的系统有相互矛盾的要求，一个将输给另一个，通常是前者。例如，对延迟敏感的短磁盘读取将不得不在较长的读取之后排队等待，而较长的读取则试图挤出尽可能多的吞吐量。写入HBase的MR作业还将生成刷新和压缩，这将依次使<a href="#block.cache">Block Cache</a>中的<a href="#block.cache">块</a>无效。</p>
</div>
<div class="paragraph">
<p>如果需要处理来自MR中实时HBase群集的数据，则可以将<a href="#copy.table">[deltas]</a>与<a href="#copy.table">[copy.table]一起发送，</a>或使用复制在OLAP群集上实时获取新数据。在最坏的情况下，如果您确实需要同时配置两者，请将MR设置为使用比通常配置更少的Map和Reduce插槽，可能只有一个。</p>
</div>
<div class="paragraph">
<p>当将HBase用于OLAP操作时，最好以强化的方式进行设置，例如配置较高的ZooKeeper会话超时并为MemStores提供更多的内存（这种说法是，由于工作负载少，块缓存不会被大量使用）通常是长时间扫描）。</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="perf.casestudy"><a class="anchor" href="#perf.casestudy"></a> 96。实例探究</h2>
<div class="sectionbody">
<div class="paragraph">
<p>有关性能和故障排除案例研究，请参阅<a href="#casestudies">Apache HBase案例研究</a> 。</p>
</div>
</div>
</div>
<h1 id="profiler" class="sect0"><a class="anchor" href="#profiler"></a>探查器Servlet</h1>
<div class="sect1">
<h2 id="_background"><a class="anchor" href="#_background"></a> 97。背景</h2>
<div class="sectionbody">
<div class="paragraph">
<p>HBASE-21926引入了一个新的servlet，它支持通过async-profiler进行集成分析。</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_prerequisites_2"><a class="anchor" href="#_prerequisites_2"></a> 98。先决条件</h2>
<div class="sectionbody">
<div class="paragraph">
<p>转到<a href="https://github.com/jvm-profiling-tools/async-profiler" class="bare">https://github.com/jvm-profiling-tools/async-profiler</a> ，下载适合您平台的发行版，然后在每个群集主机上安装。</p>
</div>
<div class="paragraph">
<p>组<code>ASYNC_PROFILER_HOME</code>在环境中（将其放在hbase-env.sh中）放置到async-profiler安装位置的根目录中，或在HBase守护程序的命令行中将其作为系统属性传递给<code>-Dasync.profiler.home=/path/to/async-profiler</code> 。</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_usage"><a class="anchor" href="#_usage"></a> 99。用法</h2>
<div class="sectionbody">
<div class="paragraph">
<p>一旦满足先决条件，就可以通过HBase UI或直接与信息服务器交互来访问async-profiler。</p>
</div>
<div class="paragraph">
<p>例子：</p>
</div>
<div class="ulist">
<ul>
<li>
<p>收集当前进程的30秒CPU配置文件（返回FlameGraph svg）<code>curl <a href="http://localhost:16030/prof" class="bare">http://localhost:16030/prof</a></code></p>
</li>
<li>
<p>收集1分钟的当前进程的CPU配置文件并以树格式（html）输出<code>curl <a href="http://localhost:16030/prof?output=tree&duration=60" class="bare">http://localhost:16030/prof?output=tree&duration=60</a></code></p>
</li>
<li>
<p>收集当前进程的30秒堆分配配置文件（返回FlameGraph svg）<code>curl <a href="http://localhost:16030/prof?event=alloc" class="bare">http://localhost:16030/prof?event=alloc</a></code></p>
</li>
<li>
<p>收集当前进程的锁竞争配置文件（返回FlameGraph svg）<code>curl <a href="http://localhost:16030/prof?event=lock" class="bare">http://localhost:16030/prof?event=lock</a></code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>async-profiler支持以下事件类型。使用“事件”参数进行指定。默认值为“ cpu”。并非所有操作系统都支持所有类型。</p>
</div>
<div class="paragraph">
<p>性能事件：</p>
</div>
<div class="ulist">
<ul>
<li>
<p>中央处理器</p>
</li>
<li>
<p>页面错误</p>
</li>
<li>
<p>上下文切换</p>
</li>
<li>
<p>周期</p>
</li>
<li>
<p>指示</p>
</li>
<li>
<p>缓存引用</p>
</li>
<li>
<p>缓存未命中</p>
</li>
<li>
<p>分行</p>
</li>
<li>
<p>分支缺失</p>
</li>
<li>
<p>公交车</p>
</li>
<li>
<p>L1-dcache-load-misses</p>
</li>
<li>
<p>LLC负载缺失</p>
</li>
<li>
<p>dTLB-load-misses</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Java事件：</p>
</div>
<div class="ulist">
<ul>
<li>
<p>分配</p>
</li>
<li>
<p>锁</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>支持以下输出格式。使用“输出”参数进行指定。默认值为“ flamegraph”。</p>
</div>
<div class="paragraph">
<p>输出格式：</p>
</div>
<div class="ulist">
<ul>
<li>
<p>摘要：基本概要分析统计信息的转储。</p>
</li>
<li>
<p>跟踪：呼叫跟踪。</p>
</li>
<li>
<p>扁平：扁平轮廓（前N种热方法）。</p>
</li>
<li>
<p>折叠：以FlameGraph脚本使用的格式折叠的呼叫跟踪。这是调用堆栈的集合，其中每行是用分号分隔的帧列表，后跟一个计数器。</p>
</li>
<li>
<p>svg：SVG格式的FlameGraph。</p>
</li>
<li>
<p>tree：HTML格式的调用树。</p>
</li>
<li>
<p>jfr：Java Flight Recorder格式的呼叫跟踪。</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>“ duration”参数指定生成输出之前收集跟踪数据的时间（以秒为单位）。默认值为10秒。</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_ui"><a class="anchor" href="#_ui"></a> 100用户界面</h2>
<div class="sectionbody">
<div class="paragraph">
<p>在用户界面中，顶部菜单中有一个新条目“ Profiler”，它将运行默认操作，该操作用于分析本地进程的CPU使用情况三十秒钟，然后生成FlameGraph SVG输出。</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_notes"><a class="anchor" href="#_notes"></a> 101。笔记</h2>
<div class="sectionbody">
<div class="paragraph">
<p>查询参数<code>pid</code>可以用来指定要分析的特定进程的进程ID。如果缺少此参数，将分析嵌入信息服务器的本地进程。不是JVM的概要文件目标可能会起作用，但没有特别支持。存在安全隐患。应适当限制对信息服务器的访问。</p>
</div>
</div>
</div>
<h1 id="trouble" class="sect0"><a class="anchor" href="#trouble"></a>故障排除和调试Apache HBase</h1>
<div class="sect1">
<h2 id="trouble.general"><a class="anchor" href="#trouble.general"></a> 102。一般准则</h2>
<div class="sectionbody">
<div class="paragraph">
<p>始终从主日志开始（TODO：哪几行？）。通常，它只是一遍又一遍地打印相同的行。如果没有，那就有问题了。Google或<a href="http://search-hadoop.com">search-hadoop.com</a>应该为您看到的那些异常返回一些匹配。</p>
</div>
<div class="paragraph">
<p>在Apache HBase中，很少有错误会单独出现，通常是当发生问题时，可能会出现来自各地的数百个异常和堆栈跟踪信息。解决此类问题的最佳方法是将日志记录到所有内容的开始处，例如，使用RegionServers的一个技巧是它们在中止时将打印一些指标，因此对<em>Dump</em>进行<em>grepping</em>应该可以使您解决问题的开始。</p>
</div>
<div class="paragraph">
<p>RegionServer的自杀是“正常的”，因为这是出问题时的自杀行为。例如，如果ulimit和max传输线程（两个最重要的初始设置，请参见<a href="#ulimit">[ulimit]</a>和<a href="#dfs.datanode.max.transfer.threads"><code>dfs.datanode.max.transfer.threads</code></a> ）没有更改，这将使DataNode在某些时候无法创建新线程，从HBase的角度来看，新线程似乎已经消失了HDFS。想一想，如果您的MySQL数据库突然无法访问本地文件系统上的文件，将会发生什么事情，HBase和HDFS也是一样。看到RegionServer提交seppuku的另一个非常常见的原因是，当它们进入长时间的垃圾回收暂停时，该暂停的持续时间长于默认的ZooKeeper会话超时。有关GC暂停的详细信息，请参阅Todd Lipcon撰写的<a href="http://www.cloudera.com/blog/2011/02/avoiding-full-gcs-in-hbase-with-memstore-local-allocation-buffers-part-1/">博客博客</a> ，共<a href="http://www.cloudera.com/blog/2011/02/avoiding-full-gcs-in-hbase-with-memstore-local-allocation-buffers-part-1/">3部分</a> ，上面有<a href="#gcpause">Long GC暂停</a> 。</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="trouble.log"><a class="anchor" href="#trouble.log"></a> 103。日志</h2>
<div class="sectionbody">
<div class="paragraph">
<p>关键进程日志如下...（用<user>启动服务的用户</user>替换<user>并</user>替换<user><hostname>计算机名）</hostname></user></p>
</div>
<div class="paragraph">
<p>NameNode： <em>$ HADOOP_HOME / logs / <user>hadoop- -namenode- <hostname>.log</hostname></user></em></p>
</div>
<div class="paragraph">
<p>数据节点： <em>$ HADOOP_HOME / logs / <user>hadoop- -datanode- <hostname>.log</hostname></user></em></p>
</div>
<div class="paragraph">
<p>JobTracker： <em>$ HADOOP_HOME / logs / <user>hadoop- -jobtracker- <hostname>.log</hostname></user></em></p>
</div>
<div class="paragraph">
<p>TaskTracker： <em>$ HADOOP_HOME / logs / <user>hadoop- -tasktracker- <hostname>.log</hostname></user></em></p>
</div>
<div class="paragraph">
<p>HMaster： <em>$ HBASE_HOME / logs / hbase- <user>-master- <hostname>.log</hostname></user></em></p>
</div>
<div class="paragraph">
<p>RegionServer： <em>$ HBASE_HOME / logs / hbase- <user>-regionserver- <hostname>.log</hostname></user></em></p>
</div>
<div class="paragraph">
<p>ZooKeeper： <em>TODO</em></p>
</div>
<div class="sect2">
<h3 id="trouble.log.locations"><a class="anchor" href="#trouble.log.locations"></a> 103.1。日志位置</h3>
<div class="paragraph">
<p>对于独立部署，日志显然将存储在单台计算机上，但这仅是开发配置。生产部署需要在集群上运行。</p>
</div>
<div class="sect3">
<h4 id="trouble.log.locations.namenode"><a class="anchor" href="#trouble.log.locations.namenode"></a> 103.1.1。名称节点</h4>
<div class="paragraph">
<p>NameNode日志位于NameNode服务器上。HBase Master通常在NameNode服务器以及ZooKeeper上运行。</p>
</div>
<div class="paragraph">
<p>对于较小的群集，JobTracker / ResourceManager通常也可以在NameNode服务器上运行。</p>
</div>
</div>
<div class="sect3">
<h4 id="trouble.log.locations.datanode"><a class="anchor" href="#trouble.log.locations.datanode"></a> 103.1.2。数据节点</h4>
<div class="paragraph">
<p>每个DataNode服务器将具有HDFS的DataNode日志以及HBase的RegionServer日志。</p>
</div>
<div class="paragraph">
<p>此外，每个DataNode服务器还将具有一个TaskTracker / NodeManager日志，用于执行MapReduce任务。</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="trouble.log.levels"><a class="anchor" href="#trouble.log.levels"></a> 103.2。日志级别</h3>
<div class="sect3">
<h4 id="rpc.logging"><a class="anchor" href="#rpc.logging"></a> 103.2.1。启用RPC级别的日志记录</h4>
<div class="paragraph">
<p>在RegionServer上启用RPC级别的日志记录通常可以深入了解服务器的时序。启用后，涌出的日志量非常大。不建议您将此登录保持不超过一小段时间。要启用RPC级别的日志记录，请浏览到RegionServer UI并单击<em>Log Level</em> 。将日志级别设置为<code>DEBUG</code>包装<code>org.apache.hadoop.ipc</code> （是的，因为<code>hadoop.ipc</code> ，不是， <code>hbase.ipc</code> ）。然后尾随RegionServers日志。分析。</p>
</div>
<div class="paragraph">
<p>要禁用，请将日志记录级别设置回<code>INFO</code>水平。</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="trouble.log.gc"><a class="anchor" href="#trouble.log.gc"></a> 103.3。JVM垃圾收集日志</h3>
<div class="listingblock">
<div class="content">
<pre>All example Garbage Collection logs in this section are based on Java 7 and Java 8 output. The introduction of Unified Logging in Java 9 and newer will result in very different looking logs.</pre>
</div>
</div>
<div class="paragraph">
<p>HBase占用大量内存，使用默认GC，您可以在所有线程中看到长时间的停顿，包括<em>Juliet Pause</em>又名“死亡GC”。为了帮助调试或确认正在发生这种情况，可以在Java虚拟机中打开GC日志记录。</p>
</div>
<div class="paragraph">
<p>要启用，请在<em>hbase-env.sh</em>中取消注释以下行之一：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bourne"># This enables basic gc logging to the .out file.
# export SERVER_GC_OPTS=&quot;-verbose:gc -XX:+PrintGCDetails -XX:+PrintGCDateStamps&quot;

# This enables basic gc logging to its own file.
# export SERVER_GC_OPTS=&quot;-verbose:gc -XX:+PrintGCDetails -XX:+PrintGCDateStamps -Xloggc:&lt;FILE-PATH&gt;&quot;

# This enables basic GC logging to its own file with automatic log rolling. Only applies to jdk 1.6.0_34+ and 1.7.0_2+.
# export SERVER_GC_OPTS=&quot;-verbose:gc -XX:+PrintGCDetails -XX:+PrintGCDateStamps -Xloggc:&lt;FILE-PATH&gt; -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=1 -XX:GCLogFileSize=512M&quot;

# If &lt;FILE-PATH&gt; is not replaced, the log file(.gc) would be generated in the HBASE_LOG_DIR.</code></pre>
</div>
</div>
<div class="paragraph">
<p>此时，您应该看到如下日志：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="float">64898.952</span>: [GC [<span class="integer">1</span> CMS-initial-mark: <span class="integer">2811538</span>K(<span class="integer">3055704</span>K)] <span class="integer">2812179</span>K(<span class="integer">3061272</span>K), <span class="float">0.0007360</span> secs] [Times: user=<span class="float">0.00</span> sys=<span class="float">0.00</span>, real=<span class="float">0.00</span> secs]
<span class="float">64898.953</span>: [CMS-concurrent-mark-start]
<span class="float">64898.971</span>: [GC <span class="float">64898.971</span>: [ParNew: <span class="integer">5567</span>K-&gt;<span class="integer">576</span>K(<span class="integer">5568</span>K), <span class="float">0.0101110</span> secs] <span class="integer">2817105</span>K-&gt;<span class="integer">2812715</span>K(<span class="integer">3061272</span>K), <span class="float">0.0102200</span> secs] [Times: user=<span class="float">0.07</span> sys=<span class="float">0.00</span>, real=<span class="float">0.01</span> secs]</code></pre>
</div>
</div>
<div class="paragraph">
<p>在此部分中，第一行表示CMS最初标记为0.0007360秒的暂停。这会暂停整个VM，该时间段内的所有线程。</p>
</div>
<div class="paragraph">
<p>第三行表示“次要GC”，它将VM暂停0.0101110秒（也就是10毫秒）。它已将“ ParNew”从大约5.5m减少到576k。在本周期的后面，我们看到：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="float">64901.445</span>: [CMS-concurrent-mark: <span class="float">1.542</span>/<span class="float">2.492</span> secs] [Times: user=<span class="float">10.49</span> sys=<span class="float">0.33</span>, real=<span class="float">2.49</span> secs]
<span class="float">64901.445</span>: [CMS-concurrent-preclean-start]
<span class="float">64901.453</span>: [GC <span class="float">64901.453</span>: [ParNew: <span class="integer">5505</span>K-&gt;<span class="integer">573</span>K(<span class="integer">5568</span>K), <span class="float">0.0062440</span> secs] <span class="integer">2868746</span>K-&gt;<span class="integer">2864292</span>K(<span class="integer">3061272</span>K), <span class="float">0.0063360</span> secs] [Times: user=<span class="float">0.05</span> sys=<span class="float">0.00</span>, real=<span class="float">0.01</span> secs]
<span class="float">64901.476</span>: [GC <span class="float">64901.476</span>: [ParNew: <span class="integer">5563</span>K-&gt;<span class="integer">575</span>K(<span class="integer">5568</span>K), <span class="float">0.0072510</span> secs] <span class="integer">2869283</span>K-&gt;<span class="integer">2864837</span>K(<span class="integer">3061272</span>K), <span class="float">0.0073320</span> secs] [Times: user=<span class="float">0.05</span> sys=<span class="float">0.01</span>, real=<span class="float">0.01</span> secs]
<span class="float">64901.500</span>: [GC <span class="float">64901.500</span>: [ParNew: <span class="integer">5517</span>K-&gt;<span class="integer">573</span>K(<span class="integer">5568</span>K), <span class="float">0.0120390</span> secs] <span class="integer">2869780</span>K-&gt;<span class="integer">2865267</span>K(<span class="integer">3061272</span>K), <span class="float">0.0121150</span> secs] [Times: user=<span class="float">0.09</span> sys=<span class="float">0.00</span>, real=<span class="float">0.01</span> secs]
<span class="float">64901.529</span>: [GC <span class="float">64901.529</span>: [ParNew: <span class="integer">5507</span>K-&gt;<span class="integer">569</span>K(<span class="integer">5568</span>K), <span class="float">0.0086240</span> secs] <span class="integer">2870200</span>K-&gt;<span class="integer">2865742</span>K(<span class="integer">3061272</span>K), <span class="float">0.0087180</span> secs] [Times: user=<span class="float">0.05</span> sys=<span class="float">0.00</span>, real=<span class="float">0.01</span> secs]
<span class="float">64901.554</span>: [GC <span class="float">64901.555</span>: [ParNew: <span class="integer">5516</span>K-&gt;<span class="integer">575</span>K(<span class="integer">5568</span>K), <span class="float">0.0107130</span> secs] <span class="integer">2870689</span>K-&gt;<span class="integer">2866291</span>K(<span class="integer">3061272</span>K), <span class="float">0.0107820</span> secs] [Times: user=<span class="float">0.06</span> sys=<span class="float">0.00</span>, real=<span class="float">0.01</span> secs]
<span class="float">64901.578</span>: [CMS-concurrent-preclean: <span class="float">0.070</span>/<span class="float">0.133</span> secs] [Times: user=<span class="float">0.48</span> sys=<span class="float">0.01</span>, real=<span class="float">0.14</span> secs]
<span class="float">64901.578</span>: [CMS-concurrent-abortable-preclean-start]
<span class="float">64901.584</span>: [GC <span class="float">64901.584</span>: [ParNew: <span class="integer">5504</span>K-&gt;<span class="integer">571</span>K(<span class="integer">5568</span>K), <span class="float">0.0087270</span> secs] <span class="integer">2871220</span>K-&gt;<span class="integer">2866830</span>K(<span class="integer">3061272</span>K), <span class="float">0.0088220</span> secs] [Times: user=<span class="float">0.05</span> sys=<span class="float">0.00</span>, real=<span class="float">0.01</span> secs]
<span class="float">64901.609</span>: [GC <span class="float">64901.609</span>: [ParNew: <span class="integer">5512</span>K-&gt;<span class="integer">569</span>K(<span class="integer">5568</span>K), <span class="float">0.0063370</span> secs] <span class="integer">2871771</span>K-&gt;<span class="integer">2867322</span>K(<span class="integer">3061272</span>K), <span class="float">0.0064230</span> secs] [Times: user=<span class="float">0.06</span> sys=<span class="float">0.00</span>, real=<span class="float">0.01</span> secs]
<span class="float">64901.615</span>: [CMS-concurrent-abortable-preclean: <span class="float">0.007</span>/<span class="float">0.037</span> secs] [Times: user=<span class="float">0.13</span> sys=<span class="float">0.00</span>, real=<span class="float">0.03</span> secs]
<span class="float">64901.616</span>: [GC[YG occupancy: <span class="integer">645</span> K (<span class="integer">5568</span> K)]<span class="float">64901.616</span>: [Rescan (parallel) , <span class="float">0.0020210</span> secs]<span class="float">64901.618</span>: [weak refs processing, <span class="float">0.0027950</span> secs] [<span class="integer">1</span> CMS-remark: <span class="integer">2866753</span>K(<span class="integer">3055704</span>K)] <span class="integer">2867399</span>K(<span class="integer">3061272</span>K), <span class="float">0.0049380</span> secs] [Times: user=<span class="float">0.00</span> sys=<span class="float">0.01</span>, real=<span class="float">0.01</span> secs]
<span class="float">64901.621</span>: [CMS-concurrent-sweep-start]</code></pre>
</div>
</div>
<div class="paragraph">
<p>第一行表示CMS并发标记（查找垃圾）已花费2.4秒。但这是<em>并发的</em> 2.4秒，Java在任何时间都没有暂停过。</p>
</div>
<div class="paragraph">
<p>还有一些次要的GC，然后在最后第二行有一个停顿：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="float">64901.616</span>: [GC[YG occupancy: <span class="integer">645</span> K (<span class="integer">5568</span> K)]<span class="float">64901.616</span>: [Rescan (parallel) , <span class="float">0.0020210</span> secs]<span class="float">64901.618</span>: [weak refs processing, <span class="float">0.0027950</span> secs] [<span class="integer">1</span> CMS-remark: <span class="integer">2866753</span>K(<span class="integer">3055704</span>K)] <span class="integer">2867399</span>K(<span class="integer">3061272</span>K), <span class="float">0.0049380</span> secs] [Times: user=<span class="float">0.00</span> sys=<span class="float">0.01</span>, real=<span class="float">0.01</span> secs]</code></pre>
</div>
</div>
<div class="paragraph">
<p>此处的暂停为0.0049380秒（即4.9毫秒），以“标记”堆。</p>
</div>
<div class="paragraph">
<p>此时，扫描开始，您可以看到堆大小减小了：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="float">64901.637</span>: [GC <span class="float">64901.637</span>: [ParNew: <span class="integer">5501</span>K-&gt;<span class="integer">569</span>K(<span class="integer">5568</span>K), <span class="float">0.0097350</span> secs] <span class="integer">2871958</span>K-&gt;<span class="integer">2867441</span>K(<span class="integer">3061272</span>K), <span class="float">0.0098370</span> secs] [Times: user=<span class="float">0.05</span> sys=<span class="float">0.00</span>, real=<span class="float">0.01</span> secs]
...  lines removed ...
<span class="float">64904.936</span>: [GC <span class="float">64904.936</span>: [ParNew: <span class="integer">5532</span>K-&gt;<span class="integer">568</span>K(<span class="integer">5568</span>K), <span class="float">0.0070720</span> secs] <span class="integer">1365024</span>K-&gt;<span class="integer">1360689</span>K(<span class="integer">3061272</span>K), <span class="float">0.0071930</span> secs] [Times: user=<span class="float">0.05</span> sys=<span class="float">0.00</span>, real=<span class="float">0.01</span> secs]
<span class="float">64904.953</span>: [CMS-concurrent-sweep: <span class="float">2.030</span>/<span class="float">3.332</span> secs] [Times: user=<span class="float">9.57</span> sys=<span class="float">0.26</span>, real=<span class="float">3.33</span> secs]</code></pre>
</div>
</div>
<div class="paragraph">
<p>此时，CMS扫描花费了3.332秒，并且堆从大约2.8 GB变为了1.3 GB（大约）。</p>
</div>
<div class="paragraph">
<p>这里的关键点是保持所有这些低暂停。CMS暂停总是很低，但是如果您的ParNew开始增长，您会看到较小的GC暂停接近100毫秒，超过100毫秒，然后达到400毫秒。</p>
</div>
<div class="paragraph">
<p>这可能是由于ParNew的大小，该大小应该相对较小。如果在运行HBase一段时间后您的ParNew非常大，例如一个ParNew约为150MB，则您可能必须限制ParNew的大小（它越大，集合花费的时间就越长，但是如果对象太小，则对象被提升为老一代太快）。在下面，我们将新发电机的尺寸限制为64m。</p>
</div>
<div class="paragraph">
<p>在<em>hbase-env.sh中</em>添加以下行：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bourne">export SERVER_GC_OPTS=&quot;$SERVER_GC_OPTS -XX:NewSize=64m -XX:MaxNewSize=64m&quot;</code></pre>
</div>
</div>
<div class="paragraph">
<p>同样，要为客户端进程启用GC日志记录，请在<em>hbase-env.sh中</em>取消注释以下行之一：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bourne"># This enables basic gc logging to the .out file.
# export CLIENT_GC_OPTS=&quot;-verbose:gc -XX:+PrintGCDetails -XX:+PrintGCDateStamps&quot;

# This enables basic gc logging to its own file.
# export CLIENT_GC_OPTS=&quot;-verbose:gc -XX:+PrintGCDetails -XX:+PrintGCDateStamps -Xloggc:&lt;FILE-PATH&gt;&quot;

# This enables basic GC logging to its own file with automatic log rolling. Only applies to jdk 1.6.0_34+ and 1.7.0_2+.
# export CLIENT_GC_OPTS=&quot;-verbose:gc -XX:+PrintGCDetails -XX:+PrintGCDateStamps -Xloggc:&lt;FILE-PATH&gt; -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=1 -XX:GCLogFileSize=512M&quot;

# If &lt;FILE-PATH&gt; is not replaced, the log file(.gc) would be generated in the HBASE_LOG_DIR .</code></pre>
</div>
</div>
<div class="paragraph">
<p>有关GC暂停的详细信息，请参阅Todd Lipcon撰写的<a href="http://www.cloudera.com/blog/2011/02/avoiding-full-gcs-in-hbase-with-memstore-local-allocation-buffers-part-1/">博客博客</a> ，共<a href="http://www.cloudera.com/blog/2011/02/avoiding-full-gcs-in-hbase-with-memstore-local-allocation-buffers-part-1/">3部分</a> ，上面有<a href="#gcpause">Long GC暂停</a> 。</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="trouble.resources"><a class="anchor" href="#trouble.resources"></a> 104。资源资源</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="trouble.resources.searchhadoop"><a class="anchor" href="#trouble.resources.searchhadoop"></a> 104.1。 search-hadoop.com</h3>
<div class="paragraph">
<p><a href="http://search-hadoop.com">search-hadoop.com为</a>所有邮件列表<a href="http://search-hadoop.com">建立</a>索引，非常适合历史搜索。当您遇到问题时，请先在此处搜索，因为问题可能已经有人解决了。</p>
</div>
</div>
<div class="sect2">
<h3 id="trouble.resources.lists"><a class="anchor" href="#trouble.resources.lists"></a> 104.2。邮件列表</h3>
<div class="paragraph">
<p>在<a href="http://hbase.apache.org/mail-lists.html">Apache HBase邮件列表</a>上提出问题。“ dev”邮件列表针对的是实际构建Apache HBase的开发人员社区以及当前正在开发的功能，而“ user”通常用于对Apache HBase的发行版提出疑问。在转到邮件列表之前，请先搜索邮件列表档案，以确保您的问题尚未得到回答。使用<a href="#trouble.resources.searchhadoop">search-hadoop.com</a> 。花一些时间来准备您的问题。请参阅<a href="http://www.mikeash.com/getting_answers.html">获取答案，</a>以<a href="http://www.mikeash.com/getting_answers.html">获取</a>有关精心设计好的问题的想法。包含所有上下文并显示出作者试图在手册中找到答案并列在清单中的证据的质量问题更有可能得到迅速的答复。</p>
</div>
</div>
<div class="sect2">
<h3 id="trouble.resources.irc"><a class="anchor" href="#trouble.resources.irc"></a> 104.3。IRC</h3>
<div class="paragraph">
<p>#hbase在irc.freenode.net上</p>
</div>
</div>
<div class="sect2">
<h3 id="trouble.resources.jira"><a class="anchor" href="#trouble.resources.jira"></a> 104.4。吉拉</h3>
<div class="paragraph">
<p>在寻找特定于Hadoop / HBase的问题时， <a href="https://issues.apache.org/jira/browse/HBASE">JIRA</a>确实也很有帮助。</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="trouble.tools"><a class="anchor" href="#trouble.tools"></a> 105。工具类</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="trouble.tools.builtin"><a class="anchor" href="#trouble.tools.builtin"></a> 105.1。内建工具</h3>
<div class="sect3">
<h4 id="trouble.tools.builtin.webmaster"><a class="anchor" href="#trouble.tools.builtin.webmaster"></a> 105.1.1。主网页界面</h4>
<div class="paragraph">
<p>主机默认在端口16010上启动Web界面。</p>
</div>
<div class="paragraph">
<p>主Web UI列出了创建的表及其定义（例如ColumnFamilies，blocksize等）。此外，列出了群集中可用的RegionServer以及选定的高级指标（请求，区域数，usedHeap，maxHeap）。主Web UI允许导航到每个RegionServer的Web UI。</p>
</div>
</div>
<div class="sect3">
<h4 id="trouble.tools.builtin.webregion"><a class="anchor" href="#trouble.tools.builtin.webregion"></a> 105.1.2。RegionServer Web界面</h4>
<div class="paragraph">
<p>默认情况下，RegionServers在端口16030上启动Web界面。</p>
</div>
<div class="paragraph">
<p>RegionServer Web UI列出了联机区域及其开始/结束键，以及时间点RegionServer指标（请求，区域，storeFileIndexSize，compressionionSize等）。</p>
</div>
<div class="paragraph">
<p>有关度量标准定义的更多信息，请参见<a href="#hbase_metrics">[hbase_metrics]</a> 。</p>
</div>
</div>
<div class="sect3">
<h4 id="trouble.tools.builtin.zkcli"><a class="anchor" href="#trouble.tools.builtin.zkcli"></a> 105.1.3。 zkcli</h4>
<div class="paragraph">
<p><code>zkcli</code>是调查ZooKeeper相关问题的非常有用的工具。调用：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bourne">./hbase zkcli -server host:port &lt;cmd&gt; &lt;args&gt;</code></pre>
</div>
</div>
<div class="paragraph">
<p>命令（和参数）为：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">  connect host:port
  get path [watch]
  ls path [watch]
  set path data [version]
  delquota [-n|-b] path
  quit
  printwatches on|off
  create [-s] [-e] path data acl
  stat path [watch]
  close
  ls2 path [watch]
  history
  listquota path
  setAcl path acl
  getAcl path
  sync path
  redo cmdno
  addauth scheme auth
  delete path [version]
  setquota -n|-b val path</code></pre>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="trouble.tools.external"><a class="anchor" href="#trouble.tools.external"></a> 105.2。外部工具</h3>
<div class="sect3">
<h4 id="trouble.tools.tail"><a class="anchor" href="#trouble.tools.tail"></a> 105.2.1。尾巴</h4>
<div class="paragraph">
<p><code>tail</code>是可让您查看文件末尾的命令行工具。添加<code>-f</code>选项，并在有新数据可用时刷新。当您想知道正在发生的事情时，此功能非常有用，例如，当集群需要很长时间关闭或启动时，您只需触发一个新终端并尾随主日志（可能还有一些RegionServers）即可。</p>
</div>
</div>
<div class="sect3">
<h4 id="trouble.tools.top"><a class="anchor" href="#trouble.tools.top"></a> 105.2.2。最佳</h4>
<div class="paragraph">
<p><code>top</code>首次尝试查看计算机上正在运行的东西以及如何消耗资源时，它可能是最重要的工具之一。这是生产系统中的一个示例：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">top - <span class="integer">14</span>:<span class="integer">46</span>:<span class="integer">59</span> up <span class="integer">39</span> days, <span class="integer">11</span>:<span class="integer">55</span>,  <span class="integer">1</span> user,  load average: <span class="float">3.75</span>, <span class="float">3.57</span>, <span class="float">3.84</span>
Tasks: <span class="integer">309</span> total,   <span class="integer">1</span> running, <span class="integer">308</span> sleeping,   <span class="integer">0</span> stopped,   <span class="integer">0</span> zombie
Cpu(s):  <span class="float">4.5</span>%us,  <span class="float">1.6</span>%sy,  <span class="float">0.0</span>%ni, <span class="float">91.7</span>%id,  <span class="float">1.4</span>%wa,  <span class="float">0.1</span>%hi,  <span class="float">0.6</span>%si,  <span class="float">0.0</span>%st
Mem:  <span class="integer">24414432</span>k total, <span class="integer">24296956</span>k used,   <span class="integer">117476</span>k free,     <span class="integer">7196</span>k buffers
Swap: <span class="integer">16008732</span>k total,        <span class="integer">14348</span>k used, <span class="integer">15994384</span>k free, <span class="integer">11106908</span>k cached

  PID USER          PR  NI  VIRT  RES  SHR S %CPU %MEM        TIME+  COMMAND
<span class="integer">15558</span> hadoop        <span class="integer">18</span>  -<span class="integer">2</span> <span class="integer">3292</span>m <span class="float">2.4</span>g <span class="integer">3556</span> S   <span class="integer">79</span> <span class="float">10.4</span>   <span class="integer">6523</span>:<span class="integer">52</span> java
<span class="integer">13268</span> hadoop        <span class="integer">18</span>  -<span class="integer">2</span> <span class="integer">8967</span>m <span class="float">8.2</span>g <span class="integer">4104</span> S   <span class="integer">21</span> <span class="float">35.1</span>   <span class="integer">5170</span>:<span class="integer">30</span> java
 <span class="integer">8895</span> hadoop        <span class="integer">18</span>  -<span class="integer">2</span> <span class="integer">1581</span>m <span class="integer">497</span>m <span class="integer">3420</span> S   <span class="integer">11</span>  <span class="float">2.1</span>   <span class="integer">4002</span>:<span class="integer">32</span> java
<span class="error">…</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>在这里，我们可以看到最近五分钟的系统平均负载为3.75，这非常粗略地意味着这五分钟中平均有3.75个线程在等待CPU时间。通常， <em>理想的</em>利用率等于内核数，在该数目下，机器的利用率不足，而在利用率超过的情况下。这是一个重要的概念，请参阅本文以进一步了解它： <a href="http://www.linuxjournal.com/article/9001" class="bare">http</a> : <a href="http://www.linuxjournal.com/article/9001" class="bare">//www.linuxjournal.com/article/9001</a> 。</p>
</div>
<div class="paragraph">
<p>除了负载，我们可以看到系统几乎在使用所有可用的RAM，但是大部分都用于OS缓存（很好）。交换中只有几个KB，这是需要的，较高的数字表示交换活动，这是Java系统性能的克星。检测交换的另一种方法是平均负载何时通过屋顶（尽管这也可能是由于磁盘即将耗尽等引起的）。</p>
</div>
<div class="paragraph">
<p>默认情况下，进程列表并不是超级有用，我们所知道的是3个Java进程正在使用约111％的CPU。要知道哪个是哪个，只需键入<code>c</code>并且每行都会扩展。打字<code>1</code>将为您提供有关如何使用每个CPU的详细信息，而不是如此处所示的所有CPU的平均值。</p>
</div>
</div>
<div class="sect3">
<h4 id="trouble.tools.jps"><a class="anchor" href="#trouble.tools.jps"></a> 105.2.3。 jps</h4>
<div class="paragraph">
<p><code>jps</code>每个JDK都附带了该文件，并为当前用户提供了Java进程ID（如果为root，则为所有用户提供了ID）。例：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bourne">hadoop@sv4borg12:~$ jps
1322 TaskTracker
17789 HRegionServer
27862 Child
1158 DataNode
25115 HQuorumPeer
2950 Jps
19750 ThriftServer
18776 jmx</code></pre>
</div>
</div>
<div class="paragraph">
<p>依次看到：</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Hadoop TaskTracker，管理本地Childs</p>
</li>
<li>
<p>HBase RegionServer，服务区域</p>
</li>
<li>
<p>子项，其MapReduce任务，无法确切分辨出哪种类型</p>
</li>
<li>
<p>Hadoop TaskTracker，管理本地Childs</p>
</li>
<li>
<p>Hadoop DataNode，服务块</p>
</li>
<li>
<p>HQuorumPeer，ZooKeeper合奏成员</p>
</li>
<li>
<p>JPS，好吧...这是当前过程</p>
</li>
<li>
<p>ThriftServer，这是一种特殊的，只有在启动Thrift时才会运行</p>
</li>
<li>
<p>jmx，这是一个本地进程，它是我们的监视平台的一部分（可能命名不佳）。您可能没有。</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>然后，您可以执行诸如检查启动该过程的完整命令行的操作：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bourne">hadoop@sv4borg12:~$ ps aux | grep HRegionServer
hadoop   17789  155 35.2 9067824 8604364 ?     S&amp;lt;l  Mar04 9855:48 /usr/java/jdk1.6.0_14/bin/java -Xmx8000m -XX:+DoEscapeAnalysis -XX:+AggressiveOpts -XX:+UseConcMarkSweepGC -XX:NewSize=64m -XX:MaxNewSize=64m -XX:CMSInitiatingOccupancyFraction=88 -verbose:gc -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -Xloggc:/export1/hadoop/logs/gc-hbase.log -Dcom.sun.management.jmxremote.port=10102 -Dcom.sun.management.jmxremote.authenticate=true -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.password.file=/home/hadoop/hbase/conf/jmxremote.password -Dcom.sun.management.jmxremote -Dhbase.log.dir=/export1/hadoop/logs -Dhbase.log.file=hbase-hadoop-regionserver-sv4borg12.log -Dhbase.home.dir=/home/hadoop/hbase -Dhbase.id.str=hadoop -Dhbase.root.logger=INFO,DRFA -Djava.library.path=/home/hadoop/hbase/lib/native/Linux-amd64-64 -classpath /home/hadoop/hbase/bin/../conf:[many jars]:/home/hadoop/hadoop/conf org.apache.hadoop.hbase.regionserver.HRegionServer start</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="trouble.tools.jstack"><a class="anchor" href="#trouble.tools.jstack"></a> 105.2.4。 jstack</h4>
<div class="paragraph">
<p><code>jstack</code>除了查看日志之外，它是试图弄清楚java进程正在执行的操作时最重要的工具之一。它必须与jps结合使用才能为其赋予进程ID。它显示了一个线程列表，每个线程都有一个名称，并且按照创建顺序显示（因此，最前面的是最新的线程）。以下是一些示例：</p>
</div>
<div class="paragraph">
<p>RegionServer的主线程等待主服务器执行操作：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="string"><span class="delimiter">&quot;</span><span class="content">regionserver60020</span><span class="delimiter">&quot;</span></span> prio=<span class="integer">10</span> tid=<span class="hex">0x0000000040ab4000</span> nid=<span class="hex">0x45cf</span> waiting on condition [<span class="hex">0x00007f16b6a96000</span>.<span class="float">.0</span>x00007f16b6a96a70]
java.lang.Thread.State: TIMED_WAITING (parking)
    at sun.misc.Unsafe.park(Native <span class="predefined-type">Method</span>)
    - parking to wait <span class="keyword">for</span>  &lt;<span class="hex">0x00007f16cd5c2f30</span>&gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer<span class="error">$</span>ConditionObject)
    at java.util.concurrent.locks.LockSupport.parkNanos(<span class="predefined-type">LockSupport</span>.java:<span class="integer">198</span>)
    at java.util.concurrent.locks.AbstractQueuedSynchronizer<span class="error">$</span>ConditionObject.awaitNanos(<span class="predefined-type">AbstractQueuedSynchronizer</span>.java:<span class="integer">1963</span>)
    at java.util.concurrent.LinkedBlockingQueue.poll(<span class="predefined-type">LinkedBlockingQueue</span>.java:<span class="integer">395</span>)
    at org.apache.hadoop.hbase.regionserver.HRegionServer.run(HRegionServer.java:<span class="integer">647</span>)
    at java.lang.Thread.run(<span class="predefined-type">Thread</span>.java:<span class="integer">619</span>)</code></pre>
</div>
</div>
<div class="paragraph">
<p>目前正在刷新到文件的MemStore刷新程序线程：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="string"><span class="delimiter">&quot;</span><span class="content">regionserver60020.cacheFlusher</span><span class="delimiter">&quot;</span></span> daemon prio=<span class="integer">10</span> tid=<span class="hex">0x0000000040f4e000</span> nid=<span class="hex">0x45eb</span> in <span class="predefined-type">Object</span>.wait() [<span class="hex">0x00007f16b5b86000</span>.<span class="float">.0</span>x00007f16b5b87af0]
java.lang.Thread.State: WAITING (on object monitor)
    at java.lang.Object.wait(Native <span class="predefined-type">Method</span>)
    at java.lang.Object.wait(<span class="predefined-type">Object</span>.java:<span class="integer">485</span>)
    at org.apache.hadoop.ipc.Client.call(Client.java:<span class="integer">803</span>)
    - locked &lt;<span class="hex">0x00007f16cb14b3a8</span>&gt; (a org.apache.hadoop.ipc.Client<span class="error">$</span>Call)
    at org.apache.hadoop.ipc.RPC<span class="error">$</span>Invoker.invoke(RPC.java:<span class="integer">221</span>)
    at <span class="error">$</span>Proxy1.complete(Unknown <span class="predefined-type">Source</span>)
    at sun.reflect.GeneratedMethodAccessor38.invoke(Unknown <span class="predefined-type">Source</span>)
    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:<span class="integer">25</span>)
    at java.lang.reflect.Method.invoke(<span class="predefined-type">Method</span>.java:<span class="integer">597</span>)
    at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:<span class="integer">82</span>)
    at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:<span class="integer">59</span>)
    at <span class="error">$</span>Proxy1.complete(Unknown <span class="predefined-type">Source</span>)
    at org.apache.hadoop.hdfs.DFSClient<span class="error">$</span>DFSOutputStream.closeInternal(DFSClient.java:<span class="integer">3390</span>)
    - locked &lt;<span class="hex">0x00007f16cb14b470</span>&gt; (a org.apache.hadoop.hdfs.DFSClient<span class="error">$</span>DFSOutputStream)
    at org.apache.hadoop.hdfs.DFSClient<span class="error">$</span>DFSOutputStream.close(DFSClient.java:<span class="integer">3304</span>)
    at org.apache.hadoop.fs.FSDataOutputStream<span class="error">$</span>PositionCache.close(FSDataOutputStream.java:<span class="integer">61</span>)
    at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:<span class="integer">86</span>)
    at org.apache.hadoop.hbase.io.hfile.HFile<span class="error">$</span><span class="predefined-type">Writer</span>.close(HFile.java:<span class="integer">650</span>)
    at org.apache.hadoop.hbase.regionserver.StoreFile<span class="error">$</span><span class="predefined-type">Writer</span>.close(StoreFile.java:<span class="integer">853</span>)
    at org.apache.hadoop.hbase.regionserver.Store.internalFlushCache(Store.java:<span class="integer">467</span>)
    - locked &lt;<span class="hex">0x00007f16d00e6f08</span>&gt; (a java.lang.Object)
    at org.apache.hadoop.hbase.regionserver.Store.flushCache(Store.java:<span class="integer">427</span>)
    at org.apache.hadoop.hbase.regionserver.Store.access<span class="error">$</span><span class="integer">100</span>(Store.java:<span class="integer">80</span>)
    at org.apache.hadoop.hbase.regionserver.Store<span class="error">$</span>StoreFlusherImpl.flushCache(Store.java:<span class="integer">1359</span>)
    at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:<span class="integer">907</span>)
    at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:<span class="integer">834</span>)
    at org.apache.hadoop.hbase.regionserver.HRegion.flushcache(HRegion.java:<span class="integer">786</span>)
    at org.apache.hadoop.hbase.regionserver.MemStoreFlusher.flushRegion(MemStoreFlusher.java:<span class="integer">250</span>)
    at org.apache.hadoop.hbase.regionserver.MemStoreFlusher.flushRegion(MemStoreFlusher.java:<span class="integer">224</span>)
    at org.apache.hadoop.hbase.regionserver.MemStoreFlusher.run(MemStoreFlusher.java:<span class="integer">146</span>)</code></pre>
</div>
</div>
<div class="paragraph">
<p>正在等待操作（例如放置，删除，扫描等）的处理程序线程：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="string"><span class="delimiter">&quot;</span><span class="content">IPC Server handler 16 on 60020</span><span class="delimiter">&quot;</span></span> daemon prio=<span class="integer">10</span> tid=<span class="hex">0x00007f16b011d800</span> nid=<span class="hex">0x4a5e</span> waiting on condition [<span class="hex">0x00007f16afefd000</span>.<span class="float">.0</span>x00007f16afefd9f0]
   java.lang.Thread.State: WAITING (parking)
          at sun.misc.Unsafe.park(Native <span class="predefined-type">Method</span>)
          - parking to wait <span class="keyword">for</span>  &lt;<span class="hex">0x00007f16cd3f8dd8</span>&gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer<span class="error">$</span>ConditionObject)
          at java.util.concurrent.locks.LockSupport.park(<span class="predefined-type">LockSupport</span>.java:<span class="integer">158</span>)
          at java.util.concurrent.locks.AbstractQueuedSynchronizer<span class="error">$</span>ConditionObject.await(<span class="predefined-type">AbstractQueuedSynchronizer</span>.java:<span class="integer">1925</span>)
          at java.util.concurrent.LinkedBlockingQueue.take(<span class="predefined-type">LinkedBlockingQueue</span>.java:<span class="integer">358</span>)
          at org.apache.hadoop.hbase.ipc.HBaseServer<span class="error">$</span><span class="predefined-type">Handler</span>.run(HBaseServer.java:<span class="integer">1013</span>)</code></pre>
</div>
</div>
<div class="paragraph">
<p>一个正在忙着增加计数器的计数器（它正处于尝试创建扫描器以读取最后一个值的阶段）：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="string"><span class="delimiter">&quot;</span><span class="content">IPC Server handler 66 on 60020</span><span class="delimiter">&quot;</span></span> daemon prio=<span class="integer">10</span> tid=<span class="hex">0x00007f16b006e800</span> nid=<span class="hex">0x4a90</span> runnable [<span class="hex">0x00007f16acb77000</span>.<span class="float">.0</span>x00007f16acb77cf0]
   java.lang.Thread.State: RUNNABLE
          at org.apache.hadoop.hbase.regionserver.KeyValueHeap.&lt;init&gt;(KeyValueHeap.java:<span class="integer">56</span>)
          at org.apache.hadoop.hbase.regionserver.StoreScanner.&lt;init&gt;(StoreScanner.java:<span class="integer">79</span>)
          at org.apache.hadoop.hbase.regionserver.Store.getScanner(Store.java:<span class="integer">1202</span>)
          at org.apache.hadoop.hbase.regionserver.HRegion<span class="error">$</span>RegionScanner.&lt;init&gt;(HRegion.java:<span class="integer">2209</span>)
          at org.apache.hadoop.hbase.regionserver.HRegion.instantiateInternalScanner(HRegion.java:<span class="integer">1063</span>)
          at org.apache.hadoop.hbase.regionserver.HRegion.getScanner(HRegion.java:<span class="integer">1055</span>)
          at org.apache.hadoop.hbase.regionserver.HRegion.getScanner(HRegion.java:<span class="integer">1039</span>)
          at org.apache.hadoop.hbase.regionserver.HRegion.getLastIncrement(HRegion.java:<span class="integer">2875</span>)
          at org.apache.hadoop.hbase.regionserver.HRegion.incrementColumnValue(HRegion.java:<span class="integer">2978</span>)
          at org.apache.hadoop.hbase.regionserver.HRegionServer.incrementColumnValue(HRegionServer.java:<span class="integer">2433</span>)
          at sun.reflect.GeneratedMethodAccessor20.invoke(Unknown <span class="predefined-type">Source</span>)
          at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:<span class="integer">25</span>)
          at java.lang.reflect.Method.invoke(<span class="predefined-type">Method</span>.java:<span class="integer">597</span>)
          at org.apache.hadoop.hbase.ipc.HBaseRPC<span class="error">$</span>Server.call(HBaseRPC.java:<span class="integer">560</span>)
          at org.apache.hadoop.hbase.ipc.HBaseServer<span class="error">$</span><span class="predefined-type">Handler</span>.run(HBaseServer.java:<span class="integer">1027</span>)</code></pre>
</div>
</div>
<div class="paragraph">
<p>从HDFS接收数据的线程：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="string"><span class="delimiter">&quot;</span><span class="content">IPC Client (47) connection to sv4borg9/10.4.24.40:9000 from hadoop</span><span class="delimiter">&quot;</span></span> daemon prio=<span class="integer">10</span> tid=<span class="hex">0x00007f16a02d0000</span> nid=<span class="hex">0x4fa3</span> runnable [<span class="hex">0x00007f16b517d000</span>.<span class="float">.0</span>x00007f16b517dbf0]
   java.lang.Thread.State: RUNNABLE
          at sun.nio.ch.EPollArrayWrapper.epollWait(Native <span class="predefined-type">Method</span>)
          at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:<span class="integer">215</span>)
          at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:<span class="integer">65</span>)
          at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:<span class="integer">69</span>)
          - locked &lt;<span class="hex">0x00007f17d5b68c00</span>&gt; (a sun.nio.ch.Util<span class="error">$</span><span class="integer">1</span>)
          - locked &lt;<span class="hex">0x00007f17d5b68be8</span>&gt; (a java.util.Collections<span class="error">$</span>UnmodifiableSet)
          - locked &lt;<span class="hex">0x00007f1877959b50</span>&gt; (a sun.nio.ch.EPollSelectorImpl)
          at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:<span class="integer">80</span>)
          at org.apache.hadoop.net.SocketIOWithTimeout<span class="error">$</span>SelectorPool.select(SocketIOWithTimeout.java:<span class="integer">332</span>)
          at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:<span class="integer">157</span>)
          at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:<span class="integer">155</span>)
          at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:<span class="integer">128</span>)
          at java.io.FilterInputStream.read(<span class="predefined-type">FilterInputStream</span>.java:<span class="integer">116</span>)
          at org.apache.hadoop.ipc.Client<span class="error">$</span><span class="predefined-type">Connection</span><span class="error">$</span>PingInputStream.read(Client.java:<span class="integer">304</span>)
          at java.io.BufferedInputStream.fill(<span class="predefined-type">BufferedInputStream</span>.java:<span class="integer">218</span>)
          at java.io.BufferedInputStream.read(<span class="predefined-type">BufferedInputStream</span>.java:<span class="integer">237</span>)
          - locked &lt;<span class="hex">0x00007f1808539178</span>&gt; (a java.io.BufferedInputStream)
          at java.io.DataInputStream.readInt(<span class="predefined-type">DataInputStream</span>.java:<span class="integer">370</span>)
          at org.apache.hadoop.ipc.Client<span class="error">$</span><span class="predefined-type">Connection</span>.receiveResponse(Client.java:<span class="integer">569</span>)
          at org.apache.hadoop.ipc.Client<span class="error">$</span><span class="predefined-type">Connection</span>.run(Client.java:<span class="integer">477</span>)</code></pre>
</div>
</div>
<div class="paragraph">
<p>这是一个在RegionServer死后试图收回租约的管理员：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="string"><span class="delimiter">&quot;</span><span class="content">LeaseChecker</span><span class="delimiter">&quot;</span></span> daemon prio=<span class="integer">10</span> tid=<span class="hex">0x00000000407ef800</span> nid=<span class="hex">0x76cd</span> waiting on condition [<span class="hex">0x00007f6d0eae2000</span>.<span class="float">.0</span>x00007f6d0eae2a70]
--
   java.lang.Thread.State: WAITING (on object monitor)
          at java.lang.Object.wait(Native <span class="predefined-type">Method</span>)
          at java.lang.Object.wait(<span class="predefined-type">Object</span>.java:<span class="integer">485</span>)
          at org.apache.hadoop.ipc.Client.call(Client.java:<span class="integer">726</span>)
          - locked &lt;<span class="hex">0x00007f6d1cd28f80</span>&gt; (a org.apache.hadoop.ipc.Client<span class="error">$</span>Call)
          at org.apache.hadoop.ipc.RPC<span class="error">$</span>Invoker.invoke(RPC.java:<span class="integer">220</span>)
          at <span class="error">$</span>Proxy1.recoverBlock(Unknown <span class="predefined-type">Source</span>)
          at org.apache.hadoop.hdfs.DFSClient<span class="error">$</span>DFSOutputStream.processDatanodeError(DFSClient.java:<span class="integer">2636</span>)
          at org.apache.hadoop.hdfs.DFSClient<span class="error">$</span>DFSOutputStream.&lt;init&gt;(DFSClient.java:<span class="integer">2832</span>)
          at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:<span class="integer">529</span>)
          at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:<span class="integer">186</span>)
          at org.apache.hadoop.fs.FileSystem.append(FileSystem.java:<span class="integer">530</span>)
          at org.apache.hadoop.hbase.util.FSUtils.recoverFileLease(FSUtils.java:<span class="integer">619</span>)
          at org.apache.hadoop.hbase.regionserver.wal.HLog.splitLog(HLog.java:<span class="integer">1322</span>)
          at org.apache.hadoop.hbase.regionserver.wal.HLog.splitLog(HLog.java:<span class="integer">1210</span>)
          at org.apache.hadoop.hbase.master.HMaster.splitLogAfterStartup(HMaster.java:<span class="integer">648</span>)
          at org.apache.hadoop.hbase.master.HMaster.joinCluster(HMaster.java:<span class="integer">572</span>)
          at org.apache.hadoop.hbase.master.HMaster.run(HMaster.java:<span class="integer">503</span>)</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="trouble.tools.opentsdb"><a class="anchor" href="#trouble.tools.opentsdb"></a> 105.2.5。OpenTSDB</h4>
<div class="paragraph">
<p><a href="http://opentsdb.net">OpenTSDB</a>是Ganglia的绝佳替代品，因为它使用Apache HBase存储所有时间序列，而不必进行降采样。监视托管OpenTSDB的HBase群集是一个不错的练习。</p>
</div>
<div class="paragraph">
<p>这是一个群集的示例，该群集几乎在同一时间几乎同时启动了数百次压缩，这严重影响了IO性能：（TODO：插入图表绘制compactionQueueSize）</p>
</div>
<div class="paragraph">
<p>最好使用每台计算机和每个集群的所有重要图形来构建仪表板，以便快速查看调试问题。例如，在StumbleUpon上，每个集群都有一个仪表板，其中包含来自操作系统和Apache HBase的最重要的指标。然后，您可以在计算机级别查看详细信息。</p>
</div>
</div>
<div class="sect3">
<h4 id="trouble.tools.clustersshtop"><a class="anchor" href="#trouble.tools.clustersshtop"></a> 105.2.6。 clusterssh + top</h4>
<div class="paragraph">
<p>clusterssh + top，它就像一个穷人的监视系统，当您只有几台机器时，它非常有用，因为它很容易设置。启动clusterssh将为您提供每台计算机一个终端，并为您提供另一个终端，在该终端中您键入的内容将在每个窗口中重新输入。这意味着您可以输入<code>top</code>一次，它将同时为所有计算机启动它，从而使您可以全面了解群集的当前状态。您还可以同时拖尾所有日志，编辑文件等。</p>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="trouble.client"><a class="anchor" href="#trouble.client"></a> 106。客户</h2>
<div class="sectionbody">
<div class="paragraph">
<p>有关HBase客户端的更多信息，请参见<a href="#architecture.client">client</a> 。</p>
</div>
<div class="sect2">
<h3 id="trouble.client.scantimeout"><a class="anchor" href="#trouble.client.scantimeout"></a> 106.1。ScannerTimeoutException或UnknownScannerException</h3>
<div class="paragraph">
<p>如果从客户端到RegionServer的RPC调用之间的时间间隔超过了扫描超时，则抛出此错误。例如，如果<code>Scan.setCaching</code>设置为500，那么将有一个RPC调用，每500取一次下一行<code>.next()</code>之所以调用ResultScanner，是因为数据以500行的块的形式传输到客户端。减小setCaching值可能是一个选项，但是将此值设置得太低会使行数处理效率低下。</p>
</div>
<div class="paragraph">
<p>请参阅<a href="#perf.hbase.client.caching">扫描缓存</a> 。</p>
</div>
</div>
<div class="sect2">
<h3 id="_performance_differences_in_thrift_and_java_apis"><a class="anchor" href="#_performance_differences_in_thrift_and_java_apis"></a> 106.2。Thrift和Java API的性能差异</h3>
<div class="paragraph">
<p>表现不佳，甚至<code>ScannerTimeoutExceptions</code> ，如果发生<code>Scan.setCaching</code>太高，如<a href="#trouble.client.scantimeout">ScannerTimeoutException或UnknownScannerException中</a>所讨论。如果Thrift客户端对给定的工作负载使用了错误的缓存设置，则与Java API相比，性能可能会受到影响。要在Thrift客户端中为给定扫描设置缓存，请使用<code>scannerGetList(scannerId, numRows)</code>方法，在哪里<code>numRows</code>是一个整数，代表要缓存的行数。在一种情况下，发现在相同查询的情况下，将Thrift扫描的缓存从1000减少到100可将性能提高到与Java API几乎相等。</p>
</div>
<div class="paragraph">
<p>另请参阅Jesse Andersen的<a href="http://blog.cloudera.com/blog/2014/04/how-to-use-the-hbase-thrift-interface-part-3-using-scans/">博客文章，其中</a>介绍了如何在Thrift中使用Scans。</p>
</div>
</div>
<div class="sect2">
<h3 id="trouble.client.lease.exception"><a class="anchor" href="#trouble.client.lease.exception"></a> 106.3。 <code>LeaseException</code>打电话时<code>Scanner.next</code></h3>
<div class="paragraph">
<p>在某些情况下，从RegionServer获取数据的客户端会获得LeaseException而不是通常的<a href="#trouble.client.scantimeout">ScannerTimeoutException或UnknownScannerException</a> 。通常，异常的来源是<code>org.apache.hadoop.hbase.regionserver.Leases.removeLease(Leases.java:230)</code> （行号可能会有所不同）。它倾向于在缓慢/冻结的情况下发生<code>RegionServer#next</code>呼叫。可以通过预防<code>hbase.rpc.timeout</code> > <code>hbase.client.scanner.timeout.period</code> 。Harsh J作为邮件列表线程<a href="https://mail-archives.apache.org/mod_mbox/hbase-user/201209.mbox/%3CCAOcnVr3R-LqtKhFsk8Bhrm-YW2i9O6J6Fhjz2h7q6_sxvwd2yw%40mail.gmail.com%3E">HBase（邮件＃用户）的</a>一部分调查了此问题<a href="https://mail-archives.apache.org/mod_mbox/hbase-user/201209.mbox/%3CCAOcnVr3R-LqtKhFsk8Bhrm-YW2i9O6J6Fhjz2h7q6_sxvwd2yw%40mail.gmail.com%3E">-租赁不存在异常</a></p>
</div>
</div>
<div class="sect2">
<h3 id="trouble.client.scarylogs"><a class="anchor" href="#trouble.client.scarylogs"></a> 106.4。Shell或客户端应用程序在正常运行期间会引发许多可怕的异常</h3>
<div class="paragraph">
<p>从0.20.0开始，org.apache.hadoop.hbase。*的默认日志级别是DEBUG。</p>
</div>
<div class="paragraph">
<p>在您的客户端上，编辑<em>$ HBASE_HOME / conf / log4j.properties</em>并进行以下更改： <code>log4j.logger.org.apache.hadoop.hbase=DEBUG</code>对此： <code>log4j.logger.org.apache.hadoop.hbase=INFO</code> ， 甚至<code>log4j.logger.org.apache.hadoop.hbase=WARN</code> 。</p>
</div>
</div>
<div class="sect2">
<h3 id="trouble.client.longpauseswithcompression"><a class="anchor" href="#trouble.client.longpauseswithcompression"></a> 106.5。长期客户因压缩而暂停</h3>
<div class="paragraph">
<p>在Apache HBase dist-list上，这是一个相当常见的问题。场景是，客户端通常会将大量数据插入相对未优化的HBase群集中。压缩可能会加剧暂停，尽管这不是问题的根源。</p>
</div>
<div class="paragraph">
<p>有关<a href="#precreate.regions">预创建区域</a> ，请参见模式上的<a href="#precreate.regions">表创建：预</a>创建区域，并确认表不是从单个区域开始的。</p>
</div>
<div class="paragraph">
<p>有关群集配置，请参阅<a href="#perf.configurations">HBase配置</a> 。 <code>hbase.hstore.blockingStoreFiles</code> ， <code>hbase.hregion.memstore.block.multiplier</code> ， <code>MAX_FILESIZE</code> （区域大小），以及<code>MEMSTORE_FLUSHSIZE.</code></p>
</div>
<div class="paragraph">
<p>关于为什么会出现暂停的稍长解释如下：有时，在刷新池线程阻止的MemStores上放置了puts，而该刷新器线程被阻塞是因为要压缩的文件太多，因为为压缩器提供了太多要压缩的小文件，必须反复压缩相同的数据。即使进行较小的压实，也会出现这种情况。使这种情况更加复杂的是，Apache HBase不会压缩内存中的数据。因此，压缩后，驻留在MemStore中的64MB可能会变成6MB的文件-这将导致较小的StoreFile。好处是可以将更多数据打包到同一区域，但是可以通过写入更大的文件来实现性能-这就是为什么HBase在写入新的StoreFile之前要等到flushsize的原因。较小的StoreFiles成为压缩的目标。如果不进行压缩，则文件会更大，并且不需要太多压缩，但这是以I / O为代价的。</p>
</div>
<div class="paragraph">
<p>有关更多信息，请参<a href="http://search-hadoop.com/m/WUnLM6ojHm1/Long+client+pauses+with+compression&subj=Long+client+pauses+with+compression">见长客户端在压缩时暂停的</a>线程。</p>
</div>
</div>
<div class="sect2">
<h3 id="trouble.client.security.rpc.krb"><a class="anchor" href="#trouble.client.security.rpc.krb"></a> 106.6。安全客户端连接（[由GSSException引起：未提供有效的凭据...]）</h3>
<div class="paragraph">
<p>您可能会遇到以下错误：</p>
</div>
<div class="listingblock">
<div class="content">
<pre>Secure Client Connect ([Caused by GSSException: No valid credentials provided
        (Mechanism level: Request is a replay (34) V PROCESS_TGS)])</pre>
</div>
</div>
<div class="paragraph">
<p>此问题是由MIT Kerberos replay_cache组件<a href="http://krbdev.mit.edu/rt/Ticket/Display.html?id=1201">＃1201</a>和<a href="http://krbdev.mit.edu/rt/Ticket/Display.html?id=5924">＃5924中</a>的错误引起的。这些错误导致旧版本的krb5-server错误地阻止了从主体发送的后续请求。这导致krb5-server阻止从一个客户端（一个HTable实例和每个RegionServer的多线程连接实例）发送的连接；消息，例如<code>Request is a replay (34)</code> ，将记录在客户端日志中，您可以忽略该消息，因为默认情况下，HTable将为每个失败的连接重试5 * 10（50）次。重试后，如果与RegionServer的任何连接失败，则HTable将引发IOException，以便HTable实例的用户客户端代码可以进一步处理它。注意： <code>HTable</code>在HBase 1.0中已弃用，建议使用<code>Table</code> 。</p>
</div>
<div class="paragraph">
<p>或者，将krb5-server更新到解决这些问题的版本，例如krb5-server-1.10.3。有关更多详细信息，请参见JIRA <a href="https://issues.apache.org/jira/browse/HBASE-10379">HBASE-10379</a> 。</p>
</div>
</div>
<div class="sect2">
<h3 id="trouble.client.zookeeper"><a class="anchor" href="#trouble.client.zookeeper"></a> 106.7。ZooKeeper客户端连接错误</h3>
<div class="paragraph">
<p>这样的错误...</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="integer">11</span>/<span class="octal">07</span>/<span class="octal">05</span> <span class="integer">11</span>:<span class="integer">26</span>:<span class="integer">41</span> WARN zookeeper.ClientCnxn: Session <span class="hex">0x0</span> <span class="keyword">for</span> server <span class="predefined-constant">null</span>,
 unexpected error, closing socket connection and attempting reconnect
 java.net.ConnectException: <span class="predefined-type">Connection</span> refused: no further information
        at sun.nio.ch.SocketChannelImpl.checkConnect(Native <span class="predefined-type">Method</span>)
        at sun.nio.ch.SocketChannelImpl.finishConnect(Unknown <span class="predefined-type">Source</span>)
        at org.apache.zookeeper.ClientCnxn<span class="error">$</span>SendThread.run(ClientCnxn.java:<span class="integer">1078</span>)
 <span class="integer">11</span>/<span class="octal">07</span>/<span class="octal">05</span> <span class="integer">11</span>:<span class="integer">26</span>:<span class="integer">43</span> INFO zookeeper.ClientCnxn: Opening socket connection to
 server localhost/<span class="float">127.0</span><span class="float">.0</span><span class="float">.1</span>:<span class="integer">2181</span>
 <span class="integer">11</span>/<span class="octal">07</span>/<span class="octal">05</span> <span class="integer">11</span>:<span class="integer">26</span>:<span class="integer">44</span> WARN zookeeper.ClientCnxn: Session <span class="hex">0x0</span> <span class="keyword">for</span> server <span class="predefined-constant">null</span>,
 unexpected error, closing socket connection and attempting reconnect
 java.net.ConnectException: <span class="predefined-type">Connection</span> refused: no further information
        at sun.nio.ch.SocketChannelImpl.checkConnect(Native <span class="predefined-type">Method</span>)
        at sun.nio.ch.SocketChannelImpl.finishConnect(Unknown <span class="predefined-type">Source</span>)
        at org.apache.zookeeper.ClientCnxn<span class="error">$</span>SendThread.run(ClientCnxn.java:<span class="integer">1078</span>)
 <span class="integer">11</span>/<span class="octal">07</span>/<span class="octal">05</span> <span class="integer">11</span>:<span class="integer">26</span>:<span class="integer">45</span> INFO zookeeper.ClientCnxn: Opening socket connection to
 server localhost/<span class="float">127.0</span><span class="float">.0</span><span class="float">.1</span>:<span class="integer">2181</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>......要么是由于ZooKeeper宕机，要么是由于网络问题而无法访问。</p>
</div>
<div class="paragraph">
<p>实用程序<a href="#trouble.tools.builtin.zkcli">zkcli</a>可能有助于调查ZooKeeper问题。</p>
</div>
</div>
<div class="sect2">
<h3 id="trouble.client.oome.directmemory.leak"><a class="anchor" href="#trouble.client.oome.directmemory.leak"></a> 106.8。尽管堆大小似乎稳定，但客户端用尽了内存（但堆外/直接堆不断增长）</h3>
<div class="paragraph">
<p>您可能会遇到在邮件线程<a href="http://search-hadoop.com/m/ubhrX8KvcH/Suspected+memory+leak&subj=Re+Suspected+memory+leak">HBase中</a>描述并解决的问题<a href="http://search-hadoop.com/m/ubhrX8KvcH/Suspected+memory+leak&subj=Re+Suspected+memory+leak">，邮件＃用户-怀疑内存泄漏，</a>并在<a href="http://search-hadoop.com/m/p2Agc1Zy7Va/MaxDirectMemorySize+Was%253A+Suspected+memory+leak&subj=Re+FeedbackRe+Suspected+memory+leak">HBase中</a>继续存在<a href="http://search-hadoop.com/m/p2Agc1Zy7Va/MaxDirectMemorySize+Was%253A+Suspected+memory+leak&subj=Re+FeedbackRe+Suspected+memory+leak">，邮件＃dev-FeedbackRe：怀疑内存泄漏</a> 。一种解决方法是为您的客户端JVM传递合理的价值<code>-XX:MaxDirectMemorySize</code> 。默认情况下， <code>MaxDirectMemorySize</code>等于你的<code>-Xmx</code>最大堆大小设置（如果<code>-Xmx</code>设置）。尝试将其设置为较小的值（例如，一个用户成功将其设置为<code>1g</code>当他们有一个客户端堆<code>12g</code> ）。如果设置得太小，它将启动<code>FullGCs</code>所以要保持一点沉重。您只想在客户端进行此设置，尤其是在运行新的实验性服务器端堆外高速缓存时，因为此功能取决于能否使用大的直接缓冲区（您可能必须将客户端和服务器端保持独立，侧面配置目录）。</p>
</div>
</div>
<div class="sect2">
<h3 id="trouble.client.security.rpc"><a class="anchor" href="#trouble.client.security.rpc"></a> 106.9。安全客户端无法连接（[由GSSException引起：未提供有效的凭据（机制级别：无法找到任何Kerberos tgt）]）</h3>
<div class="paragraph">
<p>可能有几种原因导致此症状。</p>
</div>
<div class="paragraph">
<p>首先，检查您是否具有有效的Kerberos票证。为了与安全的Apache HBase集群建立通信，需要一个。通过运行以下命令检查当前在凭证高速缓存中的票证（如果有） <code>klist</code>命令行实用程序。如果未列出票证，则必须通过运行<code>kinit</code>使用指定的密钥表或通过交互输入所需主体的密码来执行命令。</p>
</div>
<div class="paragraph">
<p>然后，查阅<a href="http://docs.oracle.com/javase/1.5.0/docs/guide/security/jgss/tutorials/Troubleshooting.html">Java安全指南的疑难解答部分</a> 。解决此问题的最常见问题是通过设置<code>javax.security.auth.useSubjectCredsOnly</code>系统属性值<code>false</code> 。</p>
</div>
<div class="paragraph">
<p>由于MIT Kerberos写入其凭据缓存的格式发生了变化，因此Oracle JDK 6 Update 26和更早版本中存在一个错误，该错误导致Java无法读取由MIT Kerberos 1.8.1版本创建的Kerberos凭据缓存。或更高。如果您的环境中组件的组合存在这种问题，要变通解决此问题，请首先使用<code>kinit</code>然后立即刷新凭证缓存<code>kinit -R</code> 。刷新将重写凭据缓存，而不会出现格式问题。</p>
</div>
<div class="paragraph">
<p>最后，根据您的Kerberos配置，您可能需要安装<a href="http://docs.oracle.com/javase/1.4.2/docs/guide/security/jce/JCERefGuide.html">Java Cryptography Extension</a>或JCE。确保JCE jar在服务器和客户机系统上都在类路径上。</p>
</div>
<div class="paragraph">
<p>您可能还需要下载<a href="http://www.oracle.com/technetwork/java/javase/downloads/jce-6-download-429243.html">无限强度的JCE策略文件</a> 。解压缩并解压缩下载的文件，然后将策略jar安装到<em><java-home>/ lib / security中</java-home></em> 。</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="trouble.mapreduce"><a class="anchor" href="#trouble.mapreduce"></a> 107。MapReduce</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="trouble.mapreduce.local"><a class="anchor" href="#trouble.mapreduce.local"></a> 107.1。您以为自己在集群上，但实际上是本地人</h3>
<div class="paragraph">
<p>以下堆栈跟踪发生在使用<code>ImportTsv</code> ，但这种情况可能在配置错误的任何作业上发生。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="text">    WARN mapred.LocalJobRunner: job_local_0001
java.lang.IllegalArgumentException: Can't read partitions file
       at org.apache.hadoop.hbase.mapreduce.hadoopbackport.TotalOrderPartitioner.setConf(TotalOrderPartitioner.java:111)
       at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:62)
       at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:117)
       at org.apache.hadoop.mapred.MapTask$NewOutputCollector.&lt;init&gt;(MapTask.java:560)
       at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:639)
       at org.apache.hadoop.mapred.MapTask.run(MapTask.java:323)
       at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:210)
Caused by: java.io.FileNotFoundException: File _partition.lst does not exist.
       at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:383)
       at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:251)
       at org.apache.hadoop.fs.FileSystem.getLength(FileSystem.java:776)
       at org.apache.hadoop.io.SequenceFile$Reader.&lt;init&gt;(SequenceFile.java:1424)
       at org.apache.hadoop.io.SequenceFile$Reader.&lt;init&gt;(SequenceFile.java:1419)
       at org.apache.hadoop.hbase.mapreduce.hadoopbackport.TotalOrderPartitioner.readPartitions(TotalOrderPartitioner.java:296)</code></pre>
</div>
</div>
<div class="paragraph">
<p>......看到堆栈的关键部分吗？是...</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">at org.apache.hadoop.mapred.LocalJobRunner<span class="error">$</span>Job.run(LocalJobRunner.java:<span class="integer">210</span>)</code></pre>
</div>
</div>
<div class="paragraph">
<p>LocalJobRunner意味着作业正在本地运行，而不是在群集上运行。</p>
</div>
<div class="paragraph">
<p>要解决此问题，您应该将MR工作与<code>HADOOP_CLASSPATH</code>设置为包括HBase依赖项。可以使用“ hbase classpath”实用程序轻松完成此操作。例如（用您的HBase版本替换VERSION）：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bourne">HADOOP_CLASSPATH=`hbase classpath` hadoop jar $HBASE_HOME/hbase-server-VERSION.jar rowcounter usertable</code></pre>
</div>
</div>
<div class="paragraph">
<p>有关HBase MapReduce作业和类路径的更多信息，请参见<a href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/mapreduce/package-summary.html#classpathfor" class="bare">http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/mapreduce/package-summary.html#classpath</a> 。</p>
</div>
</div>
<div class="sect2">
<h3 id="trouble.hbasezerocopybytestring"><a class="anchor" href="#trouble.hbasezerocopybytestring"></a> 107.2。启动工作，您将得到java.lang。IllegalAccessError：com / google / protobuf / HBaseZeroCopyByteString或com.google.protobuf类。ZeroCopyLiteralByteString无法访问其超类com.google.protobuf。LiteralByteString</h3>
<div class="paragraph">
<p>请参见<a href="https://issues.apache.org/jira/browse/HBASE-10304">HBASE-10304运行hbase作业jar：IllegalAccessError：com.google.protobuf类。ZeroCopyLiteralByteString无法访问其超类com.google.protobuf。</a><a href="https://issues.apache.org/jira/browse/HBASE-11118">针对“ IllegalAccessError：com.google.protobuf类”的 LiteralByteString</a>和<a href="https://issues.apache.org/jira/browse/HBASE-11118">HBASE-11118非环境变量解决方案。ZeroCopyLiteralByteString无法访问其超类com.google.protobuf。LiteralByteString”</a> 。尝试运行Spark作业时，该问题也会出现。请参阅<a href="https://issues.apache.org/jira/browse/HBASE-10877">HBASE-10877</a> 。 <a href="https://issues.apache.org/jira/browse/HBASE-10877">应扩展HBase不可重试异常列表</a> 。</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="trouble.namenode"><a class="anchor" href="#trouble.namenode"></a> 108。名称节点</h2>
<div class="sectionbody">
<div class="paragraph">
<p>有关NameNode的更多信息，请参见<a href="#arch.hdfs">HDFS</a> 。</p>
</div>
<div class="sect2">
<h3 id="trouble.namenode.disk"><a class="anchor" href="#trouble.namenode.disk"></a> 108.1。表和区域的HDFS利用</h3>
<div class="paragraph">
<p>要确定HBase在HDFS上使用了多少空间，请使用<code>hadoop</code>来自NameNode的shell命令。例如...</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bourne">hadoop fs -dus /hbase/</code></pre>
</div>
</div>
<div class="paragraph">
<p>…返回所有HBase对象的汇总磁盘利用率。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bourne">hadoop fs -dus /hbase/myTable</code></pre>
</div>
</div>
<div class="paragraph">
<p>......返回HBase表'myTable'的汇总磁盘利用率。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bourne">hadoop fs -du /hbase/myTable</code></pre>
</div>
</div>
<div class="paragraph">
<p>......返回HBase表'myTable'下的区域及其磁盘利用率的列表。</p>
</div>
<div class="paragraph">
<p>有关HDFS Shell命令的更多信息，请参见<a href="http://hadoop.apache.org/common/docs/current/file_system_shell.html">HDFS FileSystem Shell文档</a> 。</p>
</div>
</div>
<div class="sect2">
<h3 id="trouble.namenode.hbase.objects"><a class="anchor" href="#trouble.namenode.hbase.objects"></a> 108.2。浏览HBase对象的HDFS</h3>
<div class="paragraph">
<p>有时有必要探索HDFS上存在的HBase对象。这些对象可以包括WAL（预写日志），表，区域，StoreFiles等。最简单的方法是使用在端口50070上运行的NameNode Web应用程序。NameNode Web应用程序将提供指向集群中所有DataNode的链接，以便可以无缝浏览它们。</p>
</div>
<div class="paragraph">
<p>集群中HBase表的HDFS目录结构是...</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">/hbase
    /&lt;Table&gt;                    (Tables in the cluster)
        /&lt;<span class="predefined-type">Region</span>&gt;               (Regions <span class="keyword">for</span> the table)
            /&lt;ColumnFamily&gt;     (ColumnFamilies <span class="keyword">for</span> the <span class="predefined-type">Region</span> <span class="keyword">for</span> the table)
                /&lt;StoreFile&gt;    (StoreFiles <span class="keyword">for</span> the ColumnFamily <span class="keyword">for</span> the Regions <span class="keyword">for</span> the table)</code></pre>
</div>
</div>
<div class="paragraph">
<p>HBase WAL的HDFS目录结构为..</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">/hbase
    /.logs
        /&lt;RegionServer&gt;    (RegionServers)
            /&lt;WAL&gt;         (WAL files <span class="keyword">for</span> the RegionServer)</code></pre>
</div>
</div>
<div class="paragraph">
<p>请参阅《 <a href="http://hadoop.apache.org/common/docs/current/hdfs_user_guide.html">HDFS用户指南》，</a>以获取其他非Shell诊断实用程序，例如<code>fsck</code> 。</p>
</div>
<div class="sect3">
<h4 id="trouble.namenode.0size.hlogs"><a class="anchor" href="#trouble.namenode.0size.hlogs"></a> 108.2.1。零尺寸WAL，其中包含数据</h4>
<div class="paragraph">
<p>问题：在获得RegionServer的<em>.logs</em>目录中所有文件的列表时，一个文件的大小为0，但其中包含数据。</p>
</div>
<div class="paragraph">
<p>答：这是HDFS的怪癖。当前正在写入的文件的大小似乎为0，但关闭后将显示其真实大小</p>
</div>
</div>
<div class="sect3">
<h4 id="trouble.namenode.uncompaction"><a class="anchor" href="#trouble.namenode.uncompaction"></a> 108.2.2。用例</h4>
<div class="paragraph">
<p>用于查询HFS对象的HDFS的两个常见用例是研究表的未压缩程度。如果每个ColumnFamily有大量的StoreFiles，则可能表明需要进行重大压缩。此外，在进行重大压缩后，如果所得的StoreFile是“ small”，则可能表明需要减少该表的ColumnFamilies。</p>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="trouble.network"><a class="anchor" href="#trouble.network"></a> 109。网络</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="trouble.network.spikes"><a class="anchor" href="#trouble.network.spikes"></a> 109.1。网络尖峰</h3>
<div class="paragraph">
<p>如果您看到周期性的网络高峰，则可能需要检查<code>compactionQueues</code>看看是否正在进行重大压实。</p>
</div>
<div class="paragraph">
<p>有关<a href="#managed.compactions">管理压缩</a>的更多信息，请参见<a href="#managed.compactions">托管</a>压缩。</p>
</div>
</div>
<div class="sect2">
<h3 id="trouble.network.loopback"><a class="anchor" href="#trouble.network.loopback"></a> 109.2。回送IP</h3>
<div class="paragraph">
<p>HBase希望回送IP地址为127.0.0.1。</p>
</div>
</div>
<div class="sect2">
<h3 id="trouble.network.ints"><a class="anchor" href="#trouble.network.ints"></a> 109.3。网络接口</h3>
<div class="paragraph">
<p>所有网络接口是否正常运行？你确定吗？请参阅案例研究中的故障排除<a href="#trouble.casestudy">案例研究</a> 。</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="trouble.rs"><a class="anchor" href="#trouble.rs"></a> 110。区域服务器</h2>
<div class="sectionbody">
<div class="paragraph">
<p>有关RegionServer的更多信息，请参见<a href="#regionserver.arch">RegionServer</a> 。</p>
</div>
<div class="sect2">
<h3 id="trouble.rs.startup"><a class="anchor" href="#trouble.rs.startup"></a> 110.1。启动错误</h3>
<div class="sect3">
<h4 id="trouble.rs.startup.master_no_region"><a class="anchor" href="#trouble.rs.startup.master_no_region"></a> 110.1.1。主机启动，但RegionServers不启动</h4>
<div class="paragraph">
<p>主服务器认为RegionServer的IP为127.0.0.1-这是本地主机，并解析为主服务器自己的本地主机。</p>
</div>
<div class="paragraph">
<p>区域服务器错误地通知主服务器其IP地址为127.0.0.1。</p>
</div>
<div class="paragraph">
<p>从...修改区域服务器上的<em>/ etc / hosts</em></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="error">#</span> Do not remove the following line, or various programs
<span class="error">#</span> that require network functionality will fail.
<span class="float">127.0</span><span class="float">.0</span><span class="float">.1</span>               fully.qualified.regionservername regionservername  localhost.localdomain localhost
::<span class="integer">1</span>             localhost6.localdomain6 localhost6</code></pre>
</div>
</div>
<div class="paragraph">
<p>...到（从本地主机中删除主节点的名称）...</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="error">#</span> Do not remove the following line, or various programs
<span class="error">#</span> that require network functionality will fail.
<span class="float">127.0</span><span class="float">.0</span><span class="float">.1</span>               localhost.localdomain localhost
::<span class="integer">1</span>             localhost6.localdomain6 localhost6</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="trouble.rs.startup.compression"><a class="anchor" href="#trouble.rs.startup.compression"></a> 110.1.2。压缩链接错误</h4>
<div class="paragraph">
<p>由于需要在每个群集上安装和配置LZO等压缩算法，因此这是启动错误的常见来源。如果您看到这样的消息...</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="integer">11</span>/<span class="octal">02</span>/<span class="integer">20</span> <span class="octal">01</span>:<span class="integer">32</span>:<span class="integer">15</span> ERROR lzo.GPLNativeCodeLoader: Could not load <span class="directive">native</span> gpl library
java.lang.UnsatisfiedLinkError: no gplcompression in java.library.path
        at java.lang.ClassLoader.loadLibrary(<span class="predefined-type">ClassLoader</span>.java:<span class="integer">1734</span>)
        at java.lang.Runtime.loadLibrary0(<span class="predefined-type">Runtime</span>.java:<span class="integer">823</span>)
        at java.lang.System.loadLibrary(<span class="predefined-type">System</span>.java:<span class="integer">1028</span>)</code></pre>
</div>
</div>
<div class="paragraph">
<p>...然后压缩库出现路径问题。请参阅链接：[LZO压缩配置]上的“配置”部分。</p>
</div>
</div>
<div class="sect3">
<h4 id="trouble.rs.startup.hsync"><a class="anchor" href="#trouble.rs.startup.hsync"></a> 110.1.3。由于缺少文件系统的hsync，RegionServer中止</h4>
<div class="paragraph">
<p>为了为写入集群提供数据持久性，HBase依赖于将状态持久保存在预写日志中的能力。当使用支持检查所需调用的可用性的Apache Hadoop Common的文件系统API版本时，如果发现无法安全运行HBase，则HBase将主动中止该集群。</p>
</div>
<div class="paragraph">
<p>对于RegionServer角色，失败将显示在以下日志中：</p>
</div>
<div class="listingblock">
<div class="content">
<pre>2018-04-05 11:36:22,785 ERROR [regionserver/192.168.1.123:16020] wal.AsyncFSWALProvider: The RegionServer async write ahead log provider relies on the ability to call hflush and hsync for proper operation during component failures, but the current FileSystem does not support doing so. Please check the config value of 'hbase.wal.dir' and ensure it points to a FileSystem mount that has suitable capabilities for output streams.
2018-04-05 11:36:22,799 ERROR [regionserver/192.168.1.123:16020] regionserver.HRegionServer: ***** ABORTING region server 192.168.1.123,16020,1522946074234: Unhandled: cannot get log writer *****
java.io.IOException: cannot get log writer
        at org.apache.hadoop.hbase.wal.AsyncFSWALProvider.createAsyncWriter(AsyncFSWALProvider.java:112)
        at org.apache.hadoop.hbase.regionserver.wal.AsyncFSWAL.createWriterInstance(AsyncFSWAL.java:612)
        at org.apache.hadoop.hbase.regionserver.wal.AsyncFSWAL.createWriterInstance(AsyncFSWAL.java:124)
        at org.apache.hadoop.hbase.regionserver.wal.AbstractFSWAL.rollWriter(AbstractFSWAL.java:759)
        at org.apache.hadoop.hbase.regionserver.wal.AbstractFSWAL.rollWriter(AbstractFSWAL.java:489)
        at org.apache.hadoop.hbase.regionserver.wal.AsyncFSWAL.&lt;init&gt;(AsyncFSWAL.java:251)
        at org.apache.hadoop.hbase.wal.AsyncFSWALProvider.createWAL(AsyncFSWALProvider.java:69)
        at org.apache.hadoop.hbase.wal.AsyncFSWALProvider.createWAL(AsyncFSWALProvider.java:44)
        at org.apache.hadoop.hbase.wal.AbstractFSWALProvider.getWAL(AbstractFSWALProvider.java:138)
        at org.apache.hadoop.hbase.wal.AbstractFSWALProvider.getWAL(AbstractFSWALProvider.java:57)
        at org.apache.hadoop.hbase.wal.WALFactory.getWAL(WALFactory.java:252)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.getWAL(HRegionServer.java:2105)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.buildServerLoad(HRegionServer.java:1326)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.tryRegionServerReport(HRegionServer.java:1191)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.run(HRegionServer.java:1007)
        at java.lang.Thread.run(Thread.java:745)
Caused by: org.apache.hadoop.hbase.util.CommonFSUtils$StreamLacksCapabilityException: hflush and hsync
        at org.apache.hadoop.hbase.io.asyncfs.AsyncFSOutputHelper.createOutput(AsyncFSOutputHelper.java:69)
        at org.apache.hadoop.hbase.regionserver.wal.AsyncProtobufLogWriter.initOutput(AsyncProtobufLogWriter.java:168)
        at org.apache.hadoop.hbase.regionserver.wal.AbstractProtobufLogWriter.init(AbstractProtobufLogWriter.java:167)
        at org.apache.hadoop.hbase.wal.AsyncFSWALProvider.createAsyncWriter(AsyncFSWALProvider.java:99)
        ... 15 more</pre>
</div>
</div>
<div class="paragraph">
<p>如果您尝试以独立模式运行并看到此错误，请返回<a href="#quickstart">快速入门-独立HBase部分，</a>并确保已包括<strong>所有</strong>给定的配置设置。</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="trouble.rs.runtime"><a class="anchor" href="#trouble.rs.runtime"></a> 110.2。运行时错误</h3>
<div class="sect3">
<h4 id="trouble.rs.runtime.hang"><a class="anchor" href="#trouble.rs.runtime.hang"></a> 110.2.1。RegionServer挂起</h4>
<div class="paragraph">
<p>您是否正在运行旧的JVM（<1.6.0_u21？）？当您查看线程转储时，是否看起来线程已被阻塞，但是没有人持有所有被锁定的锁？请参见<a href="https://issues.apache.org/jira/browse/HBASE-3622">HBaseServer中的HBASE 3622死锁（JVM错误？）</a> 。新增中<code>-XX:+UseMembar</code>到HBase <code>HBASE_OPTS</code>在<em>conf / hbase-env.sh中</em>可以修复它。</p>
</div>
</div>
<div class="sect3">
<h4 id="trouble.rs.runtime.filehandles"><a class="anchor" href="#trouble.rs.runtime.filehandles"></a> 110.2.2。 java.io。IOException ...（打开的文件太多）</h4>
<div class="paragraph">
<p>如果您看到这样的日志消息...</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="integer">2010</span>-<span class="integer">09</span>-<span class="integer">13</span> <span class="octal">01</span>:<span class="integer">24</span>:<span class="integer">17</span>,<span class="integer">336</span> WARN org.apache.hadoop.hdfs.server.datanode.DataNode:
Disk-related <span class="exception">IOException</span> in BlockReceiver constructor. Cause is java.io.IOException: Too many open files
        at java.io.UnixFileSystem.createFileExclusively(Native <span class="predefined-type">Method</span>)
        at java.io.File.createNewFile(<span class="predefined-type">File</span>.java:<span class="integer">883</span>)</code></pre>
</div>
</div>
<div class="paragraph">
<p>...请参阅链接：[ulimit和nproc配置]的“入门”部分。</p>
</div>
</div>
<div class="sect3">
<h4 id="trouble.rs.runtime.xceivers"><a class="anchor" href="#trouble.rs.runtime.xceivers"></a> 110.2.3。 xceiverCount 258超过并发xcievers 256的限制</h4>
<div class="paragraph">
<p>这通常显示在DataNode日志中。</p>
</div>
<div class="paragraph">
<p>请参阅link：[xceivers配置]上的“入门”部分。</p>
</div>
</div>
<div class="sect3">
<h4 id="trouble.rs.runtime.oom_nt"><a class="anchor" href="#trouble.rs.runtime.oom_nt"></a> 110.2.4。系统不稳定，并且存在“ java.lang。OutOfMemoryError：无法在异常” HDFS DataNode日志或任何系统守护程序的日志中创建新的本机线程</h4>
<div class="paragraph">
<p>请参见有关ulimit和nproc配置的“入门”部分。最近的Linux发行版中的默认值为1024-对于HBase而言太低了。</p>
</div>
</div>
<div class="sect3">
<h4 id="trouble.rs.runtime.gc"><a class="anchor" href="#trouble.rs.runtime.gc"></a> 110.2.5。DFS不稳定和/或RegionServer租约超时</h4>
<div class="paragraph">
<p>如果您看到这样的警告消息...</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="integer">2009</span>-<span class="octal">02</span>-<span class="integer">24</span> <span class="integer">10</span>:<span class="octal">01</span>:<span class="integer">33</span>,<span class="integer">516</span> WARN org.apache.hadoop.hbase.util.Sleeper: We slept xxx ms, ten times longer than scheduled: <span class="integer">10000</span>
<span class="integer">2009</span>-<span class="octal">02</span>-<span class="integer">24</span> <span class="integer">10</span>:<span class="octal">01</span>:<span class="integer">33</span>,<span class="integer">516</span> WARN org.apache.hadoop.hbase.util.Sleeper: We slept xxx ms, ten times longer than scheduled: <span class="integer">15000</span>
<span class="integer">2009</span>-<span class="octal">02</span>-<span class="integer">24</span> <span class="integer">10</span>:<span class="octal">01</span>:<span class="integer">36</span>,<span class="integer">472</span> WARN org.apache.hadoop.hbase.regionserver.HRegionServer: unable to report to master <span class="keyword">for</span> xxx milliseconds - retrying</code></pre>
</div>
</div>
<div class="paragraph">
<p>...或者看到完整的GC压缩信息，则可能是完整的GC。</p>
</div>
</div>
<div class="sect3">
<h4 id="trouble.rs.runtime.nolivenodes"><a class="anchor" href="#trouble.rs.runtime.nolivenodes"></a> 110.2.6。 “没有活动节点包含当前块”和/或YouAreDeadException</h4>
<div class="paragraph">
<p>在操作系统文件句柄用尽或节点无法访问的严重网络问题期间，可能会发生这些错误。</p>
</div>
<div class="paragraph">
<p>请参阅有关ulimit和nproc配置的入门部分，并检查您的网络。</p>
</div>
</div>
<div class="sect3">
<h4 id="trouble.rs.runtime.zkexpired"><a class="anchor" href="#trouble.rs.runtime.zkexpired"></a> 110.2.7。ZooKeeper SessionExpired事件</h4>
<div class="paragraph">
<p>Master或RegionServers关闭，并显示类似日志中的消息：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">WARN org.apache.zookeeper.ClientCnxn: <span class="exception">Exception</span>
closing session <span class="hex">0x278bd16a96000f</span> to sun.nio.ch.SelectionKeyImpl<span class="error">@</span><span class="integer">355811</span>ec
java.io.IOException: TIMED OUT
       at org.apache.zookeeper.ClientCnxn<span class="error">$</span>SendThread.run(ClientCnxn.java:<span class="integer">906</span>)
WARN org.apache.hadoop.hbase.util.Sleeper: We slept <span class="integer">79410</span>ms, ten times longer than scheduled: <span class="integer">5000</span>
INFO org.apache.zookeeper.ClientCnxn: Attempting connection to server hostname/IP:PORT
INFO org.apache.zookeeper.ClientCnxn: Priming connection to java.nio.channels.SocketChannel[connected local=/IP:PORT remote=hostname/IP:PORT]
INFO org.apache.zookeeper.ClientCnxn: Server connection successful
WARN org.apache.zookeeper.ClientCnxn: <span class="exception">Exception</span> closing session <span class="hex">0x278bd16a96000d</span> to sun.nio.ch.SelectionKeyImpl<span class="error">@</span><span class="float">3544d</span><span class="integer">65</span>e
java.io.IOException: Session Expired
       at org.apache.zookeeper.ClientCnxn<span class="error">$</span>SendThread.readConnectResult(ClientCnxn.java:<span class="integer">589</span>)
       at org.apache.zookeeper.ClientCnxn<span class="error">$</span>SendThread.doIO(ClientCnxn.java:<span class="integer">709</span>)
       at org.apache.zookeeper.ClientCnxn<span class="error">$</span>SendThread.run(ClientCnxn.java:<span class="integer">945</span>)
ERROR org.apache.hadoop.hbase.regionserver.HRegionServer: ZooKeeper session expired</code></pre>
</div>
</div>
<div class="paragraph">
<p>JVM正在进行长时间运行的垃圾收集，这会暂停每个线程（也称为“停止世界”）。由于RegionServer的本地ZooKeeper客户端无法发送心跳，因此会话超时。按照设计，我们在超时后关闭了任何无法联系ZooKeeper集成的节点，以使其停止提供可能已经分配给其他地方的数据。</p>
</div>
<div class="ulist">
<ul>
<li>
<p>确保提供足够的RAM（在<em>hbase-env.sh中</em> ），默认值1GB将无法承受长时间运行的导入。</p>
</li>
<li>
<p>确保不交换，JVM在交换下永远不会表现良好。</p>
</li>
<li>
<p>确保您没有CPU耗尽RegionServer线程。例如，如果您在具有4个核心的计算机上使用6个CPU密集型任务运行MapReduce作业，则可能是让RegionServer饿死了以至于创建了更长的垃圾收集暂停。</p>
</li>
<li>
<p>增加ZooKeeper会话超时</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>如果您希望增加会话超时，请将以下内容添加到<em>hbase-site.xml中，</em>以将超时从默认的60秒增加到120秒。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="xml"><span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>zookeeper.session.timeout<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>1200000<span class="tag">&lt;/value&gt;</span>
<span class="tag">&lt;/property&gt;</span>
<span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>hbase.zookeeper.property.tickTime<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>6000<span class="tag">&lt;/value&gt;</span>
<span class="tag">&lt;/property&gt;</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>请注意，设置较高的超时时间意味着故障的RegionServer服务的区域将至少花费该时间量才能传输到另一个RegionServer。对于服务实时请求的生产系统，我们建议将其设置为小于1分钟，并为群集提供过多的空间，以降低每台计算机上的内存负载（因此每台计算机收集的垃圾较少）。</p>
</div>
<div class="paragraph">
<p>如果这种情况仅在一次上传中发生（例如，最初将所有数据加载到HBase中），请考虑批量加载。</p>
</div>
<div class="paragraph">
<p>有关ZooKeeper疑难解答的其他常规信息<a href="#trouble.zookeeper.general">，</a>请参见<a href="#trouble.zookeeper.general">Cluster Canary</a>的ZooKeeper。</p>
</div>
</div>
<div class="sect3">
<h4 id="trouble.rs.runtime.notservingregion"><a class="anchor" href="#trouble.rs.runtime.notservingregion"></a> 110.2.8。NotServingRegionException</h4>
<div class="paragraph">
<p>在RegionServer日志中以DEBUG级别找到此异常是“正常”。该异常返回给客户端，然后客户端返回<code>hbase:meta</code>查找移动区域的新位置。</p>
</div>
<div class="paragraph">
<p>但是，如果NotServingRegionException记录为ERROR，则客户端的重试用尽，可能是错误的。</p>
</div>
</div>
<div class="sect3">
<h4 id="brand.new.compressor"><a class="anchor" href="#brand.new.compressor"></a> 110.2.9。日志中充斥着“ 2011-01-10 12：40：48,407 INFO org.apache.hadoop.io.compress。CodecPool：全新压缩机的消息</h4>
<div class="paragraph">
<p>我们未使用压缩库的本机版本。请参阅<a href="https://issues.apache.org/jira/browse/HBASE-1900">HBASE-1900</a> 。 <a href="https://issues.apache.org/jira/browse/HBASE-1900">发布hadoop 0.21时放回本机支持</a> 。从Hoop lib目录下的hadoop复制本机lib或将它们符号链接到适当位置，消息将消失。</p>
</div>
</div>
<div class="sect3">
<h4 id="trouble.rs.runtime.client_went_away"><a class="anchor" href="#trouble.rs.runtime.client_went_away"></a> 110.2.10。60020上的服务器处理程序X被捕获：java.nio.channels。ClosedChannelException</h4>
<div class="paragraph">
<p>如果您看到此类型的消息，则表示区域服务器正尝试从客户端读取数据/向客户端发送数据，但该服务器已消失。造成这种情况的典型原因是客户端被杀死（当MapReduce作业被杀死或失败时，您会看到大量此类消息）或客户端收到SocketTimeoutException。这是无害的，但是如果您没有做任何事情来触发它们，则应该考虑多挖一些。</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_snapshot_errors_due_to_reverse_dns"><a class="anchor" href="#_snapshot_errors_due_to_reverse_dns"></a> 110.3。反向DNS导致的快照错误</h3>
<div class="paragraph">
<p>HBase中的一些操作（包括快照）都依赖于正确配置的反向DNS。某些环境（例如Amazon EC2）在使用反向DNS时会遇到麻烦。如果您在RegionServers上看到类似以下的错误，请检查反向DNS配置：</p>
</div>
<div class="listingblock">
<div class="content">
<pre>2013-05-01 00:04:56,356 DEBUG org.apache.hadoop.hbase.procedure.Subprocedure: Subprocedure 'backup1'
coordinator notified of 'acquire', waiting on 'reached' or 'abort' from coordinator.</pre>
</div>
</div>
<div class="paragraph">
<p>通常，RegionServer报告的主机名必须与主服务器尝试访问的主机名相同。通过在启动时在RegionServer日志中查找以下类型的消息，可以看到主机名不匹配。</p>
</div>
<div class="listingblock">
<div class="content">
<pre>2013-05-01 00:03:00,614 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: Master passed us hostname
to use. Was=myhost-1234, Now=ip-10-55-88-99.ec2.internal</pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="trouble.rs.shutdown"><a class="anchor" href="#trouble.rs.shutdown"></a> 110.4。关机错误</h3>

</div>
</div>
</div>
<div class="sect1">
<h2 id="trouble.master"><a class="anchor" href="#trouble.master"></a> 111。主</h2>
<div class="sectionbody">
<div class="paragraph">
<p>有关Master的更多信息，请参阅<a href="#master">master</a> 。</p>
</div>
<div class="sect2">
<h3 id="trouble.master.startup"><a class="anchor" href="#trouble.master.startup"></a> 111.1。启动错误</h3>
<div class="sect3">
<h4 id="trouble.master.startup.migration"><a class="anchor" href="#trouble.master.startup.migration"></a> 111.1.1。师父说您需要运行HBase迁移脚本</h4>
<div class="paragraph">
<p>运行该命令后，HBase迁移脚本会说根目录中没有文件。</p>
</div>
<div class="paragraph">
<p>HBase希望根目录不存在，或者已经由先前运行的HBase初始化过。如果使用Hadoop DFS为HBase创建新目录，则会发生此错误。确保HBase根目录当前不存在或已由HBase的先前运行初始化。确定的解决方案是仅使用Hadoop dfs删除HBase根目录，然后让HBase创建和初始化目录本身。</p>
</div>
</div>
<div class="sect3">
<h4 id="trouble.master.startup.zk.buffer"><a class="anchor" href="#trouble.master.startup.zk.buffer"></a> 111.1.2。数据包len6080218超出范围！</h4>
<div class="paragraph">
<p>如果群集上有很多区域，并且在日志的此部分标题中看到了类似上面报告的错误，请参见<a href="https://issues.apache.org/jira/browse/HBASE-4246">HBASE-4246具有太多区域的群集无法承受某些主故障转移方案</a> 。</p>
</div>
</div>
<div class="sect3">
<h4 id="trouble.master.startup.hsync"><a class="anchor" href="#trouble.master.startup.hsync"></a> 111.1.3。由于缺少文件系统的hsync，Master无法激活</h4>
<div class="paragraph">
<p>HBase的集群操作内部框架要求能够持久保存状态到预写日志中。当使用支持检查所需调用的可用性的Apache Hadoop Common的文件系统API版本时，如果发现无法安全运行HBase，则HBase将主动中止该集群。</p>
</div>
<div class="paragraph">
<p>对于主角色，失败将显示在以下日志中：</p>
</div>
<div class="listingblock">
<div class="content">
<pre>2018-04-05 11:18:44,653 ERROR [Thread-21] master.HMaster: Failed to become active master
java.lang.IllegalStateException: The procedure WAL relies on the ability to hsync for proper operation during component failures, but the underlying filesystem does not support doing so. Please check the config value of 'hbase.procedure.store.wal.use.hsync' to set the desired level of robustness and ensure the config value of 'hbase.wal.dir' points to a FileSystem mount that can provide it.
        at org.apache.hadoop.hbase.procedure2.store.wal.WALProcedureStore.rollWriter(WALProcedureStore.java:1034)
        at org.apache.hadoop.hbase.procedure2.store.wal.WALProcedureStore.recoverLease(WALProcedureStore.java:374)
        at org.apache.hadoop.hbase.procedure2.ProcedureExecutor.start(ProcedureExecutor.java:530)
        at org.apache.hadoop.hbase.master.HMaster.startProcedureExecutor(HMaster.java:1267)
        at org.apache.hadoop.hbase.master.HMaster.startServiceThreads(HMaster.java:1173)
        at org.apache.hadoop.hbase.master.HMaster.finishActiveMasterInitialization(HMaster.java:881)
        at org.apache.hadoop.hbase.master.HMaster.startActiveMasterManager(HMaster.java:2048)
        at org.apache.hadoop.hbase.master.HMaster.lambda$run$0(HMaster.java:568)
        at java.lang.Thread.run(Thread.java:745)</pre>
</div>
</div>
<div class="paragraph">
<p>如果您尝试以独立模式运行并看到此错误，请返回<a href="#quickstart">快速入门-独立HBase部分，</a>并确保已包括<strong>所有</strong>给定的配置设置。</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="trouble.master.shutdown"><a class="anchor" href="#trouble.master.shutdown"></a> 111.2。关机错误</h3>

</div>
</div>
</div>
<div class="sect1">
<h2 id="trouble.zookeeper"><a class="anchor" href="#trouble.zookeeper"></a> 112。动物园管理员</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="trouble.zookeeper.startup"><a class="anchor" href="#trouble.zookeeper.startup"></a> 111.2。启动错误</h3>
<div class="sect3">
<h4 id="trouble.zookeeper.startup.address"><a class="anchor" href="#trouble.zookeeper.startup.address"></a> 112.1.1。在ZooKeeper仲裁服务器列表中找不到我的地址：xyz</h4>
<div class="paragraph">
<p>ZooKeeper服务器无法启动，引发该错误。xyz是您的服务器的名称。</p>
</div>
<div class="paragraph">
<p>这是一个名称查找问题。HBase尝试在某台计算机上启动ZooKeeper服务器，但该计算机无法在<code>hbase.zookeeper.quorum</code>组态。</p>
</div>
<div class="paragraph">
<p>使用错误消息中显示的主机名代替您使用的值。如果您有DNS服务器，则可以设置<code>hbase.zookeeper.dns.interface</code>和<code>hbase.zookeeper.dns.nameserver</code>在<em>hbase-site.xml中</em>以确保它解析为正确的FQDN。</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="trouble.zookeeper.general"><a class="anchor" href="#trouble.zookeeper.general"></a> 111.2。ZooKeeper，集群金丝雀</h3>
<div class="paragraph">
<p>ZooKeeper是集群的“矿井中的金丝雀”。它将是第一个注意到问题的人，以确保它很高兴成为嗡嗡作响的集群的捷径。</p>
</div>
<div class="paragraph">
<p>请参阅<a href="http://wiki.apache.org/hadoop/ZooKeeper/Troubleshooting">ZooKeeper操作环境故障排除</a>页面。它具有用于检查磁盘和网络性能的建议和工具；即您的ZooKeeper和HBase在其中运行的操作环境。</p>
</div>
<div class="paragraph">
<p>此外，实用程序<a href="#trouble.tools.builtin.zkcli">zkcli</a>可能有助于调查ZooKeeper问题。</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="trouble.ec2"><a class="anchor" href="#trouble.ec2"></a> 113。亚马逊EC2</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="trouble.ec2.zookeeper"><a class="anchor" href="#trouble.ec2.zookeeper"></a> 113.1。ZooKeeper在Amazon EC2上似乎不起作用</h3>
<div class="paragraph">
<p>部署为Amazon EC2实例时，HBase无法启动。Master和/或RegionServer日志中会出现类似以下的异常：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">  <span class="integer">2009</span>-<span class="integer">10</span>-<span class="integer">19</span> <span class="integer">11</span>:<span class="integer">52</span>:<span class="integer">27</span>,<span class="octal">030</span> INFO org.apache.zookeeper.ClientCnxn: Attempting
  connection to server ec2-<span class="integer">174</span>-<span class="integer">129</span>-<span class="integer">15</span>-<span class="integer">236</span>.compute-<span class="integer">1</span>.amazonaws.com/<span class="float">10.244</span><span class="float">.9</span><span class="float">.171</span>:<span class="integer">2181</span>
  <span class="integer">2009</span>-<span class="integer">10</span>-<span class="integer">19</span> <span class="integer">11</span>:<span class="integer">52</span>:<span class="integer">27</span>,<span class="octal">032</span> WARN org.apache.zookeeper.ClientCnxn: <span class="exception">Exception</span>
  closing session <span class="hex">0x0</span> to sun.nio.ch.SelectionKeyImpl<span class="error">@</span><span class="float">656d</span>c861
  java.net.ConnectException: <span class="predefined-type">Connection</span> refused</code></pre>
</div>
</div>
<div class="paragraph">
<p>安全组策略阻止了公用地址上的ZooKeeper端口。配置ZooKeeper仲裁对等列表时，请使用内部EC2主机名。</p>
</div>
</div>
<div class="sect2">
<h3 id="trouble.ec2.instability"><a class="anchor" href="#trouble.ec2.instability"></a> 113.2。Amazon EC2上的不稳定</h3>
<div class="paragraph">
<p>有关HBase和Amazon EC2的问题经常出现在HBase分发列表中。使用<a href="http://search-hadoop.com/">Search Hadoop</a>搜索旧线程</p>
</div>
</div>
<div class="sect2">
<h3 id="trouble.ec2.connection"><a class="anchor" href="#trouble.ec2.connection"></a> 113.3。到EC2群集的远程Java连接不起作用</h3>
<div class="paragraph">
<p>在用户列表中，请参阅此处的Andrew的答案： <a href="http://search-hadoop.com/m/sPdqNFAwyg2">到EC2实例的远程Java客户端连接</a> 。</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="trouble.versions"><a class="anchor" href="#trouble.versions"></a> 114。HBase和Hadoop版本问题</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="trouble.wrong.version"><a class="anchor" href="#trouble.wrong.version"></a> 114.1。 ......无法与客户端版本进行通信...</h3>
<div class="paragraph">
<p>如果您在日志中看到类似以下内容的信息<span class="computeroutput">...2012-09-24 10：20：52,168致命org.apache.hadoop.hbase.master。HMaster：未处理的异常。开始关机。 org.apache.hadoop.ipc。RemoteException：服务器IPC版本7无法与客户端版本4通信...</span> ...您是否正在尝试从具有Hadoop 1.0.x客户端的HBase与Hadoop 2.0.x进行通信？使用针对Hadoop 2.0构建的HBase或通过将-Dhadoop.profile = 2.0属性传递给Maven来重建HBase（有关更多信息，请参见<a href="#maven.build.hadoop">针对各种hadoop版本构建。</a> ）。</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_hbase_and_hdfs"><a class="anchor" href="#_hbase_and_hdfs"></a> 115。HBase和HDFS</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Apache HDFS的常规配置指南不在本指南的范围之内。有关配置HDFS的详细信息，请参阅<a href="http://hadoop.apache.org/" class="bare">http://hadoop.apache.org/</a>上的文档。本节从HBase角度处理HDFS。</p>
</div>
<div class="paragraph">
<p>在大多数情况下，HBase会将其数据存储在Apache HDFS中。这包括包含数据的HFile，以及在将数据写入HFile之前存储数据并防止RegionServer崩溃的预写日志（WAL）。HDFS为HBase中的数据提供了可靠性和保护，因为它是分布式的。为了以最高效率运行，HBase需要本地提供数据。因此，在每个RegionServer上运行HDFS DataNode是一个好习惯。</p>
</div>
<div class="dlist">
<div class="title">HBase和HDFS的重要信息和准则</div>
<dl>
<dt class="hdlist1">HBase是HDFS的客户端。</dt>
<dd>
<p>HBase是使用HDFS的HDFS客户端<code>DFSClient</code>类，并且对该类的引用与其他HDFS客户端日志消息一起出现在HBase日志中。</p>
</dd>
<dt class="hdlist1">必须在多个位置进行配置。</dt>
<dd>
<p>与HBase相关的某些HDFS配置需要在HDFS（服务器）端进行。其他必须在HBase（在客户端）上完成。服务器和客户端都需要设置其他设置。</p>
</dd>
<dt class="hdlist1">影响HBase的写入错误可能会记录在HDFS日志中，而不是HBase日志中。</dt>
<dd>
<p>写入时，HDFS通过管道将通信从一个DataNode流向另一个。HBase使用HDFS客户端类与HDFS NameNode和DataNode进行通信。数据节点之间的通信问题记录在HDFS日志中，而不是HBase日志中。</p>
</dd>
<dt class="hdlist1">HBase使用两个不同的端口与HDFS通信。</dt>
<dd>
<p>HBase使用<code>ipc.Client</code>界面和<code>DataNode</code>类。对它们的引用将出现在HBase日志中。这些通信通道均使用不同的端口（默认情况下为50010和50020）。通过以下方式在HDFS配置中配置端口： <code>dfs.datanode.address</code>和<code>dfs.datanode.ipc.address</code>参数。</p>
</dd>
<dt class="hdlist1">错误可能会记录在HBase和/或HDFS中。</dt>
<dd>
<p>对HBase中的HDFS问题进行故障排除时，请检查两个地方的日志中是否有错误。</p>
</dd>
<dt class="hdlist1">HDFS需要一段时间才能将节点标记为已死。您可以配置HDFS以避免使用陈旧的DataNode。</dt>
<dd>
<p>默认情况下，HDFS不会在630秒内无法访问节点之前将其标记为死节点。在Hadoop 1.1和Hadoop 2.x中，可以通过启用对过时的DataNode的检查来缓解此问题，尽管默认情况下会禁用此检查。您可以通过以下方式分别启用读写检查功能<code>dfs.namenode.avoid.read.stale.datanode</code>和<code>dfs.namenode.avoid.write.stale.datanode settings</code> 。过时的DataNode是无法达到的<code>dfs.namenode.stale.datanode.interval</code> （默认值为30秒）。避免使用过时的数据节点，并将其标记为读取或写入操作的最后一个可能的目标。有关配置的详细信息，请参阅HDFS文档。</p>
</dd>
<dt class="hdlist1">HDFS重试和超时的设置对于HBase非常重要。</dt>
<dd>
<p>您可以配置各种重试和超时设置。请始终参阅HDFS文档以获取最新建议和默认值。这里列出了一些对HBase重要的设置。从Hadoop 2.3开始，默认值是最新的。查看Hadoop文档以获取最新值和建议。</p>
</dd>
</dl>
</div>
<div class="paragraph">
<div class="title">连接超时</div>
<p>连接超时发生在客户端（HBASE）和HDFS DataNode之间。它们可能在建立连接，尝试读取或尝试写入时发生。下面的两个设置结合使用，会影响DFSClient和DataNode之间的连接，ipc.cClient和DataNode之间的连接以及两个DataNode之间的通信。</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1"><code>dfs.client.socket-timeout</code> （默认值：60000）</dt>
<dd>
<p>建立连接或读取时客户端连接超时之前的时间。该值以毫秒表示，因此默认值为60秒。</p>
</dd>
<dt class="hdlist1"><code>dfs.datanode.socket.write.timeout</code> （预设值：480000）</dt>
<dd>
<p>写操作超时之前的时间。默认值为8分钟，以毫秒为单位。</p>
</dd>
</dl>
</div>
<div class="paragraph">
<div class="title">典型错误日志</div>
<p>日志中经常出现以下类型的错误。</p>
</div>
<div class="paragraph">
<p><code>INFO HDFS.DFSClient: Failed to connect to /xxx50010, add to deadNodes and continue java.net.SocketTimeoutException: 60000 millis timeout while waiting for channel to be ready for connect. ch : java.nio.channels.SocketChannel[connection-pending remote=/region-server-1:50010]</code> ::一个块的所有DataNode都已失效，无法恢复。这是导致此错误的事件序列：</p>
</div>
<div class="paragraph">
<p><code>INFO org.apache.hadoop.HDFS.DFSClient: Exception in createBlockOutputStream java.net.SocketTimeoutException: 69000 millis timeout while waiting for channel to be ready for connect. ch : java.nio.channels.SocketChannel[connection-pending remote=/ xxx:50010]</code> ::此类型的错误指示写问题。在这种情况下，主服务器要拆分日志。它没有本地DataNodes，因此它尝试连接到远程DataNode，但是该DataNode已死。</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="trouble.tests"><a class="anchor" href="#trouble.tests"></a> 116。运行单元或集成测试</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="trouble.hdfs_2556"><a class="anchor" href="#trouble.hdfs_2556"></a> 16.1。运行测试时MiniDFSCluster的运行时异常</h3>
<div class="paragraph">
<p>如果您看到类似以下内容</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">...
java.lang.NullPointerException: <span class="predefined-constant">null</span>
at org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes
at org.apache.hadoop.hdfs.MiniDFSCluster.&lt;init&gt;
at org.apache.hadoop.hbase.MiniHBaseCluster.&lt;init&gt;
at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniDFSCluster
at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniCluster
...</code></pre>
</div>
</div>
<div class="paragraph">
<p>要么</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">...
java.io.IOException: Shutting down
at org.apache.hadoop.hbase.MiniHBaseCluster.init
at org.apache.hadoop.hbase.MiniHBaseCluster.&lt;init&gt;
at org.apache.hadoop.hbase.MiniHBaseCluster.&lt;init&gt;
at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniHBaseCluster
at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniCluster
...</code></pre>
</div>
</div>
<div class="paragraph">
<p>...然后在启动测试之前尝试发出命令umask 022。这是<a href="https://issues.apache.org/jira/browse/HDFS-2556">HDFS-2556</a>的解决方法</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="trouble.casestudy"><a class="anchor" href="#trouble.casestudy"></a> 117。实例探究</h2>
<div class="sectionbody">
<div class="paragraph">
<p>有关性能和故障排除案例研究，请参阅<a href="#casestudies">Apache HBase案例研究</a> 。</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="trouble.crypto"><a class="anchor" href="#trouble.crypto"></a> 118。加密功能</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="trouble.crypto.hbase_10132"><a class="anchor" href="#trouble.crypto.hbase_10132"></a> 18.1。 sun.security.pkcs11.wrapper。PKCS11Exception：CKR_ARGUMENTS_BAD</h3>
<div class="paragraph">
<p>此问题表现为最终导致以下异常的情况：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">Caused by: sun.security.pkcs11.wrapper.PKCS11Exception: CKR_ARGUMENTS_BAD
  at sun.security.pkcs11.wrapper.PKCS11.C_DecryptUpdate(Native <span class="predefined-type">Method</span>)
  at sun.security.pkcs11.P11Cipher.implDoFinal(P11Cipher.java:<span class="integer">795</span>)</code></pre>
</div>
</div>
<div class="paragraph">
<p>此问题似乎影响某些Linux供应商提供的某些版本的OpenJDK 7。NSS被配置为默认提供程序。如果主机具有x86_64体系结构，则取决于供应商软件包是否包含缺陷，NSS提供程序将无法正常运行。</p>
</div>
<div class="paragraph">
<p>要解决此问题，请找到JRE主目录并编辑文件<em>lib / security / java.security</em> 。编辑文件以注释掉该行：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">security.provider<span class="float">.1</span>=sun.security.pkcs11.SunPKCS11 <span class="error">$</span>{java.home}/lib/security/nss.cfg</code></pre>
</div>
</div>
<div class="paragraph">
<p>然后相应地重新编号其余的提供程序。</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_operating_system_specific_issues"><a class="anchor" href="#_operating_system_specific_issues"></a> 119。操作系统特定问题</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_page_allocation_failure"><a class="anchor" href="#_page_allocation_failure"></a> 119.1。页面分配失败</h3>
<div class="admonitionblock note">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-note" title="注意"></i>
</td>
<td class="content">已知此问题会影响CentOS 6.2以及可能的CentOS 6.5。根据<a href="https://bugzilla.redhat.com/show_bug.cgi?id=770545" class="bare">https://bugzilla.redhat.com/show_bug.cgi?id=770545的描述</a> ，它可能还会影响某些版本的Red Hat Enterprise Linux。</td>
</tr>
</tbody></table>
</div>
<div class="paragraph">
<p>一些用户报告看到以下错误：</p>
</div>
<div class="listingblock">
<div class="content">
<pre>kernel: java: page allocation failure. order:4, mode:0x20</pre>
</div>
</div>
<div class="paragraph">
<p>提升价值<code>min_free_kbytes</code>据报道可以解决此问题。此参数设置为系统上RAM量的百分比，有关详细信息， <a href="http://www.centos.org/docs/5/html/5.1/Deployment_Guide/s3-proc-sys-vm.html" class="bare">请参见http://www.centos.org/docs/5/html/5.1/Deployment_Guide/s3-proc-sys-vm .html</a> 。</p>
</div>
<div class="paragraph">
<p>要查找系统上的当前值，请运行以下命令：</p>
</div>
<div class="listingblock">
<div class="content">
<pre>[user@host]# cat /proc/sys/vm/min_free_kbytes</pre>
</div>
</div>
<div class="paragraph">
<p>接下来，提高价值。尝试加倍，然后将值增加四倍。请注意，将该值设置得太低或太高可能会对您的系统产生不利影响。有关具体建议，请咨询您的操作系统供应商。</p>
</div>
<div class="paragraph">
<p>使用以下命令来修改<code>min_free_kbytes</code> ，代替<em><value></value></em>具有您的预期值：</p>
</div>
<div class="listingblock">
<div class="content">
<pre>[user@host]# echo &lt;value&gt; &gt; /proc/sys/vm/min_free_kbytes</pre>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_jdk_issues"><a class="anchor" href="#_jdk_issues"></a> 120。JDK问题</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_nosuchmethoderror_java_util_concurrent_concurrenthashmap_keyset"><a class="anchor" href="#_nosuchmethoderror_java_util_concurrent_concurrenthashmap_keyset"></a> 120.1。NoSuchMethodError：java.util.concurrent。ConcurrentHashMap.keySet</h3>
<div class="paragraph">
<p>如果您在日志中看到此信息：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">Caused by: java.lang.NoSuchMethodError: java.util.concurrent.ConcurrentHashMap.keySet()Ljava/util/concurrent/<span class="predefined-type">ConcurrentHashMap</span><span class="error">$</span>KeySetView;
  at org.apache.hadoop.hbase.master.ServerManager.findServerWithSameHostnamePortWithLock(ServerManager.java:<span class="integer">393</span>)
  at org.apache.hadoop.hbase.master.ServerManager.checkAndRecordNewServer(ServerManager.java:<span class="integer">307</span>)
  at org.apache.hadoop.hbase.master.ServerManager.regionServerStartup(ServerManager.java:<span class="integer">244</span>)
  at org.apache.hadoop.hbase.master.MasterRpcServices.regionServerStartup(MasterRpcServices.java:<span class="integer">304</span>)
  at org.apache.hadoop.hbase.protobuf.generated.RegionServerStatusProtos<span class="error">$</span>RegionServerStatusService<span class="error">$</span><span class="integer">2</span>.callBlockingMethod(RegionServerStatusProtos.java:<span class="integer">7910</span>)
  at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:<span class="integer">2020</span>)
  ... <span class="integer">4</span> more</code></pre>
</div>
</div>
<div class="paragraph">
<p>然后检查是否使用jdk8编译并尝试在jdk7上运行它。如果是这样，这将行不通。在jdk8上运行或与jdk7一起重新编译。<a href="https://issues.apache.org/jira/browse/HBASE-10607">如果在JRE 7上运行，</a>请参见<a href="https://issues.apache.org/jira/browse/HBASE-10607">涉及ConcurrentHashMap.keySet的HBASE-10607 JDK8 NoSuchMethodError</a> 。</p>
</div>
</div>
</div>
</div>
<h1 id="casestudies" class="sect0"><a class="anchor" href="#casestudies"></a> Apache HBase案例研究</h1>
<div class="sect1">
<h2 id="casestudies.overview"><a class="anchor" href="#casestudies.overview"></a> 121。总览</h2>
<div class="sectionbody">
<div class="paragraph">
<p>本章将介绍各种性能和故障排除案例研究，这些案例研究可为诊断Apache HBase群集问题提供有用的蓝图。</p>
</div>
<div class="paragraph">
<p>有关性能和故障排除的更多信息，请参阅<a href="#performance">Apache HBase性能调优</a>以及<a href="#trouble">Apache HBase的故障排除和调试</a> 。</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="casestudies.schema"><a class="anchor" href="#casestudies.schema"></a> 122。模式设计</h2>
<div class="sectionbody">
<div class="paragraph">
<p>在这里查看架构设计案例研究： <a href="#schema.casestudies">架构设计案例研究</a></p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="casestudies.perftroub"><a class="anchor" href="#casestudies.perftroub"></a> 123。性能/故障排除</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="casestudies.slownode"><a class="anchor" href="#casestudies.slownode"></a> 123.1。案例研究1（单个节点上的性能问题）</h3>
<div class="sect3">
<h4 id="_scenario"><a class="anchor" href="#_scenario"></a> 123.1.1。情境</h4>
<div class="paragraph">
<p>在计划的重启之后，一个数据节点开始表现出异常行为。常规MapReduce作业针对HBase表运行，而HBase表通常在五到六分钟内完成，开始需要30或40分钟才能完成。一致地发现这些作业正在等待地图，从而减少了分配给有问题的数据节点的任务（例如，慢速地图任务都具有相同的输入分割）。在分布式副本期间，当延迟节点严重拖延副本时，这种情况变得非常严重。</p>
</div>
</div>
<div class="sect3">
<h4 id="_hardware"><a class="anchor" href="#_hardware"></a> 123.1.2。硬件</h4>
<div class="ulist">
<div class="title">数据节点：</div>
<ul>
<li>
<p>两个12核处理器</p>
</li>
<li>
<p>六个Enerprise SATA磁盘</p>
</li>
<li>
<p>24GB RAM</p>
</li>
<li>
<p>两个绑定的千兆网卡</p>
</li>
</ul>
</div>
<div class="ulist">
<div class="title">网络：</div>
<ul>
<li>
<p>10个千兆架顶式交换机</p>
</li>
<li>
<p>机架之间有20个千兆位绑定互连。</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_hypotheses"><a class="anchor" href="#_hypotheses"></a> 123.1.3。假设</h4>
<div class="sect4">
<h5 id="_hbase_hot_spot_region"><a class="anchor" href="#_hbase_hot_spot_region"></a> HBase“热点”区域</h5>
<div class="paragraph">
<p>我们假设遇到了一个熟悉的痛点：HBase表中的“热点”区域，其中不均匀的键空间分布可以将大量请求集中到单个HBase区域，从而轰炸RegionServer进程并导致响应缓慢时间。对HBase主站状态页面的检查显示，发往故障节点的HBase请求数量几乎为零。此外，对HBase日志的检查显示没有正在进行的区域划分，压实或其他区域转换。这有效地排除了“热点”作为观察到的缓慢的根本原因。</p>
</div>
</div>
<div class="sect4">
<h5 id="_hbase_region_with_non_local_data"><a class="anchor" href="#_hbase_region_with_non_local_data"></a>具有非本地数据的HBase区域</h5>
<div class="paragraph">
<p>我们的下一个假设是，MapReduce任务之一是从HBase请求非DataNode本地的数据，从而迫使HDFS通过网络从其他服务器请求数据块。对DataNode日志的检查表明，通过网络请求的块很少，这表明已正确分配了HBase区域，并且大多数必要数据位于该节点上。这排除了非本地数据导致速度降低的可能性。</p>
</div>
</div>
<div class="sect4">
<h5 id="_excessive_i_o_wait_due_to_swapping_or_an_over_worked_or_failing_hard_disk"><a class="anchor" href="#_excessive_i_o_wait_due_to_swapping_or_an_over_worked_or_failing_hard_disk"></a>由于交换，硬盘工作过度或出现故障而导致的I / O等待过多</h5>
<div class="paragraph">
<p>在确定Hadoop和HBase不太可能成为罪魁祸首之后，我们着手对DataNode的硬件进行故障排除。根据设计，Java将定期扫描其整个内存空间以进行垃圾回收。如果系统内存使用过多，则Linux内核可能会进入恶性循环，用尽所有资源，在Java尝试运行垃圾回收时将Java堆从磁盘来回交换到RAM。此外，发生故障的硬盘通常会在放弃并返回错误之前重试多次读取和/或写入。当正在运行的进程等待读取和写入完成时，这可能表现为高iowait。最后，接近其性能范围上限的磁盘将开始引起iowait，因为它通知内核它不能再接受任何数据，并且内核将传入的数据排队到内存中的脏写入池中。但是，使用<code>vmstat(1)</code>和<code>free(1)</code> ，我们可以看到没有使用任何交换，并且磁盘IO的数量仅为每秒几千字节。</p>
</div>
</div>
<div class="sect4">
<h5 id="_slowness_due_to_high_processor_usage"><a class="anchor" href="#_slowness_due_to_high_processor_usage"></a>由于处理器使用率高而导致速度慢</h5>
<div class="paragraph">
<p>接下来，我们检查了系统是否仅由于非常高的计算负荷而运行缓慢。 <code>top(1)</code>表明系统负载高于正常水平，但是<code>vmstat(1)</code>和<code>mpstat(1)</code>表明用于实际计算的处理器数量很少。</p>
</div>
</div>
<div class="sect4">
<h5 id="_network_saturation_the_winner"><a class="anchor" href="#_network_saturation_the_winner"></a>网络饱和度（获胜者）</h5>
<div class="paragraph">
<p>由于磁盘和处理器均未得到充分利用，因此我们继续介绍网络接口的性能。DataNode具有两个千兆位以太网适配器，它们被绑定以形成一个主备接口。 <code>ifconfig(8)</code>显示一些异常异常，即接口错误，超限，成帧错误。尽管并非闻所未闻，但这些错误在现代硬件上却极为罕见，它应该按以下方式运行：</p>
</div>
<div class="listingblock">
<div class="content">
<pre>$ /sbin/ifconfig bond0
bond0  Link encap:Ethernet  HWaddr 00:00:00:00:00:00
inet addr:10.x.x.x  Bcast:10.x.x.255  Mask:255.255.255.0
UP BROADCAST RUNNING MASTER MULTICAST  MTU:1500  Metric:1
RX packets:2990700159 errors:12 dropped:0 overruns:1 frame:6          &lt;--- Look Here! Errors!
TX packets:3443518196 errors:0 dropped:0 overruns:0 carrier:0
collisions:0 txqueuelen:0
RX bytes:2416328868676 (2.4 TB)  TX bytes:3464991094001 (3.4 TB)</pre>
</div>
</div>
<div class="paragraph">
<p>这些错误立即使我们怀疑一个或多个以太网接口可能协商了错误的线速。通过从外部主机运行ICMP ping并观察到往返时间超过700毫秒，以及通过运行<code>ethtool(8)</code>在绑定接口的成员上发现活动接口正在以100Mbs /全双工运行。</p>
</div>
<div class="listingblock">
<div class="content">
<pre>$ sudo ethtool eth0
Settings for eth0:
Supported ports: [ TP ]
Supported link modes:   10baseT/Half 10baseT/Full
                       100baseT/Half 100baseT/Full
                       1000baseT/Full
Supports auto-negotiation: Yes
Advertised link modes:  10baseT/Half 10baseT/Full
                       100baseT/Half 100baseT/Full
                       1000baseT/Full
Advertised pause frame use: No
Advertised auto-negotiation: Yes
Link partner advertised link modes:  Not reported
Link partner advertised pause frame use: No
Link partner advertised auto-negotiation: No
Speed: 100Mb/s                                     &lt;--- Look Here!  Should say 1000Mb/s!
Duplex: Full
Port: Twisted Pair
PHYAD: 1
Transceiver: internal
Auto-negotiation: on
MDI-X: Unknown
Supports Wake-on: umbg
Wake-on: g
Current message level: 0x00000003 (3)
Link detected: yes</pre>
</div>
</div>
<div class="paragraph">
<p>在正常操作中，ICMP ping往返时间应为20ms左右，并且接口速度和双工应分别为“ 1000MB / s”和“ Full”。</p>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_resolution"><a class="anchor" href="#_resolution"></a> 123.1.4。解析度</h4>
<div class="paragraph">
<p>确定活动的以太网适配器的速度不正确后，我们使用了<code>ifenslave(8)</code>命令将备用接口设置为活动接口，从而立即改善了MapReduce性能，并使网络吞吐量提高了10倍：</p>
</div>
<div class="paragraph">
<p>在下次访问数据中心时，我们确定线速问题最终是由不良的网络电缆引起的，已将其更换。</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="casestudies.perf.1"><a class="anchor" href="#casestudies.perf.1"></a> 123.2。案例研究2（2012年性能研究）</h3>
<div class="paragraph">
<p>自我描述的“我们不确定是什么问题，但似乎很慢”问题的调查结果。 <a href="http://gbif.blogspot.com/2012/03/hbase-performance-evaluation-continued.html" class="bare">http://gbif.blogspot.com/2012/03/hbase-performance-evaluation-continued.html</a></p>
</div>
</div>
<div class="sect2">
<h3 id="casestudies.perf.2"><a class="anchor" href="#casestudies.perf.2"></a> 123.3。案例研究3（2010年性能研究）</h3>
<div class="paragraph">
<p>2010年总体集群绩效的调查结果。尽管此研究是在较旧版本的代码库上进行的，但是在方法上，此编写仍然非常有用。 <a href="http://hstack.org/hbase-performance-testing/" class="bare">http://hstack.org/hbase-performance-testing/</a></p>
</div>
</div>
<div class="sect2">
<h3 id="casestudies.max.transfer.threads"><a class="anchor" href="#casestudies.max.transfer.threads"></a> 123.4。案例研究4（最大传输线程配置）</h3>
<div class="paragraph">
<p>配置案例研究<code>max.transfer.threads</code> （以前称为<code>xcievers</code> ），并从配置错误中诊断错误。 <a href="http://www.larsgeorge.com/2012/03/hadoop-hbase-and-xceivers.html" class="bare">http://www.larsgeorge.com/2012/03/hadoop-hbase-and-xceivers.html</a></p>
</div>
<div class="paragraph">
<p>也可以看看<a href="#dfs.datanode.max.transfer.threads"><code>dfs.datanode.max.transfer.threads</code></a> 。</p>
</div>
</div>
</div>
</div>
<h1 id="ops_mgt" class="sect0"><a class="anchor" href="#ops_mgt"></a> Apache HBase运营管理</h1>
<div class="openblock partintro">
<div class="content">本章将介绍正在运行的Apache HBase集群所需的操作工具和实践。操作的主题<a href="#trouble">与“ Apache HBase故障排除和调试”</a> ，“ <a href="#performance">Apache HBase性能调优</a> ”和“ <a href="#configuration">Apache HBase配置”有关，</a>但本身就是一个与众不同的主题。
</div>
</div>
<div class="sect1">
<h2 id="tools"><a class="anchor" href="#tools"></a> 124。HBase工具和实用程序</h2>
<div class="sectionbody">
<div class="paragraph">
<p>HBase提供了几种用于管理，分析和调试群集的工具。尽管<em>dev-support /</em>目录中提供了一些工具，但是大多数这些工具的入口点都是<em>bin / hbase</em>命令。</p>
</div>
<div class="paragraph">
<p>要查看<em>bin / hbase</em>命令的用法说明，请不带任何参数或使用<code>-h</code>论点。这些是HBase 0.98.x的使用说明。一些命令，例如<code>version</code> ， <code>pe</code> ， <code>ltt</code> ， <code>clean</code> ，在以前的版本中不可用。</p>
</div>
<div class="listingblock">
<div class="content">
<pre>$ bin/hbase
Usage: hbase [&lt;options&gt;] &lt;command&gt; [&lt;args&gt;]
Options:
  --config DIR     Configuration direction to use. Default: ./conf
  --hosts HOSTS    Override the list in 'regionservers' file
  --auth-as-server Authenticate to ZooKeeper using servers configuration

Commands:
Some commands take arguments. Pass no args or -h for usage.
  shell           Run the HBase shell
  hbck            Run the hbase 'fsck' tool
  snapshot        Tool for managing snapshots
  snapshotinfo    Tool for dumping snapshot information
  wal             Write-ahead-log analyzer
  hfile           Store file analyzer
  zkcli           Run the ZooKeeper shell
  upgrade         Upgrade hbase
  master          Run an HBase HMaster node
  regionserver    Run an HBase HRegionServer node
  zookeeper       Run a Zookeeper server
  rest            Run an HBase REST server
  thrift          Run the HBase Thrift server
  thrift2         Run the HBase Thrift2 server
  clean           Run the HBase clean up script
  classpath       Dump hbase CLASSPATH
  mapredcp        Dump CLASSPATH entries required by mapreduce
  completebulkload Run LoadIncrementalHFiles tool
  pe              Run PerformanceEvaluation
  ltt             Run LoadTestTool
  canary          Run the Canary tool
  version         Print the version
  CLASSNAME       Run the class named CLASSNAME</pre>
</div>
</div>
<div class="paragraph">
<p>下面的一些工具和实用程序是Java类，它们直接传递到<em>bin / hbase</em>命令，如用法说明的最后一行所述。其他，例如<code>hbase shell</code> （ <a href="#shell">Apache HBase Shell</a> ）， <code>hbase upgrade</code> （ <a href="#upgrading">升级</a> ），以及<code>hbase thrift</code> （ <a href="#thrift">Thrift API和过滤器语言</a> ），在本指南的其他地方介绍。</p>
</div>
<div class="sect2">
<h3 id="_canary"><a class="anchor" href="#_canary"></a> 124.1。金丝雀</h3>
<div class="paragraph">
<p>有一个Canary类可以帮助用户对每个区域或RegionServer粒度的每个列族进行Canary测试HBase群集状态。要查看用法，请使用<code>--help</code>参数。</p>
</div>
<div class="listingblock">
<div class="content">
<pre>$ ${HBASE_HOME}/bin/hbase canary -help

Usage: hbase canary [opts] [table1 [table2]...] | [regionserver1 [regionserver2]..]
 where [opts] are:
   -help          Show this help and exit.
   -regionserver  replace the table argument to regionserver,
      which means to enable regionserver mode
   -allRegions    Tries all regions on a regionserver,
      only works in regionserver mode.
   -zookeeper    Tries to grab zookeeper.znode.parent
      on each zookeeper instance
   -daemon        Continuous check at defined intervals.
   -permittedZookeeperFailures &lt;N&gt;    Ignore first N failures when attempting to
      connect to individual zookeeper nodes in the ensemble
   -interval &lt;N&gt;  Interval between checks (sec)
   -e             Use table/regionserver as regular expression
      which means the table/regionserver is regular expression pattern
   -f &lt;B&gt;         stop whole program if first error occurs, default is true
   -t &lt;N&gt;         timeout for a check, default is 600000 (millisecs)
   -writeTableTimeout &lt;N&gt;         write timeout for the writeTable, default is 600000 (millisecs)
   -readTableTimeouts &lt;tableName&gt;=&lt;read timeout&gt;,&lt;tableName&gt;=&lt;read timeout&gt;, ...    comma-separated list of read timeouts per table (no spaces), default is 600000 (millisecs)
   -writeSniffing enable the write sniffing in canary
   -treatFailureAsError treats read / write failure as error
   -writeTable    The table used for write sniffing. Default is hbase:canary
   -Dhbase.canary.read.raw.enabled=&lt;true/false&gt; Use this flag to enable or disable raw scan during read canary test Default is false and raw is not enabled during scan
   -D&lt;configProperty&gt;=&lt;value&gt; assigning or override the configuration params</pre>
</div>
</div>
<div class="paragraph">
<p>该工具将向用户返回非零错误代码，以与其他监视工具（例如Nagios）协作。错误代码定义为：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="directive">private</span> <span class="directive">static</span> <span class="directive">final</span> <span class="type">int</span> USAGE_EXIT_CODE = <span class="integer">1</span>;
<span class="directive">private</span> <span class="directive">static</span> <span class="directive">final</span> <span class="type">int</span> INIT_ERROR_EXIT_CODE = <span class="integer">2</span>;
<span class="directive">private</span> <span class="directive">static</span> <span class="directive">final</span> <span class="type">int</span> TIMEOUT_ERROR_EXIT_CODE = <span class="integer">3</span>;
<span class="directive">private</span> <span class="directive">static</span> <span class="directive">final</span> <span class="type">int</span> ERROR_EXIT_CODE = <span class="integer">4</span>;
<span class="directive">private</span> <span class="directive">static</span> <span class="directive">final</span> <span class="type">int</span> FAILURE_EXIT_CODE = <span class="integer">5</span>;</code></pre>
</div>
</div>
<div class="paragraph">
<p>这是基于以下给定情况的一些示例。有两个Table对象，分别称为test-01和test-02，它们分别具有两个列族cf1和cf2，并部署在3个RegionServer上。请参阅下表。</p>
</div>
<table class="tableblock frame-all grid-all spread">
<colgroup>
<col style="width:33%">
<col style="width:33%">
<col style="width:33%">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">区域服务器</th>
<th class="tableblock halign-left valign-top">测试01</th>
<th class="tableblock halign-left valign-top">测试02</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">rs1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">11</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">22</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">rs2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">22</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">rs3</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">22</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">11</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p>以下是基于先前给定情况的一些示例。</p>
</div>
<div class="sect3">
<h4 id="_canary_test_for_every_column_family_store_of_every_region_of_every_table"><a class="anchor" href="#_canary_test_for_every_column_family_store_of_every_region_of_every_table"></a> 124.1.1。对每个表的每个区域的每个列族（存储）进行金丝雀测试</h4>
<div class="listingblock">
<div class="content">
<pre>$ ${HBASE_HOME}/bin/hbase canary

3/12/09 03:26:32 INFO tool.Canary: read from region test-01,,1386230156732.0e3c7d77ffb6361ea1b996ac1042ca9a. column family cf1 in 2ms
13/12/09 03:26:32 INFO tool.Canary: read from region test-01,,1386230156732.0e3c7d77ffb6361ea1b996ac1042ca9a. column family cf2 in 2ms
13/12/09 03:26:32 INFO tool.Canary: read from region test-01,0004883,1386230156732.87b55e03dfeade00f441125159f8ca87. column family cf1 in 4ms
13/12/09 03:26:32 INFO tool.Canary: read from region test-01,0004883,1386230156732.87b55e03dfeade00f441125159f8ca87. column family cf2 in 1ms
...
13/12/09 03:26:32 INFO tool.Canary: read from region test-02,,1386559511167.aa2951a86289281beee480f107bb36ee. column family cf1 in 5ms
13/12/09 03:26:32 INFO tool.Canary: read from region test-02,,1386559511167.aa2951a86289281beee480f107bb36ee. column family cf2 in 3ms
13/12/09 03:26:32 INFO tool.Canary: read from region test-02,0004883,1386559511167.cbda32d5e2e276520712d84eaaa29d84. column family cf1 in 31ms
13/12/09 03:26:32 INFO tool.Canary: read from region test-02,0004883,1386559511167.cbda32d5e2e276520712d84eaaa29d84. column family cf2 in 8ms</pre>
</div>
</div>
<div class="paragraph">
<p>因此，您可以看到，表test-01具有两个区域和两个列族，因此Canary工具将从4个（2个区域* 2个存储）不同的存储中选择4个小数据。这是此工具的默认行为。</p>
</div>
</div>
<div class="sect3">
<h4 id="_canary_test_for_every_column_family_store_of_every_region_of_specific_table_s"><a class="anchor" href="#_canary_test_for_every_column_family_store_of_every_region_of_specific_table_s"></a> 124.1.2。对特定表每个区域的每个列族（存储）进行金丝雀测试</h4>
<div class="paragraph">
<p>您还可以测试一个或多个特定表。</p>
</div>
<div class="listingblock">
<div class="content">
<pre>$ ${HBASE_HOME}/bin/hbase canary test-01 test-02</pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_canary_test_with_regionserver_granularity"><a class="anchor" href="#_canary_test_with_regionserver_granularity"></a> 124.1.3。具有RegionServer粒度的Canary测试</h4>
<div class="paragraph">
<p>这将从每个RegionServer中选择一小部分数据，并且还可以将RegionServer名称用作特定于Canary测试的RegionServer的输入选项。</p>
</div>
<div class="listingblock">
<div class="content">
<pre>$ ${HBASE_HOME}/bin/hbase canary -regionserver

13/12/09 06:05:17 INFO tool.Canary: Read from table:test-01 on region server:rs2 in 72ms
13/12/09 06:05:17 INFO tool.Canary: Read from table:test-02 on region server:rs3 in 34ms
13/12/09 06:05:17 INFO tool.Canary: Read from table:test-01 on region server:rs1 in 56ms</pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_canary_test_with_regular_expression_pattern"><a class="anchor" href="#_canary_test_with_regular_expression_pattern"></a> 124.1.4。具有正则表达式模式的Canary测试</h4>
<div class="paragraph">
<p>这将测试表test-01和test-02。</p>
</div>
<div class="listingblock">
<div class="content">
<pre>$ ${HBASE_HOME}/bin/hbase canary -e test-0[1-2]</pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_run_canary_test_as_daemon_mode"><a class="anchor" href="#_run_canary_test_as_daemon_mode"></a> 124.1.5。将金丝雀测试作为守护程序模式运行</h4>
<div class="paragraph">
<p>以选项中定义的间隔重复运行<code>-interval</code>其默认值为60秒。由于选项-f的默认值为true，因此该守护程序将自行停止并返回非零错误代码（如果发生任何错误）。</p>
</div>
<div class="listingblock">
<div class="content">
<pre>$ ${HBASE_HOME}/bin/hbase canary -daemon</pre>
</div>
</div>
<div class="paragraph">
<p>内部5秒钟重复运行，即使测试中发生错误也不会停止运行。</p>
</div>
<div class="listingblock">
<div class="content">
<pre>$ ${HBASE_HOME}/bin/hbase canary -daemon -interval 50000 -f false</pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_force_timeout_if_canary_test_stuck"><a class="anchor" href="#_force_timeout_if_canary_test_stuck"></a> 124.1.6。如果金丝雀测试卡住，则强制超时</h4>
<div class="paragraph">
<p>在某些情况下，请求被卡住，并且没有响应发送回客户端。主机尚未注意到的RegionServer死机可能会发生这种情况。因此，我们提供了一个超时选项来终止Canary测试并返回非零错误代码。此运行将超时值设置为60秒，默认值为600秒。</p>
</div>
<div class="listingblock">
<div class="content">
<pre>$ ${HBASE_HOME}/bin/hbase canary -t 600000</pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_enable_write_sniffing_in_canary"><a class="anchor" href="#_enable_write_sniffing_in_canary"></a> 124.1.7。在金丝雀中启用写嗅探</h4>
<div class="paragraph">
<p>默认情况下，canary工具仅检查读取操作，很难在写入路径中发现问题。要启用写嗅探功能，可以使用<code>-writeSniffing</code>选项。启用写嗅探后，canary工具将创建一个hbase表，并确保该表的区域分布在所有区域服务器上。在每个嗅探周期中，金丝雀都会尝试将数据放入这些区域，以检查每个区域服务器的写入可用性。</p>
</div>
<div class="listingblock">
<div class="content">
<pre>$ ${HBASE_HOME}/bin/hbase canary -writeSniffing</pre>
</div>
</div>
<div class="paragraph">
<p>默认写表是<code>hbase:canary</code>并可以通过选项指定<code>-writeTable</code> 。</p>
</div>
<div class="listingblock">
<div class="content">
<pre>$ ${HBASE_HOME}/bin/hbase canary -writeSniffing -writeTable ns:canary</pre>
</div>
</div>
<div class="paragraph">
<p>每个put的默认值大小为10个字节，您可以通过config键设置它： <code>hbase.canary.write.value.size</code> 。</p>
</div>
</div>
<div class="sect3">
<h4 id="_treat_read_write_failure_as_error"><a class="anchor" href="#_treat_read_write_failure_as_error"></a> 124.1.8。将读取/写入失败视为错误</h4>
<div class="paragraph">
<p>默认情况下，canary工具仅记录由于RetriesExhaustedException等导致的读取失败，同时返回正常的退出代码。要将读取/写入失败视为错误，您可以使用<code>-treatFailureAsError</code>选项。启用后，读/写失败将导致错误退出代码。</p>
</div>
<div class="listingblock">
<div class="content">
<pre>$ ${HBASE_HOME}/bin/hbase canary --treatFailureAsError</pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_running_canary_in_a_kerberos_enabled_cluster"><a class="anchor" href="#_running_canary_in_a_kerberos_enabled_cluster"></a> 124.1.9。在启用Kerberos的群集中运行Canary</h4>
<div class="paragraph">
<p>要在启用Kerberos的群集中运行Canary，请在<em>hbase-site.xml中</em>配置以下两个属性：</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>hbase.client.keytab.file</code></p>
</li>
<li>
<p><code>hbase.client.kerberos.principal</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>当Canary在守护程序模式下运行时，Kerberos凭据每30秒刷新一次。</p>
</div>
<div class="paragraph">
<p>要为客户端配置DNS接口，请在<em>hbase-site.xml中</em>配置以下可选属性。</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>hbase.client.dns.interface</code></p>
</li>
<li>
<p><code>hbase.client.dns.nameserver</code></p>
</li>
</ul>
</div>
<div class="exampleblock">
<div class="title">示例46。启用Kerberos的群集中的Canary</div>
<div class="content">
<div class="paragraph">
<p>本示例显示具有有效值的每个属性。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="xml"><span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>hbase.client.kerberos.principal<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>hbase/_HOST@YOUR-REALM.COM<span class="tag">&lt;/value&gt;</span>
<span class="tag">&lt;/property&gt;</span>
<span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>hbase.client.keytab.file<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>/etc/hbase/conf/keytab.krb5<span class="tag">&lt;/value&gt;</span>
<span class="tag">&lt;/property&gt;</span>
<span class="comment">&lt;!-- optional params --&gt;</span>
property<span class="error">&gt;</span>
  <span class="tag">&lt;name&gt;</span>hbase.client.dns.interface<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>default<span class="tag">&lt;/value&gt;</span>
<span class="tag">&lt;/property&gt;</span>
<span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>hbase.client.dns.nameserver<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>default<span class="tag">&lt;/value&gt;</span>
<span class="tag">&lt;/property&gt;</span></code></pre>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="health.check"><a class="anchor" href="#health.check"></a> 124.2。健康检查</h3>
<div class="paragraph">
<p>您可以将HBase配置为定期运行脚本，如果脚本失败N次（可配置），请退出服务器。有关配置和详细信息，请参见<em>HBASE-7351定期运行状况检查脚本</em> 。</p>
</div>
</div>
<div class="sect2">
<h3 id="_driver"><a class="anchor" href="#_driver"></a> 124.3。司机</h3>
<div class="paragraph">
<p>提供了一些常用的实用程序，例如<code>Driver</code>类，并由<em>bin / hbase</em>命令执行。这些实用程序代表在群集上运行的MapReduce作业。它们以以下方式运行，将<em>UtilityName</em>替换为要运行的实用程序。该命令假定您已设置环境变量<code>HBASE_HOME</code>到服务器上HBase的解压缩目录。</p>
</div>
<div class="listingblock">
<div class="content">
<pre>${HBASE_HOME}/bin/hbase org.apache.hadoop.hbase.mapreduce.UtilityName</pre>
</div>
</div>
<div class="paragraph">
<p>可以使用以下实用程序：</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1"><code>LoadIncrementalHFiles</code></dt>
<dd>
<p>完成批量数据加载。</p>
</dd>
<dt class="hdlist1"><code>CopyTable</code></dt>
<dd>
<p>将表从本地群集导出到对等群集。</p>
</dd>
<dt class="hdlist1"><code>Export</code></dt>
<dd>
<p>将表数据写入HDFS。</p>
</dd>
<dt class="hdlist1"><code>Import</code></dt>
<dd>
<p>导入先前的数据<code>Export</code>操作。</p>
</dd>
<dt class="hdlist1"><code>ImportTsv</code></dt>
<dd>
<p>以TSV格式导入数据。</p>
</dd>
<dt class="hdlist1"><code>RowCounter</code></dt>
<dd>
<p>计算HBase表中的行。</p>
</dd>
<dt class="hdlist1"><code>replication.VerifyReplication</code></dt>
<dd>
<p>比较来自两个不同群集中表的数据。警告：自从更改时间戳以来，它不适用于增量列值的单元格。请注意，此命令与其他命令位于不同的软件包中。</p>
</dd>
</dl>
</div>
<div class="paragraph">
<p>每个命令除外<code>RowCounter</code>接受一个<code>--help</code>参数以打印使用说明。</p>
</div>
</div>
<div class="sect2">
<h3 id="hbck"><a class="anchor" href="#hbck"></a> 124.4。HBase的<code>hbck</code></h3>
<div class="paragraph">
<p>跑步<code>hbck</code>针对您的HBase集群运行<code>$./bin/hbase hbck</code> 。在命令输出的末尾打印<code>OK</code>要么<code>INCONSISTENCY</code> 。如果您的集群报告不一致，则通过<code>-details</code>查看更多发出的细节。如果不一致，请运行<code>hbck</code>几次，因为不一致可能是暂时的（例如，群集正在启动或区域正在分裂）。通过<code>-fix</code>可能会纠正不一致（这是一个实验功能）。</p>
</div>
<div class="paragraph">
<p>有关更多信息，请参见<a href="#hbck.in.depth">hbck In Depth</a> 。</p>
</div>
</div>
<div class="sect2">
<h3 id="hfile_tool2"><a class="anchor" href="#hfile_tool2"></a> 124.5。HFile工具</h3>
<div class="paragraph">
<p>参见<a href="#hfile_tool">[hfile_tool]</a> 。</p>
</div>
</div>
<div class="sect2">
<h3 id="_wal_tools"><a class="anchor" href="#_wal_tools"></a> 124.6。WAL工具</h3>
<div class="sect3">
<h4 id="hlog_tool"><a class="anchor" href="#hlog_tool"></a> 124.6.1。 <code>FSHLog</code>工具</h4>
<div class="paragraph">
<p>主要方法<code>FSHLog</code>提供手动拆分和转储功能。它传递华尔兹或拆分的产品，其<em>recovered.edits</em>的内容。目录。</p>
</div>
<div class="paragraph">
<p>通过执行以下操作，可以获取WAL文件内容的文本转储：</p>
</div>
<div class="listingblock">
<div class="content">
<pre> $ ./bin/hbase org.apache.hadoop.hbase.regionserver.wal.FSHLog --dump hdfs://example.org:8020/hbase/.logs/example.org,60020,1283516293161/10.10.21.10%3A60020.1283973724012</pre>
</div>
</div>
<div class="paragraph">
<p>如果文件有任何问题，返回码将为非零，因此您可以通过重定向来测试文件的完整性<code>STDOUT</code>至<code>/dev/null</code>并测试程序返回。</p>
</div>
<div class="paragraph">
<p>同样，您可以执行以下操作来强制拆分日志文件目录：</p>
</div>
<div class="listingblock">
<div class="content">
<pre> $ ./bin/hbase org.apache.hadoop.hbase.regionserver.wal.FSHLog --split hdfs://example.org:8020/hbase/.logs/example.org,60020,1283516293161/</pre>
</div>
</div>
<div class="sect4">
<h5 id="hlog_tool.prettyprint"><a class="anchor" href="#hlog_tool.prettyprint"></a>沃尔美式打印机</h5>
<div class="paragraph">
<p>WAL Pretty Printer是一种具有可配置选项的工具，用于打印WAL的内容。您可以使用“ wal”命令通过HBase cli调用它。</p>
</div>
<div class="listingblock">
<div class="content">
<pre> $ ./bin/hbase wal hdfs://example.org:8020/hbase/.logs/example.org,60020,1283516293161/10.10.21.10%3A60020.1283973724012</pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-note" title="注意"></i>
</td>
<td class="content">
<div class="title">较旧版本的HBase中的WAL打印</div>
<div class="paragraph">
<p>在2.0版之前，WAL Pretty Printer被称为<code>HLogPrettyPrinter</code> ，以HBase的预写日志的内部名称命名。在那些版本中，您可以使用与上述相同的配置来预加载WAL的内容，但使用“ hlog”命令。</p>
</div>
<div class="listingblock">
<div class="content">
<pre> $ ./bin/hbase hlog hdfs://example.org:8020/hbase/.logs/example.org,60020,1283516293161/10.10.21.10%3A60020.1283973724012</pre>
</div>
</div>
</td>
</tr>
</tbody></table>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="compression.tool"><a class="anchor" href="#compression.tool"></a> 124.7。压缩工具</h3>
<div class="paragraph">
<p>参见<a href="#compression.test">compression.test</a> 。</p>
</div>
</div>
<div class="sect2">
<h3 id="_copytable"><a class="anchor" href="#_copytable"></a> 124.8。复制表</h3>
<div class="paragraph">
<p>CopyTable是一种实用程序，可以将表的部分或全部复制到同一群集或另一个群集中。目标表必须首先存在。用法如下：</p>
</div>
<div class="listingblock">
<div class="content">
<pre>$ ./bin/hbase org.apache.hadoop.hbase.mapreduce.CopyTable --help
/bin/hbase org.apache.hadoop.hbase.mapreduce.CopyTable --help
Usage: CopyTable [general options] [--starttime=X] [--endtime=Y] [--new.name=NEW] [--peer.adr=ADR] &lt;tablename&gt;

Options:
 rs.class     hbase.regionserver.class of the peer cluster,
              specify if different from current cluster
 rs.impl      hbase.regionserver.impl of the peer cluster,
 startrow     the start row
 stoprow      the stop row
 starttime    beginning of the time range (unixtime in millis)
              without endtime means from starttime to forever
 endtime      end of the time range.  Ignored if no starttime specified.
 versions     number of cell versions to copy
 new.name     new table's name
 peer.adr     Address of the peer cluster given in the format
              hbase.zookeeer.quorum:hbase.zookeeper.client.port:zookeeper.znode.parent
 families     comma-separated list of families to copy
              To copy from cf1 to cf2, give sourceCfName:destCfName.
              To keep the same name, just give "cfName"
 all.cells    also copy delete markers and deleted cells

Args:
 tablename    Name of the table to copy

Examples:
 To copy 'TestTable' to a cluster that uses replication for a 1 hour window:
 $ bin/hbase org.apache.hadoop.hbase.mapreduce.CopyTable --starttime=1265875194289 --endtime=1265878794289 --peer.adr=server1,server2,server3:2181:/hbase --families=myOldCf:myNewCf,cf2,cf3 TestTable

For performance consider the following general options:
  It is recommended that you set the following to &gt;=100. A higher value uses more memory but
  decreases the round trip time to the server and may increase performance.
    -Dhbase.client.scanner.caching=100
  The following should always be set to false, to prevent writing data twice, which may produce
  inaccurate results.
    -Dmapred.map.tasks.speculative.execution=false</pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-note" title="注意"></i>
</td>
<td class="content">
<div class="title">扫描仪缓存</div>
<div class="paragraph">
<p>通过以下方式配置输入扫描的缓存<code>hbase.client.scanner.caching</code>在作业配置中。</p>
</div>
</td>
</tr>
</tbody></table>
</div>
<div class="admonitionblock note">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-note" title="注意"></i>
</td>
<td class="content">
<div class="title">版本号</div>
<div class="paragraph">
<p>默认情况下，CopyTable实用程序仅复制最新版本的行单元格，除非<code>--versions=n</code>在命令中明确指定。</p>
</div>
</td>
</tr>
</tbody></table>
</div>
<div class="paragraph">
<p>有关更多信息，请参见Jonathan Hsieh的<a href="http://www.cloudera.com/blog/2012/06/online-hbase-backups-with-copytable-2/">CopyTable在线HBase备份</a>博客文章。 <code>CopyTable</code> 。</p>
</div>
</div>
<div class="sect2">
<h3 id="hashtable.synctable"><a class="anchor" href="#hashtable.synctable"></a> 124.9。哈希表/同步表</h3>
<div class="paragraph">
<p>HashTable / SyncTable是用于同步表数据的两步工具，其中的每个步骤都作为MapReduce作业实现。与CopyTable相似，它可用于在相同或远程群集下同步部分或全部表数据。但是，它以比CopyTable更有效的方式执行同步。HashTable（第一步）不是在指定的行键/时间段范围内复制所有单元格，而是为源表上的一批单元格创建哈希索引，并将其作为结果输出。在下一阶段，SyncTable扫描源表，现在计算表单元的哈希索引，将这些哈希与HashTable的输出进行比较，然后仅扫描（并比较）单元以查找散列的哈希，仅更新不匹配的单元。这样可以减少网络流量/数据传输，在远程集群上同步大型表时可能会产生影响。</p>
</div>
<div class="sect3">
<h4 id="_step_1_hashtable"><a class="anchor" href="#_step_1_hashtable"></a> 124.9.1。步骤1，HashTable</h4>
<div class="paragraph">
<p>首先，在源表集群上运行HashTable（这是将其状态复制到其对应表的表）。</p>
</div>
<div class="paragraph">
<p>用法：</p>
</div>
<div class="listingblock">
<div class="content">
<pre>$ ./bin/hbase org.apache.hadoop.hbase.mapreduce.HashTable --help
Usage: HashTable [options] &lt;tablename&gt; &lt;outputpath&gt;

Options:
 batchsize     the target amount of bytes to hash in each batch
               rows are added to the batch until this size is reached
               (defaults to 8000 bytes)
 numhashfiles  the number of hash files to create
               if set to fewer than number of regions then
               the job will create this number of reducers
               (defaults to 1/100 of regions -- at least 1)
 startrow      the start row
 stoprow       the stop row
 starttime     beginning of the time range (unixtime in millis)
               without endtime means from starttime to forever
 endtime       end of the time range.  Ignored if no starttime specified.
 scanbatch     scanner batch size to support intra row scans
 versions      number of cell versions to include
 families      comma-separated list of families to include

Args:
 tablename     Name of the table to hash
 outputpath    Filesystem path to put the output data

Examples:
 To hash 'TestTable' in 32kB batches for a 1 hour window into 50 files:
 $ bin/hbase org.apache.hadoop.hbase.mapreduce.HashTable --batchsize=32000 --numhashfiles=50 --starttime=1265875194289 --endtime=1265878794289 --families=cf2,cf3 TestTable /hashes/testTable</pre>
</div>
</div>
<div class="paragraph">
<p><strong>batchsize</strong>属性定义在给定区域中将在一个哈希值中哈希多少单元数据。正确调整其大小直接影响同步效率，因为它可能导致SyncTable的映射器任务执行的扫描次数减少（该过程的下一步）。经验法则是，不同步的单元数越小（找到差异的可能性越低），可以确定更大的批处理大小值。</p>
</div>
</div>
<div class="sect3">
<h4 id="_step_2_synctable"><a class="anchor" href="#_step_2_synctable"></a> 124.9.2。步骤2，SyncTable</h4>
<div class="paragraph">
<p>一旦HashTable在源群集上完成，就可以在目标群集上运行SyncTable。就像复制和其他同步作业一样，它要求源群集上的所有RegionServers / DataNode都可由目标群集上的NodeManager（可在其中运行SyncTable作业任务）访问。</p>
</div>
<div class="paragraph">
<p>用法：</p>
</div>
<div class="listingblock">
<div class="content">
<pre>$ ./bin/hbase org.apache.hadoop.hbase.mapreduce.SyncTable --help
Usage: SyncTable [options] &lt;sourcehashdir&gt; &lt;sourcetable&gt; &lt;targettable&gt;

Options:
 sourcezkcluster  ZK cluster key of the source table
                  (defaults to cluster in classpath's config)
 targetzkcluster  ZK cluster key of the target table
                  (defaults to cluster in classpath's config)
 dryrun           if true, output counters but no writes
                  (defaults to false)
 doDeletes        if false, does not perform deletes
                  (defaults to true)
 doPuts           if false, does not perform puts
                  (defaults to true)

Args:
 sourcehashdir    path to HashTable output dir for source table
                  (see org.apache.hadoop.hbase.mapreduce.HashTable)
 sourcetable      Name of the source table to sync from
 targettable      Name of the target table to sync to

Examples:
 For a dry run SyncTable of tableA from a remote source cluster
 to a local target cluster:
 $ bin/hbase org.apache.hadoop.hbase.mapreduce.SyncTable --dryrun=true --sourcezkcluster=zk1.example.com,zk2.example.com,zk3.example.com:2181:/hbase hdfs://nn:9000/hashes/tableA tableA tableA</pre>
</div>
</div>
<div class="paragraph">
<p>当需要只读差异报告时， <strong>dryrun</strong>选项很有用，因为它将仅产生COUNTERS个指示差异的内容，但不会执行任何实际更改。它可以用作VerifyReplication工具的替代方法。</p>
</div>
<div class="paragraph">
<p>默认情况下，SyncTable将使目标表成为源表的精确副本（至少对于指定的开始行/停止行或/和开始时间/结束时间）。</p>
</div>
<div class="paragraph">
<p>将doDeletes设置为false会修改默认行为，以不删除源中缺少的目标单元格。同样，将doPuts设置为false会修改默认行为，以不在目标上添加缺少的单元格。将doDeletes和doPuts都设置为false与将dryrun设置为true具有相同的效果。</p>
</div>
<div class="admonitionblock note">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-note" title="注意"></i>
</td>
<td class="content">
<div class="title">有关doDeletes / doPuts的附加信息</div>
<div class="paragraph">
<p>HDO <a href="https://jira.apache.org/jira/browse/HBASE-20305">-20305</a>仅添加了“ doDeletes / doPuts”，因此可能并非在所有发行版本中都可用。对于主要的1.x版本，最低次要版本包括<strong>1.4.10</strong> 。对于主要的2.x版本，最低次要版本包括<strong>2.1.5</strong> 。</p>
</div>
</td>
</tr>
</tbody></table>
</div>
<div class="admonitionblock note">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-note" title="注意"></i>
</td>
<td class="content">
<div class="title">在双向复制方案中将doDeletes设置为false</div>
<div class="paragraph">
<p>在双向复制或源群集和目标群集都可以提取数据的其他方案上，建议始终将doDeletes选项设置为false，因为在SyncTable目标群集上插入但尚未复制到源的任何其他单元都将被删除，并且可能永久丢失。</p>
</div>
</td>
</tr>
</tbody></table>
</div>
<div class="admonitionblock note">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-note" title="注意"></i>
</td>
<td class="content">
<div class="title">将sourcezkcluster设置为实际的源群集ZK仲裁</div>
<div class="paragraph">
<p>尽管不是必需的，但如果未设置sourcezkcluster，则SyncTable将连接到源和目标的本地HBase群集，这不会产生任何有意义的结果。</p>
</div>
</td>
</tr>
</tbody></table>
</div>
<div class="admonitionblock note">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-note" title="注意"></i>
</td>
<td class="content">
<div class="title">不同Kerberos领域上的远程群集</div>
<div class="paragraph">
<p>当前，无法为不同Kerberos领域中的远程群集运行SyncTable。<a href="https://jira.apache.org/jira/browse/HBASE-20586">HBASE-20586</a>上正在解决此问题</p>
</div>
</td>
</tr>
</tbody></table>
</div>
</div>
</div>
<div class="sect2">
<h3 id="export"><a class="anchor" href="#export"></a> 124.10。出口</h3>
<div class="paragraph">
<p>导出是一种实用程序，它将表的内容转储到序列文件中的HDFS中。通过以下方式调用：</p>
</div>
<div class="listingblock">
<div class="content">
<pre>$ bin/hbase org.apache.hadoop.hbase.mapreduce.Export &lt;tablename&gt; &lt;outputdir&gt; [&lt;versions&gt; [&lt;starttime&gt; [&lt;endtime&gt;]]]</pre>
</div>
</div>
<div class="paragraph">
<p>默认情况下， <code>Export</code>该工具仅导出给定单元格的最新版本，而不管存储的版本数如何。要导出多个版本，请替换<strong><em><versions></versions></em></strong>带有所需数量的版本。</p>
</div>
<div class="paragraph">
<p>注意：输入扫描的缓存是通过配置的<code>hbase.client.scanner.caching</code>在作业配置中。</p>
</div>
</div>
<div class="sect2">
<h3 id="_import"><a class="anchor" href="#_import"></a> 124.11。进口</h3>
<div class="paragraph">
<p>导入是一个实用程序，它将加载已导出回HBase的数据。通过以下方式调用：</p>
</div>
<div class="listingblock">
<div class="content">
<pre>$ bin/hbase org.apache.hadoop.hbase.mapreduce.Import &lt;tablename&gt; &lt;inputdir&gt;</pre>
</div>
</div>
<div class="paragraph">
<p>要在0.96或更高版本的群集中导入0.94导出的文件，需要在运行以下导入命令时设置系统属性“ hbase.import.version”：</p>
</div>
<div class="listingblock">
<div class="content">
<pre>$ bin/hbase -Dhbase.import.version=0.94 org.apache.hadoop.hbase.mapreduce.Import &lt;tablename&gt; &lt;inputdir&gt;</pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_importtsv"><a class="anchor" href="#_importtsv"></a> 124.12。导入电视</h3>
<div class="paragraph">
<p>ImportTsv是一个实用程序，可以将TSV格式的数据加载到HBase中。它有两种不同的用法：通过Puts将HDFS中的TSV格式的数据通过Puts加载到HBase中，以及准备要通过<code>completebulkload</code> 。</p>
</div>
<div class="paragraph">
<p>通过看跌期权加载数据（即非批量加载）：</p>
</div>
<div class="listingblock">
<div class="content">
<pre>$ bin/hbase org.apache.hadoop.hbase.mapreduce.ImportTsv -Dimporttsv.columns=a,b,c &lt;tablename&gt; &lt;hdfs-inputdir&gt;</pre>
</div>
</div>
<div class="paragraph">
<p>要生成用于批量加载的StoreFiles：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bourne">$ bin/hbase org.apache.hadoop.hbase.mapreduce.ImportTsv -Dimporttsv.columns=a,b,c -Dimporttsv.bulk.output=hdfs://storefile-outputdir &lt;tablename&gt; &lt;hdfs-data-inputdir&gt;</code></pre>
</div>
</div>
<div class="paragraph">
<p>这些生成的StoreFiles可以通过<a href="#completebulkload">completebulkload</a>加载到HBase中。</p>
</div>
<div class="sect3">
<h4 id="importtsv.options"><a class="anchor" href="#importtsv.options"></a> 124.12.1。ImportTsv选项</h4>
<div class="paragraph">
<p>跑步<code>ImportTsv</code>不带参数的情况下，会打印出简要的用法信息：</p>
</div>
<div class="listingblock">
<div class="content">
<pre>Usage: importtsv -Dimporttsv.columns=a,b,c &lt;tablename&gt; &lt;inputdir&gt;

Imports the given input directory of TSV data into the specified table.

The column names of the TSV data must be specified using the -Dimporttsv.columns
option. This option takes the form of comma-separated column names, where each
column name is either a simple column family, or a columnfamily:qualifier. The special
column name HBASE_ROW_KEY is used to designate that this column should be used
as the row key for each imported record. You must specify exactly one column
to be the row key, and you must specify a column name for every column that exists in the
input data.

By default importtsv will load data directly into HBase. To instead generate
HFiles of data to prepare for a bulk data load, pass the option:
  -Dimporttsv.bulk.output=/path/for/output
  Note: the target table will be created with default column family descriptors if it does not already exist.

Other options that may be specified with -D include:
  -Dimporttsv.skip.bad.lines=false - fail if encountering an invalid line
  '-Dimporttsv.separator=|' - eg separate on pipes instead of tabs
  -Dimporttsv.timestamp=currentTimeAsLong - use the specified timestamp for the import
  -Dimporttsv.mapper.class=my.Mapper - A user-defined Mapper to use instead of org.apache.hadoop.hbase.mapreduce.TsvImporterMapper</pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="importtsv.example"><a class="anchor" href="#importtsv.example"></a> 124.12.2。ImportTsv示例</h4>
<div class="paragraph">
<p>例如，假设我们正在将数据加载到名为“ datatsv”的表中，该表的列族名为“ d”，具有两列“ c1”和“ c2”。</p>
</div>
<div class="paragraph">
<p>假设存在一个输入文件，如下所示：</p>
</div>
<div class="listingblock">
<div class="content">
<pre>row1	c1	c2
row2	c1	c2
row3	c1	c2
row4	c1	c2
row5	c1	c2
row6	c1	c2
row7	c1	c2
row8	c1	c2
row9	c1	c2
row10	c1	c2</pre>
</div>
</div>
<div class="paragraph">
<p>为了使ImportTsv使用此输入文件，命令行需要如下所示：</p>
</div>
<div class="listingblock">
<div class="content">
<pre> HADOOP_CLASSPATH=`${HBASE_HOME}/bin/hbase classpath` ${HADOOP_HOME}/bin/hadoop jar ${HBASE_HOME}/hbase-server-VERSION.jar importtsv -Dimporttsv.columns=HBASE_ROW_KEY,d:c1,d:c2 -Dimporttsv.bulk.output=hdfs://storefileoutput datatsv hdfs://inputfile</pre>
</div>
</div>
<div class="paragraph">
<p>...，在此示例中，第一列是行键，这就是使用HBASE_ROW_KEY的原因。文件中的第二和第三列将分别导入为“ d：c1”和“ d：c2”。</p>
</div>
</div>
<div class="sect3">
<h4 id="importtsv.warning"><a class="anchor" href="#importtsv.warning"></a> 124.12.3。ImportTsv警告</h4>
<div class="paragraph">
<p>如果您准备了很多数据以进行批量加载，请确保已正确拆分了目标HBase表。</p>
</div>
</div>
<div class="sect3">
<h4 id="importtsv.also"><a class="anchor" href="#importtsv.also"></a> 124.12.4。也可以看看</h4>
<div class="paragraph">
<p>有关将HFile批量加载到HBase中的更多信息，请参见<a href="#arch.bulk.load">arch.bulk.load</a></p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_completebulkload"><a class="anchor" href="#_completebulkload"></a> 124.13。CompleteBulkLoad</h3>
<div class="paragraph">
<p>的<code>completebulkload</code>实用程序会将生成的StoreFiles移动到HBase表中。该实用程序通常与<a href="#importtsv">importtsv的</a>输出结合使用。</p>
</div>
<div class="paragraph">
<p>有两种方法可以使用显式类名和通过驱动程序来调用此实用程序：</p>
</div>
<div class="listingblock">
<div class="title">明确的类名</div>
<div class="content">
<pre>$ bin/hbase org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles &lt;hdfs://storefileoutput&gt; &lt;tablename&gt;</pre>
</div>
</div>
<div class="listingblock">
<div class="title">司机</div>
<div class="content">
<pre>HADOOP_CLASSPATH=`${HBASE_HOME}/bin/hbase classpath` ${HADOOP_HOME}/bin/hadoop jar ${HBASE_HOME}/hbase-server-VERSION.jar completebulkload &lt;hdfs://storefileoutput&gt; &lt;tablename&gt;</pre>
</div>
</div>
<div class="sect3">
<h4 id="completebulkload.warning"><a class="anchor" href="#completebulkload.warning"></a> 124.13.1。CompleteBulkLoad警告</h4>
<div class="paragraph">
<p>通过MapReduce生成的数据通常是使用与正在运行的HBase进程不兼容的文件权限创建的。假设您在启用了权限的情况下运行HDFS，则在运行CompleteBulkLoad之前需要更新这些权限。</p>
</div>
<div class="paragraph">
<p>有关将HFile批量加载到HBase中的更多信息，请参见<a href="#arch.bulk.load">arch.bulk.load</a> 。</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_walplayer"><a class="anchor" href="#_walplayer"></a> 124.14。WALPlayer</h3>
<div class="paragraph">
<p>WALPlayer是将WAL文件重播到HBase中的实用程序。</p>
</div>
<div class="paragraph">
<p>可以为一组表或所有表重放WAL，并且可以提供一个时间范围（以毫秒为单位）。WAL被过滤到这组表。可以选择将输出映射到另一组表。</p>
</div>
<div class="paragraph">
<p>WALPlayer还可以生成HFile，以供以后批量导入，在这种情况下，只能指定一个表，而不能指定任何映射。</p>
</div>
<div class="paragraph">
<p>通过以下方式调用：</p>
</div>
<div class="listingblock">
<div class="content">
<pre>$ bin/hbase org.apache.hadoop.hbase.mapreduce.WALPlayer [options] &lt;wal inputdir&gt; &lt;tables&gt; [&lt;tableMappings&gt;]&gt;</pre>
</div>
</div>
<div class="paragraph">
<p>例如：</p>
</div>
<div class="listingblock">
<div class="content">
<pre>$ bin/hbase org.apache.hadoop.hbase.mapreduce.WALPlayer /backuplogdir oldTable1,oldTable2 newTable1,newTable2</pre>
</div>
</div>
<div class="paragraph">
<p>默认情况下，WALPlayer作为mapreduce作业运行。要不在集群上将WALPlayer作为mapreduce作业运行，请通过添加标志来强制其在本地进程中全部运行<code>-Dmapreduce.jobtracker.address=local</code>在命令行上。</p>
</div>
</div>
<div class="sect2">
<h3 id="rowcounter"><a class="anchor" href="#rowcounter"></a> 124.15。RowCounter和CellCounter</h3>
<div class="paragraph">
<p><a href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/mapreduce/RowCounter.html">RowCounter</a>是一个mapreduce作业，用于对表的所有行进行计数。这是一个很好的实用程序，可以用作完整性检查，以确保在担心元数据不一致时，HBase可以读取表的所有块。它会在一个进程中全部运行mapreduce，但是如果您有一个MapReduce集群可供利用，它将运行得更快。</p>
</div>
<div class="listingblock">
<div class="content">
<pre>$ bin/hbase org.apache.hadoop.hbase.mapreduce.RowCounter &lt;tablename&gt; [&lt;column1&gt; &lt;column2&gt;...]</pre>
</div>
</div>
<div class="paragraph">
<p>RowCounter每个单元仅计数一个版本。</p>
</div>
<div class="paragraph">
<p>注意：输入扫描的缓存是通过配置的<code>hbase.client.scanner.caching</code>在作业配置中。</p>
</div>
<div class="paragraph">
<p>HBase提供了另一个名为<a href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/mapreduce/CellCounter.html">CellCounter的</a>诊断mapreduce作业。与RowCounter一样，它收集有关表的更多细粒度统计信息。RowCounter收集的统计数据更细粒度，包括：</p>
</div>
<div class="ulist">
<ul>
<li>
<p>表中的总行数。</p>
</li>
<li>
<p>所有行中CF的总数。</p>
</li>
<li>
<p>所有行的总限定词。</p>
</li>
<li>
<p>每个CF的总数。</p>
</li>
<li>
<p>每个预选赛的总数。</p>
</li>
<li>
<p>每个限定符的版本总数。</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>该程序允许您限制运行范围。提供行正则表达式或前缀以限制要分析的行。使用<code>hbase.mapreduce.scan.column.family</code>指定扫描单个列族。</p>
</div>
<div class="listingblock">
<div class="content">
<pre>$ bin/hbase org.apache.hadoop.hbase.mapreduce.CellCounter &lt;tablename&gt; &lt;outputDir&gt; [regex or prefix]</pre>
</div>
</div>
<div class="paragraph">
<p>注意：就像RowCounter一样，输入Scan的缓存是通过配置<code>hbase.client.scanner.caching</code>在作业配置中。</p>
</div>
</div>
<div class="sect2">
<h3 id="_mlockall"><a class="anchor" href="#_mlockall"></a> 124.16。麦克洛克</h3>
<div class="paragraph">
<p>可以选择将服务器固定在物理内存中，通过使服务器在启动时调用<a href="http://linux.die.net/man/2/mlockall">mlockall</a> ，从而使它们不太可能在超额订购的环境中换出。请参见<a href="https://issues.apache.org/jira/browse/HBASE-4391">HBASE-4391添加以root身份启动RS并调用mlockall的功能，</a>以了解如何构建可选库并使它在启动时运行。</p>
</div>
</div>
<div class="sect2">
<h3 id="compaction.tool"><a class="anchor" href="#compaction.tool"></a> 124.17。离线压缩工具</h3>
<div class="paragraph">
<p>请参阅<a href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/regionserver/CompactionTool.html">压缩工具</a>的用法。像./bin/hbase org.apache.hadoop.hbase.regionserver这样运行它。压实工具</p>
</div>
</div>
<div class="sect2">
<h3 id="__code_hbase_clean_code"><a class="anchor" href="#__code_hbase_clean_code"></a> 124.18。<code>hbase clean</code></h3>
<div class="paragraph">
<p>的<code>hbase clean</code>命令从ZooKeeper和/或HDFS中清除HBase数据。适合用于测试。在没有使用说明选项的情况下运行它。的<code>hbase clean</code> HBase 0.98中引入了命令。</p>
</div>
<div class="listingblock">
<div class="content">
<pre>$ bin/hbase clean
Usage: hbase clean (--cleanZk|--cleanHdfs|--cleanAll)
Options:
        --cleanZk   cleans hbase related data from zookeeper.
        --cleanHdfs cleans hbase related data from hdfs.
        --cleanAll  cleans hbase related data from both zookeeper and hdfs.</pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="__code_hbase_pe_code"><a class="anchor" href="#__code_hbase_pe_code"></a> 124.19。<code>hbase pe</code></h3>
<div class="paragraph">
<p>的<code>hbase pe</code>命令运行PerformanceEvaluation工具，该工具用于测试。</p>
</div>
<div class="paragraph">
<p>PerformanceEvaluation工具接受许多不同的选项和命令。有关用法说明，请运行不带任何选项的命令。</p>
</div>
<div class="paragraph">
<p>PerformanceEvaluation工具在最新的HBase版本中已获得许多更新，包括对名称空间的支持，对标签的支持，单元级别的ACL和可见性标签，对RPC调用的多get支持，增加的采样大小，在测试过程中可以随机休眠的选项以及在测试开始之前“预热”群集。</p>
</div>
</div>
<div class="sect2">
<h3 id="__code_hbase_ltt_code"><a class="anchor" href="#__code_hbase_ltt_code"></a> 124.20。<code>hbase ltt</code></h3>
<div class="paragraph">
<p>的<code>hbase ltt</code>命令运行用于测试的LoadTestTool实用程序。</p>
</div>
<div class="paragraph">
<p>您必须指定以下一项<code>-write</code> ， <code>-update</code> ， 要么<code>-read</code>作为第一个选择。有关一般用法说明，请通过<code>-h</code>选项。</p>
</div>
<div class="paragraph">
<p>LoadTestTool在最近的HBase版本中已获得许多更新，包括对名称空间的支持，对标签的支持，单元级别的ACLS和可见性标签，测试与安全性相关的功能，指定每个服务器的区域数量的能力，对多获取RPC的测试呼叫以及与复制有关的测试。</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="ops.regionmgt"><a class="anchor" href="#ops.regionmgt"></a> 125。区域管理</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="ops.regionmgt.majorcompact"><a class="anchor" href="#ops.regionmgt.majorcompact"></a> 125.1。大压实</h3>
<div class="paragraph">
<p>可以通过HBase shell或<a href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/client/Admin.html#majorCompact%28java.lang.String%29">Admin.majorCompact</a>请求进行大型压缩。</p>
</div>
<div class="paragraph">
<p>注意：大型压缩不进行区域合并。有关<a href="#compaction">压缩</a>的更多信息，请参见压缩。</p>
</div>
</div>
<div class="sect2">
<h3 id="ops.regionmgt.merge"><a class="anchor" href="#ops.regionmgt.merge"></a> 125.2。合并</h3>
<div class="paragraph">
<p>合并是一种实用程序，可以合并同一表中的相邻区域（请参阅org.apache.hadoop.hbase.util。合并）。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bourne">$ bin/hbase org.apache.hadoop.hbase.util.Merge &lt;tablename&gt; &lt;region1&gt; &lt;region2&gt;</code></pre>
</div>
</div>
<div class="paragraph">
<p>如果您觉得您有太多的地区并想要合并它们，Merge是您需要的实用程序。群集关闭时必须运行合并。有关用法示例，请参见《 <a href="http://ofps.oreilly.com/titles/9781449396107/performance.html">O'Reilly HBase手册》</a> 。</p>
</div>
<div class="paragraph">
<p>您将需要向此应用程序传递3个参数。第一个是表名。第二个是要合并的第一个区域的完全限定名称，例如“ table_name，\ x0A，1342956111995.7cef47f192318ba7ccc75b1bbf27a82b”。第三个是要合并的第二个区域的完全限定名称。</p>
</div>
<div class="paragraph">
<p>此外， <a href="https://issues.apache.org/jira/browse/HBASE-1621">HBASE-1621</a>附带了一个Ruby脚本，用于区域合并。</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="node.management"><a class="anchor" href="#node.management"></a> 126。节点管理</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="decommission"><a class="anchor" href="#decommission"></a> 126.1。节点停用</h3>
<div class="paragraph">
<p>您可以通过在特定节点上的HBase目录中运行以下脚本来停止单个RegionServer：</p>
</div>
<div class="listingblock">
<div class="content">
<pre>$ ./bin/hbase-daemon.sh stop regionserver</pre>
</div>
</div>
<div class="paragraph">
<p>RegionServer将首先关闭所有区域，然后关闭自身。关闭时，ZooKeeper中RegionServer的临时节点将过期。主服务器会注意到RegionServer消失了，并将其视为“崩溃的”服务器；它将重新分配RegionServer承载的节点。</p>
</div>
<div class="admonitionblock note">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-note" title="注意"></i>
</td>
<td class="content">
<div class="title">在停用节点之前禁用负载均衡器</div>
<div class="paragraph">
<p>如果负载均衡器在节点关闭时运行，则负载均衡器与主服务器刚刚停用的RegionServer的恢复之间可能存在争用。通过首先禁用平衡器来避免任何问题。参见下面的<a href="#lb">磅</a> 。</p>
</div>
</td>
</tr>
</tbody></table>
</div>
<div class="admonitionblock note">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-note" title="注意"></i>
</td>
<td class="content">
<div class="title">杀死节点工具</div>
<div class="paragraph">
<p>在HBase的-2.0，在bin目录中，我们添加了一个名为<em>considerAsDead.sh</em>脚本，可以用来杀死一个RegionServer的。在Zookeeper超时到期之前，专用的监视工具可以检测到硬件问题。 <em>considerAsDead.sh</em>是一个简单的函数来标记RegionServer的死。它将删除服务器的所有znode，开始恢复过程。将脚本插入监视/故障检测工具中，以启动更快的故障转移。请谨慎使用此破坏性工具。如果需要在hbase-2.0之前的hbase版本中使用脚本，请复制该脚本。</p>
</div>
</td>
</tr>
</tbody></table>
</div>
<div class="paragraph">
<p>RegionServer的上述障碍的一个缺点是，区域可能会长时间处于脱机状态。区域按顺序关闭。如果服务器上有许多区域，则第一个要关闭的区域可能要等到所有区域都关闭并且在主服务器通知RegionServer的znode消失后才能恢复联机。在Apache HBase 0.90.2中，我们添加了使节点逐渐减轻负载然后关闭自身的功能。Apache HBase 0.90.2添加了<em>graceful_stop.sh</em>脚本。这是它的用法：</p>
</div>
<div class="listingblock">
<div class="content">
<pre>$ ./bin/graceful_stop.sh
Usage: graceful_stop.sh [--config &amp;conf-dir&gt;] [--restart] [--reload] [--thrift] [--rest] &amp;hostname&gt;
 thrift      If we should stop/start thrift before/after the hbase stop/start
 rest        If we should stop/start rest before/after the hbase stop/start
 restart     If we should restart after graceful stop
 reload      Move offloaded regions back on to the stopped server
 debug       Move offloaded regions back on to the stopped server
 hostname    Hostname of server we are to stop</pre>
</div>
</div>
<div class="paragraph">
<p>要停用已加载的RegionServer，请运行以下命令：$ ./bin/graceful_stop.sh HOSTNAME其中<code>HOSTNAME</code>是承载要停用的RegionServer的主机。</p>
</div>
<div class="admonitionblock note">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-note" title="注意"></i>
</td>
<td class="content">
<div class="title">上<code>HOSTNAME</code></div>
<div class="paragraph">
<p>的<code>HOSTNAME</code>传递给<em>graceful_stop.sh</em>的主机名必须与hbase用来标识RegionServer的主机名匹配。检查主UI中的RegionServers列表，以了解HBase如何引用服务器。它通常是主机名，但也可以是FQDN。无论HBase使用什么，这都应该传递<em>graceful_stop.sh</em>停用脚本。如果您通过IP，则该脚本还不够智能，无法为其创建主机名（或FQDN），因此在检查服务器当前是否正在运行时它将失败。区域的正常卸载将无法进行。</p>
</div>
</td>
</tr>
</tbody></table>
</div>
<div class="paragraph">
<p><em>graceful_stop.sh</em>脚本将一次将区域移出已停用的RegionServer，以最大程度地减少区域搅动。在移动下一个区域之前，它将验证部署在新位置的区域，依此类推，直到停用的服务器承载零个区域。此时， <em>graceful_stop.sh</em>告诉RegionServer <code>stop</code> 。此时，主服务器将通知RegionServer消失，但是所有区域都将被重新部署，并且由于RegionServer干净地关闭，因此不会拆分WAL日志。</p>
</div>
<div class="admonitionblock note">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-note" title="注意"></i>
</td>
<td class="content">
<div class="title">负载均衡器</div>
<div class="paragraph">
<p>假定区域负载均衡器在<code>graceful_stop</code>脚本运行（否则平衡器和停用脚本最终将为区域部署而战）。使用外壳禁用平衡器：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">hbase(main):<span class="octal">001</span>:<span class="integer">0</span>&gt; balance_switch <span class="predefined-constant">false</span>
<span class="predefined-constant">true</span>
<span class="integer">0</span> row(s) in <span class="float">0.3590</span> seconds</code></pre>
</div>
</div>
<div class="paragraph">
<p>这将关闭平衡器。要重新启用，请执行以下操作：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">hbase(main):<span class="octal">001</span>:<span class="integer">0</span>&gt; balance_switch <span class="predefined-constant">true</span>
<span class="predefined-constant">false</span>
<span class="integer">0</span> row(s) in <span class="float">0.3590</span> seconds</code></pre>
</div>
</div>
<div class="paragraph">
<p>的<code>graceful_stop</code>将检查平衡器，如果启用了平衡器，将在工作之前将其关闭。如果由于错误而过早退出，则不会重置平衡器。因此，最好除了管理平衡器<code>graceful_stop</code> w / graceful_stop完成后重新启用它。</p>
</div>
</td>
</tr>
</tbody></table>
</div>
<div class="sect3">
<h4 id="draining.servers"><a class="anchor" href="#draining.servers"></a> 126.1.1。同时停用多个Regions服务器</h4>
<div class="paragraph">
<p>如果您有大型群集，则可能希望通过同时并发停止多个RegionServer来一次停用一台以上的计算机。若要同时耗尽多个Regionserver，可以将RegionServer置于“耗尽”状态。通过在ZooKeeper中的<em>hbase_root /</em> draining znode下创建一个条目，将RegionServer标记为排水节点来完成此操作。此znode具有格式<code>name,port,startcode</code>就像<em>hbase_root / rs</em> znode下的regionserver条目一样。</p>
</div>
<div class="paragraph">
<p>如果没有此功能，则停用多个节点可能不是最佳的，因为从一个区域服务器排放的区域可能会移动到也正在排放的其他区域服务器。将RegionServers标记为耗尽状态可以防止这种情况的发生。有关更多详细信息，请参<a href="http://inchoate-clatter.blogspot.com/2012/03/hbase-ops-automation.html">见此博客文章</a> 。</p>
</div>
</div>
<div class="sect3">
<h4 id="bad.disk"><a class="anchor" href="#bad.disk"></a> 126.1.2。磁盘损坏或故障</h4>
<div class="paragraph">
<p>如果在磁盘无格式的情况下，每台计算机上有相当数量的磁盘，最好设置<a href="#dfs.datanode.failed.volumes.tolerated">dfs.datanode.failed.volumes.tolered</a> 。但是通常磁盘会执行“ John Wayne”操作（即花一些时间解决<em>dmesg中</em>喷出的错误），或者由于某种原因，其运行速度比其同伴慢得多。在这种情况下，您要停用磁盘。您有两个选择。您可以<a href="http://wiki.apache.org/hadoop/FAQ#I_want_to_make_a_large_cluster_smaller_by_taking_out_a_bunch_of_nodes_simultaneously._How_can_this_be_done.3F">停用</a>数据节点，也可以减少破坏性，因为只有坏磁盘数据才能被复制，可以停止数据节点，卸载坏卷（在数据节点使用时无法卸载卷），然后重新启动数据节点（假设您已将dfs.datanode.failed.volumes.tolerated设置为> 0）。区域服务器在重新校准从何处获取数据时会在其日志中引发一些错误-它也可能会滚动其WAL日志-但通常，但对于某些延迟尖峰，它应继续进行调整。</p>
</div>
<div class="admonitionblock note">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-note" title="注意"></i>
</td>
<td class="content">
<div class="title">短路读</div>
<div class="paragraph">
<p>如果要进行短路读取，则必须在停止数据节点之前将区域移出区域服务器。当进行短路读取时，尽管通过chmod进行了修改，因此regionserver无法访问，因为它已经打开了文件，即使datanode处于关闭状态，它也能够继续从坏磁盘读取文件块。重新启动数据节点后，将区域移回。</p>
</div>
</td>
</tr>
</tbody></table>
</div>
</div>
</div>
<div class="sect2">
<h3 id="rolling"><a class="anchor" href="#rolling"></a> 126.2。滚动重启</h3>
<div class="paragraph">
<p>某些群集配置更改要求重新启动整个群集或RegionServer，以获取更改。此外，还支持滚动重启以升级到次要版本或维护版本，并尽可能升级到主要版本。请参阅要升级到的发行版本的发行说明，以了解执行滚动升级功能的限制。</p>
</div>
<div class="paragraph">
<p>有多种方法可以重新启动群集节点，具体取决于您的情况。这些方法将在下面详细介绍。</p>
</div>
<div class="sect3">
<h4 id="_using_the_code_rolling_restart_sh_code_script"><a class="anchor" href="#_using_the_code_rolling_restart_sh_code_script"></a> 126.2.1。使用<code>rolling-restart.sh</code>脚本</h4>
<div class="paragraph">
<p>HBase附带了脚本<em>bin / rolling-restart.sh</em> ，该脚本使您可以在整个集群（仅限主服务器或仅RegionServer）上执行滚动重启。该脚本是作为您自己的脚本的模板提供的，未经明确测试。它要求配置无密码的SSH登录，并假定您已使用tarball进行部署。该脚本要求您在运行之前设置一些环境变量。检查脚本并对其进行修改以适合您的需求。</p>
</div>
<div class="exampleblock">
<div class="title">例子47. <em>rolling-restart.sh</em>常规用法</div>
<div class="content">
<div class="listingblock">
<div class="content">
<pre>$ ./bin/rolling-restart.sh --help
Usage: rolling-restart.sh [--config &lt;hbase-confdir&gt;] [--rs-only] [--master-only] [--graceful] [--maxthreads xx]</pre>
</div>
</div>
</div>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">仅在RegionServers上滚动重启</dt>
<dd>
<p>要仅在RegionServers上执行滚动重启，请使用<code>--rs-only</code>选项。如果需要重新引导单个RegionServer或进行仅影响RegionServer而不影响其他HBase进程的配置更改，则可能有必要。</p>
</dd>
<dt class="hdlist1">仅在主机上滚动重启</dt>
<dd>
<p>要在活动主Master和备份Master上执行滚动重启，请使用<code>--master-only</code>选项。如果知道配置更改仅影响主服务器而不影响RegionServer，或者需要重新启动运行活动主服务器的服务器，则可以使用此功能。</p>
</dd>
<dt class="hdlist1">优雅重启</dt>
<dd>
<p>如果您指定<code>--graceful</code>选项，使用<em>bin / graceful_stop.sh</em>脚本重新启动RegionServer，该脚本会将区域移出RegionServer，然后再重新启动。这样比较安全，但是会延迟重新启动。</p>
</dd>
<dt class="hdlist1">限制线程数</dt>
<dd>
<p>要将滚动重启限制为仅使用特定数量的线程，请使用<code>--maxthreads</code>选项。</p>
</dd>
</dl>
</div>
</div>
<div class="sect3">
<h4 id="rolling.restart.manual"><a class="anchor" href="#rolling.restart.manual"></a> 126.2.2。手动滚动重启</h4>
<div class="paragraph">
<p>为了保持对过程的更多控制，您可能希望手动在整个群集中进行滚动重启。这使用<code>graceful-stop.sh</code>命令<a href="#decommission">退役</a> 。使用这种方法，您可以分别重新启动每个RegionServer，然后将其旧区域移回原位，并保持局部性。如果还需要重新启动主服务器，则需要单独进行操作，并在使用此方法重新启动RegionServer之前先重新启动主服务器。以下是这种命令的示例。您可能需要根据环境进行调整。该脚本仅滚动重启RegionServers。它会在移动区域之前禁用负载均衡器。</p>
</div>
<div class="listingblock">
<div class="content">
<pre>$ for i in `cat conf/regionservers|sort`; do ./bin/graceful_stop.sh --restart --reload --debug $i; done &amp;&gt; /tmp/log.txt &amp;;</pre>
</div>
</div>
<div class="paragraph">
<p>监视<em>/tmp/log.txt</em>文件的输出以跟踪脚本的进度。</p>
</div>
</div>
<div class="sect3">
<h4 id="_logic_for_crafting_your_own_rolling_restart_script"><a class="anchor" href="#_logic_for_crafting_your_own_rolling_restart_script"></a> 126.2.3。编写自己的滚动重启脚本的逻辑</h4>
<div class="paragraph">
<p>如果要创建自己的滚动重启脚本，请使用以下准则。</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>提取新版本，验证其配置，然后使用同步到集群的所有节点<code>rsync</code> ， <code>scp</code> ，或其他安全同步机制。</p>
</li>
<li>
<p>使用hbck实用程序可确保群集一致。</p>
<div class="listingblock">
<div class="content">
<pre>$ ./bin/hbck</pre>
</div>
</div>
<div class="paragraph">
<p>如果需要，请进行维修。有关详细信息，请参见<a href="#hbck">hbck</a> 。</p>
</div>
</li>
<li>
<p>首先重新启动主机。如果新的HBase目录不同于旧的HBase目录（例如，用于升级），则可能需要修改这些命令。</p>
<div class="listingblock">
<div class="content">
<pre>$ ./bin/hbase-daemon.sh stop master; ./bin/hbase-daemon.sh start master</pre>
</div>
</div>
</li>
<li>
<p>使用以下脚本从主服务器正常重启每个RegionServer。</p>
<div class="listingblock">
<div class="content">
<pre>$ for i in `cat conf/regionservers|sort`; do ./bin/graceful_stop.sh --restart --reload --debug $i; done &amp;&gt; /tmp/log.txt &amp;</pre>
</div>
</div>
<div class="paragraph">
<p>如果您正在运行Thrift或REST服务器，请传递--thrift或--rest选项。有关其他可用选项，请运行<code>bin/graceful-stop.sh --help</code>命令。</p>
</div>
<div class="paragraph">
<p>重新启动多个RegionServer时，缓慢耗尽HBase区域很重要。否则，多个区域将同时脱机，必须将其重新分配给其他节点，这些节点也可能很快会脱机。这会对性能产生负面影响。例如，您可以通过添加Shell命令（例如， <code>sleep</code> 。要在每次RegionServer重新启动之间等待5分钟，请将上面的脚本修改为以下内容：</p>
</div>
<div class="listingblock">
<div class="content">
<pre>$ for i in `cat conf/regionservers|sort`; do ./bin/graceful_stop.sh --restart --reload --debug $i &amp; sleep 5m; done &amp;&gt; /tmp/log.txt &amp;</pre>
</div>
</div>
</li>
<li>
<p>再次重新启动主服务器，以清除失效的服务器列表并重新启用负载均衡器。</p>
</li>
<li>
<p>跑过<code>hbck</code>再次确认实用程序，以确保群集一致。</p>
</li>
</ol>
</div>
</div>
</div>
<div class="sect2">
<h3 id="adding.new.node"><a class="anchor" href="#adding.new.node"></a> 126.3。添加一个新节点</h3>
<div class="paragraph">
<p>在HBase中添加新的Regionserver本质上是免费的，您只需像这样启动它： <code>$ ./bin/hbase-daemon.sh start regionserver</code>它将向主服务器注册。理想情况下，您还要在同一台计算机上启动一个DataNode，以便RS最终可以开始具有本地文件。如果您依靠ssh启动守护程序，请不要忘记在主服务器的<em>conf / regionservers中</em>添加新的主机名。</p>
</div>
<div class="paragraph">
<p>此时，区域服务器无法提供数据，因为还没有区域移至该区域。如果启用了平衡器，它将开始将区域移动到新的RS。在中小型群集上，这可能会对延迟产生非常不利的影响，因为许多区域会同时处于离线状态。因此，建议以与停用节点时相同的方式禁用平衡器，并手动移动区域（甚至更好的是，使用将它们一一移动的脚本）。</p>
</div>
<div class="paragraph">
<p>移动的区域都将具有0％的局部性，并且在缓存中将没有任何块，因此区域服务器将必须使用网络来处理请求。除了导致更高的延迟外，它还可以使用您所有网卡的容量。出于实际目的，请考虑标准的1GigE NIC读取速度不能超过<em>100MB / s</em> 。在这种情况下，或者如果您在OLAP环境中并且需要具有局部性，则建议对压缩的区域进行较大压缩。</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_hbase_metrics"><a class="anchor" href="#_hbase_metrics"></a> 127。HBase指标</h2>
<div class="sectionbody">
<div class="paragraph">
<p>HBase发出符合<a href="http://hadoop.apache.org/core/docs/current/api/org/apache/hadoop/metrics/package-summary.html">Hadoop指标</a> API的<a href="http://hadoop.apache.org/core/docs/current/api/org/apache/hadoop/metrics/package-summary.html">指标</a> 。从HBase 0.95 <sup class="footnote">[ <a id="_footnoteref_4" class="footnote" href="#_footnote_4" title="查看脚注。">4</a> ]开始</sup> ，HBase被配置为发出默认度量标准集，默认采样周期为每10秒。您可以将HBase指标与Ganglia结合使用。您还可以过滤发出哪些度量，并扩展度量框架以捕获适合您的环境的自定义度量。</p>
</div>
<div class="sect2">
<h3 id="_metric_setup"><a class="anchor" href="#_metric_setup"></a> 127.1。指标设置</h3>
<div class="paragraph">
<p>对于HBase 0.95及更高版本，HBase附带了默认的指标配置或接收<em class="firstterm">器</em> 。这包括各种单独的指标，默认情况下每10秒发出一次。要为给定的区域服务器配置指标，请编辑<em>conf / hadoop-metrics2-hbase.properties</em>文件。重新启动区域服务器，以使更改生效。</p>
</div>
<div class="paragraph">
<p>要更改默认接收器的采样率，请编辑以<code>*.period</code> 。要过滤发出哪些度量或扩展度量框架，请参阅链接：http：//hadoop.apache.org/docs/current/api/org/apache/hadoop/metrics2/package-summary.html</p>
</div>
<div class="admonitionblock note">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-note" title="注意"></i>
</td>
<td class="content">
<div class="title">HBase指标和神经节</div>
<div class="paragraph">
<p>默认情况下，HBase每台区域服务器发出大量指标。神经节可能难以处理所有这些指标。考虑增加Ganglia服务器的容量或减少HBase发出的度量标准数量。请参阅<a href="http://hadoop.apache.org/docs/current/api/org/apache/hadoop/metrics2/package-summary.html#filtering">指标过滤</a> 。</p>
</div>
</td>
</tr>
</tbody></table>
</div>
</div>
<div class="sect2">
<h3 id="_disabling_metrics"><a class="anchor" href="#_disabling_metrics"></a> 127.2。禁用指标</h3>
<div class="paragraph">
<p>要禁用区域服务器的指标，请编辑<em>conf / hadoop-metrics2-hbase.properties</em>文件并注释掉所有未注释的行。重新启动区域服务器，以使更改生效。</p>
</div>
</div>
<div class="sect2">
<h3 id="discovering.available.metrics"><a class="anchor" href="#discovering.available.metrics"></a> 127.3。发现可用指标</h3>
<div class="paragraph">
<p>您可以列出JSON或JMX来浏览可用的指标，而不必列出HBase默认发出的每个指标。针对主进程和每个区域服务器进程公开了不同的指标。</p>
</div>
<div class="olist arabic">
<div class="title">过程：访问可用度量的JSON输出</div>
<ol class="arabic">
<li>
<p>启动HBase后，访问区域服务器的Web UI，网址为： <code><a href="http://REGIONSERVER_HOSTNAME:60030" class="bare">http://REGIONSERVER_HOSTNAME:60030</a></code>默认情况下（或HBase 1.0+中的端口16030）。</p>
</li>
<li>
<p>单击顶部附近的“ <span class="label">度量标准转储”</span>链接。区域服务器的度量标准以JSON格式的JMX bean的转储形式显示。这将转储所有度量标准名称及其值。要将清单中的指标描述包括在内（当您探索可用指标时这会很有用），添加一个查询字符串<code>?description=true</code>所以你的网址变成<code><a href="http://REGIONSERVER_HOSTNAME:60030/jmx?description=true" class="bare">http://REGIONSERVER_HOSTNAME:60030/jmx?description=true</a></code> 。并非所有的bean和属性都有描述。</p>
</li>
<li>
<p>要查看母版的指标，请改为连接到母版的网络用户界面（默认为<code><a href="http://localhost:60010" class="bare">http://localhost:60010</a></code>或HBase 1.0+中的端口16010），然后单击其<span class="label">指标转储</span>链接。要将清单中的指标描述包括在内（当您探索可用指标时这会很有用），添加一个查询字符串<code>?description=true</code>所以你的网址变成<code><a href="http://REGIONSERVER_HOSTNAME:60010/jmx?description=true" class="bare">http://REGIONSERVER_HOSTNAME:60010/jmx?description=true</a></code> 。并非所有的bean和属性都有描述。</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>您可以使用许多不同的工具通过浏览MBean来查看JMX内容。该程序使用<code>jvisualvm</code> ，这是JDK中通常可用的应用程序。</p>
</div>
<div class="olist arabic">
<div class="title">过程：浏览可用度量的JMX输出</div>
<ol class="arabic">
<li>
<p>启动HBase（如果尚未运行）。</p>
</li>
<li>
<p>运行命令<code>jvisualvm</code>带有GUI显示的主机上的命令。您可以从命令行或适用于您的操作系统的其他方法启动它。</p>
</li>
<li>
<p>确保已安装<span class="label">VisualVM-MBeans</span>插件。浏览到<strong>工具→插件</strong> 。单击“ <span class="label">已安装”，</span>然后检查是否列出了插件。如果不是，请单击<span class="label">可用插件</span> ，将其选中，然后单击<b class="button">安装</b> 。完成后，点击<b class="button">关闭</b> 。</p>
</li>
<li>
<p>要查看给定HBase进程的详细信息，请在左侧面板的<span class="label">Local</span>子树中双击该进程。在右侧面板中将打开一个详细视图。单击“ <span class="label">MBeans”</span>选项卡，该选项卡显示在右侧面板顶部。</p>
</li>
<li>
<p>要访问HBase指标，请导航至相应的子bean：</p>
</li>
<li>
<p>每个度量标准的名称及其当前值显示在“ <span class="label">属性”</span>选项卡中。对于包含更多详细信息（包括每个属性的描述）的视图，请单击“ <span class="label">元数据”</span>选项卡。</p>
</li>
</ol>
</div>
</div>
<div class="sect2">
<h3 id="_units_of_measure_for_metrics"><a class="anchor" href="#_units_of_measure_for_metrics"></a> 127.4。度量单位</h3>
<div class="paragraph">
<p>适当时，以不同的单位表示不同的指标。通常，度量单位是名称（如公制<code>shippedKBs</code> ）。否则，请遵循以下准则。如有疑问，您可能需要检查给定指标的来源。</p>
</div>
<div class="ulist">
<ul>
<li>
<p>引用时间点的指标通常表示为时间戳。</p>
</li>
<li>
<p>指代年龄的指标（例如<code>ageOfLastShippedOp</code> ）通常以毫秒为单位。</p>
</li>
<li>
<p>引用内存大小的指标以字节为单位。</p>
</li>
<li>
<p>队列大小（例如<code>sizeOfLogQueue</code> ）表示为队列中的项目数。通过乘以块大小来确定大小（HDFS中默认为64 MB）。</p>
</li>
<li>
<p>指代诸如给定类型的操作数之类的指标的指标（例如<code>logEditsRead</code> ）表示为整数。</p>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="master_metrics"><a class="anchor" href="#master_metrics"></a> 127.5。最重要的主指标</h3>
<div class="paragraph">
<p>注意：计数通常在上一个指标报告间隔内。</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">hbase.master.numRegionServers</dt>
<dd>
<p>实时区域服务器数量</p>
</dd>
<dt class="hdlist1">hbase.master.numDeadRegionServers</dt>
<dd>
<p>死区服务器数量</p>
</dd>
<dt class="hdlist1">hbase.master.ritCount</dt>
<dd>
<p>转换中的区域数</p>
</dd>
<dt class="hdlist1">hbase.master.ritCountOverThreshold</dt>
<dd>
<p>过渡时间超过阈值时间的区域数（默认值：60秒）</p>
</dd>
<dt class="hdlist1">hbase.master.ritOldestAge</dt>
<dd>
<p>转换中最长区域的年龄（以毫秒为单位）</p>
</dd>
</dl>
</div>
</div>
<div class="sect2">
<h3 id="rs_metrics"><a class="anchor" href="#rs_metrics"></a> 127.6。最重要的RegionServer指标</h3>
<div class="paragraph">
<p>注意：计数通常在上一个指标报告间隔内。</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">hbase.regionserver.regionCount</dt>
<dd>
<p>区域服务器托管的区域数</p>
</dd>
<dt class="hdlist1">hbase.regionserver.storeFileCount</dt>
<dd>
<p>区域服务器当前管理的磁盘上的存储文件数</p>
</dd>
<dt class="hdlist1">hbase.regionserver.storeFileSize</dt>
<dd>
<p>磁盘上存储文件的总大小</p>
</dd>
<dt class="hdlist1">hbase.regionserver.hlogFileCount</dt>
<dd>
<p>尚未归档的预写日志数</p>
</dd>
<dt class="hdlist1">hbase.regionserver.totalRequestCount</dt>
<dd>
<p>收到的请求总数</p>
</dd>
<dt class="hdlist1">hbase.regionserver.readRequestCount</dt>
<dd>
<p>收到的读取请求数</p>
</dd>
<dt class="hdlist1">hbase.regionserver.writeRequestCount</dt>
<dd>
<p>收到的写请求数</p>
</dd>
<dt class="hdlist1">hbase.regionserver.numOpenConnections</dt>
<dd>
<p>RPC层上打开的连接数</p>
</dd>
<dt class="hdlist1">hbase.regionserver.numActiveHandler</dt>
<dd>
<p>主动处理请求的RPC处理程序的数量</p>
</dd>
<dt class="hdlist1">hbase.regionserver.numCallsInGeneralQueue</dt>
<dd>
<p>当前排队的用户请求数</p>
</dd>
<dt class="hdlist1">hbase.regionserver.numCallsInReplicationQueue</dt>
<dd>
<p>从复制接收到的当前排队的操作数</p>
</dd>
<dt class="hdlist1">hbase.regionserver.numCallsInPriorityQueue</dt>
<dd>
<p>当前排队的优先级（内部整理）请求数</p>
</dd>
<dt class="hdlist1">hbase.regionserver.flushQueueLength</dt>
<dd>
<p>memstore刷新队列的当前深度。如果增加的话，我们在将内存存储清除到HDFS方面是落后的。</p>
</dd>
<dt class="hdlist1">hbase.regionserver.updatesBlockedTime</dt>
<dd>
<p>毫秒更新数已被阻止，因此可以刷新内存存储</p>
</dd>
<dt class="hdlist1">hbase.regionserver.compactionQueueLength</dt>
<dd>
<p>压缩请求队列的当前深度。如果增加的话，我们将在存储文件压缩方面落后。</p>
</dd>
<dt class="hdlist1">hbase.regionserver.blockCacheHitCount</dt>
<dd>
<p>块缓存命中数</p>
</dd>
<dt class="hdlist1">hbase.regionserver.blockCacheMissCount</dt>
<dd>
<p>块缓存未命中数</p>
</dd>
<dt class="hdlist1">hbase.regionserver.blockCacheExpressHitPercent</dt>
<dd>
<p>启用缓存的请求所占的时间百分比命中了缓存</p>
</dd>
<dt class="hdlist1">hbase.regionserver.percentFilesLocal</dt>
<dd>
<p>可以从本地DataNode读取的存储文件数据的百分比，0-100</p>
</dd>
<dt class="hdlist1">hbase.regionserver。<op>_<measure></measure></op></dt>
<dd>
<p>操作延迟，其中<op>之一是追加，删除，突变，获取，重播，递增； <measure>最小，最大，均值，中位数，75th_percentile，95th_percentile，99th_percentile之一</measure></op></p>
</dd>
<dt class="hdlist1">hbase.regionserver.slow <op>计数</op></dt>
<dd>
<p>我们认为操作速度很慢，这<op>是上面的列表之一</op></p>
</dd>
<dt class="hdlist1">hbase.regionserver。GcTimeMillis</dt>
<dd>
<p>垃圾收集所花费的时间（以毫秒为单位）</p>
</dd>
<dt class="hdlist1">hbase.regionserver。GcTimeMillisParNew</dt>
<dd>
<p>花费在年轻一代垃圾收集上的时间（毫秒）</p>
</dd>
<dt class="hdlist1">hbase.regionserver。GcTimeMillisConcurrentMarkSweep</dt>
<dd>
<p>上一代垃圾回收所花费的时间（以毫秒为单位）</p>
</dd>
<dt class="hdlist1">hbase.regionserver.authentication成功</dt>
<dd>
<p>身份验证成功的客户端连接数</p>
</dd>
<dt class="hdlist1">hbase.regionserver.authenticationFailures</dt>
<dd>
<p>客户端连接身份验证失败的次数</p>
</dd>
<dt class="hdlist1">hbase.regionserver.mutationsWithoutWALCount</dt>
<dd>
<p>提交的带有标志的写计数，该标志指示它们应绕过预写日志</p>
</dd>
</dl>
</div>
</div>
<div class="sect2">
<h3 id="rs_meta_metrics"><a class="anchor" href="#rs_meta_metrics"></a> 127.7。元表负载指标</h3>
<div class="paragraph">
<p>HBase元表指标收集功能在HBase 1.4+中可用，但默认情况下已禁用，因为它会影响群集的性能。启用后，它可以通过收集以下统计信息来帮助监视客户端访问模式：</p>
</div>
<div class="ulist">
<ul>
<li>
<p>获取，放置和删除操作的数量<code>hbase:meta</code>表</p>
</li>
<li>
<p>前N个客户端进行的获取，放置和删除操作的数量</p>
</li>
<li>
<p>每个表相关的操作数</p>
</li>
<li>
<p>与前N个区域相关的操作数</p>
<div class="dlist">
<dl>
<dt class="hdlist1">何时使用功能</dt>
<dd>
<p>此功能可以通过显示修改元信息（例如，通过创建，删除，拆分或移动表）或最频繁检索到的区域或表来帮助识别元表中的热点。它还可以通过显示哪个客户端最频繁地使用元表来帮助发现异常的客户端应用程序，例如，这可能表明缺少元表缓冲或在客户端应用程序中没有重新使用开放的客户端连接。</p>
</dd>
</dl>
</div>
</li>
</ul>
</div>
<div class="admonitionblock warning">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-warning" title="警告"></i>
</td>
<td class="content">
<div class="title">启用此功能的可能的副作用</div>
<div class="paragraph">
<p>群集中拥有大量客户端和区域会导致注册和跟踪大量指标，这可能会增加处理该问题的HBase区域服务器的内存和CPU占用空间。 <code>hbase:meta</code>表。它还可能导致JMX转储大小的显着增加，这可能会影响您在HBase旁边使用的监视或日志聚合系统。建议仅在调试期间打开此功能。</p>
</div>
</td>
</tr>
</tbody></table>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">在JMX哪里找到指标</dt>
<dd>
<p>每个度量标准属性名称都将以“ MetaTable_”前缀开头。对于所有度量，您将看到五个不同的JMX属性：计数，平均速率，1分钟速率，5分钟速率和15分钟速率。您可以在以下MBean的JMX中找到这些指标： <code>Hadoop → HBase → RegionServer → Coprocessor.Region.CP_org.apache.hadoop.hbase.coprocessor.MetaTableMetrics</code> 。</p>
</dd>
</dl>
</div>
<div class="listingblock">
<div class="title">示例：您可以在JMX转储中看到的一些元表指标</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="json">{
  <span class="key"><span class="delimiter">&quot;</span><span class="content">MetaTable_get_request_count</span><span class="delimiter">&quot;</span></span>: <span class="integer">77309</span>,
  <span class="key"><span class="delimiter">&quot;</span><span class="content">MetaTable_put_request_mean_rate</span><span class="delimiter">&quot;</span></span>: <span class="float">0.06339092997186495</span>,
  <span class="key"><span class="delimiter">&quot;</span><span class="content">MetaTable_table_MyTestTable_request_15min_rate</span><span class="delimiter">&quot;</span></span>: <span class="float">1.1020599841623246</span>,
  <span class="key"><span class="delimiter">&quot;</span><span class="content">MetaTable_client_/172.30.65.42_lossy_request_count</span><span class="delimiter">&quot;</span></span>: <span class="integer">1786</span>
  <span class="key"><span class="delimiter">&quot;</span><span class="content">MetaTable_client_/172.30.65.45_put_request_5min_rate</span><span class="delimiter">&quot;</span></span>: <span class="float">0.6189810954855728</span>,
  <span class="key"><span class="delimiter">&quot;</span><span class="content">MetaTable_region_1561131112259.c66e4308d492936179352c80432ccfe0._lossy_request_count</span><span class="delimiter">&quot;</span></span>: <span class="integer">38342</span>,
  <span class="key"><span class="delimiter">&quot;</span><span class="content">MetaTable_region_1561131043640.5bdffe4b9e7e334172065c853cf0caa6._lossy_request_1min_rate</span><span class="delimiter">&quot;</span></span>: <span class="float">0.04925099917433935</span>,
}</code></pre>
</div>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">组态</dt>
<dd>
<p>要启用此功能，必须通过将以下部分添加到hbase-site.xml来启用自定义协处理器。该协处理器将在所有HBase RegionServer上运行，但仅在服务器上处于活动状态（即消耗内存/ CPU）。 <code>hbase:meta</code>表位于。它将生成JMX度量，可以从给定RegionServer的Web UI或通过简单的REST调用下载JMX度量。这些度量将不会出现在其他RegionServer的JMX转储中。</p>
</dd>
</dl>
</div>
<div class="listingblock">
<div class="title">启用元表指标功能</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="xml"><span class="tag">&lt;property&gt;</span>
    <span class="tag">&lt;name&gt;</span>hbase.coprocessor.region.classes<span class="tag">&lt;/name&gt;</span>
    <span class="tag">&lt;value&gt;</span>org.apache.hadoop.hbase.coprocessor.MetaTableMetrics<span class="tag">&lt;/value&gt;</span>
<span class="tag">&lt;/property&gt;</span></code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-note" title="注意"></i>
</td>
<td class="content">
<div class="title">前N个指标如何计算？</div>
<div class="paragraph">
<p>指标的“前N个”类型将使用有损计数算法（如<a href="http://www.vldb.org/conf/2002/S10P03.pdf">Motwani，R; Manku，GS（2002）中定义。“数据流的近似频率计数”</a> ）进行<a href="http://www.vldb.org/conf/2002/S10P03.pdf">计数</a> ，该算法旨在识别频率计数超过用户给定阈值的数据流。用这种算法计算出的频率并不总是准确的，但是有一个误差阈值，用户可以将其指定为配置参数。算法所需的运行时间空间与指定的错误阈值成反比，因此，错误参数越大，占位面积越小且度量的准确性越低。</p>
</div>
<div class="paragraph">
<p>您可以将算法的错误率指定为0到1（不包括）之间的浮点值，默认值为0.02。将错误率设置为<code>E</code>并且有<code>N</code>作为元表操作的总数，那么（假设低频元素的活动均匀分布） <code>7 / E</code>仪表将被保存，每个保存的元素的频率将高于<code>E * N</code> 。</p>
</div>
<div class="paragraph">
<p>一个示例：假设我们对访问元表最活跃的HBase客户端感兴趣。到目前为止，当元表上有1,000,000次操作且错误率参数设置为0.02时，我们可以假定JMX中最多只能存在350个与客户端IP地址相关的计数器，并且这些客户端中的每一个都在以下位置访问元表至少20,000次。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="xml"><span class="tag">&lt;property&gt;</span>
    <span class="tag">&lt;name&gt;</span>hbase.util.default.lossycounting.errorrate<span class="tag">&lt;/name&gt;</span>
    <span class="tag">&lt;value&gt;</span>0.02<span class="tag">&lt;/value&gt;</span>
<span class="tag">&lt;/property&gt;</span></code></pre>
</div>
</div>
</td>
</tr>
</tbody></table>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="ops.monitoring"><a class="anchor" href="#ops.monitoring"></a> 128。HBase监控</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="ops.monitoring.overview"><a class="anchor" href="#ops.monitoring.overview"></a> 128.1。总览</h3>
<div class="paragraph">
<p>对于每个RegionServer进行“宏监视”监视，以下指标可以说是最重要的，最好使用像<a href="http://opentsdb.net/">OpenTSDB</a>这样的系统。如果您的群集出现性能问题，则您可能会在该组中看到一些不寻常的情况。</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">HBase的</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>查看<a href="#rs_metrics">RS指标</a></p>
</li>
</ul>
</div>
</dd>
<dt class="hdlist1">操作系统</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>IO等待</p>
</li>
<li>
<p>用户CPU</p>
</li>
</ul>
</div>
</dd>
<dt class="hdlist1">爪哇</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>GC</p>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="paragraph">
<p>有关HBase指标的更多信息，请参见<a href="#hbase_metrics">hbase指标</a> 。</p>
</div>
</div>
<div class="sect2">
<h3 id="ops.slow.query"><a class="anchor" href="#ops.slow.query"></a> 128.2。慢查询日志</h3>
<div class="paragraph">
<p>HBase慢查询日志由可解析的JSON结构组成，这些JSON结构描述了这些客户端操作（获取，放置，删除等）的属性，这些客户端操作花费的时间太长，或者产生的输出过多。如下所述，“运行时间太长”和“输出太多”的阈值是可配置的。输出是在主区域服务器日志中内联生成的，因此很容易从上下文和其他已记录的事件中发现更多详细信息。它还带有识别标签<code>(responseTooSlow)</code> ， <code>(responseTooLarge)</code> ， <code>(operationTooSlow)</code>和<code>(operationTooLarge)</code>如果用户只希望查看慢速查询，则可以使用grep轻松进行过滤。</p>
</div>
<div class="sect3">
<h4 id="_configuration"><a class="anchor" href="#_configuration"></a> 128.2.1。组态</h4>
<div class="paragraph">
<p>有两个配置旋钮可用于调整记录查询时的阈值。</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>hbase.ipc.warn.response.time</code>可以在不记录查询的情况下运行查询的最大毫秒数。默认为10000，即10秒。可以设置为-1以禁用按时间记录。</p>
</li>
<li>
<p><code>hbase.ipc.warn.response.size</code>查询可以不记录就返回的最大响应字节大小。默认为100兆字节。可以设置为-1以禁用按大小记录。</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_metrics"><a class="anchor" href="#_metrics"></a> 128.2.2。指标</h4>
<div class="paragraph">
<p>慢查询日志向JMX公开指标。</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>hadoop.regionserver_rpc_slowResponse</code>反映所有触发记录的响应持续时间的全局指标。</p>
</li>
<li>
<p><code>hadoop.regionserver_rpc_methodName.aboveOneSec</code>反映持续超过一秒的所有响应的持续时间的度量。</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_output"><a class="anchor" href="#_output"></a> 128.2.3。输出量</h4>
<div class="paragraph">
<p>用操作标记输出，例如<code>(operationTooSlow)</code> （如果调用是客户端操作，例如Put，Get或Delete），我们将为其提供详细的指纹信息。如果没有，它被标记<code>(responseTooSlow)</code>并且仍会产生可解析的JSON输出，但仅在RPC本身中仅提供有关其持续时间和大小的详细信息。 <code>TooLarge</code>代替<code>TooSlow</code>如果响应大小触发了日志记录，则使用<code>TooLarge</code>即使在大小和持续时间都触发了日志记录的情况下也会出现。</p>
</div>
</div>
<div class="sect3">
<h4 id="_example"><a class="anchor" href="#_example"></a> 128.2.4。例</h4>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="integer">2011</span>-<span class="integer">09</span>-<span class="integer">08</span> <span class="integer">10</span>:<span class="octal">01</span>:<span class="integer">25</span>,<span class="integer">824</span> WARN org.apache.hadoop.ipc.HBaseServer: (operationTooSlow): {<span class="string"><span class="delimiter">&quot;</span><span class="content">tables</span><span class="delimiter">&quot;</span></span>:{<span class="string"><span class="delimiter">&quot;</span><span class="content">riley2</span><span class="delimiter">&quot;</span></span>:{<span class="string"><span class="delimiter">&quot;</span><span class="content">puts</span><span class="delimiter">&quot;</span></span>:[{<span class="string"><span class="delimiter">&quot;</span><span class="content">totalColumns</span><span class="delimiter">&quot;</span></span>:<span class="integer">11</span>,<span class="string"><span class="delimiter">&quot;</span><span class="content">families</span><span class="delimiter">&quot;</span></span>:{<span class="string"><span class="delimiter">&quot;</span><span class="content">actions</span><span class="delimiter">&quot;</span></span>:[{<span class="string"><span class="delimiter">&quot;</span><span class="content">timestamp</span><span class="delimiter">&quot;</span></span>:<span class="integer">1315501284459</span>,<span class="string"><span class="delimiter">&quot;</span><span class="content">qualifier</span><span class="delimiter">&quot;</span></span>:<span class="string"><span class="delimiter">&quot;</span><span class="content">0</span><span class="delimiter">&quot;</span></span>,<span class="string"><span class="delimiter">&quot;</span><span class="content">vlen</span><span class="delimiter">&quot;</span></span>:<span class="integer">9667580</span>},{<span class="string"><span class="delimiter">&quot;</span><span class="content">timestamp</span><span class="delimiter">&quot;</span></span>:<span class="integer">1315501284459</span>,<span class="string"><span class="delimiter">&quot;</span><span class="content">qualifier</span><span class="delimiter">&quot;</span></span>:<span class="string"><span class="delimiter">&quot;</span><span class="content">1</span><span class="delimiter">&quot;</span></span>,<span class="string"><span class="delimiter">&quot;</span><span class="content">vlen</span><span class="delimiter">&quot;</span></span>:<span class="integer">10122412</span>},{<span class="string"><span class="delimiter">&quot;</span><span class="content">timestamp</span><span class="delimiter">&quot;</span></span>:<span class="integer">1315501284459</span>,<span class="string"><span class="delimiter">&quot;</span><span class="content">qualifier</span><span class="delimiter">&quot;</span></span>:<span class="string"><span class="delimiter">&quot;</span><span class="content">2</span><span class="delimiter">&quot;</span></span>,<span class="string"><span class="delimiter">&quot;</span><span class="content">vlen</span><span class="delimiter">&quot;</span></span>:<span class="integer">11104617</span>},{<span class="string"><span class="delimiter">&quot;</span><span class="content">timestamp</span><span class="delimiter">&quot;</span></span>:<span class="integer">1315501284459</span>,<span class="string"><span class="delimiter">&quot;</span><span class="content">qualifier</span><span class="delimiter">&quot;</span></span>:<span class="string"><span class="delimiter">&quot;</span><span class="content">3</span><span class="delimiter">&quot;</span></span>,<span class="string"><span class="delimiter">&quot;</span><span class="content">vlen</span><span class="delimiter">&quot;</span></span>:<span class="integer">13430635</span>}]},<span class="string"><span class="delimiter">&quot;</span><span class="content">row</span><span class="delimiter">&quot;</span></span>:<span class="string"><span class="delimiter">&quot;</span><span class="content">cfcd208495d565ef66e7dff9f98764da:0</span><span class="delimiter">&quot;</span></span>}],<span class="string"><span class="delimiter">&quot;</span><span class="content">families</span><span class="delimiter">&quot;</span></span>:[<span class="string"><span class="delimiter">&quot;</span><span class="content">actions</span><span class="delimiter">&quot;</span></span>]}},<span class="string"><span class="delimiter">&quot;</span><span class="content">processingtimems</span><span class="delimiter">&quot;</span></span>:<span class="integer">956</span>,<span class="string"><span class="delimiter">&quot;</span><span class="content">client</span><span class="delimiter">&quot;</span></span>:<span class="string"><span class="delimiter">&quot;</span><span class="content">10.47.34.63:33623</span><span class="delimiter">&quot;</span></span>,<span class="string"><span class="delimiter">&quot;</span><span class="content">starttimems</span><span class="delimiter">&quot;</span></span>:<span class="integer">1315501284456</span>,<span class="string"><span class="delimiter">&quot;</span><span class="content">queuetimems</span><span class="delimiter">&quot;</span></span>:<span class="integer">0</span>,<span class="string"><span class="delimiter">&quot;</span><span class="content">totalPuts</span><span class="delimiter">&quot;</span></span>:<span class="integer">1</span>,<span class="string"><span class="delimiter">&quot;</span><span class="content">class</span><span class="delimiter">&quot;</span></span>:<span class="string"><span class="delimiter">&quot;</span><span class="content">HRegionServer</span><span class="delimiter">&quot;</span></span>,<span class="string"><span class="delimiter">&quot;</span><span class="content">responsesize</span><span class="delimiter">&quot;</span></span>:<span class="integer">0</span>,<span class="string"><span class="delimiter">&quot;</span><span class="content">method</span><span class="delimiter">&quot;</span></span>:<span class="string"><span class="delimiter">&quot;</span><span class="content">multiPut</span><span class="delimiter">&quot;</span></span>}</code></pre>
</div>
</div>
<div class="paragraph">
<p>请注意，“表”结构内部的所有内容都是由MultiPut指纹生成的，而其余信息则是特定于RPC的，例如处理时间和客户端IP /端口。其他客户端操作遵循相同的模式和相同的一般结构，但由于各个操作的性质而存在必要的差异。在呼叫不是客户操作的情况下，将完全没有详细的指纹信息。</p>
</div>
<div class="paragraph">
<p>例如，此特定示例将表明，导致速度缓慢的可能原因仅仅是非常大的（大约100MB）多输入，正如我们可以通过“ vlen”（即值长度）来判断multiPut中每个输入的字段所表明的那样。</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_block_cache_monitoring"><a class="anchor" href="#_block_cache_monitoring"></a> 128.3。块缓存监控</h3>
<div class="paragraph">
<p>从HBase 0.98开始，HBase Web UI包含监视和报告块缓存性能的功能。要查看块缓存报告，请单击。以下是一些报告功能的示例。</p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/bc_basic.png" alt="卑诗省基本">
</div>
<div class="title">图5。基本信息</div>
</div>
<div class="imageblock">
<div class="content">
<img src="images/bc_config.png" alt="BC配置">
</div>
<div class="title">图6。设定档</div>
</div>
<div class="imageblock">
<div class="content">
<img src="images/bc_stats.png" alt="卑诗省统计资料">
</div>
<div class="title">图7。统计资料</div>
</div>
<div class="imageblock">
<div class="content">
<img src="images/bc_l1.png" alt="公元前l1">
</div>
<div class="title">图8。L1和L2</div>
</div>
<div class="paragraph">
<p>这不是所有可用屏幕和报告的详尽列表。在Web UI中查看。</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_cluster_replication"><a class="anchor" href="#_cluster_replication"></a> 129。集群复制</h2>
<div class="sectionbody">
<div class="admonitionblock note">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-note" title="注意"></i>
</td>
<td class="content">该信息以前在“ <a href="http://hbase.apache.org/replication.html">群集复制”中</a>可用。
</td>
</tr>
</tbody></table>
</div>
<div class="paragraph">
<p>HBase提供了一种群集复制机制，通过使用源群集的预写日志（WAL）传播更改，可以使一个群集的状态与另一个群集的状态保持同步。群集复制的一些用例包括：</p>
</div>
<div class="ulist">
<ul>
<li>
<p>备份与灾难恢复</p>
</li>
<li>
<p>资料汇整</p>
</li>
<li>
<p>地理数据分布</p>
</li>
<li>
<p>在线数据提取与离线数据分析相结合</p>
</li>
</ul>
</div>
<div class="admonitionblock note">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-note" title="注意"></i>
</td>
<td class="content">以列系列的粒度启用复制。在为列系列启用复制之前，请在目标群集上创建表和要复制的所有列系列。
</td>
</tr>
</tbody></table>
</div>
<div class="sect2">
<h3 id="_replication_overview"><a class="anchor" href="#_replication_overview"></a> 129.1。复制概述</h3>
<div class="paragraph">
<p>群集复制使用源推送方法。HBase群集可以是源（也称为主服务器或主动服务器，表示它是新数据的发起者），目的地（也称为从机或被动服务器，这意味着它是通过复制接收数据的），或者可以同时履行两个角色。复制是异步的，复制的目标是最终的一致性。当源接收到对启用了复制的列系列的编辑时，该编辑将使用WAL传播到所有目标群集，该WAL用于管理相关区域的RegionServer上该列系列的WAL。</p>
</div>
<div class="paragraph">
<p>当数据从一个群集复制到另一个群集时，数据的原始来源将通过作为元数据一部分的群集ID进行跟踪。在HBase 0.96和更高版本（ <a href="https://issues.apache.org/jira/browse/HBASE-7709">HBASE-7709</a> ）中，还将跟踪所有已消耗数据的群集。这样可以防止复制循环。</p>
</div>
<div class="paragraph">
<p>只要将区域服务器的WAL复制到任何从属群集中，它们就必须保留在HDFS中。每个区域服务器都从需要复制的最旧日志中读取信息，并跟踪其在ZooKeeper内部处理WAL的进度，以简化故障恢复。对于每个从属群集，指示从属群集的进度以及要处理的WAL队列的位置标记可能会有所不同。</p>
</div>
<div class="paragraph">
<p>参与复制的群集可以具有不同的大小。主群集依靠随机化来尝试平衡从群集上的复制流。期望从群集具有存储容量来保存复制的数据以及负责提取的任何数据。如果从属群集确实用完了空间，或由于其他原因无法访问，则它将引发错误，而主群集将保留WAL，并每隔一段时间重试复制。</p>
</div>
<div class="admonitionblock note">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-note" title="注意"></i>
</td>
<td class="content">
<div class="title">术语变更</div>
<div class="paragraph">
<p>以前，诸如<em class="firstterm">master-master</em> ， <em class="firstterm">master-slave</em>和<em class="firstterm">周期性</em>的术语用于描述HBase中的复制关系。这些术语增加了混乱，已被抛弃以支持有关适用于不同场景的群集拓扑的讨论。</p>
</div>
</td>
</tr>
</tbody></table>
</div>
<div class="ulist">
<div class="title">集群拓扑</div>
<ul>
<li>
<p>中央源群集可能会将更改传播到多个目标群集，以进行故障转移或由于地理分布。</p>
</li>
<li>
<p>源群集可能会将更改推送到目标群集，也可能会将其自己的更改推送回原始群集。</p>
</li>
<li>
<p>许多不同的低延迟群集可能会将更改推送到一个集中式群集，以进行备份或资源密集型数据分析作业。然后，可以将处理后的数据复制回低延迟群集。</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>多个复制级别可以链接在一起，以满足组织的需求。下图显示了一个假设的场景。使用箭头跟随数据路径。</p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/hbase_replication_diagram.jpg" alt="hbase复制图">
</div>
<div class="title">图9。复杂群集复制配置的示例</div>
</div>
<div class="paragraph">
<p>HBase复制借鉴了MySQL使用<em class="firstterm">的基于语句的复制</em>设计中的许多概念。为了维护原子性，将复制整个WALEdit（由来自客户端上的Put和Delete操作的多个单元插入组成），而不是SQL语句。</p>
</div>
</div>
<div class="sect2">
<h3 id="_managing_and_configuring_cluster_replication"><a class="anchor" href="#_managing_and_configuring_cluster_replication"></a> 129.2。管理和配置群集复制</h3>
<div class="olist arabic">
<div class="title">群集配置概述</div>
<ol class="arabic">
<li>
<p>配置并启动源集群和目标集群。在源集群和目标集群上创建具有相同名称和列族的表，以便目标集群知道将接收数据的存储位置。</p>
</li>
<li>
<p>源群集和目标群集中的所有主机应相互可达。</p>
</li>
<li>
<p>如果两个群集使用相同的ZooKeeper群集，则必须使用其他群集<code>zookeeper.znode.parent</code> ，因为它们不能写在同一文件夹中。</p>
</li>
<li>
<p>检查以确保未禁用复制。 <code>hbase.replication</code>默认为<code>true</code> 。</p>
</li>
<li>
<p>在源群集的HBase Shell中，使用<code>add_peer</code>命令。</p>
</li>
<li>
<p>在源群集的HBase Shell中，使用以下命令启用表复制： <code>enable_table_replication</code>命令。</p>
</li>
<li>
<p>检查日志以查看是否正在复制。如果是这样，您将看到来自ReplicationSource的以下消息。</p>
</li>
</ol>
</div>
<div class="listingblock">
<div class="content">
<pre>LOG.info("Replicating "+clusterId + " -&gt; " + peerClusterId);</pre>
</div>
</div>
<div class="dlist">
<div class="title">集群管理命令</div>
<dl>
<dt class="hdlist1">add_peer <id> <cluster_key></cluster_key></id></dt>
<dd>
<p>在两个群集之间添加复制关系。<br></p>
<div class="ulist">
<ul>
<li>
<p>ID —一个唯一的字符串，不能包含连字符。</p>
</li>
<li>
<p>CLUSTER_KEY：使用以下模板组成，带有适当的占位符：<code>hbase.zookeeper.quorum:hbase.zookeeper.property.clientPort:zookeeper.znode.parent</code></p>
</li>
</ul>
</div>
</dd>
<dt class="hdlist1">list_peers</dt>
<dd>
<p>列出此群集已知的所有复制关系</p>
</dd>
<dt class="hdlist1">enable_peer<id></id></dt>
<dd>
<p>启用先前禁用的复制关系</p>
</dd>
<dt class="hdlist1">disable_peer<id></id></dt>
<dd>
<p>禁用复制关系。HBase不再将编辑发送到该对等群集，但是如果重新启用，则它仍会跟踪需要复制的所有新WAL。</p>
</dd>
<dt class="hdlist1">remove_peer<id></id></dt>
<dd>
<p>禁用并删除复制关系。HBase将不再将编辑发送到该对等群集或跟踪WAL。</p>
</dd>
<dt class="hdlist1">enable_table_replication<table_name></table_name></dt>
<dd>
<p>为所有列系列启用表复制开关。如果在目标群集中找不到该表，则它将创建一个具有相同名称和列族的表。</p>
</dd>
<dt class="hdlist1">disable_table_replication<table_name></table_name></dt>
<dd>
<p>禁用所有表列系列的表复制开关。</p>
</dd>
</dl>
</div>
</div>
<div class="sect2">
<h3 id="_verifying_replicated_data"><a class="anchor" href="#_verifying_replicated_data"></a> 129.3。验证复制的数据</h3>
<div class="paragraph">
<p>的<code>VerifyReplication</code> HBase中包含的MapReduce作业对两个不同群集之间的复制数据进行了系统的比较。在主群集上运行VerifyReplication作业，并为其提供对等ID和表名称以用于验证。您可以通过指定时间范围或特定系列进一步限制验证。职位的简称是<code>verifyrep</code> 。要运行作业，请使用如下命令：</p>
</div>
<div class="paragraph">
<p>+</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">$ HADOOP_CLASSPATH=`${HBASE_HOME}/bin/hbase classpath` &quot;${HADOOP_HOME}/bin/hadoop&quot; jar &quot;${HBASE_HOME}/hbase-server-VERSION.jar&quot; verifyrep --starttime=&lt;timestamp&gt; --endtime=&lt;timestamp&gt; --families=&lt;myFam&gt; &lt;ID&gt; &lt;tableName&gt;</code></pre>
</div>
</div>
<div class="paragraph">
<p>+的<code>VerifyReplication</code>命令打印出来<code>GOODROWS</code>和<code>BADROWS</code>计数器以指示已正确复制和未正确复制的行。</p>
</div>
</div>
<div class="sect2">
<h3 id="_detailed_information_about_cluster_replication"><a class="anchor" href="#_detailed_information_about_cluster_replication"></a> 129.4。有关群集复制的详细信息</h3>
<div class="imageblock">
<div class="content">
<img src="images/replication_overview.png" alt="复制概述">
</div>
<div class="title">图10。复制体系结构概述</div>
</div>
<div class="sect3">
<h4 id="_life_of_a_wal_edit"><a class="anchor" href="#_life_of_a_wal_edit"></a> 129.4.1。WAL的生活</h4>
<div class="paragraph">
<p>一次WAL编辑要经历几个步骤，才能复制到从属群集。</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>HBase客户端使用“放置”或“删除”操作来操纵HBase中的数据。</p>
</li>
<li>
<p>区域服务器以某种方式将请求写入WAL，如果未成功将其重播。</p>
</li>
<li>
<p>如果更改的单元格对应于要复制的列族，则将编辑添加到复制队列中。</p>
</li>
<li>
<p>在单独的线程中，作为批处理过程的一部分，从日志中读取编辑内容。仅保留符合复制条件的键值。可复制键值是其模式范围为GLOBAL的列族的一部分，不属于诸如<code>hbase:meta</code> ，不是源于目标从群集，并且尚未被目标从群集使用。</p>
</li>
<li>
<p>该编辑带有主服务器的UUID标记，并添加到缓冲区中。当缓冲区已满或读取器到达文件末尾时，缓冲区将发送到从属群集上的随机区域服务器。</p>
</li>
<li>
<p>区域服务器顺序读取编辑内容，并将其分成缓冲区，每个表一个缓冲区。读取所有编辑后，将使用HBase的普通客户端<a href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/client/Table.html">Table</a>刷新每个缓冲区。已经使用了数据的主服务器的UUID和从服务器的UUID保留在应用它们的编辑中，以防止复制循环。</p>
</li>
<li>
<p>在主服务器中，当前正在复制的WAL的偏移量已在ZooKeeper中注册。</p>
</li>
<li>
<p>插入编辑的前三个步骤是相同的。</p>
</li>
<li>
<p>同样，在单独的线程中，区域服务器以与上述相同的方式读取，过滤和编辑日志编辑。从属区域服务器不应答RPC调用。</p>
</li>
<li>
<p>主机休眠，然后重试可配置的次数。</p>
</li>
<li>
<p>如果从属区域服务器仍然不可用，则主服务器选择要复制到的新区域服务器子集，然后再次尝试发送编辑缓冲区。</p>
</li>
<li>
<p>同时，WAL被滚动并存储在ZooKeeper中的队列中。通过将其区域服务器<em class="firstterm">归档</em>的日志从区域服务器的日志目录移动到中央日志目录，这些日志将在复制线程的内存队列中更新其路径。</p>
</li>
<li>
<p>当从属群集最终可用时，将以与正常处理期间相同的方式应用缓冲区。然后，主区域服务器将复制停机期间累积的日志积压。</p>
</li>
</ol>
</div>
<div class="paragraph">
<div class="title">传播队列故障转移负载</div>
<p>复制处于活动状态时，源集群中的区域服务器的子集负责将编辑内容传送到接收器。像进程或节点崩溃一样，必须像其他所有区域服务器功能一样故障转移此责任。建议使用以下配置设置，以在源群集中其余活动服务器上保持复制活动的均匀分布：</p>
</div>
<div class="ulist">
<ul>
<li>
<p>组<code>replication.source.maxretriesmultiplier</code>至<code>300</code> 。</p>
</li>
<li>
<p>组<code>replication.source.sleepforretries</code>至<code>1</code> （1秒）。这个值，加上<code>replication.source.maxretriesmultiplier</code> ，导致重试周期持续约5分钟。</p>
</li>
<li>
<p>组<code>replication.sleep.before.failover</code>至<code>30000</code> （30秒）在源群集站点配置中。</p>
</li>
</ul>
</div>
<div class="paragraph">
<div class="title">复制期间保留标签</div>
<p>默认情况下，用于集群之间复制的编解码器会从单元中删除标记，例如单元级别的ACL。为了防止标签被剥离，可以使用不剥离标签的其他编解码器。配置<code>hbase.replication.rpc.codec</code>使用<code>org.apache.hadoop.hbase.codec.KeyValueCodecWithTags</code>在复制所涉及的源RegionServer和宿RegionServer上。<a href="https://issues.apache.org/jira/browse/HBASE-10322">HBASE-10322中</a>引入了此选项。</p>
</div>
</div>
<div class="sect3">
<h4 id="_replication_internals"><a class="anchor" href="#_replication_internals"></a> 129.4.2。复制内部</h4>
<div class="dlist">
<dl>
<dt class="hdlist1">ZooKeeper中的复制状态</dt>
<dd>
<p>HBase复制在ZooKeeper中保持其状态。默认情况下，状态包含在基本节点<em>/ hbase / replication中</em> 。该节点包含两个子节点， <code>Peers</code> znode和<code>RS</code> znode。</p>
</dd>
<dt class="hdlist1">的<code>Peers</code> Znode</dt>
<dd>
<p>的<code>peers</code> znode默认情况下存储在<em>/ hbase / replication / peers中</em> 。它由所有对等复制群集的列表以及每个群集的状态组成。每个对等方的值是其群集密钥，该密钥在HBase Shell中提供。群集密钥包含群集仲裁中的ZooKeeper节点列表，ZooKeeper仲裁的客户端端口以及该群集上HDFS中HBase的基本znode。</p>
</dd>
<dt class="hdlist1">的<code>RS</code> Znode</dt>
<dd>
<p>的<code>rs</code> znode包含需要复制的WAL日志的列表。此列表按区域服务器和区域服务器要将日志传送到的对等群集划分为一组队列。rs znode对于群集中的每个区域服务器都有一个子znode。子znode名称是区域服务器的主机名，客户端端口和起始代码。此列表包括活动区域服务器和死区服务器。</p>
</dd>
</dl>
</div>
</div>
<div class="sect3">
<h4 id="_choosing_region_servers_to_replicate_to"><a class="anchor" href="#_choosing_region_servers_to_replicate_to"></a> 129.4.3。选择要复制到的区域服务器</h4>
<div class="paragraph">
<p>当主群集区域服务器启动到从属群集的复制源时，它首先使用提供的群集密钥连接到从属服务器的ZooKeeper集成。然后，它扫描<em>rs /</em>目录以发现所有可用的接收器（接受输入的要复制的复制流的区域服务器），并使用默认值为10％的配置比率随机选择它们的子集。例如，如果从属群集有150台计算机，则将选择15个作为该主群集区域服务器发送的编辑的潜在收件人。由于此选择是由每个主区域服务器执行的，因此使用所有从属区域服务器的可能性非常高，并且此方法适用于任何大小的群集。例如，将10台计算机的主群集复制到5台计算机的从属群集，并以10％的比率进行复制，这将导致主群集区域服务器随机选择一台计算机。</p>
</div>
<div class="paragraph">
<p>每个主群集的区域服务器将一个ZooKeeper监视程序放置在从群集的<em>$ {zookeeper.znode.parent} / rs</em>节点上。该监视用于监视从属群集组成的变化。当从从群集中删除节点时，或者如果节点出现故障或重新启动，则主群集的区域服务器将通过选择要复制到的新的从属区域服务器池来做出响应。</p>
</div>
</div>
<div class="sect3">
<h4 id="_keeping_track_of_logs"><a class="anchor" href="#_keeping_track_of_logs"></a> 129.4.4。记录日志</h4>
<div class="paragraph">
<p>每个主群集区域服务器在复制znodes层次结构中都有自己的znode。每个对等群集包含一个znode（如果创建5个从属群集，则创建5个znode），并且每个群集都包含要处理的WAL队列。这些队列中的每个队列都将跟踪由该区域服务器创建的WAL，但是它们的大小可以不同。例如，如果一个从集群在一段时间内不可用，则不应删除WAL，因此在处理其他从集群时，它们需要留在队列中。有关<a href="#rs.failover.details">示例</a> ，请参见<a href="#rs.failover.details">rs.failover.details</a> 。</p>
</div>
<div class="paragraph">
<p>实例化源时，它包含区域服务器正在写入的当前WAL。在日志滚动期间，新文件将在可用之前将其添加到每个从属群集的znode的队列中。这样可以确保所有消息源在区域服务器能够向其添加编辑之前都知道一个新日志，但是此操作现在更加昂贵。当复制线程无法从文件中读取更多条目（因为它到达最后一个块的末尾）并且队列中还有其他文件时，将丢弃队列项。这意味着，如果源是最新的并且从区域服务器写入的日志中复制，则读取当前文件的“结尾”将不会删除队列中的项目。</p>
</div>
<div class="paragraph">
<p>如果不再使用日志或日志数量超过限制，则可以将其归档<code>hbase.regionserver.maxlogs</code>因为插入速率比刷新区域快。归档日志后，将通知源线程该日志的路径已更改。如果某个特定源已经完成了归档日志，它将仅忽略该消息。如果日志在队列中，则路径将在内存中更新。如果当前正在复制日志，则将自动进行更改，以使阅读器在已移动时不会尝试打开文件。因为移动文件是NameNode操作，所以如果读取器当前正在读取日志，则不会生成任何异常。</p>
</div>
</div>
<div class="sect3">
<h4 id="_reading_filtering_and_sending_edits"><a class="anchor" href="#_reading_filtering_and_sending_edits"></a> 129.4.5。读取，过滤和发送编辑</h4>
<div class="paragraph">
<p>默认情况下，源尝试从WAL读取并将日志条目尽快发送到接收器。速度受日志条目筛选的限制，将仅保留范围为GLOBAL且不属于目录表的键值。速度也受每个从属要复制的编辑列表的总大小限制，默认情况下，限制为64 MB。使用此配置，具有三个从属的主群集区域服务器最多将使用192 MB来存储要复制的数据。这不考虑已过滤但未收集垃圾的数据。</p>
</div>
<div class="paragraph">
<p>一旦最大编辑量被缓冲或读取器进入WAL的结尾，源线程将停止读取并随机选择要复制到的接收器（从仅保留从属区域服务器的子集而生成的列表中） 。它直接向选定的区域服务器发出RPC，并等待方法返回。如果RPC成功，则源将确定当前文件是否已清空，或者它包含更多需要读取的数据。如果文件已清空，则源将删除队列中的znode。否则，它将在日志的znode中注册新的偏移量。如果RPC引发异常，则源将重试10次，然后再尝试查找其他接收器。</p>
</div>
</div>
<div class="sect3">
<h4 id="_cleaning_logs"><a class="anchor" href="#_cleaning_logs"></a> 129.4.6。清洁日志</h4>
<div class="paragraph">
<p>如果未启用复制，则主服务器的日志清理线程将使用配置的TTL删除旧日志。这种基于TTL的方法不适用于复制，因为超出其TTL的已存档日志可能仍在队列中。默认行为得到了增强，因此，如果日志超出其TTL，则清理线程将查找每个队列，直到找到日志为止，同时将已找到的队列缓存。如果在任何队列中都找不到该日志，则将删除该日志。下次清理过程需要查找日志时，它将使用其缓存列表开始。</p>
</div>
</div>
<div class="sect3">
<h4 id="rs.failover.details"><a class="anchor" href="#rs.failover.details"></a> 129.4.7。区域服务器故障转移</h4>
<div class="paragraph">
<p>当没有区域服务器发生故障时，跟踪ZooKeeper中的日志不会增加任何价值。不幸的是，区域服务器确实发生了故障，并且由于ZooKeeper的可用性很高，因此在发生故障时管理队列的传输非常有用。</p>
</div>
<div class="paragraph">
<p>每个主群集区域服务器都会在每个其他区域服务器上保留一个监视程序，以便在一个服务器死亡时得到通知（就像主服务器一样）。当发生故障时，他们都竞相创建一个名为<code>lock</code>在包含其队列的死区服务器的znode中。成功创建它的区域服务器然后将所有队列转移到自己的znode，一次一次，因为ZooKeeper不支持重命名队列。队列全部传输后，将从旧位置删除队列。恢复的znode将使用从属群集的ID重命名，并附加死服务器的名称。</p>
</div>
<div class="paragraph">
<p>接下来，主群集区域服务器为每个复制的队列创建一个新的源线程，并且每个源线程都遵循读取/过滤器/发送模式。主要区别在于那些队列将永远不会收到新数据，因为它们不属于新的区域服务器。当阅读器到达最后一个日志的末尾时，队列的znode被删除，主群集区域服务器关闭该复制源。</p>
</div>
<div class="paragraph">
<p>给定一个具有3个区域服务器的主群集，该服务器复制到ID为的单个从属<code>2</code> ，以下层次结构表示znodes布局在某个时间点可能是什么。区域服务器的znode都包含一个<code>peers</code>包含单个队列的znode。队列中的znode名称以以下形式表示HDFS上的实际文件名<code>address,port.timestamp</code> 。</p>
</div>
<div class="listingblock">
<div class="content">
<pre>/hbase/replication/rs/
  1.1.1.1,60020,123456780/
    2/
      1.1.1.1,60020.1234  (Contains a position)
      1.1.1.1,60020.1265
  1.1.1.2,60020,123456790/
    2/
      1.1.1.2,60020.1214  (Contains a position)
      1.1.1.2,60020.1248
      1.1.1.2,60020.1312
  1.1.1.3,60020,    123456630/
    2/
      1.1.1.3,60020.1280  (Contains a position)</pre>
</div>
</div>
<div class="paragraph">
<p>假定1.1.1.2丢失了其ZooKeeper会话。幸存者将争分夺秒，并任意赢得1.1.1.3的胜利。然后，它将通过附加死服务器的名称来开始将所有队列传输到其本地对等节点znode。在1.1.1.3能够清理旧的znode之前，布局将如下所示：</p>
</div>
<div class="listingblock">
<div class="content">
<pre>/hbase/replication/rs/
  1.1.1.1,60020,123456780/
    2/
      1.1.1.1,60020.1234  (Contains a position)
      1.1.1.1,60020.1265
  1.1.1.2,60020,123456790/
    lock
    2/
      1.1.1.2,60020.1214  (Contains a position)
      1.1.1.2,60020.1248
      1.1.1.2,60020.1312
  1.1.1.3,60020,123456630/
    2/
      1.1.1.3,60020.1280  (Contains a position)

    2-1.1.1.2,60020,123456790/
      1.1.1.2,60020.1214  (Contains a position)
      1.1.1.2,60020.1248
      1.1.1.2,60020.1312</pre>
</div>
</div>
<div class="paragraph">
<p>一段时间后，但在1.1.1.3能够完成从1.1.1.2复制最后一个WAL之前，它也死了。在普通队列中还创建了一些新日志。然后，最后一个区域服务器将尝试锁定1.1.1.3的znode并将开始传输所有队列。新的布局将是：</p>
</div>
<div class="listingblock">
<div class="content">
<pre>/hbase/replication/rs/
  1.1.1.1,60020,123456780/
    2/
      1.1.1.1,60020.1378  (Contains a position)

    2-1.1.1.3,60020,123456630/
      1.1.1.3,60020.1325  (Contains a position)
      1.1.1.3,60020.1401

    2-1.1.1.2,60020,123456790-1.1.1.3,60020,123456630/
      1.1.1.2,60020.1312  (Contains a position)
  1.1.1.3,60020,123456630/
    lock
    2/
      1.1.1.3,60020.1325  (Contains a position)
      1.1.1.3,60020.1401

    2-1.1.1.2,60020,123456790/
      1.1.1.2,60020.1312  (Contains a position)</pre>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_replication_metrics"><a class="anchor" href="#_replication_metrics"></a> 129.5。复制指标</h3>
<div class="paragraph">
<p>以下度量标准在全局区域服务器级别和对等级别公开：</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1"><code>source.sizeOfLogQueue</code></dt>
<dd>
<p>复制源上要处理的WAL数量（不包括正在处理的WAL）</p>
</dd>
<dt class="hdlist1"><code>source.shippedOps</code></dt>
<dd>
<p>运送的突变数量</p>
</dd>
<dt class="hdlist1"><code>source.logEditsRead</code></dt>
<dd>
<p>在复制源处从WAL读取的突变数</p>
</dd>
<dt class="hdlist1"><code>source.ageOfLastShippedOp</code></dt>
<dd>
<p>复制源出厂的最后一批的使用期限</p>
</dd>
<dt class="hdlist1"><code>source.completedLogs</code></dt>
<dd>
<p>已完成向与该源关联的对等方的已确认发送的预写日志文件的数量。该指标的增加是HBase复制正常操作的一部分。</p>
</dd>
<dt class="hdlist1"><code>source.completedRecoverQueues</code></dt>
<dd>
<p>此源已完成发送到关联对等方的恢复队列数。面对失败的区域服务器，此指标的增加是HBase复制正常恢复的一部分。</p>
</dd>
<dt class="hdlist1"><code>source.uncleanlyClosedLogs</code></dt>
<dd>
<p>面对未完全关闭的文件，在达到可读条目的末尾之后，复制系统认为已完成的预写日志文件数。</p>
</dd>
<dt class="hdlist1"><code>source.ignoredUncleanlyClosedLogContentsInBytes</code></dt>
<dd>
<p>如果未完全关闭预写日志文件，则可能存在某些已部分序列化的条目。该度量标准包含HBase复制系统认为在面对未完全关闭的文件时跳过的文件末尾保留的此类条目的字节数。这些字节应该在不同的文件中，或者表示未确认的客户端写入。</p>
</dd>
<dt class="hdlist1"><code>source.restartedLogReading</code></dt>
<dd>
<p>HBase复制系统检测到未能正确解析干净关闭的预写日志文件的次数。在这种情况下，系统将从头开始重播整个日志，以确保相关对等方不会确认任何编辑失败。该指标的增加表示HBase复制系统在正确处理基础分布式存储系统中的故障时遇到困难。不会发生数据丢失，但是您应该检查Region Server日志文件以获取失败的详细信息。</p>
</dd>
<dt class="hdlist1"><code>source.repeatedLogFileBytes</code></dt>
<dd>
<p>当HBase复制系统确定需要重播给定的预写日志文件时，该度量标准将增加复制系统认为在重新开始之前相关联的对等方已经确认的字节数。</p>
</dd>
<dt class="hdlist1"><code>source.closedLogsWithUnknownFileLength</code></dt>
<dd>
<p>当HBase复制系统认为它位于预写日志文件的末尾但无法确定基础分布式存储系统中该文件的长度时，此值增加。由于复制系统无法确定可读条目的末尾是否与文件的预期末尾对齐，因此可能表示数据丢失。您应该检查Region Server日志文件以获取失败的详细信息。</p>
</dd>
</dl>
</div>
</div>
<div class="sect2">
<h3 id="_replication_configuration_options"><a class="anchor" href="#_replication_configuration_options"></a> 129.6。复制配置选项</h3>
<table class="tableblock frame-all grid-all spread">
<colgroup>
<col style="width:33%">
<col style="width:33%">
<col style="width:33%">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">选项</th>
<th class="tableblock halign-left valign-top">描述</th>
<th class="tableblock halign-left valign-top">默认</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">zookeeper.znode.parent</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">用于HBase的基本ZooKeeper znode的名称</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">/ hbase</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">zookeeper.znode.replication</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">用于复制的基本znode的名称</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">复制</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">zookeeper.znode.replication.peers</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">对等znode的名称</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">同行</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">zookeeper.znode.replication.peers.state</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">对等状态znode的名称</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">同伴国家</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">zookeeper.znode.replication.rs</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">rs znode的名称</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">rs</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">hbase.replication</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">在给定群集上是启用还是禁用复制</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">假</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">故障转移之前的睡眠</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">在尝试复制死区服务器的WAL队列之前，工作人员应该睡多少毫秒。</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">复制执行者工人</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">给定的区域服务器应尝试同时进行故障转移的区域服务器的数量。</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1个</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="_monitoring_replication_status"><a class="anchor" href="#_monitoring_replication_status"></a> 129.7。监视复制状态</h3>
<div class="paragraph">
<p>您可以使用HBase Shell命令<code>status 'replication'</code>监视群集上的复制状态。该命令具有三种变体：* <code>status 'replication'</code> —打印每个源及其接收器的状态，按主机名排序。* <code>status 'replication', 'source'</code> —打印每个复制源的状态，按主机名排序。* <code>status 'replication', 'sink'</code> —打印每个复制接收器的状态，按主机名排序。</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="ops.backup"><a class="anchor" href="#ops.backup"></a> 130。HBase备份</h2>
<div class="sectionbody">
<div class="paragraph">
<p>执行HBase备份有两种主要策略：在完全关闭集群的情况下进行备份，以及在活动集群上进行备份。每种方法都有优点和缺点。</p>
</div>
<div class="paragraph">
<p>有关更多信息，请参见Sematext博客上的<a href="http://blog.sematext.com/2011/03/11/hbase-backup-options/">HBase备份选项</a> 。</p>
</div>
<div class="sect2">
<h3 id="ops.backup.fullshutdown"><a class="anchor" href="#ops.backup.fullshutdown"></a> 130.1。完全关机备份</h3>
<div class="paragraph">
<p>某些环境可以忍受其HBase群集的定期完全关闭，例如，如果正在使用它的后端分析功能并且不为前端网页提供服务。这样做的好处是NameNode / Master区域服务器处于关闭状态，因此不会丢失对StoreFiles或元数据的任何运行中更改。明显的缺点是群集已关闭。这些步骤包括：</p>
</div>
<div class="sect3">
<h4 id="ops.backup.fullshutdown.stop"><a class="anchor" href="#ops.backup.fullshutdown.stop"></a> 130.1.1。停止HBase</h4>

</div>
<div class="sect3">
<h4 id="ops.backup.fullshutdown.distcp"><a class="anchor" href="#ops.backup.fullshutdown.distcp"></a> 130.1.2。Distcp</h4>
<div class="paragraph">
<p>Distcp可用于将HDFS中HBase目录的内容复制到另一个目录中的同一群集，或复制到另一个群集。</p>
</div>
<div class="paragraph">
<p>注意：Distcp在这种情况下可以工作，因为群集已关闭并且对文件没有进行中的编辑。通常不建议在活动群集上对HBase目录中的文件进行分区。</p>
</div>
</div>
<div class="sect3">
<h4 id="ops.backup.fullshutdown.restore"><a class="anchor" href="#ops.backup.fullshutdown.restore"></a> 130.1.3。恢复（如果需要）</h4>
<div class="paragraph">
<p>HDFS中hbase目录的备份将通过distcp复制到“真实” hbase目录中。复制这些文件的操作将创建新的HDFS元数据，这就是为什么这种还原无需从HBase备份时还原NameNode编辑的原因，因为它是特定HDFS目录的还原（通过distcp） （即HBase部分）而不是整个HDFS文件系统。</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="ops.backup.live.replication"><a class="anchor" href="#ops.backup.live.replication"></a> 130.2。实时群集备份-复制</h3>
<div class="paragraph">
<p>该方法假定存在第二个群集。有关更多信息，请参见有关<a href="http://hbase.apache.org/replication.html">复制</a>的HBase页面。</p>
</div>
</div>
<div class="sect2">
<h3 id="ops.backup.live.copytable"><a class="anchor" href="#ops.backup.live.copytable"></a> 130.3。实时群集备份-CopyTable</h3>
<div class="paragraph">
<p><a href="#copytable">copytable</a>实用程序既可以用于将数据从一个表复制到同一集群中的另一个表，也可以将数据复制到另一个集群上的另一个表。</p>
</div>
<div class="paragraph">
<p>由于群集已启动，因此存在复制过程中可能会丢失编辑内容的风险。</p>
</div>
</div>
<div class="sect2">
<h3 id="ops.backup.live.export"><a class="anchor" href="#ops.backup.live.export"></a> 130.4。实时群集备份-导出</h3>
<div class="paragraph">
<p><a href="#export">导出</a>方法将表的内容转储到同一群集上的HDFS。要恢复数据，将使用<a href="#import">导入</a>实用程序。</p>
</div>
<div class="paragraph">
<p>由于群集已启动，因此存在导出过程中可能会丢失编辑内容的风险。</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="ops.snapshots"><a class="anchor" href="#ops.snapshots"></a> 131。HBase快照</h2>
<div class="sectionbody">
<div class="paragraph">
<p>HBase快照允许您对表进行快照，而对区域服务器没有太大影响。快照，克隆和还原操作不涉及数据复制。另外，将快照导出到另一个群集不会对区域服务器产生影响。</p>
</div>
<div class="paragraph">
<p>在0.94.6版之前，备份或克隆表的唯一方法是使用CopyTable / ExportTable，或者在禁用表后复制HDFS中的所有hfile。这些方法的缺点是，可能会降低区域服务器的性能（“复制/导出表”），或者需要禁用该表，这意味着无法进行读取或写入。这通常是不可接受的。</p>
</div>
<div class="sect2">
<h3 id="ops.snapshots.configuration"><a class="anchor" href="#ops.snapshots.configuration"></a> 131.1。组态</h3>
<div class="paragraph">
<p>要打开快照支持，只需设置<code>hbase.snapshot.enabled</code>属性为true。（快照默认在0.95+中启用，默认情况下在0.94.6+中禁用）</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">  &lt;property&gt;
    &lt;name&gt;hbase.snapshot.enabled&lt;/name&gt;
    &lt;value&gt;<span class="predefined-constant">true</span>&lt;/value&gt;
  &lt;/property&gt;</code></pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="ops.snapshots.takeasnapshot"><a class="anchor" href="#ops.snapshots.takeasnapshot"></a> 131.2。拍摄快照</h3>
<div class="paragraph">
<p>您可以对表进行快照，而不管它是启用还是禁用。快照操作不涉及任何数据复制。</p>
</div>
<div class="listingblock">
<div class="content">
<pre>$ ./bin/hbase shell
hbase&gt; snapshot 'myTable', 'myTableSnapshot-122112'</pre>
</div>
</div>
<div class="paragraph">
<div class="title">拍摄快照而不冲洗</div>
<p>默认行为是在拍摄快照之前执行刷新内存中的数据的操作。这意味着快照中包括内存中的数据。在大多数情况下，这是所需的行为。但是，如果您的设置可以忍受快照中排除的内存中的数据，则可以使用<code>SKIP_FLUSH</code>的选项<code>snapshot</code>命令以在拍摄快照时禁用和刷新。</p>
</div>
<div class="listingblock">
<div class="content">
<pre>hbase&gt; snapshot 'mytable', 'snapshot123', {SKIP_FLUSH =&gt; true}</pre>
</div>
</div>
<div class="admonitionblock warning">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-warning" title="警告"></i>
</td>
<td class="content">无法确定或预测给定快照中是否包含非常并发的插入或更新，无论启用还是禁用了刷新。快照只是一个时间段内表的表示。快照操作到达每个区域服务器所需的时间可能从几秒钟到一分钟不等，具体取决于资源负载和硬件或网络的速度以及其他因素。也没有办法知道给定的插入或更新是在内存中还是已刷新。
</td>
</tr>
</tbody></table>
</div>
<div class="paragraph">
<div class="title">使用TTL拍摄快照</div>
<p>快照的生命周期与创建快照的表无关。尽管表中的数据可以使用TTL存储，但是包含它们的数据文件将被快照冻结。过期的单元所消耗的空间不会像压缩那样通过普通的表管理来回收。虽然这是预期的，但在规模上可能会带来不便。当管理许多快照并且TTL中的各种表中的数据已过期时，快照的一些可选TTL（和可选的默认TTL）概念可能会很有用。</p>
</div>
<div class="listingblock">
<div class="content">
<pre>hbase&gt; snapshot 'mytable', 'snapshot1234', {TTL =&gt; 86400}</pre>
</div>
</div>
<div class="paragraph">
<p>上面的命令创建快照<code>snapshot1234</code> TTL为86400秒（24小时），因此快照应在24小时后清除</p>
</div>
<div class="ulist">
<div class="title">默认快照TTL：</div>
<ul>
<li>
<p>默认为永远</p>
</li>
<li>
<p>用户指定的带有配置的默认TTL<code>hbase.master.snapshot.ttl</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>创建快照时，如果未指定以秒为单位的TTL，则默认情况下不会自动删除快照。即它将被永久保留，直到被手动删除。但是，用户可以通过在几秒钟内为密钥提供默认TTL来更新此默认TTL行为： <code>hbase.master.snapshot.ttl</code> 。此配置的值0表示TTL：永远</p>
</div>
<div class="paragraph">
<div class="title">在正在运行的群集上启用/禁用快照自动清除：</div>
<p>默认情况下，将为所有新群集启用基于TTL的快照自动清除。在任何时候，如果由于某些快照还原活动或任何其他原因而应停止快照清理，建议使用shell命令将其禁用：</p>
</div>
<div class="listingblock">
<div class="content">
<pre>hbase&gt; snapshot_cleanup_switch false</pre>
</div>
</div>
<div class="paragraph">
<p>我们可以使用以下方法重新启用它：</p>
</div>
<div class="listingblock">
<div class="content">
<pre>hbase&gt; snapshot_cleanup_switch true</pre>
</div>
</div>
<div class="paragraph">
<p>带有switch false的shell命令将禁用基于TTL的快照自动清除活动，并返回该活动的先前状态（true：已在运行，false：已被禁用）</p>
</div>
<div class="paragraph">
<p>以上命令的示例输出：</p>
</div>
<div class="listingblock">
<div class="content">
<pre>Previous snapshot cleanup state : true
Took 0.0069 seconds
=&gt; "true"</pre>
</div>
</div>
<div class="paragraph">
<p>我们可以使用以下命令查询是否为集群启用了快照自动清除功能：</p>
</div>
<div class="listingblock">
<div class="content">
<pre>hbase&gt; snapshot_cleanup_enabled</pre>
</div>
</div>
<div class="paragraph">
<p>该命令将以true / false返回输出。</p>
</div>
</div>
<div class="sect2">
<h3 id="ops.snapshots.list"><a class="anchor" href="#ops.snapshots.list"></a> 131.3。列出快照</h3>
<div class="paragraph">
<p>列出所有拍摄的快照（通过打印名称和相关信息）。</p>
</div>
<div class="listingblock">
<div class="content">
<pre>$ ./bin/hbase shell
hbase&gt; list_snapshots</pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="ops.snapshots.delete"><a class="anchor" href="#ops.snapshots.delete"></a> 131.4。删除快照</h3>
<div class="paragraph">
<p>您可以删除快照，如果不再需要，将删除为该快照保留的文件。</p>
</div>
<div class="listingblock">
<div class="content">
<pre>$ ./bin/hbase shell
hbase&gt; delete_snapshot 'myTableSnapshot-122112'</pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="ops.snapshots.clone"><a class="anchor" href="#ops.snapshots.clone"></a> 131.5。从快照克隆表</h3>
<div class="paragraph">
<p>您可以从快照中创建一个新表（克隆操作），该表具有与拍摄快照时相同的数据。克隆操作不涉及数据副本，并且对克隆表的更改不会影响快照或原始表。</p>
</div>
<div class="listingblock">
<div class="content">
<pre>$ ./bin/hbase shell
hbase&gt; clone_snapshot 'myTableSnapshot-122112', 'myNewTestTable'</pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="ops.snapshots.restore"><a class="anchor" href="#ops.snapshots.restore"></a> 131.6。恢复快照</h3>
<div class="paragraph">
<p>恢复操作需要禁用该表，并且该表将恢复到拍摄快照时的状态，并根据需要更改数据和架构。</p>
</div>
<div class="listingblock">
<div class="content">
<pre>$ ./bin/hbase shell
hbase&gt; disable 'myTable'
hbase&gt; restore_snapshot 'myTableSnapshot-122112'</pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-note" title="注意"></i>
</td>
<td class="content">由于复制工作在日志级别，快照工作在文件系统级别，因此还原后，副本将与主副本处于不同状态。如果要使用还原，则需要停止复制并重做引导程序。
</td>
</tr>
</tbody></table>
</div>
<div class="paragraph">
<p>如果由于客户端行为不当导致部分数据丢失，则可以从快照克隆表并使用Map-Reduce作业从快照中复制所需的数据，而不是需要禁用表的完全还原。克隆到主要的。</p>
</div>
</div>
<div class="sect2">
<h3 id="ops.snapshots.acls"><a class="anchor" href="#ops.snapshots.acls"></a> 131.7。快照操作和ACL</h3>
<div class="paragraph">
<p>如果将安全性与AccessController协处理器一起使用（请参阅<a href="#hbase.accesscontrol.configuration">hbase.accesscontrol.configuration</a> ），则只有全局管理员才能创建，克隆或还原快照，并且这些操作不会捕获ACL权限。这意味着还原表将保留现有表的ACL权限，而克隆表时将创建一个没有ACL权限的新表，直到管理员添加它们为止。</p>
</div>
</div>
<div class="sect2">
<h3 id="ops.snapshots.export"><a class="anchor" href="#ops.snapshots.export"></a> 131.8。导出到另一个集群</h3>
<div class="paragraph">
<p>ExportSnapshot工具会将与快照相关的所有数据（hfile，日志，快照元数据）复制到另一个群集。该工具执行类似于distcp的Map-Reduce作业，以在两个集群之间复制文件，并且由于它在文件系统级别工作，因此hbase集群不必处于联机状态。</p>
</div>
<div class="paragraph">
<p>要使用16个映射器将名为MySnapshot的快照复制到HBase群集srv2（hdfs：/// srv2：8082 / hbase）：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bourne">$ bin/hbase org.apache.hadoop.hbase.snapshot.ExportSnapshot -snapshot MySnapshot -copy-to hdfs://srv2:8082/hbase -mappers 16</code></pre>
</div>
</div>
<div class="paragraph">
<div class="title">限制带宽消耗</div>
<p>您可以通过指定快照来限制导出快照时的带宽消耗。 <code>-bandwidth</code>参数，该参数需要一个表示每秒兆字节的整数。下面的示例将上面的示例限制为200 MB /秒。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bourne">$ bin/hbase org.apache.hadoop.hbase.snapshot.ExportSnapshot -snapshot MySnapshot -copy-to hdfs://srv2:8082/hbase -mappers 16 -bandwidth 200</code></pre>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="ops.capacity"><a class="anchor" href="#ops.capacity"></a> 132。容量规划和区域调整</h2>
<div class="sectionbody">
<div class="paragraph">
<p>在规划HBase群集的容量并执行初始配置时，有一些注意事项。首先要对HBase如何在内部处理数据有扎实的了解。</p>
</div>
<div class="sect2">
<h3 id="ops.capacity.nodes"><a class="anchor" href="#ops.capacity.nodes"></a> 132.1。节点数和硬件/ VM配置</h3>
<div class="sect3">
<h4 id="ops.capacity.nodes.datasize"><a class="anchor" href="#ops.capacity.nodes.datasize"></a> 132.1.1。物理数据大小</h4>
<div class="paragraph">
<p>磁盘上的物理数据大小与数据的逻辑大小不同，并且受以下因素影响：</p>
</div>
<div class="ulist">
<ul>
<li>
<p>HBase开销增加</p>
</li>
<li>
<p>请参阅<a href="#keyvalue">keyvalue</a>和<a href="#keysize">keysize</a> 。每个键值（单元格）至少24个字节可以更多。小键/值意味着更多的相对开销。</p>
</li>
<li>
<p>KeyValue实例聚合到块中，并对其建立索引。索引也必须存储。块大小可以在每个ColumnFamily的基础上进行配置。参见<a href="#regions.arch">regions.arch</a> 。</p>
</li>
<li>
<p>通过<a href="#compression">压缩</a>和数据块编码来减少，具体取决于数据。另请参<a href="http://search-hadoop.com/m/lL12B1PFVhp1">见此线程</a> 。您可能需要测试哪种压缩和编码（如果有）对您的数据有意义。</p>
</li>
<li>
<p>通过区域服务器<a href="#wal">沃尔</a>的大小增加（通常是固定的，可以忽略不计-每个RS小于RS内存大小的一半）。</p>
</li>
<li>
<p>通过HDFS复制增加-通常为x3。</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>除了存储数据所需的磁盘空间之外，由于区域计数和大小的某些实际限制，一个RS可能无法提供任意数量的数据（请参阅<a href="#ops.capacity.regions">ops.capacity.regions</a> ）。</p>
</div>
</div>
<div class="sect3">
<h4 id="ops.capacity.nodes.throughput"><a class="anchor" href="#ops.capacity.nodes.throughput"></a> 132.1.2。读/写吞吐量</h4>
<div class="paragraph">
<p>节点的数量也可以由读取和/或写入所需的吞吐量来驱动。每个节点可以获得的吞吐量在很大程度上取决于数据（特别是键/值大小）和请求模式，以及节点和系统配置。如果峰值负载可能是导致节点数量增加的主要驱动力，则应该对峰值负载进行规划。PerformanceEvaluation和<a href="#ycsb">ycsb</a>工具可用于测试单节点或测试集群。</p>
</div>
<div class="paragraph">
<p>对于写操作，由于每个区域服务器只有一个活动的WAL，通常每个RS可以期望5-15Mb / s。没有很好的读取估计，因为它很大程度上取决于数据，请求和缓存命中率。 <a href="#perf.casestudy">perf.casestudy</a>可能会有所帮助。</p>
</div>
</div>
<div class="sect3">
<h4 id="ops.capacity.nodes.gc"><a class="anchor" href="#ops.capacity.nodes.gc"></a> 132.1.3。JVM GC限制</h4>
<div class="paragraph">
<p>由于GC的成本，RS当前无法利用非常大的堆。除了在每台计算机上运行多个VM之外，也没有一种很好的方法在每个服务器上运行多个RS-es。因此，建议为一个RS专用〜20-24Gb或更少的内存。大堆大小需要GC调整。见<a href="#gcpause">gcpause</a> ， <a href="#trouble.log.gc">trouble.log.gc</a>和其他地方（TODO：在哪里？）</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="ops.capacity.regions"><a class="anchor" href="#ops.capacity.regions"></a> 132.2。确定区域数和大小</h3>
<div class="paragraph">
<p>通常，较少的区域可以使集群运行得更顺畅（您随时可以稍后手动分割较大的区域（如有必要），以在集群上分散数据或请求负载）；每个RS 20-200个区域是一个合理的范围。不能直接配置区域的数量（除非您完全<a href="#disable.splitting">禁用</a> ）。调整区域大小以达到给定表大小的目标区域大小。</p>
</div>
<div class="paragraph">
<p>为多个表配置区域时，请注意，大多数区域设置都可以通过<a href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/HTableDescriptor.html">HTableDescriptor</a>以及shell命令在每个表的基础上进行<a href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/HTableDescriptor.html">设置</a> 。这些设置将覆盖<code>hbase-site.xml</code> 。如果您的表具有不同的工作负载/用例，这将很有用。</p>
</div>
<div class="paragraph">
<p>还要注意的是，在此处讨论区域大小时， <em>没有（也不应该）考虑HDFS复制因子，而应该考虑其他因素<a href="#ops.capacity.nodes.datasize">ops.capacity.nodes.datasize</a> 。</em> 因此，如果您的数据通过HDFS压缩和复制3种方式，则“ 9 Gb区域”表示9 Gb的压缩数据。HDFS复制因子仅影响磁盘使用情况，对于大多数HBase代码而言是看不见的。</p>
</div>
<div class="sect3">
<h4 id="_viewing_the_current_number_of_regions"><a class="anchor" href="#_viewing_the_current_number_of_regions"></a> 132.2.1。查看当前区域数</h4>
<div class="paragraph">
<p>您可以使用HMaster UI查看给定表的当前区域数。在“ <span class="label">表”</span>部分中，“在线区域”列中列出了每个表的<span class="label">在线区域数</span> 。此总数仅包括内存中状态，不包括禁用或脱机区域。如果您不想使用HMaster UI，则可以通过计算/ hbase /的子目录数来确定区域数</p><table><tbody><tr><td>/ HDFS中的/子目录，或通过运行<code>bin/hbase hbck</code>命令。这些方法中的每一个可能会返回略有不同的数字，具体取决于每个区域的状态。
</td></tr></tbody></table></div>
</div>
<div class="sect3">
<h4 id="ops.capacity.regions.count"><a class="anchor" href="#ops.capacity.regions.count"></a> 132.2.2。每个RS的区域数-上限</h4>
<div class="paragraph">
<p>在生产环境中，如果您有大量数据，通常会担心每个服务器可以拥有的最大区域数。 <a href="#too_many_regions">太多地区</a>对此进行了技术讨论。基本上，最大区域数主要由内存存储使用情况决定。每个地区都有自己的记忆库；这些长到可配置的大小；通常在128-256 MB范围内，请参见<a href="#hbase.hregion.memstore.flush.size">hbase.hregion.memstore.flush.size</a> 。每个列族存在一个内存存储（因此，如果表中有一个CF，则每个区域只有一个）。RS将总内存的一部分分配给其内存存储（请参阅<a href="#hbase.regionserver.global.memstore.size">hbase.regionserver.global.memstore.size</a> ）。如果超出此内存（内存存储使用过多），则可能导致不良后果，例如服务器无响应或压缩风暴。每个RS的区域数（假设一张表）的一个很好的起点是：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">((RS memory) * (total memstore fraction)) / ((memstore size)*(<span class="error">#</span> column families))</code></pre>
</div>
</div>
<div class="paragraph">
<p>此公式是伪代码。这是两个使用实际可调参数的公式，第一个公式用于HBase 0.98+，第二个公式用于HBase0.94.x。</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">HBase 0.98.x</dt>
</dl>
</div>
<div class="listingblock">
<div class="content">
<pre>((RS Xmx) * hbase.regionserver.global.memstore.size) / (hbase.hregion.memstore.flush.size * (# column families))</pre>
</div>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">HBase 0.94.x</dt>
</dl>
</div>
<div class="listingblock">
<div class="content">
<pre>((RS Xmx) * hbase.regionserver.global.memstore.upperLimit) / (hbase.hregion.memstore.flush.size * (# column families))+</pre>
</div>
</div>
<div class="paragraph">
<p>如果给定的RegionServer具有16 GB的RAM（使用默认设置），则该公式计算出每个RS 16384 * 0.4 / 128〜51个区域是一个起点。该公式可以扩展到多个表。如果它们都具有相同的配置，则仅使用家族总数。</p>
</div>
<div class="paragraph">
<p>这个数字可以调整；上面的公式假定您所有区域的填充率大致相同。如果只有一部分区域将被主动写入，则可以将结果除以该部分以得到更大的区域数。然后，即使所有区域都被写入，所有区域的内存存储也不会被均匀填充，即使它们被覆盖，最终也会出现抖动（由于并发刷新的数量有限）。因此，一个区域可能比起点多出2-3倍；然而，数量增加带来的风险增加。</p>
</div>
<div class="paragraph">
<p>对于繁重的工作负载，可以在配置中增加内存存储部分，但以块缓存为代价；这也将允许人们拥有更多区域。</p>
</div>
</div>
<div class="sect3">
<h4 id="ops.capacity.regions.mincount"><a class="anchor" href="#ops.capacity.regions.mincount"></a> 132.2.3。每个RS的区域数-下限</h4>
<div class="paragraph">
<p>HBase通过在许多服务器上具有区域来扩展。因此，如果您有2个区域可存储16GB数据，则在20节点的计算机上，您的数据将仅集中在少数计算机上-几乎整个群集都将处于空闲状态。实际上，这还不够强调，因为一个常见的问题是将200MB数据加载到HBase中，然后想知道为什么很棒的10节点集群什么也不做。</p>
</div>
<div class="paragraph">
<p>另一方面，如果您有大量数据，则可能还需要使用更多区域，以避免区域过大。</p>
</div>
</div>
<div class="sect3">
<h4 id="ops.capacity.regions.size"><a class="anchor" href="#ops.capacity.regions.size"></a> 132.2.4。最大区域大小</h4>
<div class="paragraph">
<p>对于生产方案中的大型桌子，最大区域大小主要受压实限制-特别是非常大的压实。严重，会降低群集性能。当前，建议的最大区域大小是10-20Gb，最佳是5-10Gb。对于较旧的0.90.x代码库，regionsize的上限约为4Gb，默认值为256Mb。</p>
</div>
<div class="paragraph">
<p>通常将区域划分为两个的大小通过<a href="#hbase.hregion.max.filesize">hbase.hregion.max.filesize进行</a>配置；有关详细信息，请参见<a href="#arch.region.splits">arch.region.splits</a> 。</p>
</div>
<div class="paragraph">
<p>如果您无法很好地估计表的大小，则最好在开始时坚持默认的区域大小，对于热表可能要更小（或手动拆分热区域以将负载分散到整个群集中），或者如果您的像元大小倾向于较大（100k及以上），则可以使用更大的区域。</p>
</div>
<div class="paragraph">
<p>在HBase 0.98中，添加了实验性条带压缩功能，该功能将允许更大的区域，尤其是日志数据。参见<a href="#ops.stripe">ops.stripe</a> 。</p>
</div>
</div>
<div class="sect3">
<h4 id="ops.capacity.regions.total"><a class="anchor" href="#ops.capacity.regions.total"></a> 132.2.5。每个区域服务器的总数据大小</h4>
<div class="paragraph">
<p>根据以上有关区域大小和每个区域服务器的区域数量的数字，乐观估计每个RS 10 GB x 100个区域将为每个区域服务器提供多达1TB的服务，这与某些已报告的多PB用例相符。但是，重要的是要考虑RS级别的数据与缓存大小之比。每个服务器1TB的数据和10GB的块缓存，仅1％的数据将被缓存，这几乎不能覆盖所有块索引。</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="ops.capacity.config"><a class="anchor" href="#ops.capacity.config"></a> 132.3。初始配置和调整</h3>
<div class="paragraph">
<p>首先，请参阅<a href="#important_configurations">重要配置</a> 。请注意，某些配置比其他配置更多，取决于特定的方案。要特别注意：</p>
</div>
<div class="ulist">
<ul>
<li>
<p><a href="#hbase.regionserver.handler.count">hbase.regionserver.handler.count-</a>请求处理程序线程计数，对于高吞吐量工作负载至关重要。</p>
</li>
<li>
<p><a href="#config.wals">config.wals</a> -WAL文件的阻止数量取决于您的内存存储配置，并且应进行相应设置，以防止在进行大量写操作时潜在的阻止。</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>然后，在设置集群和表时有一些注意事项。</p>
</div>
<div class="sect3">
<h4 id="ops.capacity.config.compactions"><a class="anchor" href="#ops.capacity.config.compactions"></a> 132.3.1。压实</h4>
<div class="paragraph">
<p>根据读/写量和延迟要求，最佳压缩设置可能有所不同。有关更多详细信息，请参见<a href="#compaction">压缩</a> 。</p>
</div>
<div class="paragraph">
<p>但是，在配置大数据量时，请记住紧缩会影响写入吞吐量。因此，对于写密集型工作负载，您可以选择较少的压缩频率和每个区域更多的存储文件。压缩的最小文件数（ <code>hbase.hstore.compaction.min</code> ）可以设置为更高的值；还应增加<a href="#hbase.hstore.blockingstorefiles">hbase.hstore.blockingStoreFiles</a> ，因为在这种情况下可能会积累更多文件。您也可以考虑手动管理压缩： <a href="#managed.compactions">managed.compactions</a></p>
</div>
</div>
<div class="sect3">
<h4 id="ops.capacity.config.presplit"><a class="anchor" href="#ops.capacity.config.presplit"></a> 132.3.2。预分桌</h4>
<div class="paragraph">
<p>根据每个RS的目标区域数量（请参阅<a href="#ops.capacity.regions.count">ops.capacity.regions.count</a> ）和RS的数量，可以在创建时预分割表格。这样既可以避免在表开始填满时进行某些昂贵的拆分，又可以确保表开始时已经分布在许多服务器上。</p>
</div>
<div class="paragraph">
<p>如果期望该表足够大以证明这一点，则应该为每个RS创建至少一个区域。不建议立即划分为全部目标区域数（例如50 * RSes数），但是可以选择较低的中间值。对于多个表，建议在进行预分割时保持保守（例如，每个RS最多预分割1个区域），尤其是在您不知道每个表将增长多少的情况下。如果拆分过多，可能会导致区域过多，而某些表的区域过多。</p>
</div>
<div class="paragraph">
<p>有关预拆分方法，请参见<a href="#manual_region_splitting_decisions">手动区域拆分决策</a>和<a href="#precreate.regions">precreate.regions</a> 。</p>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="table.rename"><a class="anchor" href="#table.rename"></a> 133。表重命名</h2>
<div class="sectionbody">
<div class="paragraph">
<p>在hbase及更低版本的0.90.x中，我们有一个简单的脚本，该脚本将重命名hdfs表目录，然后对hbase：meta表进行编辑，用新表名替换所有旧表名。该脚本被称为<code>./bin/rename_table.rb</code> 。不推荐使用该脚本并将其删除，主要是因为该脚本未经维护，并且该脚本执行的操作很残酷。</p>
</div>
<div class="paragraph">
<p>从hbase 0.94.x开始，您可以使用快照功能重命名表。使用hbase shell的方法如下：</p>
</div>
<div class="listingblock">
<div class="content">
<pre>hbase shell&gt; disable 'tableName'
hbase shell&gt; snapshot 'tableName', 'tableSnapshot'
hbase shell&gt; clone_snapshot 'tableSnapshot', 'newTableName'
hbase shell&gt; delete_snapshot 'tableSnapshot'
hbase shell&gt; drop 'tableName'</pre>
</div>
</div>
<div class="paragraph">
<p>或在代码中如下所示：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="type">void</span> rename(Admin admin, <span class="predefined-type">String</span> oldTableName, <span class="predefined-type">String</span> newTableName) {
  <span class="predefined-type">String</span> snapshotName = randomName();
  admin.disableTable(oldTableName);
  admin.snapshot(snapshotName, oldTableName);
  admin.cloneSnapshot(snapshotName, newTableName);
  admin.deleteSnapshot(snapshotName);
  admin.deleteTable(oldTableName);
}</code></pre>
</div>
</div>
</div>
</div>
<h1 id="developer" class="sect0"><a class="anchor" href="#developer"></a>构建和开发Apache HBase</h1>
<div class="openblock partintro">
<div class="content">本章包含有关构建和发布HBase代码和文档的信息和准则。熟悉这些准则将有助于HBase提交者更轻松地使用您的贡献。
</div>
</div>
<div class="sect1">
<h2 id="getting.involved"><a class="anchor" href="#getting.involved"></a> 134。卷入</h2>
<div class="sectionbody">
<div class="paragraph">
<p>只有人们做出贡献，Apache HBase才能变得更好！如果您想为Apache HBase做出贡献，请<a href="https://issues.apache.org/jira/issues/?jql=project %3D HBASE AND labels in (beginner) AND status in (Open%2C "In Progress"%2C Reopened)">在JIRA中</a>查找<a href="https://issues.apache.org/jira/issues/?jql=project %3D HBASE AND labels in (beginner) AND status in (Open%2C "In Progress"%2C Reopened)">带有标签“ beginner”的问题</a> 。这些是HBase贡献者认为值得但并非紧迫的问题，也是提升HBase内部结构的好方法。请参阅<a href="http://search-hadoop.com/m/DHED43re96">针对新贡献者的坡道问题使用什么标签？</a> 从开发邮件列表中获取背景信息。</p>
</div>
<div class="paragraph">
<p>在开始向HBase提交代码之前，请参考<a href="#developing">开发</a> 。</p>
</div>
<div class="paragraph">
<p>由于Apache HBase是Apache Software Foundation项目，请参阅<a href="#asf">asf</a>以获得有关ASF如何运行的更多信息。</p>
</div>
<div class="sect2">
<h3 id="mailing.list"><a class="anchor" href="#mailing.list"></a> 134.1。邮件列表</h3>
<div class="paragraph">
<p>注册开发人员列表和用户列表。请参阅<a href="https://hbase.apache.org/mail-lists.html">邮件列表</a>页面。鼓励提出问题，并帮助回答其他人的问题！两种清单上的经验水平各不相同，因此鼓励耐心和礼貌（请留意话题）。</p>
</div>
</div>
<div class="sect2">
<h3 id="slack"><a class="anchor" href="#slack"></a> 134.2。松弛</h3>
<div class="paragraph">
<p>Apache HBase项目有其自己的链接： <a href="http://apache-hbase.slack.com">Slack Channel，</a>用于实时提问和讨论。邮件<a href="mailto:dev@hbase.apache.org">dev@hbase.apache.org</a>以请求邀请。</p>
</div>
</div>
<div class="sect2">
<h3 id="irc"><a class="anchor" href="#irc"></a> 134.3。互联网中继聊天（IRC）</h3>
<div class="paragraph">
<p>（注意：我们的IRC频道似乎已不推荐使用上述Slack频道）</p>
</div>
<div class="paragraph">
<p>对于实时问题和讨论，请使用<code>#hbase</code> <a href="https://freenode.net/">FreeNode</a> IRC网络上的IRC通道。FreeNode提供了一个基于Web的客户端，但是大多数人更喜欢本机客户端，并且每个操作系统都可以使用多个客户端。</p>
</div>
</div>
<div class="sect2">
<h3 id="_jira"><a class="anchor" href="#_jira"></a> 134.4。吉拉</h3>
<div class="paragraph">
<p>检查<a href="https://issues.apache.org/jira/projects/HBASE/issues">Jira中</a>是否存在问题。如果是新功能请求，增强功能或错误，请提交票证。</p>
</div>
<div class="paragraph">
<p>我们在JIRA中跟踪多种类型的工作：</p>
</div>
<div class="ulist">
<ul>
<li>
<p>错误：HBase本身发生了问题。</p>
</li>
<li>
<p>测试：需要测试，或者测试被破坏。</p>
</li>
<li>
<p>新功能：您对新功能有所了解。通常最好先在邮件列表中列出这些内容，然后编写您添加到功能请求JIRA中的设计规范。</p>
</li>
<li>
<p>改进：存在一个功能，但可以对其进行调整或增强。通常最好先在邮件列表中列出这些内容并进行讨论，然后如果其他人似乎对改进感兴趣，则总结或链接到讨论。</p>
</li>
<li>
<p>希望：这就像一个新功能，但是对于某些事情，您可能没有充实自己的背景。</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>错误和测试具有最高优先级，应该可以执行。</p>
</div>
<div class="sect3">
<h4 id="_guidelines_for_reporting_effective_issues"><a class="anchor" href="#_guidelines_for_reporting_effective_issues"></a> 134.4.1。报告有效问题的准则</h4>
<div class="ulist">
<ul>
<li>
<p><strong>搜索重复项</strong> ：您的问题可能已经被举报。看一下，发现其他人的措词可能有所不同。</p>
<div class="paragraph">
<p>另外，搜索邮件列表，其中可能包含有关您的问题以及如何解决的信息。除非您强烈不同意该解决方案<strong>并且</strong>愿意帮助解决该问题，否则不要针对邮件列表中已经讨论并解决的问题提出问题。</p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>公开讨论</strong> ：使用邮件列表来讨论您发现的内容，并查看是否错过了某些内容。避免使用反向渠道，以使您从整个项目的经验和专业知识中受益。</p>
</li>
<li>
<p><strong>不要代表其他人提交文件</strong> ：您可能没有全部上下文，也没有像实际遇到此错误的人那样有足够的动力来查看它。从长远来看，鼓励其他人提出自己的问题会更有帮助。向他们指出此材料，并在一两次提供帮助。</p>
</li>
<li>
<p><strong>编写良好的摘要</strong> ：良好的摘要包括有关问题，对用户或开发人员的影响以及代码区域的信息。</p>
<div class="ulist">
<ul>
<li>
<p>好：<code>Address new license dependencies from hadoop3-alpha4</code></p>
</li>
<li>
<p>改进空间：<code>Canary is broken</code></p>
<div class="paragraph">
<p>如果您写的标题不好，其他人会替您改写。这是他们本可以花时间解决此问题的时间。</p>
</div>
</li>
</ul>
</div>
</li>
<li>
<p><strong>在描述中给出上下文</strong> ：最好分多个部分来考虑：</p>
<div class="ulist">
<ul>
<li>
<p>发生或不发生什么？</p>
</li>
<li>
<p>对您有何影响？</p>
</li>
<li>
<p>别人怎么能复制它？</p>
</li>
<li>
<p>“固定”会是什么样？</p>
<div class="paragraph">
<p>您不需要知道所有这些答案，但是可以提供尽可能多的信息。如果您可以提供技术信息，例如您认为可能导致问题的Git commit SHA或认为问题首先出现的builds.apache.org上的构建失败，请共享该信息。</p>
</div>
</li>
</ul>
</div>
</li>
<li>
<p><strong>填写所有相关字段</strong> ：这些字段可帮助我们进行过滤，分类和查找内容。</p>
</li>
<li>
<p><strong>一个错误，一个问题，一个补丁</strong> ：为了帮助进行反向移植，请不要在多个错误之间分配问题或修复。</p>
</li>
<li>
<p><strong>如果可以，请增加价值</strong> ：即使您不知道如何解决问题，归档问题也很棒。但是，提供尽可能多的信息，愿意进行分类和回答问题以及愿意测试潜在的修补程序甚至更好！我们希望尽快解决您的问题。</p>
</li>
<li>
<p><strong>如果我们不解决它，不要生气</strong> ：时间和资源是有限的。在某些情况下，我们可能无法（或可能选择不解决），特别是在边缘情况或有解决方法的情况下。即使未解决，JIRA还是它的公开记录，并且如果将来遇到其他类似问题，它将帮助其他人。</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_working_on_an_issue"><a class="anchor" href="#_working_on_an_issue"></a> 134.4.2。处理问题</h4>
<div class="paragraph">
<p>要检查可以作为初学者解决的现有问题，请<a href="https://issues.apache.org/jira/issues/?jql=project %3D HBASE AND labels in (beginner) AND status in (Open%2C "In Progress"%2C Reopened)">在JIRA中</a>搜索<a href="https://issues.apache.org/jira/issues/?jql=project %3D HBASE AND labels in (beginner) AND status in (Open%2C "In Progress"%2C Reopened)">带有标签“初学者”的问题</a> 。</p>
</div>
<div class="ulist">
<div class="title">JIRA Priorites</div>
<ul>
<li>
<p><strong>阻止程序</strong> ：仅在问题将可靠地导致数据丢失或群集不稳定的情况下使用。</p>
</li>
<li>
<p><strong>严重</strong> ：所描述的问题在某些情况下可能导致数据丢失或群集不稳定。</p>
</li>
<li>
<p><strong>重大</strong> ：重要但不是悲惨的问题，例如对客户端API的更新将添加许多急需的功能或需要修复但不会导致数据丢失的重大错误。</p>
</li>
<li>
<p><strong>次要的</strong> ：有用的增强功能和烦人的但不会造成破坏的错误。</p>
</li>
<li>
<p><strong>琐碎</strong> ：有用的增强功能，但通常是美观的。</p>
</li>
</ul>
</div>
<div class="exampleblock">
<div class="title">示例48Jira中的代码块注释</div>
<div class="content">
<div class="paragraph">
<p>Jira中常用的宏是{code}。标记中的所有内容均已预先格式化，如本例所示。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">{code}
code snippet
{code}</code></pre>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="repos"><a class="anchor" href="#repos"></a> 135。Apache HBase存储库</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Apache HBase有两个不同的存储库：Subversion（SVN）和Git。GIT是除Apache HBase网站以外的所有站点的记录库。我们曾经使用SVN。我们迁移了。请参阅<a href="https://issues.apache.org/jira/browse/INFRA-7768">将Apache HBase SVN存储库迁移到Git</a> 。请参阅<a href="https://hbase.apache.org/source-repository.html">源代码管理</a>页面以获取贡献者和提交者链接，或者在<a href="https://gitbox.apache.org/repos/asf/">Apache Git</a>页面上搜索HBase。</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_ides"><a class="anchor" href="#_ides"></a> 136。集成开发环境</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="eclipse"><a class="anchor" href="#eclipse"></a> 136.1。日食</h3>
<div class="sect3">
<h4 id="eclipse.code.formatting"><a class="anchor" href="#eclipse.code.formatting"></a> 136.1.1。代码格式化</h4>
<div class="paragraph">
<p>在<em>dev-support /</em>文件夹下，您将找到<em>hbase_eclipse_formatter.xml</em> 。我们鼓励您在编辑HBase代码时在Eclipse中使用此格式化程序。</p>
</div>
<div class="paragraph">
<p>去<code>Preferences→Java→Code Style→Formatter→Import</code>加载xml文件。去<code>Preferences→Java→Editor→Save Actions</code> ，并确保选择了“设置源代码格式”和“设置编辑行的格式”。</p>
</div>
<div class="paragraph">
<p>除了自动格式化之外，请确保您遵循<a href="#common.patch.feedback">common.patch.feedback中</a>说明的样式准则。</p>
</div>
</div>
<div class="sect3">
<h4 id="eclipse.git.plugin"><a class="anchor" href="#eclipse.git.plugin"></a> 136.1.2。Eclipse Git插件</h4>
<div class="paragraph">
<p>如果通过git克隆了项目，请下载并安装Git插件（EGit）。附加到本地git repo（通过<span class="label">Git Repositories</span>窗口），您将能够查看文件修订历史记录，生成补丁等。</p>
</div>
</div>
<div class="sect3">
<h4 id="eclipse.maven.setup"><a class="anchor" href="#eclipse.maven.setup"></a> 136.1.3。使用以下命令在Eclipse中进行HBase项目设置<code>m2eclipse</code></h4>
<div class="paragraph">
<p>最简单的方法是将m2eclipse插件用于Eclipse。Eclipse Indigo或更高版本包含m2eclipse，或者您可以从<a href="http://www.eclipse.org/m2e/" class="bare">http://www.eclipse.org/m2e/</a>下载。它提供了Eclipse的Maven集成，甚至允许您使用Eclipse中的直接Maven命令来编译和测试项目。</p>
</div>
<div class="paragraph">
<p>要导入项目，请单击并选择HBase根目录。 <code>m2eclipse</code>为您找到所有的hbase模块。</p>
</div>
<div class="paragraph">
<p>如果您在工作区中安装了m2eclipse并导入了HBase，请执行以下操作来修复Eclipse的构建路径。</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>删除<em>目标</em>文件夹</p>
</li>
<li>
<p>添加<em>目标/生成jamon</em>和<em>目标/生成源/ java</em>文件夹。</p>
</li>
<li>
<p>从构建路径中删除<em>src / main / resources</em>和<em>src / test / resources</em>上的排除项，以避免控制台中出现错误消息，例如：</p>
<div class="listingblock">
<div class="content">
<pre>Failed to execute goal
org.apache.maven.plugins:maven-antrun-plugin:1.6:run (default) on project hbase:
'An Ant BuildException has occurred: Replace: source file .../target/classes/hbase-default.xml
doesn't exist</pre>
</div>
</div>
<div class="paragraph">
<p>这还将减少蚀构建周期，并在开发时使您的生活更轻松。</p>
</div>
</li>
</ol>
</div>
</div>
<div class="sect3">
<h4 id="eclipse.commandline"><a class="anchor" href="#eclipse.commandline"></a> 136.1.4。使用命令行在Eclipse中进行HBase项目设置</h4>
<div class="paragraph">
<p>而不是使用<code>m2eclipse</code> ，您可以从命令行生成Eclipse文件。</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>首先，运行以下命令，该命令将构建HBase。您只需要这样做一次。</p>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bourne">mvn clean install -DskipTests</code></pre>
</div>
</div>
</li>
<li>
<p>关闭Eclipse，然后从终端在本地HBase项目目录中执行以下命令，以生成新的<em>.project</em>和<em>.classpath</em>文件。</p>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bourne">mvn eclipse:eclipse</code></pre>
</div>
</div>
</li>
<li>
<p>重新打开Eclipse并将HBase目录中的<em>.project</em>文件导入到工作区。</p>
</li>
</ol>
</div>
</div>
<div class="sect3">
<h4 id="eclipse.maven.class"><a class="anchor" href="#eclipse.maven.class"></a> 136.1.5。Maven类路径变量</h4>
<div class="paragraph">
<p>的<code>$M2_REPO</code>需要为项目设置classpath变量。这需要设置为本地Maven存储库，通常是<em>〜/ .m2 / repository</em></p>
</div>
<div class="paragraph">
<p>如果未配置此classpath变量，您将在Eclipse中看到如下编译错误：</p>
</div>
<div class="listingblock">
<div class="content">
<pre>Description	Resource	Path	Location	Type
The project cannot be built until build path errors are resolved	hbase		Unknown	Java Problem
Unbound classpath variable: 'M2_REPO/asm/asm/3.1/asm-3.1.jar' in project 'hbase'	hbase		Build path	Build Path Problem
Unbound classpath variable: 'M2_REPO/com/google/guava/guava/r09/guava-r09.jar' in project 'hbase'	hbase		Build path	Build Path Problem
Unbound classpath variable: 'M2_REPO/com/google/protobuf/protobuf-java/2.3.0/protobuf-java-2.3.0.jar' in project 'hbase'	hbase		Build path	Build Path Problem Unbound classpath variable:</pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="eclipse.issues"><a class="anchor" href="#eclipse.issues"></a> 136.1.6。Eclipse已知问题</h4>
<div class="paragraph">
<p>Eclipse当前将抱怨<em>Bytes.java</em> 。无法关闭这些错误。</p>
</div>
<div class="listingblock">
<div class="content">
<pre>Description	Resource	Path	Location	Type
Access restriction: The method arrayBaseOffset(Class) from the type Unsafe is not accessible due to restriction on required library /System/Library/Java/JavaVirtualMachines/1.6.0.jdk/Contents/Classes/classes.jar	Bytes.java	/hbase/src/main/java/org/apache/hadoop/hbase/util	line 1061	Java Problem
Access restriction: The method arrayIndexScale(Class) from the type Unsafe is not accessible due to restriction on required library /System/Library/Java/JavaVirtualMachines/1.6.0.jdk/Contents/Classes/classes.jar	Bytes.java	/hbase/src/main/java/org/apache/hadoop/hbase/util	line 1064	Java Problem
Access restriction: The method getLong(Object, long) from the type Unsafe is not accessible due to restriction on required library /System/Library/Java/JavaVirtualMachines/1.6.0.jdk/Contents/Classes/classes.jar	Bytes.java	/hbase/src/main/java/org/apache/hadoop/hbase/util	line 1111	Java Problem</pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="eclipse.more"><a class="anchor" href="#eclipse.more"></a> 136.1.7。Eclipse-更多信息</h4>
<div class="paragraph">
<p>有关在Windows上为HBase开发设置Eclipse的更多信息，请参阅<a href="http://michaelmorello.blogspot.com/2011/09/hbase-subversion-eclipse-windows.html">Michael Morello的博客</a>中的主题。</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_intellij_idea"><a class="anchor" href="#_intellij_idea"></a> 136.2。IntelliJ IDEA</h3>
<div class="paragraph">
<p>您可以将IntelliJ IDEA设置为具有与Eclipse类似的功能。跟着这些步骤。</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>选择</p>
</li>
<li>
<p>您无需选择配置文件。要选择<span class="label">需要</span>一定<span class="label">的Maven项目</span> ，然后单击<b class="button">下一步</b> 。</p>
</li>
<li>
<p>选择JDK的位置。</p>
</li>
</ol>
</div>
<div class="paragraph">
<div class="title">在IntelliJ IDEA中使用HBase格式化程序</div>
<p>使用IntelliJ IDEA的Eclipse代码格式化程序插件，可以导入<a href="#eclipse.code.formatting">eclipse.code.formatting中</a>描述的HBase代码格式化程序。</p>
</div>
</div>
<div class="sect2">
<h3 id="_other_ides"><a class="anchor" href="#_other_ides"></a> 136.3。其他IDE</h3>
<div class="paragraph">
<p>镜像其他IDE的<a href="#eclipse">Eclipse</a>设置说明会很有用。如果您想提供帮助，请查看<a href="https://issues.apache.org/jira/browse/HBASE-11704">HBASE-11704</a> 。</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="build"><a class="anchor" href="#build"></a> 137。构建Apache HBase</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="build.basic"><a class="anchor" href="#build.basic"></a> 137.1。基本编译</h3>
<div class="paragraph">
<p>HBase是使用Maven编译的。您必须至少使用Maven 3.0.4。要检查您的Maven版本，请运行命令mvn -version。</p>
</div>
<div class="admonitionblock note">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-note" title="注意"></i>
</td>
<td class="content">
<div class="title">JDK版本要求</div>
<div class="paragraph">
<p>从HBase 1.0开始，必须使用Java 7或更高版本来从源代码进行构建。有关支持的JDK版本的更多完整信息，请参见<a href="#java">java</a> 。</p>
</div>
</td>
</tr>
</tbody></table>
</div>
<div class="sect3">
<h4 id="maven.build.commands"><a class="anchor" href="#maven.build.commands"></a> 137.1.1。Maven构建命令</h4>
<div class="paragraph">
<p>所有命令均从本地HBase项目目录执行。</p>
</div>
<div class="sect4">
<h5 id="_package"><a class="anchor" href="#_package"></a>包</h5>
<div class="paragraph">
<p>从Java源代码编译HBase的最简单命令是使用<code>package</code>目标，它使用编译的文件构建JAR。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bourne">mvn package -DskipTests</code></pre>
</div>
</div>
<div class="paragraph">
<p>或者，在编译之前进行清理：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bourne">mvn clean package -DskipTests</code></pre>
</div>
</div>
<div class="paragraph">
<p>按照上面<a href="#eclipse">eclipse中</a>所述设置Eclipse之后，您还可以在Eclipse中使用<span class="menu">Build</span>命令。要创建完全可安装的HBase软件包，需要花费更多的工作，因此请继续阅读。</p>
</div>
</div>
<div class="sect4">
<h5 id="maven.build.commands.compile"><a class="anchor" href="#maven.build.commands.compile"></a>编译</h5>
<div class="paragraph">
<p>的<code>compile</code>目标不会使用编译的文件创建JAR。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bourne">mvn compile</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bourne">mvn clean compile</code></pre>
</div>
</div>
</div>
<div class="sect4">
<h5 id="_install"><a class="anchor" href="#_install"></a>安装</h5>
<div class="paragraph">
<p>要将JAR安装在<em>〜/ .m2 /</em>目录中，请使用<code>install</code>目标。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bourne">mvn install</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bourne">mvn clean install</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bourne">mvn clean install -DskipTests</code></pre>
</div>
</div>
</div>
</div>
<div class="sect3">
<h4 id="maven.build.commands.unitall"><a class="anchor" href="#maven.build.commands.unitall"></a> 137.1.2。运行所有或单个单元测试</h4>
<div class="paragraph">
<p>见<a href="#hbase.unittests.cmds">hbase.unittests.cmds</a>节<a href="#hbase.unittests">hbase.unittests</a></p>
</div>
</div>
<div class="sect3">
<h4 id="maven.build.hadoop"><a class="anchor" href="#maven.build.hadoop"></a> 137.1.3。针对各种Hadoop版本进行构建。</h4>
<div class="paragraph">
<p>HBase支持针对Apache Hadoop版本2.y和3.y（早期发行工件）进行构建。默认情况下，我们针对Hadoop 2.x构建。</p>
</div>
<div class="paragraph">
<p>要针对Hadoop 2.y系列的特定版本进行构建，请设置例如<code>-Dhadoop-two.version=2.7.4</code> 。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bourne">mvn -Dhadoop-two.version=2.7.4 ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>要更改我们构建的Hadoop的主要发行版，请在调用mvn时添加hadoop.profile属性：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bourne">mvn -Dhadoop.profile=3.0 ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>上面的代码将基于<em>pom.xml中</em>作为“ 3.0”版本的任何显式hadoop 3.y版本构建。测试可能不会全部通过，因此您可能需要通过<code>-DskipTests</code>除非您倾向于修复失败的测试。</p>
</div>
<div class="paragraph">
<p>要选择特定的Hadoop 3.y版本，请设置hadoop-three.version属性，例如<code>-Dhadoop-three.version=3.0.0</code> 。</p>
</div>
</div>
<div class="sect3">
<h4 id="build.protobuf"><a class="anchor" href="#build.protobuf"></a> 137.1.4。建立Protobuf</h4>
<div class="paragraph">
<p>您可能需要更改<em>hbase-protocol</em>模块或其他模块中的protobuf定义。</p>
</div>
<div class="paragraph">
<p>protobuf文件位于<em>hbase-protocol / src / main / protobuf中</em> 。为了使更改生效，您将需要重新生成类。您可以使用Maven个人资料<code>compile-protobuf</code>去做这个。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bourne">mvn compile -Pcompile-protobuf</code></pre>
</div>
</div>
<div class="paragraph">
<p>您可能还想定义<code>protoc.path</code>对于protoc二进制文件，请使用以下命令：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bourne">mvn compile -Pcompile-protobuf -Dprotoc.path=/opt/local/bin/protoc</code></pre>
</div>
</div>
<div class="paragraph">
<p>阅读<em>hbase-protocol / README.txt</em>以获得更多详细信息。</p>
</div>
</div>
<div class="sect3">
<h4 id="build.thrift"><a class="anchor" href="#build.thrift"></a> 137.1.5。建立节俭</h4>
<div class="paragraph">
<p>您可能需要更改<em>hbase-thrift</em>模块或其他模块中的<em>Thrift</em>定义。</p>
</div>
<div class="paragraph">
<p><em>Thrift</em>文件位于<em>hbase-thrift / src / main / resources中</em> 。为了使更改生效，您将需要重新生成类。您可以使用Maven个人资料<code>compile-thrift</code>去做这个。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bourne">mvn compile -Pcompile-thrift</code></pre>
</div>
</div>
<div class="paragraph">
<p>您可能还想定义<code>thrift.path</code>对于节俭的二进制文件，请使用以下命令：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bourne">                  mvn compile -Pcompile-thrift -Dthrift.path=/opt/local/bin/thrift</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_build_a_tarball"><a class="anchor" href="#_build_a_tarball"></a> 137.1.6。建立一个tarball</h4>
<div class="paragraph">
<p>你可以建立一个压缩包，而无需通过释放过程将在描述<a href="#releasing">释放</a> ，通过运行下面的命令：</p>
</div>
<div class="listingblock">
<div class="content">
<pre>mvn -DskipTests clean install &amp;&amp; mvn -DskipTests package assembly:single</pre>
</div>
</div>
<div class="paragraph">
<p>发行版tarball是在<em>hbase-assembly / target / hbase- <version>-bin.tar.gz中构建的</version></em> 。</p>
</div>
<div class="paragraph">
<p>您可以通过在maven命令中进行安装或部署之前具有assembly：single目标来安装或部署tarball：</p>
</div>
<div class="listingblock">
<div class="content">
<pre>mvn -DskipTests package assembly:single install</pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre>mvn -DskipTests package assembly:single deploy</pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="build.gotchas"><a class="anchor" href="#build.gotchas"></a> 137.1.7。建立陷阱</h4>
<div class="sect4">
<h5 id="_failure_to_find_dependencies_with_protocol_version_error"><a class="anchor" href="#_failure_to_find_dependencies_with_protocol_version_error"></a>找不到带有“ protocol_version”错误的依赖项</h5>
<div class="paragraph">
<p>许多Maven存储库（最著名的是Maven Central）现在都需要TLSv1.2才能进行HTTPS连接。在较旧的JDK7实例上，您可能需要手动将-Dhttps.protocols = TLSv1.2添加到您的Maven命令行调用中。</p>
</div>
</div>
<div class="sect4">
<h5 id="_maven_site_failure"><a class="anchor" href="#_maven_site_failure"></a> Maven网站故障</h5>
<div class="paragraph">
<p>如果你看到<code>Unable to find resource 'VM_global_library.vm'</code> ， 忽略它。这不是错误。虽然这在<a href="https://issues.apache.org/jira/browse/MSITE-286">官方上</a>是<a href="https://issues.apache.org/jira/browse/MSITE-286">丑陋的</a> 。</p>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="releasing"><a class="anchor" href="#releasing"></a> 138。发布Apache HBase</h2>
<div class="sectionbody">
<div class="admonitionblock note">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-note" title="注意"></i>
</td>
<td class="content">
<div class="title">针对HBase 1.x构建</div>
<div class="paragraph">
<p>HBase 1.x需要Java 7才能构建。有关每个HBase版本的Java要求，请参见<a href="#java">Java</a> 。</p>
</div>
</td>
</tr>
</tbody></table>
</div>
<div id="maven.settings.xml" class="exampleblock">
<div class="title">示例49。示例<em>〜/ .m2 / settings.xml</em>文件</div>
<div class="content">
<div class="paragraph">
<p>发布到Maven要求您对要上传的工件进行签名。为了使构建为您签名，请在<em>.m2</em>下的本地存储库中正确配置<em>settings.xml</em> ，如下所示。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="xml"><span class="tag">&lt;settings</span> <span class="attribute-name">xmlns</span>=<span class="string"><span class="delimiter">&quot;</span><span class="content">http://maven.apache.org/SETTINGS/1.0.0</span><span class="delimiter">&quot;</span></span>
  <span class="attribute-name">xmlns:xsi</span>=<span class="string"><span class="delimiter">&quot;</span><span class="content">http://www.w3.org/2001/XMLSchema-instance</span><span class="delimiter">&quot;</span></span>
  <span class="attribute-name">xsi:schemaLocation</span>=<span class="string"><span class="delimiter">&quot;</span><span class="content">http://maven.apache.org/SETTINGS/1.0.0</span>
                      <span class="content">http://maven.apache.org/xsd/settings-1.0.0.xsd</span><span class="delimiter">&quot;</span></span><span class="tag">&gt;</span>
  <span class="tag">&lt;servers&gt;</span>
    <span class="error">&lt;</span>!- To publish a snapshot of some part of Maven --<span class="error">&gt;</span>
    <span class="tag">&lt;server&gt;</span>
      <span class="tag">&lt;id&gt;</span>apache.snapshots.https<span class="tag">&lt;/id&gt;</span>
      <span class="tag">&lt;username&gt;</span>YOUR_APACHE_ID
      <span class="tag">&lt;/username&gt;</span>
      <span class="tag">&lt;password&gt;</span>YOUR_APACHE_PASSWORD
      <span class="tag">&lt;/password&gt;</span>
    <span class="tag">&lt;/server&gt;</span>
    <span class="comment">&lt;!-- To publish a website using Maven --&gt;</span>
    <span class="comment">&lt;!-- To stage a release of some part of Maven --&gt;</span>
    <span class="tag">&lt;server&gt;</span>
      <span class="tag">&lt;id&gt;</span>apache.releases.https<span class="tag">&lt;/id&gt;</span>
      <span class="tag">&lt;username&gt;</span>YOUR_APACHE_ID
      <span class="tag">&lt;/username&gt;</span>
      <span class="tag">&lt;password&gt;</span>YOUR_APACHE_PASSWORD
      <span class="tag">&lt;/password&gt;</span>
    <span class="tag">&lt;/server&gt;</span>
  <span class="tag">&lt;/servers&gt;</span>
  <span class="tag">&lt;profiles&gt;</span>
    <span class="tag">&lt;profile&gt;</span>
      <span class="tag">&lt;id&gt;</span>apache-release<span class="tag">&lt;/id&gt;</span>
      <span class="tag">&lt;properties&gt;</span>
    <span class="tag">&lt;gpg.keyname&gt;</span>YOUR_KEYNAME<span class="tag">&lt;/gpg.keyname&gt;</span>
    <span class="comment">&lt;!--Keyname is something like this ... 00A5F21E... do gpg --list-keys to find it--&gt;</span>
    <span class="tag">&lt;gpg.passphrase&gt;</span>YOUR_KEY_PASSWORD
    <span class="tag">&lt;/gpg.passphrase&gt;</span>
      <span class="tag">&lt;/properties&gt;</span>
    <span class="tag">&lt;/profile&gt;</span>
  <span class="tag">&lt;/profiles&gt;</span>
<span class="tag">&lt;/settings&gt;</span></code></pre>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="maven.release"><a class="anchor" href="#maven.release"></a> 138.1。使发布候选</h3>
<div class="admonitionblock note">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-note" title="注意"></i>
</td>
<td class="content">这些说明用于构建HBase 1.yz</td>
</tr>
</tbody></table>
</div>
<div class="paragraph">
<div class="title">点发布</div>
<p>如果要从发布分支而不是开发分支进行点发布（例如，以快速解决严重的不兼容性或安全性问题），则标记说明会稍有不同。我将在这些特殊步骤的前面加上<em>Point Release Only</em> 。</p>
</div>
<div class="paragraph">
<div class="title">在你开始之前</div>
<p>确保您的环境已正确设置。Maven和Git是下面使用的主要工具。您将需要在本地<em>〜/ .m2</em> Maven存储库中正确配置的<em>settings.xml</em>文件，并使用apache仓库登录名（请参见<a href="#maven.settings.xml">示例<em>〜/ .m2 / settings.xml</em>文件</a> ）。您还需要具有已发布的签名密钥。浏览有关<a href="http://wiki.apache.org/hadoop/HowToRelease">如何发布</a>的Hadoop <a href="http://wiki.apache.org/hadoop/HowToRelease">How to Release</a> Wiki页面。它是以下大多数说明的模型。它通常具有特定步骤的更多详细信息，例如，将代码签名密钥添加到Apache中的项目KEYS文件中，或有关如何为发布准备更新JIRA的详细信息。</p>
</div>
<div class="paragraph">
<p>在使候选版本成为可能之前，请通过部署SNAPSHOT进行练习。检查以确保要从其发布版本的分支通过了最近的构建。您还应该尝试在负载下的群集上尝试最近的分支技巧，也许是通过运行<code>hbase-it</code>集成测试套件需要几个小时，以“消耗”接近候选的位。</p>
</div>
<div class="admonitionblock note">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-note" title="注意"></i>
</td>
<td class="content">
<div class="title">指定Maven的堆空间</div>
<div class="paragraph">
<p>您可能会遇到OutOfMemoryErrors构建，特别是构建站点和文档。通过设置<code>MAVEN_OPTS</code>变量。您可以在Maven命令前添加变量，如以下示例所示：</p>
</div>
<div class="listingblock">
<div class="content">
<pre>MAVEN_OPTS="-Xmx4g -XX:MaxPermSize=256m" mvn package</pre>
</div>
</div>
<div class="paragraph">
<p>您也可以在环境变量或shell别名中进行设置。</p>
</div>
</td>
</tr>
</tbody></table>
</div>
<div class="admonitionblock note">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-note" title="注意"></i>
</td>
<td class="content">
<div class="paragraph">
<p>脚本<em>dev-support / make_rc.sh可</em>自动执行以下许多步骤。它将签出标签，清理签出，构建src和bin tarball，然后将构建的jar部署到repository.apache.org。它不会对该发行版进行<em>CHANGES.txt</em>的修改，也不会检查产生的工件以确保它们“良好”，例如，提取产生的tarball，验证它们看起来正确，然后启动HBase并检查一切是否在运行正确-或将tarball签名并推送到<a href="https://people.apache.org">people.apache.org</a> 。看一看。视需要修改/改善。</p>
</div>
</td>
</tr>
</tbody></table>
</div>
<div class="olist arabic">
<div class="title">程序：释放程序</div>
<ol class="arabic">
<li>
<p>更新<em>CHANGES.txt</em>文件和POM文件。</p>
<div class="paragraph">
<p>使用上次发布以来的更改更新<em>CHANGES.txt</em> 。确保JIRA的URL指向列出该版本修复程序的正确位置。适当调整所有POM文件中的版本。如果要发布候选版本，则必须删除<code>-SNAPSHOT</code>所有pom.xml文件中所有版本的标签。如果运行此记录以发布快照，则必须保留<code>-SNAPSHOT</code> hbase版本上的后缀。<a href="http://www.mojohaus.org/versions-maven-plugin/">Maven插件版本</a>可以在这里使用。要在hbase多模块项目的所有项目中设置版本，请使用如下命令：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bourne">$ mvn clean org.codehaus.mojo:versions-maven-plugin:2.5:set -DnewVersion=1.5.0</code></pre>
</div>
</div>
<div class="paragraph">
<p>确保poms中的所有版本均已更改！签入<em>CHANGES.txt</em>并进行任何Maven版本更改。</p>
</div>
</li>
<li>
<p>更新文档。</p>
<div class="paragraph">
<p>更新<em>src / main / asciidoc</em>下的文档。这通常涉及从master分支复制最新版本，并进行特定于版本的调整以适合此发行候选版本。</p>
</div>
</li>
<li>
<p>清理结帐目录</p>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bourne">$ mvn clean
$ git clean -f -x -d</code></pre>
</div>
</div>
</li>
<li>
<p>运行Apache-Rat Check许可证很好</p>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bourne">$ mvn apache-rat</code></pre>
</div>
</div>
<div class="paragraph">
<p>如果以上操作均失败，请检查大鼠日志。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bourne">$ grep 'Rat check' patchprocess/mvn_apache_rat.log</code></pre>
</div>
</div>
</li>
<li>
<p>创建一个发布标签。假设您已经进行了基本测试，大鼠检查，通过并且一切都看起来不错，那么现在是时候标记释放候选者了（如果需要重做，请始终删除标记）。要进行标记，请执行以下操作来替换适合您的版本的版本。所有标签应为签名标签；即，传递<em>-s</em>选项（有关如何设置git环境进行签名的信息，请参见“ <a href="http://https://git-scm.com/book/id/v2/Git-Tools-Signing-Your-Work">签署工作</a> ”）。</p>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bourne">$ git tag -s 1.5.0-RC0 -m &quot;Tagging the 1.5.0 first Releae Candidate (Candidates start at zero)&quot;</code></pre>
</div>
</div>
</li>
</ol>
</div>
<div class="paragraph">
<p>或者，如果要发布版本，标签应具有<em>rel /</em>前缀，以确保将其保存在Apache存储库中，如下所示：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bourne">+$ git tag -s rel/1.5.0 -m &quot;Tagging the 1.5.0 Release&quot;</code></pre>
</div>
</div>
<div class="paragraph">
<p>按下（特定）标签（仅），以便其他人可以访问。</p>
</div>
<div class="paragraph">
<p>+</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bourne">$ git push origin 1.5.0-RC0</code></pre>
</div>
</div>
<div class="paragraph">
<p>+有关如何删除标签的信息，请参阅<a href="http://www.manikrathee.com/how-to-delete-a-tag-in-git.html">如何删除标签</a> 。涵盖删除尚未推送到远程Apache存储库的标签，以及删除推送到Apache的标签。</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>生成源压缩包。</p>
<div class="paragraph">
<p>现在，构建源tarball。假设我们正在将标签<em>1.5.0-RC0</em>的源tarball构建到<em>/tmp/hbase-1.5.0-RC0/中</em> （此步骤要求上述的mvn和git clean步骤已经完成）。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bourne">$ git archive --format=tar.gz --output=&quot;/tmp/hbase-1.5.0-RC0/hbase-1.5.0-src.tar.gz&quot; --prefix=&quot;hbase-1.5.0/&quot; $git_tag</code></pre>
</div>
</div>
</li>
</ol>
</div>
<div class="paragraph">
<p>在上方，我们将hbase-1.5.0-src.tar.gz压缩包生成到<em>/tmp/hbase-1.5.0-RC0</em>构建输出目录中（我们不希望<em>RC0</em>出现在名称或前缀中。这些位目前是发行候选，但是如果VOTE通过，它们将成为发行，因此我们不会用<em>RCX</em>污染工件名称。</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>构建二进制压缩包。接下来，构建二进制压缩包。添加<code>-Prelease</code>建立时的配置文件。它运行许可证apache-rat检查以及其他有助于确保一切健康的规则。分两步完成。</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>首先安装到本地存储库</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bourne">$ mvn clean install -DskipTests -Prelease</code></pre>
</div>
</div>
<div class="paragraph">
<p>接下来，生成文档并组装压缩包。请注意，此下一步可能需要花费一些时间，而这会花费几个小时来生成站点文档。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bourne">$ mvn install -DskipTests site assembly:single -Prelease</code></pre>
</div>
</div>
<div class="paragraph">
<p>+否则，当您尝试一步完成所有工作时，尤其是在新的存储库中，构建会抱怨hbase模块不在maven存储库中。在这两个步骤中似乎都需要安装目标。</p>
</div>
<div class="paragraph">
<p>+提取生成的<em>tarball-</em>您将在<em>hbase-assembly / target</em>下找到它并检出。查看文档，查看其是否运行等。如果良好，请在构建输出目录中的源tarball旁边复制tarball。</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>部署到Maven存储库。</p>
<div class="paragraph">
<p>接下来，将HBase部署到Apache Maven存储库。运行时添加apache-release`配置文件<code>mvn deploy</code>命令。此配置文件来自我们pom文件引用的Apache父pom。只要对<em>settings.xml</em>进行了正确配置，它就会对发布到Maven的工件进行签名，如<a href="#maven.settings.xml">示例<em>〜/ .m2 / settings.xml</em> File中所述</a> 。此步骤取决于本地存储库是否已由之前的bin tarball构建填充。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bourne">$ mvn deploy -DskipTests -Papache-release -Prelease</code></pre>
</div>
</div>
<div class="paragraph">
<p>此命令将所有工件复制到处于“打开”状态的临时登台Apache mvn存储库。为了使这些Maven工件普遍可用，需要做更多的工作。</p>
</div>
<div class="paragraph">
<p>我们不会将HBase tarball发布到Apache Maven存储库。为避免部署tarball，请勿将<code>assembly:single</code>你的目标<code>mvn deploy</code>命令。如下一节所述，检查已部署的工件。</p>
</div>
</li>
</ol>
</div>
<div class="admonitionblock note">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-note" title="注意"></i>
</td>
<td class="content">
<div class="title">make_rc.sh</div>
<div class="paragraph">
<p>如果您运行<em>dev-support / make_rc.sh</em>脚本，这将<em>尽</em>您所能。要完成发行，请从现在开始使用脚本。</p>
</div>
</td>
</tr>
</tbody></table>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>使发布候选可用。</p>
<div class="paragraph">
<p>这些工件位于处于“打开”状态的登台区域中的Maven存储库中。在这种“开放”状态下，您可以查看自己发布的内容，以确保一切都很好。为此，请使用您的Apache ID登录到<a href="https://repository.apache.org">repository.apache.org</a>上的Apache Nexus。在登台存储库中找到您的工件。单击“登台存储库”，然后找到状态为“打开”的以“ hbase”结尾的新存储库，然后选择它。使用树形视图扩展存储库内容的列表，并检查是否存在您期望的工件。检查POM。只要登台存储库处于打开状态，就可以在缺少某些内容或构建不正确的情况下重新上传。</p>
</div>
<div class="paragraph">
<p>如果出现严重错误，并且您想撤消上载，则可以使用“拖放”按钮删除和删除登台存储库。有时上传会在中间失败。这是您可能必须从分段存储库中“拖放”上载的另一个原因。</p>
</div>
<div class="paragraph">
<p>如果签出，请使用“关闭”按钮关闭存储库。必须先关闭该存储库，然后才能使用它的公共URL。关闭存储库可能需要几分钟。完成后，您将在Nexus UI中看到存储库的公共URL。您可能还会收到带有URL的电子邮件。在宣布候选发布版本的电子邮件中，提供指向临时登台存储库的URL。（伙计们需要将此回购URL添加到其本地poms或其本地<em>settings.xml</em>文件中，以拉出已发布的发行候选工件。）</p>
</div>
<div class="paragraph">
<p>当发布投票成功结束时，返回此处并单击“发布”按钮以将工件释放到中央。发布过程将自动删除和删除登台存储库。</p>
</div>
<div class="admonitionblock note">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-note" title="注意"></i>
</td>
<td class="content">
<div class="title">HBase的下游</div>
<div class="paragraph">
<p>请参阅<a href="https://github.com/saintstack/hbase-downstreamer">hbase-downstreamer</a>测试以获取HBase下游及其依赖的项目的简单示例。对其进行检查并运行其简单测试，以确保将Maven工件正确部署到Maven存储库。确保编辑pom以指向正确的登台存储库。确保通过测试运行时从存储库中提取数据，并且不要从本地存储库中获取数据，方法是传递<code>-U</code>标记或删除本地回购内容，并检查Maven是否已从远程库中撤出登台存储库。</p>
</div>
</td>
</tr>
</tbody></table>
</div>
</li>
</ol>
</div>
<div class="paragraph">
<p>有关此Maven登台过程的一些指针，请参见<a href="https://www.apache.org/dev/publishing-maven-artifacts.html">发布Maven工件</a> 。</p>
</div>
<div class="paragraph">
<p>如果HBase版本以<code>-SNAPSHOT</code> ，这些文物会转移到其他地方。它们直接放入Apache快照存储库中，并且立即可用。制作SNAPSHOT版本，这就是您想要发生的事情。</p>
</div>
<div class="paragraph">
<p>在此阶段，您的“构建输出目录”中有两个压缩文件，并且在Maven存储库的暂存区域中处于“关闭”状态的一组工件。接下来签名，指纹，然后通过将目录提交到<a href="https://dist.apache.org/repos/dist/dev/hbase/">“ dev”分发目录</a> （请参见<a href="https://issues.apache.org/jira/browse/HBASE-10554">HBASE-10554</a>上<a href="https://issues.apache.org/jira/browse/HBASE-10554">的注释，请从镜像系统中删除旧版本，</a>但实际上是svn签出），通过svnpubsub来“暂存”您的候选版本构建输出目录的<a href="javascript:void(0);" class="bare">https://dist.apache.org/repos/dist/dev/hbase-版本</a>位于<a href="https://dist.apache.org/repos/dist/release/hbase" class="bare">https://dist.apache.org/repos/dist/release/hbase</a> ）。在<em>版本目录中，</em>运行以下命令：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bourne">$ for i in *.tar.gz; do echo $i; gpg --print-md MD5 $i &gt; $i.md5 ; done
$ for i in *.tar.gz; do echo $i; gpg --print-md SHA512 $i &gt; $i.sha ; done
$ for i in *.tar.gz; do echo $i; gpg --armor --output $i.asc --detach-sig $i  ; done
$ cd ..
# Presuming our 'build output directory' is named 1.5.0RC0, copy it to the svn checkout of the dist dev dir
# in this case named hbase.dist.dev.svn
$ cd /Users/stack/checkouts/hbase.dist.dev.svn
$ svn info
Path: .
Working Copy Root Path: /Users/stack/checkouts/hbase.dist.dev.svn
URL: https://dist.apache.org/repos/dist/dev/hbase
Repository Root: https://dist.apache.org/repos/dist
Repository UUID: 0d268c88-bc11-4956-87df-91683dc98e59
Revision: 15087
Node Kind: directory
Schedule: normal
Last Changed Author: ndimiduk
Last Changed Rev: 15045
Last Changed Date: 2016-08-28 11:13:36 -0700 (Sun, 28 Aug 2016)
$ mv 1.5.0RC0 /Users/stack/checkouts/hbase.dist.dev.svn
$ svn add 1.5.0RC0
$ svn commit ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>+通过检查<a href="https://dist.apache.org/repos/dist/dev/hbase/">https://dist.apache.org/repos/dist/dev/hbase/</a>确保它实际上已发布。</p>
</div>
<div class="paragraph">
<p>在邮件列表中宣布候选发布者并进行投票。</p>
</div>
</div>
<div class="sect2">
<h3 id="maven.snapshot"><a class="anchor" href="#maven.snapshot"></a> 138.2。发布SNAPSHOT到Maven</h3>
<div class="paragraph">
<p>确保您的<em>settings.xml</em>设置正确（请参见<a href="#maven.settings.xml">示例<em>〜/ .m2 / settings.xml</em>文件</a> ）。确保hbase版本包括<code>-SNAPSHOT</code>作为后缀。以下是发布在poms中具有hbase版本1.5.0的发行版的SNAPSHOTS的示例。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bourne"> $ mvn clean install -DskipTests  javadoc:aggregate site assembly:single -Prelease
 $ mvn -DskipTests  deploy -Papache-release</code></pre>
</div>
</div>
<div class="paragraph">
<p>上面提到的<em>make_rc.sh</em>脚本（请参阅<a href="#maven.release">maven.release</a> ）可以帮助您发布<code>SNAPSHOTS</code> 。确保你的<code>hbase.version</code>有个<code>-SNAPSHOT</code>后缀，然后再运行脚本。它将为您创建快照到apache快照存储库中。</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="hbase.rc.voting"><a class="anchor" href="#hbase.rc.voting"></a> 139。对释放候选人进行投票</h2>
<div class="sectionbody">
<div class="paragraph">
<p>鼓励大家尝试对HBase发行候选版本进行投票。仅PMC成员的投票具有约束力。PMC成员，请阅读此WIP文档，其中包含针对发行候选<a href="https://github.com/rectang/asfrelease/blob/master/release.md">版本的政策</a>投票。</p>
</div>
<div class="quoteblock">
<blockquote>
<div class="paragraph">
<p>在进行+1约束力投票之前，个人需要将签名的源代码包下载到自己的硬件上，按提供的方式进行编译，并在自己的平台上测试生成的可执行文件，同时还要验证密码签名并验证该包是否符合要求。 ASF发布政策的要求。</p>
</div>
</blockquote>
</div>
<div class="paragraph">
<p>关于后者，运行<code>mvn apache-rat:check</code>验证所有文件均已获得适当许可。参见<a href="http://search-hadoop.com/m/DHED4dhFaU">HBase，邮件＃dev-在最近的讨论中</a> ，我们<a href="http://search-hadoop.com/m/DHED4dhFaU">澄清了ASF发行政策，</a>以了解如何实现此过程。</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="documentation"><a class="anchor" href="#documentation"></a> 140。生成《 HBase参考指南》</h2>
<div class="sectionbody">
<div class="paragraph">
<p>该手册使用Asciidoc进行了标记。然后，我们使用<a href="http://asciidoctor.org/docs/asciidoctor-maven-plugin/">Asciidoctor maven插件</a>将标记转换为html。当您指定站点目标时（如运行mvn site时），将运行此插件。有关构建<a href="#appendix_contributing_to_documentation">文档</a>的更多信息，请参见<a href="#appendix_contributing_to_documentation">附录</a>文档。</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="hbase.org"><a class="anchor" href="#hbase.org"></a> 141。更新<a href="https://hbase.apache.org">hbase.apache.org</a></h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="hbase.org.site.contributing"><a class="anchor" href="#hbase.org.site.contributing"></a> 141.1。贡献给hbase.apache.org</h3>
<div class="paragraph">
<p>有关添加到文档或网站的更多信息，请参见<a href="#appendix_contributing_to_documentation">附录添加到文档</a> 。</p>
</div>
</div>
<div class="sect2">
<h3 id="hbase.org.site.publishing"><a class="anchor" href="#hbase.org.site.publishing"></a> 141.2。发布<a href="https://hbase.apache.org">hbase.apache.org</a></h3>
<div class="paragraph">
<p>有关发布网站和文档的说明，请参见<a href="#website_publish">[website_publish]</a> 。</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="hbase.tests"><a class="anchor" href="#hbase.tests"></a> 142。测验</h2>
<div class="sectionbody">
<div class="paragraph">
<p>开发人员至少应熟悉单元测试的详细信息； HBase中的单元测试具有其他项目通常不具备的特征。</p>
</div>
<div class="paragraph">
<p>此信息是关于HBase本身的单元测试的。有关为HBase应用程序开发单元测试的信息，请参见<a href="#unit.tests">unit.tests</a> 。</p>
</div>
<div class="sect2">
<h3 id="hbase.moduletests"><a class="anchor" href="#hbase.moduletests"></a> 142.1。Apache HBase模块</h3>
<div class="paragraph">
<p>从0.96开始，Apache HBase被分为多个模块。这为如何以及在何处编写测试创建了“有趣的”规则。如果您正在编写代码<code>hbase-server</code> ，请参见<a href="#hbase.unittests">hbase.unittests</a>了解如何编写测试。这些测试可以启动一个小型集群，需要对其进行分类。例如，对于其他任何模块<code>hbase-common</code> ，测试必须是严格的单元测试，并且只测试被测类-不允许使用HBaseTestingUtility或minicluster（甚至在给定依赖树的情况下也不能使用）。</p>
</div>
<div class="sect3">
<h4 id="hbase.moduletest.shell"><a class="anchor" href="#hbase.moduletest.shell"></a> 142.1.1。测试HBase Shell</h4>
<div class="paragraph">
<p>HBase shell及其测试主要用jruby编写。为了使这些测试作为标准构建的一部分运行，有一个JUnit测试， <code>TestShell</code> ，它负责加载并运行jruby实现的测试。您可以使用以下命令从顶层运行所有这些测试：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bourne">      mvn clean test -Dtest=TestShell</code></pre>
</div>
</div>
<div class="paragraph">
<p>或者，您可以限制使用系统变量运行的外壳测试<code>shell.test</code> 。该值应按名称指定与特定测试用例等效的红宝石文字。例如，测试用例中包含涵盖用于更改表的shell命令的测试。 <code>AdminAlterTableTest</code>您可以使用以下命令运行它们：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bourne">      mvn clean test -Dtest=TestShell -Dshell.test=/AdminAlterTableTest/</code></pre>
</div>
</div>
<div class="paragraph">
<p>您也可以使用<a href="http://docs.ruby-doc.com/docs/ProgrammingRuby/html/language.html#UJ">Ruby正则表达式文字</a> （在<code>/pattern/</code>样式）以选择一组测试用例。您可以使用以下命令运行所有与HBase admin相关的测试，包括常规管理和安全性管理：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bourne">      mvn clean test -Dtest=TestShell -Dshell.test=/.*Admin.*Test/</code></pre>
</div>
</div>
<div class="paragraph">
<p>如果测试失败，您可以通过检查surefire报告结果的XML版本来查看详细信息</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bourne">      vim hbase-shell/target/surefire-reports/TEST-org.apache.hadoop.hbase.client.TestShell.xml</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="hbase.moduletest.run"><a class="anchor" href="#hbase.moduletest.run"></a> 142.1.2。在其他模块中运行测试</h4>
<div class="paragraph">
<p>如果您正在开发的模块对其他HBase模块没有其他依赖关系，则可以将其插入cd并运行：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bourne">mvn test</code></pre>
</div>
</div>
<div class="paragraph">
<p>它将仅在该模块中运行测试。如果其他模块上还有其他依赖关系，那么您将已从ROOT HBASE DIRECTORY运行命令。除非您指定跳过该模块中的测试，否则它将在其他模块中运行测试。例如，要跳过hbase-server模块中的测试，可以运行：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bourne">mvn clean test -PskipServerTests</code></pre>
</div>
</div>
<div class="paragraph">
<p>从顶层目录运行除hbase-server以外的模块中的所有测试。请注意，您可以指定跳过多个模块以及单个模块的测试。例如，要跳过<code>hbase-server</code>和<code>hbase-common</code> ，您将运行：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bourne">mvn clean test -PskipServerTests -PskipCommonTests</code></pre>
</div>
</div>
<div class="paragraph">
<p>另外，请记住，如果您正在<code>hbase-server</code>模块，您将需要应用<a href="#hbase.unittests.cmds">hbase.unittests.cmds中</a>讨论的Maven配置文件，以使测试正常运行。</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="hbase.unittests"><a class="anchor" href="#hbase.unittests"></a> 142.2。单元测试</h3>
<div class="paragraph">
<p>Apache HBase测试用例分为四类：小型，中型，大型以及与相应的JUnit <a href="https://github.com/junit-team/junit4/wiki/Categories">类别的</a>集成： <code>SmallTests</code> ， <code>MediumTests</code> ， <code>LargeTests</code> ， <code>IntegrationTests</code> 。JUnit类别使用Java注释表示，并且在您的单元测试代码中看起来像这样。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">...
<span class="annotation">@Category</span>(SmallTests.class)
<span class="directive">public</span> <span class="type">class</span> <span class="class">TestHRegionInfo</span> {
  <span class="annotation">@Test</span>
  <span class="directive">public</span> <span class="type">void</span> testCreateHRegionInfoName() <span class="directive">throws</span> <span class="exception">Exception</span> {
    <span class="comment">// ...</span>
  }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>上面的示例显示了如何将测试用例标记为属于<code>small</code>类别。HBase中的所有测试用例都应该有一个分类。</p>
</div>
<div class="paragraph">
<p>前三个类别， <code>small</code> ， <code>medium</code>和<code>large</code> ，用于键入时运行的测试用例<code>$ mvn test</code> 。换句话说，这三种分类适用于HBase单元测试。的<code>integration</code> category不是用于单元测试，而是用于集成测试。这些在您调用时运行<code>$ mvn verify</code> 。集成测试在<a href="#integration.tests">integration.tests中</a>进行了描述。</p>
</div>
<div class="paragraph">
<p>HBase使用修补的maven surefire插件和maven配置文件来实现其单元测试特性。</p>
</div>
<div class="paragraph">
<p>继续阅读，以了解在新的HBase测试用例中应使用的大小，中，大型注释。</p>
</div>
<div class="dlist">
<div class="title">分类测试</div>
<dl>
<dt class="hdlist1">小测试</dt>
<dd>
<p><em>小型</em>测试用例在共享的JVM中执行，单个测试用例应在15秒或更短的时间内运行；即<a href="https://en.wikipedia.org/wiki/JUnit">junit测试治具</a> ，即由测试方法组成的java对象，应在15秒内完成。这些测试用例不能使用小型集群。这些作为补丁程序预提交的一部分运行。</p>
</dd>
<dt class="hdlist1">中级测试</dt>
<dd>
<p><em>中型</em>测试用例在单独的JVM中执行，单个测试用例应在50秒或更短的时间内运行。在一起，他们应该花费不到30分钟的时间，并且结果稳定。这些测试用例可以使用小型集群。这些作为补丁程序预提交的一部分运行。</p>
</dd>
<dt class="hdlist1">大型测试</dt>
<dd>
<p><em>大型</em>测试用例是其他所有内容。它们通常是大规模测试，针对特定错误的回归测试，超时测试，性能测试。它们在预集成计算机上提交之前执行。它们也可以在开发机器上运行。</p>
</dd>
<dt class="hdlist1">整合测试</dt>
<dd>
<p><em>集成</em>测试是系统级测试。有关更多信息，请参见<a href="#integration.tests">Integration.tests</a> 。</p>
</dd>
</dl>
</div>
</div>
<div class="sect2">
<h3 id="hbase.unittests.cmds"><a class="anchor" href="#hbase.unittests.cmds"></a> 142.3。运行测试</h3>
<div class="sect3">
<h4 id="hbase.unittests.cmds.test"><a class="anchor" href="#hbase.unittests.cmds.test"></a> 142.3.1。默认值：中小型类别测试</h4>
<div class="paragraph">
<p>跑步<code>mvn test</code>将在单个JVM（无分叉）中执行所有小型测试，然后在每个测试实例的单独JVM中执行中型测试。如果小测试中有错误，则不执行中测试。不执行大型测试。如果执行了小型测试，则有一份报告，而中型测试则有一份报告。</p>
</div>
</div>
<div class="sect3">
<h4 id="hbase.unittests.cmds.test.runalltests"><a class="anchor" href="#hbase.unittests.cmds.test.runalltests"></a> 142.3.2。运行所有测试</h4>
<div class="paragraph">
<p>跑步<code>mvn test -P runAllTests</code>将在单个JVM中执行小型测试，然后为每个测试在单独的JVM中执行中型和大型测试。如果小型测试中有错误，则不执行中型和大型测试。如果中小型测试出现错误，则不会执行大型测试。对于小型测试，有一份报告，对于中型和大型测试，如果有执行则一份报告。</p>
</div>
</div>
<div class="sect3">
<h4 id="hbase.unittests.cmds.test.localtests.mytest"><a class="anchor" href="#hbase.unittests.cmds.test.localtests.mytest"></a> 142.3.3。在包中运行单个测试或所有测试</h4>
<div class="paragraph">
<p>运行单个测试，例如<code>MyTest</code> ， 朗姆酒<code>mvn test -Dtest=MyTest</code>您还可以通过多个单独的测试作为逗号分隔列表：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">mvn test  -Dtest=MyTest1,MyTest2,MyTest3</code></pre>
</div>
</div>
<div class="paragraph">
<p>您还可以通过一个软件包，该软件包将在该软件包下运行所有测试：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">mvn test '-Dtest=org.apache.hadoop.hbase.client.*'</code></pre>
</div>
</div>
<div class="paragraph">
<p>什么时候<code>-Dtest</code>指定， <code>localTests</code>个人资料将被使用。它将使用maven surefire的正式版本，而不是我们的自定义surefire插件和旧的连接器（HBase构建使用maven surefire插件的修补版本）。每个junit测试都在单独的JVM中执行（每个测试类一个fork）。在这种模式下运行测试时，没有并行化。您将在-report的末尾看到一条新消息： <code>"[INFO] Tests are skipped"</code> 。这是无害的。但是，您需要确保<code>Tests run:</code>在里面<code>Results:</code>部分的测试报告与您指定的测试数量相匹配，因为指定了不存在的测试用例时不会报告任何错误。</p>
</div>
</div>
<div class="sect3">
<h4 id="hbase.unittests.cmds.test.profiles"><a class="anchor" href="#hbase.unittests.cmds.test.profiles"></a> 142.3.4。其他测试调用排列</h4>
<div class="paragraph">
<p>跑步<code>mvn test -P runSmallTests</code>将仅使用单个JVM执行“小型”测试。</p>
</div>
<div class="paragraph">
<p>跑步<code>mvn test -P runMediumTests</code>将仅执行“中等”测试，为每个测试类启动一个新的JVM。</p>
</div>
<div class="paragraph">
<p>跑步<code>mvn test -P runLargeTests</code>将仅执行“大型”测试，为每个测试类启动一个新的JVM。</p>
</div>
<div class="paragraph">
<p>为了方便起见，您可以运行<code>mvn test -P runDevTests</code>使用单个JVM执行中小型测试。</p>
</div>
</div>
<div class="sect3">
<h4 id="hbase.unittests.test.faster"><a class="anchor" href="#hbase.unittests.test.faster"></a> 142.3.5。更快地运行测试</h4>
<div class="paragraph">
<p>默认， <code>$ mvn test -P runAllTests</code>并行运行5个测试。可以在开发人员的机器上增加它。允许每个内核并行进行2个测试，并且每个测试大约需要2GB的内存（在极端情况下），如果您拥有8个内核，24GB的盒子，则可以并行进行16个测试。但可用内存将其限制为12（24/2），要并行运行所有包含12个测试的测试，请执行以下操作：mvn test -P runAllTests -Dsurefire.secondPartForkCount = 12。如果使用的版本早于2.0，请执行：+ mvn test -P runAllTests -Dsurefire.secondPartThreadCount = 12 +。要提高速度，您还可以使用虚拟磁盘。您将需要2GB的内存才能运行所有测试。您还需要在两次测试运行之间删除文件。在Linux上配置虚拟磁盘的典型方法是：</p>
</div>
<div class="listingblock">
<div class="content">
<pre>$ sudo mkdir /ram2G
sudo mount -t tmpfs -o size=2048M tmpfs /ram2G</pre>
</div>
</div>
<div class="paragraph">
<p>然后，您可以使用它使用以下命令在2.0上运行所有HBase测试：</p>
</div>
<div class="listingblock">
<div class="content">
<pre>mvn test
                        -P runAllTests -Dsurefire.secondPartForkCount=12
                        -Dtest.build.data.basedirectory=/ram2G</pre>
</div>
</div>
<div class="paragraph">
<p>在早期版本上，使用：</p>
</div>
<div class="listingblock">
<div class="content">
<pre>mvn test
                        -P runAllTests -Dsurefire.secondPartThreadCount=12
                        -Dtest.build.data.basedirectory=/ram2G</pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="hbase.unittests.cmds.test.hbasetests"><a class="anchor" href="#hbase.unittests.cmds.test.hbasetests"></a> 142.3.6。 hbasetests.sh</h4>
<div class="paragraph">
<p>也可以使用脚本hbasetests.sh。该脚本与两个maven实例并行运行中型和大型测试，并提供一个报告。该脚本未使用surefire的hbase版本，因此除了脚本设置的两个maven实例外，没有进行并行化。它必须从包含<em>pom.xml</em>的目录中执行。</p>
</div>
<div class="paragraph">
<p>例如，运行./dev-support/hbasetests.sh将执行中小型测试。运行./dev-support/hbasetests.sh runAllTests将执行所有测试。运行./dev-support/hbasetests.sh replayFailed将在单独的jvm中且没有并行化的情况下第二次重新运行失败的测试。</p>
</div>
</div>
<div class="sect3">
<h4 id="hbase.unittests.resource.checker"><a class="anchor" href="#hbase.unittests.resource.checker"></a> 142.3.7。测试资源检查器</h4>
<div class="paragraph">
<p>一个自定义的Maven SureFire插件侦听器在每个HBase单元测试运行之前和之后检查大量资源，并将其发现记录在测试输出文件的末尾，这些文件可以在每个Maven模块的<em>目标/ surefire报告中</em>找到（测试写入名为将测试类放入此目录。检查<em>* -out.txt</em>文件）。计数的资源是线程数，文件描述符数等。如果数量增加，会增加<em>泄漏吗？</em> 在日志中发表评论。由于您可以在后台运行HBase实例，因此可以删除/创建一些线程，而无需在测试中进行任何特定操作。但是，如果测试无法按预期方式运行，或者测试不应影响这些资源，则值得检查这些日志行<span class="computeroutput">... hbase。ResourceChecker（157）：在...</span>和<span class="computeroutput">... hbase 之前</span> <span class="computeroutput">。ResourceChecker（157）：之后...。</span>例如：</p>
</div>
<div class="listingblock">
<div class="content">
<pre>2012-09-26 09:22:15,315 INFO [pool-1-thread-1]
hbase.ResourceChecker(157): after:
regionserver.TestColumnSeeking#testReseeking Thread=65 (was 65),
OpenFileDescriptor=107 (was 107), MaxFileDescriptor=10240 (was 10240),
ConnectionCount=1 (was 1)</pre>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="hbase.tests.writing"><a class="anchor" href="#hbase.tests.writing"></a> 142.4。写作测试</h3>
<div class="sect3">
<h4 id="hbase.tests.rules"><a class="anchor" href="#hbase.tests.rules"></a> 142.4.1。一般规则</h4>
<div class="ulist">
<ul>
<li>
<p>测试应尽可能写为小测试类别。</p>
</li>
<li>
<p>必须编写所有测试以支持在同一台计算机上并行执行，因此它们不应将共享资源用作固定端口或固定文件名。</p>
</li>
<li>
<p>测试不应覆盖。每秒超过100行的速度使日志读取和使用I / O变得很复杂，因此无法用于其他测试。</p>
</li>
<li>
<p>测试可以用<code>HBaseTestingUtility</code> 。此类提供了帮助程序功能，以创建临时目录并进行清理或启动集群。</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="hbase.tests.categories"><a class="anchor" href="#hbase.tests.categories"></a> 142.4.2。类别和执行时间</h4>
<div class="ulist">
<ul>
<li>
<p>所有测试都必须分类，否则可以跳过。</p>
</li>
<li>
<p>所有测试应尽可能快地编写。</p>
</li>
<li>
<p>请参阅<a href="#hbase.unittests">hbase.unittests</a>以获取测试用例类别和相应的超时。这应该确保使用它的人员具有良好的并行性，并在测试失败时简化分析。</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="hbase.tests.sleeps"><a class="anchor" href="#hbase.tests.sleeps"></a> 142.4.3。在测试中睡觉</h4>
<div class="paragraph">
<p>只要有可能，测试就不应使用<span class="method">Thread.sleep</span> ，而应等待所需的真实事件。对于读者来说，这更快，更清晰。如果不测试结束条件，则测试不应执行<span class="method">Thread.sleep</span> 。这样可以了解测试正在等待什么。而且，无论机器性能如何，该测试都可以进行。睡眠应尽量少，以尽可能快。等待变量应在40ms的睡眠循环中完成。等待套接字操作应在200 ms的睡眠循环中完成。</p>
</div>
</div>
<div class="sect3">
<h4 id="hbase.tests.cluster"><a class="anchor" href="#hbase.tests.cluster"></a> 142.4.4。使用集群进行测试</h4>
<div class="paragraph">
<p>使用HRegion进行的测试不必启动群集：区域可以使用本地文件系统。启动/停止群集大约需要10秒钟。它们不应按测试方法启动，而应按测试类启动。必须使用<span class="method">HBaseTestingUtility＃shutdownMiniCluster</span>关闭启动的集群，这会清理目录。测试应尽可能使用群集的默认设置。如果没有，则应记录下来。这将允许以后共享群集。</p>
</div>
</div>
<div class="sect3">
<h4 id="hbase.tests.example.code"><a class="anchor" href="#hbase.tests.example.code"></a> 142.4.5。测试骨架代码</h4>
<div class="paragraph">
<p>这是一个测试框架代码，具有分类和基于类别的超时规则，可以复制和粘贴并用作测试贡献的基础。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="comment">/**
 * Describe what this testcase tests. Talk about resources initialized in @BeforeClass (before
 * any test is run) and before each test is run, etc.
 */</span>
<span class="comment">// Specify the category as explained in &lt;&lt;hbase.unittests,hbase.unittests&gt;&gt;.</span>
<span class="annotation">@Category</span>(SmallTests.class)
<span class="directive">public</span> <span class="type">class</span> <span class="class">TestExample</span> {
  <span class="comment">// Replace the TestExample.class in the below with the name of your test fixture class.</span>
  <span class="directive">private</span> <span class="directive">static</span> <span class="directive">final</span> Log LOG = LogFactory.getLog(TestExample.class);

  <span class="comment">// Handy test rule that allows you subsequently get the name of the current method. See</span>
  <span class="comment">// down in 'testExampleFoo()' where we use it to log current test's name.</span>
  <span class="annotation">@Rule</span> <span class="directive">public</span> TestName testName = <span class="keyword">new</span> TestName();

  <span class="comment">// The below rule does two things. It decides the timeout based on the category</span>
  <span class="comment">// (small/medium/large) of the testcase. This @Rule requires that the full testcase runs</span>
  <span class="comment">// within this timeout irrespective of individual test methods' times. The second</span>
  <span class="comment">// feature is we'll dump in the log when the test is done a count of threads still</span>
  <span class="comment">// running.</span>
  <span class="annotation">@Rule</span> <span class="directive">public</span> <span class="directive">static</span> TestRule timeout = CategoryBasedTimeout.builder().
    withTimeout(<span class="local-variable">this</span>.getClass()).withLookingForStuckThread(<span class="predefined-constant">true</span>).build();

  <span class="annotation">@Before</span>
  <span class="directive">public</span> <span class="type">void</span> setUp() <span class="directive">throws</span> <span class="exception">Exception</span> {
  }

  <span class="annotation">@After</span>
  <span class="directive">public</span> <span class="type">void</span> tearDown() <span class="directive">throws</span> <span class="exception">Exception</span> {
  }

  <span class="annotation">@Test</span>
  <span class="directive">public</span> <span class="type">void</span> testExampleFoo() {
    LOG.info(<span class="string"><span class="delimiter">&quot;</span><span class="content">Running test </span><span class="delimiter">&quot;</span></span> + testName.getMethodName());
  }
}</code></pre>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="integration.tests"><a class="anchor" href="#integration.tests"></a> 142.5。整合测试</h3>
<div class="paragraph">
<p>HBase集成/系统测试是超出HBase单元测试的测试。它们通常是持久的，可调整大小的（可以要求测试1M行或1B行），可定位的（它们可以进行配置，将它们指向要运行的现成集群；集成测试不包括集群起始/停止代码），并验证成功，集成测试仅依赖于公共API；他们不会尝试检查断言成功/失败的服务器内部。当您需要进行单元候选者无法完成的更为详尽的版本候选证明时，将执行集成测试。它们通常不在Apache Continuous Integration构建服务器上运行，但是，某些站点选择将集成测试作为其在实际集群上进行的连续测试的一部分。</p>
</div>
<div class="paragraph">
<p>集成测试当前位于hbase-it子模块的<em>src / test</em>目录下，并将与正则表达式匹配： <em>* <strong>/ IntegrationTest</strong> .java</em> 。所有集成测试也都带有注释<code>@Category(IntegrationTests.class)</code> 。</p>
</div>
<div class="paragraph">
<p>集成测试可以两种模式运行：使用小型集群或针对实际的分布式集群。Maven故障安全用于使用小型集群运行测试。IntegrationTestsDriver类用于对分布式集群执行测试。集成测试不应假定它们针对小型集群运行，并且不应使用私有API访问集群状态。要与分布式集群或小型集群进行统一交互， <code>IntegrationTestingUtility</code>和<code>HBaseCluster</code>类，可以使用公共客户端API。</p>
</div>
<div class="paragraph">
<p>在分布式群集上，使用ChaosMonkey或通过群集管理器（例如，重启区域服务器）操纵服务的集成测试使用SSH来完成。要运行这些命令，测试过程应该能够在远程端运行命令，因此应该相应地配置ssh（例如，如果HBase在群集中的hbase用户下运行，则可以为该用户设置无密码的ssh并运行测试）在它下面）。为方便起见， <code>hbase.it.clustermanager.ssh.user</code> ， <code>hbase.it.clustermanager.ssh.opts</code>和<code>hbase.it.clustermanager.ssh.cmd</code>可以使用配置设置。“用户”是集群管理器用来执行ssh命令的远程用户。“选项”包含传递给SSH的其他选项（例如，“-i / tmp / my-key”）。最后，如果您有一些自定义环境设置，则“ cmd”是整个tunnel（ssh）命令的替代格式。默认字符串为{ <code>/usr/bin/ssh %1$s %2$s%3$s%4$s "%5$s"</code> }，这是一个很好的起点。这是带有5个参数的标准Java格式字符串，用于执行远程命令。参数1（％1 $ s）是SSH选项，可通过via opts设置或via环境变量来设置，2是SSH用户名，3是“ @”（如果设置了用户名）或“”，否则，4是目标主机名，以及5是要执行的逻辑命令（可能包含单引号，因此请不要使用它们）。例如，如果您在非hbase用户下运行测试，并希望以该用户身份ssh并更改为远程计算机上的hbase，则可以使用：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">/usr/bin/ssh %1$s %2$s%3$s%4$s &quot;su hbase - -c \&quot;%5$s\&quot;&quot;</code></pre>
</div>
</div>
<div class="paragraph">
<p>这样，可以终止RS（例如）集成测试：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">{/usr/bin/ssh some-hostname &quot;su hbase - -c \&quot;ps aux | ... | kill ...\&quot;&quot;}</code></pre>
</div>
</div>
<div class="paragraph">
<p>该命令已记录在测试日志中，因此您可以验证它是否适合您的环境。</p>
</div>
<div class="paragraph">
<p>要禁用集成测试的运行，请在命令行中传递以下配置文件<code>-PskipIntegrationTests</code> 。例如，</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="error">$</span> mvn clean install test -Dtest=TestZooKeeper  -PskipIntegrationTests</code></pre>
</div>
</div>
<div class="sect3">
<h4 id="maven.build.commands.integration.tests.mini"><a class="anchor" href="#maven.build.commands.integration.tests.mini"></a> 142.5.1。针对小型集群运行集成测试</h4>
<div class="paragraph">
<p>HBase 0.92添加了一个<code>verify</code>行家目标。调用它，例如通过执行<code>mvn verify</code> ，将通过maven <a href="https://maven.apache.org/plugins/maven-failsafe-plugin/">failsafe插件</a>运行直到验证阶段的所有阶段，包括上述所有HBase单元测试以及HBase集成测试组中的测试。完成mvn install -DskipTests之后，您可以通过调用以下命令来仅运行集成测试：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bourne">cd hbase-it
mvn verify</code></pre>
</div>
</div>
<div class="paragraph">
<p>如果只想在顶层运行集成测试，则需要运行两个命令。首先：mvn failsafe：integration-test实际上运行所有集成测试。</p>
</div>
<div class="admonitionblock note">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-note" title="注意"></i>
</td>
<td class="content">该命令将始终输出<code>BUILD SUCCESS</code>即使有测试失败。
</td>
</tr>
</tbody></table>
</div>
<div class="paragraph">
<p>此时，您可以手工grep输出以查找失败的测试。但是，maven将为我们做到这一点；只需使用：mvn failsafe：verify上面的命令基本上会查看所有测试结果（因此请不要删除“ target”目录）以查找测试失败并报告结果。</p>
</div>
<div class="sect4">
<h5 id="maven.build.commands.integration.tests2"><a class="anchor" href="#maven.build.commands.integration.tests2"></a>运行一部分集成测试</h5>
<div class="paragraph">
<p>这与您指定运行单元测试的子集的方式非常相似（请参见上文），但是使用属性<code>it.test</code>代替<code>test</code> 。刚跑<code>IntegrationTestClassXYZ.java</code> ，使用：mvn failsafe：integration-test -Dit.test = IntegrationTestClassXYZ接下来，您可能想做的是运行集成测试组，说所有名为IntegrationTestClassX * .java的集成测试：mvn failsafe：integration-test -Dit .test = * ClassX *这将运行与<strong>ClassX</strong>匹配的所有集成测试。这意味着任何匹配的内容：“ <strong>* / IntegrationTest * ClassX</strong> ”。您还可以使用逗号分隔的列表运行多组集成测试（类似于单元测试）。使用匹配列表仍然支持每个组的完整正则表达式匹配。看起来像这样：mvn failsafe：integration-test -Dit.test = * ClassX *，* ClassY</p>
</div>
</div>
</div>
<div class="sect3">
<h4 id="maven.build.commands.integration.tests.distributed"><a class="anchor" href="#maven.build.commands.integration.tests.distributed"></a> 142.5.2。针对分布式集群运行集成测试</h4>
<div class="paragraph">
<p>如果您已经设置了HBase集群，则可以通过调用该类来启动集成测试<code>IntegrationTestsDriver</code> 。您可能必须先运行测试编译。配置将由bin / hbase脚本选择。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bourne">mvn test-compile</code></pre>
</div>
</div>
<div class="paragraph">
<p>然后使用以下命令启动测试：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bourne">bin/hbase [--config config_dir] org.apache.hadoop.hbase.IntegrationTestsDriver</code></pre>
</div>
</div>
<div class="paragraph">
<p>通过<code>-h</code>在这个甜美的工具上使用。不带任何参数运行IntegrationTestsDriver将启动在以下位置找到的测试<code>hbase-it/src/test</code> ，具有<code>@Category(IntegrationTests.class)</code>注释，以及以<code>IntegrationTests</code> 。通过传递-h来查看用法，以了解如何过滤测试类。您可以传递一个正则表达式，该正则表达式将根据完整的类名进行检查；因此，可以使用部分类名。IntegrationTestsDriver使用Junit运行测试。当前不支持使用maven对分布式集群运行集成测试（请参阅<a href="https://issues.apache.org/jira/browse/HBASE-6201">HBASE-6201</a> ）。</p>
</div>
<div class="paragraph">
<p>测试使用以下方法与分布式集群交互： <code>DistributedHBaseCluster</code> （实施<code>HBaseCluster</code> ）类，而该类又使用了可插入式<code>ClusterManager</code> 。具体的实现为执行特定于部署和环境的任务（SSH等）提供了实际功能。默认值<code>ClusterManager</code>是<code>HBaseClusterManager</code> ，它使用SSH远程执行启动/停止/杀死/信号命令，并采用一些posix命令（例如ps等）。还假设运行测试的用户具有足够的“能力”来启动/停止远程计算机上的服务器。默认情况下，它拾取<code>HBASE_SSH_OPTS</code> ， <code>HBASE_HOME</code> ， <code>HBASE_CONF_DIR</code>从环境，并使用<code>bin/hbase-daemon.sh</code>开展行动。当前支持tarball部署，使用<em>hbase-daemons.sh的</em>部署以及<a href="https://incubator.apache.org/ambari/">Apache</a> <em>Ambari</em>部署。
目前不支持<em>/etc/init.d/</em>脚本，但是可以轻松添加。对于其他部署选项，可以实施并插入ClusterManager。</p>
</div>
</div>
<div class="sect3">
<h4 id="maven.build.commands.integration.tests.destructive"><a class="anchor" href="#maven.build.commands.integration.tests.destructive"></a> 142.5.3。破坏性集成/系统测试（ChaosMonkey）</h4>
<div class="paragraph">
<p>HBase 0.96引入了一个名为<code>ChaosMonkey</code> ，以<a href="https://netflix.github.io/chaosmonkey/">Netflix的Chaos Monkey工具</a>为<a href="https://netflix.github.io/chaosmonkey/">同名工具</a>建模。ChaosMonkey通过杀死或断开随机服务器或将其他故障注入环境来模拟正在运行的群集中的实际故障。您可以将ChaosMonkey用作独立工具，以在其他测试正在运行时运行策略。在某些环境中，ChaosMonkey始终处于运行状态，以便不断检查高可用性和容错能力是否按预期工作。</p>
</div>
<div class="paragraph">
<p>ChaosMonkey定义了<strong>操作</strong>和<strong>策略</strong> 。</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">动作</dt>
<dd>
<p>动作是事件的预定义序列，例如：</p>
<div class="ulist">
<ul>
<li>
<p>重新启动活动主服务器（睡眠5秒）</p>
</li>
<li>
<p>重新启动随机区域服务器（睡眠5秒）</p>
</li>
<li>
<p>重新启动随机区域服务器（睡眠60秒）</p>
</li>
<li>
<p>重新启动META区域服务器（睡眠5秒）</p>
</li>
<li>
<p>重新启动ROOT区域服务器（休眠5秒）</p>
</li>
<li>
<p>批量重启50％的区域服务器（休眠5秒）</p>
</li>
<li>
<p>滚动重启100％的区域服务器（休眠5秒）</p>
</li>
</ul>
</div>
</dd>
<dt class="hdlist1">政策规定</dt>
<dd>
<p>策略是用于执行一个或多个动作的策略。默认策略根据预定义的操作权重每分钟执行一次随机操作。给定的策略将一直执行到ChaosMonkey被中断为止。</p>
</dd>
</dl>
</div>
<div class="paragraph">
<p>大多数ChaosMonkey操作被配置为具有合理的默认值，因此您可以对现有集群运行ChaosMonkey，而无需任何其他配置。以下示例使用默认配置运行ChaosMonkey：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">$ bin/hbase org.apache.hadoop.hbase.util.ChaosMonkey

12/11/19 23:21:57 INFO util.ChaosMonkey: Using ChaosMonkey Policy: class org.apache.hadoop.hbase.util.ChaosMonkey$PeriodicRandomActionPolicy, period:60000
12/11/19 23:21:57 INFO util.ChaosMonkey: Sleeping for 26953 to add jitter
12/11/19 23:22:24 INFO util.ChaosMonkey: Performing action: Restart active master
12/11/19 23:22:24 INFO util.ChaosMonkey: Killing master:master.example.com,60000,1353367210440
12/11/19 23:22:24 INFO hbase.HBaseCluster: Aborting Master: master.example.com,60000,1353367210440
12/11/19 23:22:24 INFO hbase.ClusterManager: Executing remote command: ps aux | grep master | grep -v grep | tr -s ' ' | cut -d ' ' -f2 | xargs kill -s SIGKILL , hostname:master.example.com
12/11/19 23:22:25 INFO hbase.ClusterManager: Executed remote command, exit code:0 , output:
12/11/19 23:22:25 INFO hbase.HBaseCluster: Waiting service:master to stop: master.example.com,60000,1353367210440
12/11/19 23:22:25 INFO hbase.ClusterManager: Executing remote command: ps aux | grep master | grep -v grep | tr -s ' ' | cut -d ' ' -f2 , hostname:master.example.com
12/11/19 23:22:25 INFO hbase.ClusterManager: Executed remote command, exit code:0 , output:
12/11/19 23:22:25 INFO util.ChaosMonkey: Killed master server:master.example.com,60000,1353367210440
12/11/19 23:22:25 INFO util.ChaosMonkey: Sleeping for:5000
12/11/19 23:22:30 INFO util.ChaosMonkey: Starting master:master.example.com
12/11/19 23:22:30 INFO hbase.HBaseCluster: Starting Master on: master.example.com
12/11/19 23:22:30 INFO hbase.ClusterManager: Executing remote command: /homes/enis/code/hbase-0.94/bin/../bin/hbase-daemon.sh --config /homes/enis/code/hbase-0.94/bin/../conf start master , hostname:master.example.com
12/11/19 23:22:31 INFO hbase.ClusterManager: Executed remote command, exit code:0 , output:starting master, logging to /homes/enis/code/hbase-0.94/bin/../logs/hbase-enis-master-master.example.com.out
....
12/11/19 23:22:33 INFO util.ChaosMonkey: Started master: master.example.com,60000,1353367210440
12/11/19 23:22:33 INFO util.ChaosMonkey: Sleeping for:51321
12/11/19 23:23:24 INFO util.ChaosMonkey: Performing action: Restart random region server
12/11/19 23:23:24 INFO util.ChaosMonkey: Killing region server:rs3.example.com,60020,1353367027826
12/11/19 23:23:24 INFO hbase.HBaseCluster: Aborting RS: rs3.example.com,60020,1353367027826
12/11/19 23:23:24 INFO hbase.ClusterManager: Executing remote command: ps aux | grep regionserver | grep -v grep | tr -s ' ' | cut -d ' ' -f2 | xargs kill -s SIGKILL , hostname:rs3.example.com
12/11/19 23:23:25 INFO hbase.ClusterManager: Executed remote command, exit code:0 , output:
12/11/19 23:23:25 INFO hbase.HBaseCluster: Waiting service:regionserver to stop: rs3.example.com,60020,1353367027826
12/11/19 23:23:25 INFO hbase.ClusterManager: Executing remote command: ps aux | grep regionserver | grep -v grep | tr -s ' ' | cut -d ' ' -f2 , hostname:rs3.example.com
12/11/19 23:23:25 INFO hbase.ClusterManager: Executed remote command, exit code:0 , output:
12/11/19 23:23:25 INFO util.ChaosMonkey: Killed region server:rs3.example.com,60020,1353367027826. Reported num of rs:6
12/11/19 23:23:25 INFO util.ChaosMonkey: Sleeping for:60000
12/11/19 23:24:25 INFO util.ChaosMonkey: Starting region server:rs3.example.com
12/11/19 23:24:25 INFO hbase.HBaseCluster: Starting RS on: rs3.example.com
12/11/19 23:24:25 INFO hbase.ClusterManager: Executing remote command: /homes/enis/code/hbase-0.94/bin/../bin/hbase-daemon.sh --config /homes/enis/code/hbase-0.94/bin/../conf start regionserver , hostname:rs3.example.com
12/11/19 23:24:26 INFO hbase.ClusterManager: Executed remote command, exit code:0 , output:starting regionserver, logging to /homes/enis/code/hbase-0.94/bin/../logs/hbase-enis-regionserver-rs3.example.com.out

12/11/19 23:24:27 INFO util.ChaosMonkey: Started region server:rs3.example.com,60020,1353367027826. Reported num of rs:6</code></pre>
</div>
</div>
<div class="paragraph">
<p>输出表明ChaosMonkey已启动默认<code>PeriodicRandomActionPolicy</code>策略，其中配置了所有可用操作。它选择运行<code>RestartActiveMaster</code>和<code>RestartRandomRs</code>动作。</p>
</div>
</div>
<div class="sect3">
<h4 id="_available_policies"><a class="anchor" href="#_available_policies"></a> 142.5.4。可用政策</h4>
<div class="paragraph">
<p>HBase附带了一些ChaosMonkey策略，可在<code>hbase/hbase-it/src/test/java/org/apache/hadoop/hbase/chaos/policies/</code>目录。</p>
</div>
</div>
<div class="sect3">
<h4 id="chaos.monkey.properties"><a class="anchor" href="#chaos.monkey.properties"></a> 142.5.5。配置单个ChaosMonkey操作</h4>
<div class="paragraph">
<p>从HBase版本1.0.0（ <a href="https://issues.apache.org/jira/browse/HBASE-11348">HBASE-11348</a> ）开始，可以在每次测试运行中配置ChaosMonkey集成测试。在HBase类路径中创建Java属性文件，然后使用将该文件传递给ChaosMonkey <code>-monkeyProps</code>配置标志。可配置属性及其默认值（如果适用）列在<code>org.apache.hadoop.hbase.chaos.factories.MonkeyConstants</code>类。对于具有默认值的属性，可以通过将其包含在属性文件中来覆盖它们。</p>
</div>
<div class="paragraph">
<p>以下示例使用一个名为<a href="#monkey.properties">monkey.properties</a>的属性文件。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bourne">$ bin/hbase org.apache.hadoop.hbase.IntegrationTestIngest -m slowDeterministic -monkeyProps monkey.properties</code></pre>
</div>
</div>
<div class="paragraph">
<p>上面的命令将启动集成测试，并通过属性文件<em>monkey.properties来搅乱猴子</em> 。这是一个混乱的猴子文件示例：</p>
</div>
<div id="monkey.properties" class="listingblock">
<div class="title">示例ChaosMonkey属性文件</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">sdm.action1.period=<span class="integer">120000</span>
sdm.action2.period=<span class="integer">40000</span>
move.regions.sleep.time=<span class="integer">80000</span>
move.regions.max.time=<span class="integer">1000000</span>
move.regions.sleep.time=<span class="integer">80000</span>
batch.restart.rs.ratio=<span class="float">0.4f</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>HBase 1.0.2及更高版本增加了重新启动HBase的基础ZooKeeper仲裁或HDFS节点的功能。要使用这些操作，您需要在ChaosMonkey属性文件中配置一些新属性，这些属性没有合理的默认值，因为它们是特定于部署的，可能是<code>hbase-site.xml</code>或其他属性文件。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="xml"><span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>hbase.it.clustermanager.hadoop.home<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>$HADOOP_HOME<span class="tag">&lt;/value&gt;</span>
<span class="tag">&lt;/property&gt;</span>
<span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>hbase.it.clustermanager.zookeeper.home<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>$ZOOKEEPER_HOME<span class="tag">&lt;/value&gt;</span>
<span class="tag">&lt;/property&gt;</span>
<span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>hbase.it.clustermanager.hbase.user<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>hbase<span class="tag">&lt;/value&gt;</span>
<span class="tag">&lt;/property&gt;</span>
<span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>hbase.it.clustermanager.hadoop.hdfs.user<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>hdfs<span class="tag">&lt;/value&gt;</span>
<span class="tag">&lt;/property&gt;</span>
<span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>hbase.it.clustermanager.zookeeper.user<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>zookeeper<span class="tag">&lt;/value&gt;</span>
<span class="tag">&lt;/property&gt;</span></code></pre>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="developing"><a class="anchor" href="#developing"></a> 143。开发人员指南</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_branches"><a class="anchor" href="#_branches"></a> 143.1。分行</h3>
<div class="paragraph">
<p>我们使用Git进行源代码管理，最新开发发生在<code>master</code>科。过去的主要/次要/维护版本都有分支机构，重要的功能和错误修复通常会向后移植到它们。</p>
</div>
</div>
<div class="sect2">
<h3 id="_release_managers"><a class="anchor" href="#_release_managers"></a> 143.2。发布经理</h3>
<div class="paragraph">
<p>每个维护的发行分支都有一个发行经理，该经理自愿协调新功能，并将错误修复程序反向移植到该发行版。发布经理是<a href="https://hbase.apache.org/team-list.html">提交者</a> 。如果您希望将功能或错误修复程序包含在给定的版本中，请与该版本管理器进行通信。如果此列表已过期或您无法与列出的人联系，请与列表中的其他人联系。</p>
</div>
<div class="admonitionblock note">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-note" title="注意"></i>
</td>
<td class="content">寿命终止版本不包括在此列表中。
</td>
</tr>
</tbody></table>
</div>
<table class="tableblock frame-all grid-all spread">
<caption class="title">表10。发布经理</caption>
<colgroup>
<col style="width:50%">
<col style="width:50%">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">发布</th>
<th class="tableblock halign-left valign-top">发布经理</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">尼克·迪米杜克（Nick Dimiduk）</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">肖恩·布斯比</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.3</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">米哈伊尔·安东诺夫（Mikhail Antonov）</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="_policy_for_fix_version_in_jira"><a class="anchor" href="#_policy_for_fix_version_in_jira"></a> 143.3。JIRA中修订版本的政策</h3>
<div class="paragraph">
<p>为了仅从发行版号确定给定修订是否在给定发行版中，定义了以下规则：</p>
</div>
<div class="paragraph">
<p>固定版本的XYZ⇒在所有发行版XYZ'中均已固定（其中Z'= Z）。<br>固定版本XY0⇒在所有发行版XY'。*中均已固定（其中Y'= Y）。<br>修复了X.0.0的版本⇒已在所有发行版X'中修复。*。*（其中X'= X）。<br></p>
</div>
<div class="paragraph">
<p>根据此策略，1.3.0的修订版本暗含1.4.0，但1.3.2并不暗含1.4.0，因为我们不能完全根据数字来判断发行顺序。</p>
</div>
</div>
<div class="sect2">
<h3 id="code.standards"><a class="anchor" href="#code.standards"></a> 143.4。规范标准</h3>
<div class="sect3">
<h4 id="_interface_classifications"><a class="anchor" href="#_interface_classifications"></a> 143.4.1。接口分类</h4>
<div class="paragraph">
<p>接口按受众和稳定性级别进行分类。这些标签显示在课程的开头。HBase遵循的约定由其父项目Hadoop继承。</p>
</div>
<div class="paragraph">
<p>通常使用以下接口分类：</p>
</div>
<div class="dlist">
<div class="title">接口受众</div>
<dl>
<dt class="hdlist1"><code>@InterfaceAudience.Public</code></dt>
<dd>
<p>用户和HBase应用程序的API。这些API将通过主要版本的HBase弃用。</p>
</dd>
<dt class="hdlist1"><code>@InterfaceAudience.Private</code></dt>
<dd>
<p>适用于HBase内部人员开发人员的API。不保证将来版本的兼容性或可用性。专用接口不需要<code>@InterfaceStability</code>分类。</p>
</dd>
<dt class="hdlist1"><code>@InterfaceAudience.LimitedPrivate(HBaseInterfaceAudience.COPROC)</code></dt>
<dd>
<p>适用于HBase协处理器编写器的API。</p>
</dd>
<dt class="hdlist1">没有<code>@InterfaceAudience</code>分类</dt>
<dd>
<p>不带包装<code>@InterfaceAudience</code>标签被视为私有标签。如果可以公开访问，请标记新软件包。</p>
</dd>
</dl>
</div>
<div class="admonitionblock note">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-note" title="注意"></i>
</td>
<td class="content">
<div class="title">从API文档中排除非公共接口</div>
<div class="paragraph">
<p>仅接口分类<code>@InterfaceAudience.Public</code>应该包含在API文档（Javadoc）中。提交者必须添加新的包裹排除<code>ExcludePackageNames</code>不包含公共类的新软件包的<em>pom.xml的“</em>部分”。</p>
</div>
</td>
</tr>
</tbody></table>
</div>
<div class="paragraph">
<div class="title">@InterfaceStability</div>
<p><code>@InterfaceStability</code>对于标记的包装很重要<code>@InterfaceAudience.Public</code> 。</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1"><code>@InterfaceStability.Stable</code></dt>
<dd>
<p>没有弃用路径或非常充分的理由，不能更改标记为稳定的公共软件包。</p>
</dd>
<dt class="hdlist1"><code>@InterfaceStability.Unstable</code></dt>
<dd>
<p>标记为不稳定的公共软件包可以更改，而无需使用弃用路径。</p>
</dd>
<dt class="hdlist1"><code>@InterfaceStability.Evolving</code></dt>
<dd>
<p>标记为不断发展的公共软件包可能会更改，但不鼓励这样做。</p>
</dd>
<dt class="hdlist1">没有<code>@InterfaceStability</code>标签</dt>
<dd>
<p>没有公开课<code>@InterfaceStability</code>不鼓励使用标签，应将其视为隐含不稳定的。</p>
</dd>
</dl>
</div>
<div class="paragraph">
<p>如果不清楚如何标记软件包，请在开发列表中询问。</p>
</div>
</div>
<div class="sect3">
<h4 id="common.patch.feedback"><a class="anchor" href="#common.patch.feedback"></a> 143.4.2。代码格式约定</h4>
<div class="paragraph">
<p>请遵守以下准则，以便可以更快地查看您的补丁。这些准则是根据新贡献者对补丁的普遍反馈而制定的。</p>
</div>
<div class="paragraph">
<p>有关<a href="http://www.oracle.com/technetwork/java/index-135089.html">Java</a>编码约定的更多信息，请参见<a href="http://www.oracle.com/technetwork/java/index-135089.html">Java编程语言</a>的编码约定。请参阅<a href="#eclipse.code.formatting">eclipse.code.formatting</a>来设置Eclipse，以自动检查其中的一些准则。</p>
</div>
<div class="sect4">
<h5 id="common.patch.feedback.space.invaders"><a class="anchor" href="#common.patch.feedback.space.invaders"></a>太空侵略者</h5>
<div class="paragraph">
<p>不要在括号周围使用多余的空格。使用第二种样式，而不是第一种。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="keyword">if</span> ( foo.equals( bar ) ) {     <span class="comment">// don't do this</span></code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="keyword">if</span> (foo.equals(bar)) {</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">foo = barArray[ i ];     <span class="comment">// don't do this</span></code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">foo = barArray[i];</code></pre>
</div>
</div>
</div>
<div class="sect4">
<h5 id="common.patch.feedback.autogen"><a class="anchor" href="#common.patch.feedback.autogen"></a>自动生成的代码</h5>
<div class="paragraph">
<p>Eclipse中自动生成的代码通常使用错误的变量名，例如<code>arg0</code> 。使用更多有用的变量名。在这里使用类似于第二个示例的代码。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"> <span class="directive">public</span> <span class="type">void</span> readFields(<span class="predefined-type">DataInput</span> arg0) <span class="directive">throws</span> <span class="exception">IOException</span> {    <span class="comment">// don't do this</span>
   foo = arg0.readUTF();                                       <span class="comment">// don't do this</span></code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"> <span class="directive">public</span> <span class="type">void</span> readFields(<span class="predefined-type">DataInput</span> di) <span class="directive">throws</span> <span class="exception">IOException</span> {
   foo = di.readUTF();</code></pre>
</div>
</div>
</div>
<div class="sect4">
<h5 id="common.patch.feedback.longlines"><a class="anchor" href="#common.patch.feedback.longlines"></a>排长龙</h5>
<div class="paragraph">
<p>行数不得超过100个字符。您可以将IDE配置为自动执行此操作。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">Bar bar = foo.veryLongMethodWithManyArguments(argument1, argument2, argument3, argument4, argument5, argument6, argument7, argument8, argument9);  <span class="comment">// don't do this</span></code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">Bar bar = foo.veryLongMethodWithManyArguments(
 argument1, argument2, argument3,argument4, argument5, argument6, argument7, argument8, argument9);</code></pre>
</div>
</div>
</div>
<div class="sect4">
<h5 id="common.patch.feedback.trailingspaces"><a class="anchor" href="#common.patch.feedback.trailingspaces"></a>尾随空格</h5>
<div class="paragraph">
<p>确保在代码末尾有换行符，并避免只有空格的行。这使得差异更加有意义。您可以配置您的IDE来帮助您。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">Bar bar = foo.getBar();     &lt;--- imagine there is an extra space(s) after the semicolon.</code></pre>
</div>
</div>
</div>
<div class="sect4">
<h5 id="common.patch.feedback.javadoc"><a class="anchor" href="#common.patch.feedback.javadoc"></a> API文档（Javadoc）</h5>
<div class="paragraph">
<p>不要忘记Javadoc！</p>
</div>
<div class="paragraph">
<p>在预提交期间检查Javadoc警告。如果预提交工具给您一个“ -1”，请解决javadoc问题。如果添加了此类警告，则不会提交您的补丁。</p>
</div>
<div class="paragraph">
<p>还没有<code>@author</code>标签-这是规则。</p>
</div>
</div>
<div class="sect4">
<h5 id="common.patch.feedback.findbugs"><a class="anchor" href="#common.patch.feedback.findbugs"></a>虫子</h5>
<div class="paragraph">
<p><code>Findbugs</code>用于检测常见的错误模式。在预提交构建过程中将对其进行检查。如果发现错误，请修复它们。您可以在本地运行findbugs <code>mvn findbugs:findbugs</code> ，这将生成<code>findbugs</code>本地文件。有时，您可能需要编写比以下代码更聪明的代码<code>findbugs</code> 。您可以注释代码以告知<code>findbugs</code>通过使用以下注释对您的类进行注释，您就知道自己在做什么：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="annotation">@edu</span>.umd.cs.findbugs.annotations.SuppressWarnings(
value=<span class="string"><span class="delimiter">&quot;</span><span class="content">HE_EQUALS_USE_HASHCODE</span><span class="delimiter">&quot;</span></span>,
justification=<span class="string"><span class="delimiter">&quot;</span><span class="content">I know what I'm doing</span><span class="delimiter">&quot;</span></span>)</code></pre>
</div>
</div>
<div class="paragraph">
<p>使用批注的Apache许可版本很重要。这通常意味着在<code>edu.umd.cs.findbugs.annotations</code>软件包，以便我们可以依靠洁净室的重新实现，而不是依赖于<code>javax.annotations</code>包。</p>
</div>
</div>
<div class="sect4">
<h5 id="common.patch.feedback.javadoc.defaults"><a class="anchor" href="#common.patch.feedback.javadoc.defaults"></a> Javadoc-无用的默认值</h5>
<div class="paragraph">
<p>不要仅仅以IDE生成Javadoc标记的方式保留它们，也不要在其中填充冗余信息。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">  <span class="comment">/**
   * @param table                              &lt;---- don't leave them empty!
   * @param region An HRegion object.          &lt;---- don't fill redundant information!
   * @return Foo Object foo just created.      &lt;---- Not useful information
   * @throws SomeException                     &lt;---- Not useful. Function declarations already tell that!
   * @throws BarException when something went wrong  &lt;---- really?
   */</span>
  <span class="directive">public</span> Foo createFoo(Bar bar);</code></pre>
</div>
</div>
<div class="paragraph">
<p>在标签中添加描述性内容，或将其删除。首选是添加一些描述性和有用的内容。</p>
</div>
</div>
<div class="sect4">
<h5 id="common.patch.feedback.onething"><a class="anchor" href="#common.patch.feedback.onething"></a>一次一件事，民间</h5>
<div class="paragraph">
<p>如果您为某件事提交了补丁，请不要在完全不同的代码区域上进行自动重新格式化或不相关的重新格式化代码。</p>
</div>
<div class="paragraph">
<p>同样，请勿在Jira的范围之外添加无关的清理或重构。</p>
</div>
</div>
<div class="sect4">
<h5 id="common.patch.feedback.tests"><a class="anchor" href="#common.patch.feedback.tests"></a>模棱两可的单元测试</h5>
<div class="paragraph">
<p>确保您清楚单元测试中要测试的内容以及原因。</p>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_garbage_collection_conserving_guidelines"><a class="anchor" href="#_garbage_collection_conserving_guidelines"></a> 143.4.3。垃圾收集保存准则</h4>
<div class="paragraph">
<p>以下指南是从<a href="http://engineering.linkedin.com/performance/linkedin-feed-faster-less-jvm-garbage" class="bare">http://engineering.linkedin.com/performance/linkedin-feed-faster-less-jvm-garbage</a>借来的。请记住它们，以尽量减少可预防的垃圾收集。请参阅博客文章，了解一些如何根据这些准则重构代码的出色示例。</p>
</div>
<div class="ulist">
<ul>
<li>
<p>小心迭代器</p>
</li>
<li>
<p>初始化时估计集合的大小</p>
</li>
<li>
<p>推迟表达评估</p>
</li>
<li>
<p>预先编译正则表达式模式</p>
</li>
<li>
<p>可以缓存</p>
</li>
<li>
<p>字符串实习生很有用，但很危险</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect2">
<h3 id="design.invariants"><a class="anchor" href="#design.invariants"></a> 143.5。不变量</h3>
<div class="paragraph">
<p>我们没有很多，但是我们在下面列出了什么。当然，所有人都面临挑战，但在此之前，请遵守道路规则。</p>
</div>
<div class="sect3">
<h4 id="design.invariants.zk.data"><a class="anchor" href="#design.invariants.zk.data"></a> 143.5.1。ZooKeeper中没有永久状态</h4>
<div class="paragraph">
<p>ZooKeeper状态应该是瞬态的（像处理内存一样进行处理）。如果删除ZooKeeper状态，则hbase应该能够恢复并且基本上处于相同状态。</p>
</div>
<div class="ulist">
<ul>
<li>
<p>。例外：目前，我们需要解决一些例外，这些例外是关于表是启用还是禁用的。</p>
</li>
<li>
<p>复制数据当前仅存储在ZooKeeper中。删除与复制相关的ZooKeeper数据可能会导致复制被禁用。不要删除复制树<em>/ hbase / replication /</em> 。</p>
<div class="admonitionblock warning">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-warning" title="警告"></i>
</td>
<td class="content">如果从ZooKeeper删除复制树（ <em>/ hbase / replication /</em> ），则复制可能会中断，并且可能会发生数据丢失。在<a href="https://issues.apache.org/jira/browse/HBASE-10295">HBASE-10295</a>上跟踪此问题<a href="https://issues.apache.org/jira/browse/HBASE-10295">的进展</a> 。
</td>
</tr>
</tbody></table>
</div>
</li>
</ul>
</div>
</div>
</div>
<div class="sect2">
<h3 id="run.insitu"><a class="anchor" href="#run.insitu"></a> 143.6。原位运行</h3>
<div class="paragraph">
<p>如果您正在开发Apache HBase，则经常需要在比单元测试中更真实的集群上测试更改，这一点很有用。在这种情况下，可以直接在本地模式下从源运行HBase。您需要做的就是运行：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bourne">${HBASE_HOME}/bin/start-hbase.sh</code></pre>
</div>
</div>
<div class="paragraph">
<p>这将启动完整的本地集群，就像打包HBase并将其安装在计算机上一样。</p>
</div>
<div class="paragraph">
<p>请记住，您需要将HBase安装到本地maven存储库中才能使原位群集正常工作。也就是说，您将需要运行：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bourne">mvn clean install -DskipTests</code></pre>
</div>
</div>
<div class="paragraph">
<p>确保maven可以找到正确的类路径和依赖项。通常，如果maven的行为异常，则上面的命令只是尝试首先运行是一件好事。</p>
</div>
</div>
<div class="sect2">
<h3 id="add.metrics"><a class="anchor" href="#add.metrics"></a> 143.7。添加指标</h3>
<div class="paragraph">
<p>添加新功能后，开发人员可能想要添加指标。HBase使用Hadoop Metrics 2系统公开指标，因此添加新指标涉及将该指标公开给hadoop系统。不幸的是，metrics2的API从hadoop 1更改为hadoop 2。为了解决这个问题，必须在运行时加载一组接口和实现。要深入了解这些类的原因和结构，请阅读<a href="https://blogs.apache.org/hbase/entry/migration_to_the_new_metrics">此处</a>的博客文章。要将度量添加到现有MBean，请遵循以下简短指南：</p>
</div>
<div class="sect3">
<h4 id="_add_metric_name_and_function_to_hadoop_compat_interface"><a class="anchor" href="#_add_metric_name_and_function_to_hadoop_compat_interface"></a> 143.7.1。将指标名称和功能添加到Hadoop Compat接口。</h4>
<div class="paragraph">
<p>在源接口内部，与度量标准的生成位置相对应（例如，来自HMaster的MetricsMasterSource用于创建度量标准名称和描述的新静态字符串）。然后添加一个将被调用以添加新读数的新方法。</p>
</div>
</div>
<div class="sect3">
<h4 id="_add_the_implementation_to_both_hadoop_1_and_hadoop_2_compat_modules"><a class="anchor" href="#_add_the_implementation_to_both_hadoop_1_and_hadoop_2_compat_modules"></a> 143.7.2。将实现添加到Hadoop 1和Hadoop 2 Compat模块中。</h4>
<div class="paragraph">
<p>内部执行源代码（例如上例中的MetricsMasterSourceImpl）在init方法中创建了新的直方图，计数器，量表或stat。然后，在添加到接口的方法中，将传入直方图的参数连接起来。</p>
</div>
<div class="paragraph">
<p>现在添加测试，以确保将数据正确导出到metrics 2系统。为此，提供了MetricsAssertHelper。</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="git.best.practices"><a class="anchor" href="#git.best.practices"></a> 143.8。Git最佳实践</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">避免git合并。</dt>
<dd>
<p>使用<code>git pull --rebase</code>要么<code>git fetch</code>其次是<code>git rebase</code> 。</p>
</dd>
<dt class="hdlist1">不使用<code>git push --force</code> 。</dt>
<dd>
<p>如果推不起作用，请解决问题或寻求帮助。</p>
</dd>
</dl>
</div>
<div class="paragraph">
<p>如果您想到其他Git最佳实践，请贡献本文档。</p>
</div>
<div class="sect3">
<h4 id="__code_rebase_all_git_branches_sh_code"><a class="anchor" href="#__code_rebase_all_git_branches_sh_code"></a> 143.8.1。<code>rebase_all_git_branches.sh</code></h4>
<div class="paragraph">
<p>提供了<em>dev-support / rebase_all_git_branches.sh</em>脚本来帮助保持Git存储库的干净。使用<code>-h</code>参数以获取使用说明。该脚本会自动刷新您的跟踪分支，尝试针对每个本地分支对其远程分支进行自动变基，并为您提供删除代表关闭的任何分支的选项<code>HBASE-</code> JIRA。该脚本具有一个可选的配置选项，即Git目录的位置。您可以通过编辑脚本来设置默认值。否则，您可以使用手动传递git目录<code>-d</code>参数，后跟绝对或相对目录名称，甚至是“。”当前工作目录。该脚本在继续之前检查目录中是否存在名为<em>.git /</em>的子目录。</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="submitting.patches"><a class="anchor" href="#submitting.patches"></a> 143.9。提交补丁</h3>
<div class="paragraph">
<p>如果您不熟悉向开源提交补丁程序，或者不熟悉向Apache提交补丁程序，请先阅读<a href="https://commons.apache.org/">Apache Commons Project</a>的<a href="https://commons.apache.org/patches.html">On Contributing Patches</a>页面。它提供了一个很好的概述，同样适用于Apache HBase Project。
<a href="https://accumulo.apache.org/git.html">阅读有关如何贡献和开发的Accumulo文档</a>也很容易理解开发工作流程。</p>
</div>
<div class="sect3">
<h4 id="submitting.patches.create"><a class="anchor" href="#submitting.patches.create"></a> 143.9.1。创建补丁</h4>
<div class="paragraph">
<p>确保检查<a href="#common.patch.feedback">common.patch.feedback</a>的代码样式。如果补丁生成不正确，或者代码不符合代码格式准则，则可能会要求您重新做一些工作。</p>
</div>
<div class="listingblock">
<div class="title">使用submit-patch.py（推荐）</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bourne">$ dev-support/submit-patch.py -jid HBASE-xxxxx</code></pre>
</div>
</div>
<div class="paragraph">
<p>使用此脚本创建补丁，上传到jira并有选择地在Review Board上创建/更新评论。补丁名称会自动格式化为<em>（JIRA）。（分支名称）。（补丁编号）</em> .patch以遵循Yetus的命名规则。使用<code>-h</code>标记以了解详细的使用信息。最有用的选项是：</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>-b BRANCH, --branch BRANCH</code> ：指定用于生成差异的基本分支。如果未指定，则使用跟踪分支。如果没有跟踪分支，将引发错误。</p>
</li>
<li>
<p><code>-jid JIRA_ID, --jira-id JIRA_ID</code> ：如果使用，则从jira的附件中推断出下一补丁版本，并上传新补丁。脚本将要求输入jira用户名/密码进行身份验证。如果未设置，则修补程序名为<branch>.patch。</branch></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>默认情况下，它还将创建/更新审查委员会。要跳过该操作，请使用<code>-srb</code>选项。它使用jira中的“问题链接”来确定是否已存在审阅请求。如果没有审阅请求，则创建一个新的审阅请求，并使用jira摘要，补丁说明等填充所有必填字段。还将此审阅的链接添加到jira。</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">保存身份验证凭据（可选）</dt>
<dd>
<p>由于在JIRA上附加补丁并在ReviewBoard上创建/更改审阅请求需要有效的用户身份验证，因此脚本将提示您输入用户名和密码。为了避免每次麻烦，请设置<code>~/.apache-creds</code>登录详细信息，并按照脚本帮助消息页脚中的步骤进行加密。</p>
</dd>
<dt class="hdlist1">Python依赖项</dt>
<dd>
<p>要安装所需的python依赖项，请执行<code>pip install -r dev-support/python-requirements.txt</code>来自master分支。</p>
</dd>
</dl>
</div>
<div class="olist arabic">
<div class="title">手动地</div>
<ol class="arabic">
<li>
<p>使用<code>git rebase -i</code>首先，将较小的提交合并（压缩）为单个较大的提交。</p>
</li>
<li>
<p>使用IDE或Git命令创建补丁。 <code>git format-patch</code>首选，因为它会保留补丁作者的姓名和提交消息。此外，它默认处理二进制文件，而<code>git diff</code>除非您使用<code>--binary</code>选项。</p>
</li>
<li>
<p>补丁名称应如下以遵守Yetus的命名约定：<br>
<code>(JIRA).(branch name).(patch number).patch</code><br>例如。HBASE-11625.master.001.patch，HBASE-XXXXX.branch-1.2.0005.patch等</p>
</li>
<li>
<p>使用以下命令将补丁附加到JIRA <code>More→Attach Files</code>然后单击“ <b class="button">提交补丁”</b>按钮，这将触发Hudson作业以检查补丁的有效性。</p>
</li>
<li>
<p>如果您的补丁程序比单个屏幕长，请在“审查委员会”上创建审查，并将链接添加到JIRA。请参阅<a href="#reviewboard">评论板</a> 。</p>
</li>
</ol>
</div>
<div class="ulist">
<div class="title">通用准则很少</div>
<ul>
<li>
<p>即使要在另一个分支中进行修补，也始终要先对master分支进行修补。HBase提交者始终始终首先将补丁应用到master分支，并在必要时进行反向移植。</p>
</li>
<li>
<p>提交一个修补程序。如有必要，请压缩本地提交以首先将本地提交合并为一个。有关压缩提交的更多信息，请参<a href="http://stackoverflow.com/questions/5308816/how-to-use-git-merge-squash">见此堆栈溢出问题</a> 。</p>
</li>
<li>
<p>请理解，并非每个补丁都可以提交，并且补丁上可能会提供反馈。</p>
</li>
<li>
<p>如果您需要修改补丁，请将先前的补丁文件保留在JIRA上，然后上传补丁号递增的新补丁文件。<br>单击<b class="button">取消补丁</b> ，然后单击<b class="button">提交补丁</b>以触发预<b class="button">提交</b>运行。</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="submitting.patches.tests"><a class="anchor" href="#submitting.patches.tests"></a> 143.9.2。单元测试</h4>
<div class="paragraph">
<p>进行更改时，请始终添加和/或更新相关的单元测试。在提交补丁之前，请确保新的/更改的单元测试在本地通过，因为它比等待运行完整测试套件的预提交结果要快。这样可以节省您的时间和精力。使用<a href="#mockito">Mockito</a>进行模拟，通过注入适当的故障对测试故障方案非常有用。</p>
</div>
<div class="paragraph">
<p>如果要创建一个新的单元测试类，请注意其他单元测试类在类名之前具有分类/大小注释，以及用于设置/拆卸测试环境的静态方法。确保在任何新的单元测试文件中包含注释。有关<a href="#hbase.tests">测试</a>的更多信息，请参见<a href="#hbase.tests">hbase.tests</a> 。</p>
</div>
</div>
<div class="sect3">
<h4 id="_integration_tests"><a class="anchor" href="#_integration_tests"></a> 143.9.3。整合测试</h4>
<div class="paragraph">
<p>除单元测试外，重要的新功能还应提供集成测试，以适合在其配置空间的不同位置使用新功能。</p>
</div>
</div>
<div class="sect3">
<h4 id="reviewboard"><a class="anchor" href="#reviewboard"></a> 143.9.4。评审委员会</h4>
<div class="paragraph">
<p>大于一个屏幕的修补程序或难以审核的修补程序应通过<a href="https://reviews.apache.org">ReviewBoard</a>进行<a href="https://reviews.apache.org">检查</a> 。</p>
</div>
<div class="olist arabic">
<div class="title">过程：使用ReviewBoard</div>
<ol class="arabic">
<li>
<p>如果您还没有帐户，请注册。它不使用<a href="https://issues.apache.org">issue.apache.org中</a>的凭据。登录。</p>
</li>
<li>
<p>点击<span class="label">新审核请求</span> 。</p>
</li>
<li>
<p>选择<code>hbase-git</code>资料库。单击选择文件以选择差异和父差异（可选）。单击<b class="button">创建审阅请求</b> 。</p>
</li>
<li>
<p>根据需要填写字段。至少填写<span class="label">摘要，</span>然后选择<code>hbase</code>作为<span class="label">审核组</span> 。如果填写“ <span class="label">错误”</span>字段，则评审委员会将链接回相关的JIRA。您填写的字段越多越好。单击<b class="button">发布</b>以公开您的评论请求。电子邮件将发送给<code>hbase</code>组，以查看补丁。</p>
</li>
<li>
<p>返回JIRA中，单击，然后粘贴ReviewBoard请求的URL。这会将ReviewBoard附加到JIRA，以便于访问。</p>
</li>
<li>
<p>要取消请求，请单击。</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>有关如何使用ReviewBoard的更多信息，请参见<a href="http://www.reviewboard.org/docs/manual/1.5/">ReviewBoard文档</a> 。</p>
</div>
</div>
<div class="sect3">
<h4 id="_guide_for_hbase_committers"><a class="anchor" href="#_guide_for_hbase_committers"></a> 143.9.5。HBase提交者指南</h4>
<div class="sect4">
<h5 id="_new_committers"><a class="anchor" href="#_new_committers"></a>新提交者</h5>
<div class="paragraph">
<p>鼓励新的提交者首先阅读Apache的通用提交者文档：</p>
</div>
<div class="ulist">
<ul>
<li>
<p><a href="https://www.apache.org/dev/new-committers-guide.html">Apache新提交者指南</a></p>
</li>
<li>
<p><a href="https://www.apache.org/dev/committers.html">Apache Committer常见问题解答</a></p>
</li>
</ul>
</div>
</div>
<div class="sect4">
<h5 id="_review"><a class="anchor" href="#_review"></a>评论</h5>
<div class="paragraph">
<p>HBase提交者应尽可能多地尝试检查其他人提交的补丁。理想情况下，提交者会<em>在几天内</em>对每个提交的补丁进行审查。如果提交者审阅了他们尚未编写的补丁程序，并认为其质量足够，则可以提交该补丁程序，否则应取消该补丁程序，并明确说明拒绝该补丁程序的原因。</p>
</div>
<div class="paragraph">
<p>提交的修补程序列表在<a href="https://issues.apache.org/jira/secure/IssueNavigator.jspa?mode=hide&requestId=12312392">HBase审查队列中</a> ，该<a href="https://issues.apache.org/jira/secure/IssueNavigator.jspa?mode=hide&requestId=12312392">队列</a>按上次修改时间排序。提交者应从上到下扫描列表，寻找他们认为有资格审查并可能提交的补丁。</p>
</div>
<div class="paragraph">
<p>对于不重要的更改，需要让另一个提交者在提交之前查看您自己的补丁。像其他贡献者一样，使用JIRA中的<b class="button">Submit Patch</b>按钮，然后等待<code>+1</code>提交之前来自其他提交者的响应。</p>
</div>
</div>
<div class="sect4">
<h5 id="_reject"><a class="anchor" href="#_reject"></a>拒绝</h5>
<div class="paragraph">
<p>不遵守<a href="https://hbase.apache.org/book.html#developer">HowToContribute</a>准则和<a href="https://wiki.apache.org/hadoop/CodeReviewChecklist">代码审查清单的</a>补丁应予以拒绝。提交者应始终对贡献者有礼貌，并尝试指导和鼓励他们做出更好的贡献。如果提交者希望改进不可接受的补丁，则应首先将其拒绝，然后提交者应附加新的补丁以进行审核。</p>
</div>
</div>
<div class="sect4">
<h5 id="committing.patches"><a class="anchor" href="#committing.patches"></a>承诺</h5>
<div class="paragraph">
<p>提交者将补丁提交到Apache HBase GIT存储库。</p>
</div>
<div class="admonitionblock note">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-note" title="注意"></i>
</td>
<td class="content">
<div class="title">在您提交之前！！！！</div>
<div class="paragraph">
<p>确保您的本地配置正确，尤其是您的身份和电子邮件。检查$ git config --list命令的输出，并确保它是正确的。如果需要指针，请参见此GitHub文章“ <a href="https://help.github.com/articles/set-up-git">设置Git”</a> 。</p>
</div>
</td>
</tr>
</tbody></table>
</div>
<div class="paragraph">
<p>提交补丁时，请：</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>在提交消息中包括Jira问题ID以及对更改的简短描述。尝试添加不仅仅是Jira标题的内容，这样一来查看git log的人就不必去Jira来了解更改的含义。确保正确获得问题ID，因为这会导致Jira链接到Git中的更改（使用问题的“全部”标签来查看这些问题）。</p>
</li>
<li>
<p>将补丁提交到基于master或其他预期分支的新分支。最好通过JIRA ID调用此分支。然后通过执行git pull --rebase或其他类似的命令，检查要提交的相关目标分支，确保本地分支具有所有远程更改，将更改樱桃选择到每个相关分支（例如master）中并执行git push <remote-server><remote-branch>。</remote-branch></remote-server></p>
<div class="admonitionblock warning">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-warning" title="警告"></i>
</td>
<td class="content">如果您没有所有远程更改，则推送将失败。如果由于任何原因推送失败，请解决问题或寻求帮助。不要执行git push --force。
</td>
</tr>
</tbody></table>
</div>
<div class="paragraph">
<p>在提交补丁之前，您需要确定补丁的创建方式。有关创建补丁的方式的说明和首选项已更改，并且会有过渡期。</p>
</div>
<div class="ulist">
<div class="title">确定如何创建补丁</div>
<ul>
<li>
<p>如果补丁的前几行看起来像是电子邮件的标题，带有“发件人”，“日期”和“主题”，则它是使用git format-patch创建的。这是首选方法，因为您可以重用提交者的提交消息。如果提交消息不合适，您仍然可以使用提交，然后运行<code>git commit --amend</code>并酌情改写。</p>
</li>
<li>
<p>如果补丁的第一行与下面的相似，则它是使用git diff创建的，没有<code>--no-prefix</code> 。这也是可以接受的。注意<code>a</code>和<code>b</code>在文件名前面。这表明补丁不是使用<code>--no-prefix</code> 。</p>
<div class="listingblock">
<div class="content">
<pre>diff --git a/src/main/asciidoc/_chapters/developer.adoc b/src/main/asciidoc/_chapters/developer.adoc</pre>
</div>
</div>
</li>
<li>
<p>如果补丁的第一行看起来与下面的相似（没有<code>a</code>和<code>b</code> ），该补丁是使用git diff --no-prefix创建的，您需要添加<code>-p0</code>到下面的git apply命令。</p>
<div class="listingblock">
<div class="content">
<pre>diff --git src/main/asciidoc/_chapters/developer.adoc src/main/asciidoc/_chapters/developer.adoc</pre>
</div>
</div>
</li>
</ul>
</div>
<div class="exampleblock">
<div class="title">示例50提交补丁的示例</div>
<div class="content">
<div class="paragraph">
<p>这些示例中您会注意到的一件事是，有很多git pull命令。实际将任何内容写入远程存储库的唯一命令是git push，您需要绝对确保所有内容的版本正确并且在推送之前没有任何冲突。多余的git pull命令通常是多余的，但比遗憾更好。</p>
</div>
<div class="paragraph">
<p>第一个示例显示了如何应用git format-patch生成的补丁并将其应用于<code>master</code>和<code>branch-1</code>分支机构。</p>
</div>
<div class="paragraph">
<p>该指令使用git format-patch而不是git diff，并且不使用<code>--no-prefix</code> ，是一个新的。请参阅第二个示例，以了解如何应用git diff创建的补丁，以及如何教育创建补丁的人员。</p>
</div>
<div class="listingblock">
<div class="content">
<pre>$ git checkout -b HBASE-XXXX
$ git am ~/Downloads/HBASE-XXXX-v2.patch --signoff  # If you are committing someone else's patch.
$ git checkout master
$ git pull --rebase
$ git cherry-pick &lt;sha-from-commit&gt;
# Resolve conflicts if necessary or ask the submitter to do it
$ git pull --rebase          # Better safe than sorry
$ git push origin master

# Backport to branch-1
$ git checkout branch-1
$ git pull --rebase
$ git cherry-pick &lt;sha-from-commit&gt;
# Resolve conflicts if necessary
$ git pull --rebase          # Better safe than sorry
$ git push origin branch-1
$ git branch -D HBASE-XXXX</pre>
</div>
</div>
<div class="paragraph">
<p>这个例子展示了如何提交使用git diff创建的补丁，而没有<code>--no-prefix</code> 。如果补丁是用<code>--no-prefix</code> ，添加<code>-p0</code>到git apply命令。</p>
</div>
<div class="listingblock">
<div class="content">
<pre>$ git apply ~/Downloads/HBASE-XXXX-v2.patch
$ git commit -m "HBASE-XXXX Really Good Code Fix (Joe Schmo)" --author=&lt;contributor&gt; -a  # This
and next command is needed for patches created with 'git diff'
$ git commit --amend --signoff
$ git checkout master
$ git pull --rebase
$ git cherry-pick &lt;sha-from-commit&gt;
# Resolve conflicts if necessary or ask the submitter to do it
$ git pull --rebase          # Better safe than sorry
$ git push origin master

# Backport to branch-1
$ git checkout branch-1
$ git pull --rebase
$ git cherry-pick &lt;sha-from-commit&gt;
# Resolve conflicts if necessary or ask the submitter to do it
$ git pull --rebase           # Better safe than sorry
$ git push origin branch-1
$ git branch -D HBASE-XXXX</pre>
</div>
</div>
</div>
</div>
</li>
<li>
<p>固定解决此问题，感谢贡献者。始终在此时设置“修复版本”，但请仅对提交更改的每个分支设置一个修订版本，该分支是该更改将出现的最早版本。</p>
</li>
</ol>
</div>
<div class="sect5">
<h6 id="_commit_message_format"><a class="anchor" href="#_commit_message_format"></a>提交消息格式</h6>
<div class="paragraph">
<p>提交消息应包含JIRA ID和补丁程序的描述。首选的提交消息格式为：</p>
</div>
<div class="listingblock">
<div class="content">
<pre>&lt;jira-id&gt; &lt;jira-title&gt; (&lt;contributor-name-if-not-commit-author&gt;)</pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre>HBASE-12345 Fix All The Things (jane@example.com)</pre>
</div>
</div>
<div class="paragraph">
<p>如果贡献者使用git format-patch生成补丁，那么他们的提交消息就在他们的补丁中，您可以使用它，但是请确保JIRA ID位于提交消息的最前面，即使贡献者将其遗漏了也是如此。</p>
</div>
</div>
<div class="sect5">
<h6 id="committer.amending.author"><a class="anchor" href="#committer.amending.author"></a>发生冲突后向后移植时添加“修改作者”</h6>
<div class="paragraph">
<p>我们已经建立了以下做法：承诺掌握，然后在可能的情况下尽量选择分支机构，除非</p>
</div>
<div class="ulist">
<ul>
<li>
<p>它破坏了兼容性：在这种情况下，如果它可以在次要版本中发布，请反向移植到Branch-1和Branch-2。</p>
</li>
<li>
<p>这是一项新功能：否针对维护版本，对于次要版本，请进行讨论并达成共识。</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>如果发生较小的冲突，我们可以修复它，然后继续进行提交。最终提交保留原始作者。如果修改作者不同于原始提交者，请在提交消息的末尾添加对此的通知，如下所示： <code>Amending-Author: Author <committer&apache></code>参见<a href="http://search-hadoop.com/m/DHED4wHGYS">HBase上的</a>讨论<a href="http://search-hadoop.com/m/DHED4wHGYS">，邮件＃dev-[讨论</a>修改从主节点到分支节点挑选的<a href="http://search-hadoop.com/m/DHED4wHGYS">落实时的</a>最佳实践]。</p>
</div>
</div>
<div class="sect5">
<h6 id="committer.tests"><a class="anchor" href="#committer.tests"></a>提交者负责确保提交不会破坏构建或测试</h6>
<div class="paragraph">
<p>如果提交者提交了补丁，则确保其通过测试套件是他们的责任。如果提供者注意他们的补丁程序不会破坏hbase的构建和/或测试，这将很有帮助，但是最终，不能期望提供者知道诸如HBase之类的项目中发生的所有特定变化和互连。提交者应该。</p>
</div>
</div>
<div class="sect5">
<h6 id="git.patch.flow"><a class="anchor" href="#git.patch.flow"></a>修补礼节</h6>
<div class="paragraph">
<p>在线程<a href="http://search-hadoop.com/m/DHED4EiwOz">HBase中，邮件＃dev-公告：正在进行Git迁移（WAS⇒Re：Git Migration）</a> ，它同意以下补丁流程</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>首先针对master开发并提交补丁。</p>
</li>
<li>
<p>如果可能的话，尝试在移植时选择修补程序。</p>
</li>
<li>
<p>如果这不起作用，请手动将补丁提交到分支。</p>
</li>
</ol>
</div>
</div>
<div class="sect5">
<h6 id="_merge_commits"><a class="anchor" href="#_merge_commits"></a>合并提交</h6>
<div class="paragraph">
<p>避免合并提交，因为它们会在git历史记录中造成问题。</p>
</div>
</div>
<div class="sect5">
<h6 id="_committing_documentation"><a class="anchor" href="#_committing_documentation"></a>提交文件</h6>
<div class="paragraph">
<p>请参阅<a href="#appendix_contributing_to_documentation">附录中的文档</a> 。</p>
</div>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_dialog"><a class="anchor" href="#_dialog"></a> 143.9.6。对话</h4>
<div class="paragraph">
<p>提交者应该在irc.freenode.net的#hbase会议室中闲逛，以进行实时讨论。但是，应在Jira或开发人员列表中再次重申任何实质性讨论（以及与项目外的项目相关的讨论）。</p>
</div>
</div>
<div class="sect3">
<h4 id="_do_not_edit_jira_comments"><a class="anchor" href="#_do_not_edit_jira_comments"></a> 143.9.7。不要编辑JIRA评论</h4>
<div class="paragraph">
<p>拼写错误和/或语法错误比JIRA注释编辑引起的中断更可取：请参见<a href="http://search-hadoop.com/?q=[Reopened]+%28HBASE-451%29+Remove+HTableDescriptor+from+HRegionInfo&fc_project=HBase">Re：（HBASE-451）上的讨论从HRegionInfo删除HTableDescriptor</a></p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="hbase.archetypes.development"><a class="anchor" href="#hbase.archetypes.development"></a> 143.10。与HBase相关的Maven原型的开发</h3>
<div class="paragraph">
<p>与HBase相关的Maven原型的开发始于<a href="https://issues.apache.org/jira/browse/HBASE-14876">HBASE-14876</a> 。有关hbase原型基础结构的概述以及开发与HBase相关的新Maven原型的说明，请参见<code>hbase/hbase-archetypes/README.md</code> 。</p>
</div>
</div>
</div>
</div>
<h1 id="unit.tests" class="sect0"><a class="anchor" href="#unit.tests"></a>单元测试HBase应用程序</h1>
<div class="openblock partintro">
<div class="content">本章讨论使用JUnit，Mockito，MRUnit和HBaseTestingUtility对HBase应用程序进行单元测试。许多信息来自<a href="http://blog.cloudera.com/blog/2013/09/how-to-test-hbase-applications-using-popular-tools/">有关测试HBase应用程序的社区博客文章</a> 。有关HBase本身的单元测试的信息，请参见<a href="#hbase.tests">hbase.tests</a> 。
</div>
</div>
<div class="sect1">
<h2 id="_junit"><a class="anchor" href="#_junit"></a> 144。JUnit的</h2>
<div class="sectionbody">
<div class="paragraph">
<p>HBase使用<a href="http://junit.org">JUnit</a> 4进行单元测试</p>
</div>
<div class="paragraph">
<p>本示例将单元测试添加到以下示例类：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="directive">public</span> <span class="type">class</span> <span class="class">MyHBaseDAO</span> {

    <span class="directive">public</span> <span class="directive">static</span> <span class="type">void</span> insertRecord(Table.getTable(table), HBaseTestObj obj)
    <span class="directive">throws</span> <span class="exception">Exception</span> {
        Put put = createPut(obj);
        table.put(put);
    }

    <span class="directive">private</span> <span class="directive">static</span> Put createPut(HBaseTestObj obj) {
        Put put = <span class="keyword">new</span> Put(Bytes.toBytes(obj.getRowKey()));
        put.add(Bytes.toBytes(<span class="string"><span class="delimiter">&quot;</span><span class="content">CF</span><span class="delimiter">&quot;</span></span>), Bytes.toBytes(<span class="string"><span class="delimiter">&quot;</span><span class="content">CQ-1</span><span class="delimiter">&quot;</span></span>),
                    Bytes.toBytes(obj.getData1()));
        put.add(Bytes.toBytes(<span class="string"><span class="delimiter">&quot;</span><span class="content">CF</span><span class="delimiter">&quot;</span></span>), Bytes.toBytes(<span class="string"><span class="delimiter">&quot;</span><span class="content">CQ-2</span><span class="delimiter">&quot;</span></span>),
                    Bytes.toBytes(obj.getData2()));
        <span class="keyword">return</span> put;
    }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>第一步是将JUnit依赖项添加到您的Maven POM文件中：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="xml"><span class="tag">&lt;dependency&gt;</span>
    <span class="tag">&lt;groupId&gt;</span>junit<span class="tag">&lt;/groupId&gt;</span>
    <span class="tag">&lt;artifactId&gt;</span>junit<span class="tag">&lt;/artifactId&gt;</span>
    <span class="tag">&lt;version&gt;</span>4.11<span class="tag">&lt;/version&gt;</span>
    <span class="tag">&lt;scope&gt;</span>test<span class="tag">&lt;/scope&gt;</span>
<span class="tag">&lt;/dependency&gt;</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>接下来，将一些单元测试添加到您的代码中。测试带有注释<code>@Test</code> 。在这里，单元测试以粗体显示。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="directive">public</span> <span class="type">class</span> <span class="class">TestMyHbaseDAOData</span> {
  <span class="annotation">@Test</span>
  <span class="directive">public</span> <span class="type">void</span> testCreatePut() <span class="directive">throws</span> <span class="exception">Exception</span> {
  HBaseTestObj obj = <span class="keyword">new</span> HBaseTestObj();
  obj.setRowKey(<span class="string"><span class="delimiter">&quot;</span><span class="content">ROWKEY-1</span><span class="delimiter">&quot;</span></span>);
  obj.setData1(<span class="string"><span class="delimiter">&quot;</span><span class="content">DATA-1</span><span class="delimiter">&quot;</span></span>);
  obj.setData2(<span class="string"><span class="delimiter">&quot;</span><span class="content">DATA-2</span><span class="delimiter">&quot;</span></span>);
  Put put = MyHBaseDAO.createPut(obj);
  assertEquals(obj.getRowKey(), Bytes.toString(put.getRow()));
  assertEquals(obj.getData1(), Bytes.toString(put.get(Bytes.toBytes(<span class="string"><span class="delimiter">&quot;</span><span class="content">CF</span><span class="delimiter">&quot;</span></span>), Bytes.toBytes(<span class="string"><span class="delimiter">&quot;</span><span class="content">CQ-1</span><span class="delimiter">&quot;</span></span>)).get(<span class="integer">0</span>).getValue()));
  assertEquals(obj.getData2(), Bytes.toString(put.get(Bytes.toBytes(<span class="string"><span class="delimiter">&quot;</span><span class="content">CF</span><span class="delimiter">&quot;</span></span>), Bytes.toBytes(<span class="string"><span class="delimiter">&quot;</span><span class="content">CQ-2</span><span class="delimiter">&quot;</span></span>)).get(<span class="integer">0</span>).getValue()));
  }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>这些测试可确保您的<code>createPut</code>方法创建，填充并返回一个<code>Put</code>具有期望值的对象。当然，JUnit可以做的还不止这些。有关JUnit的介绍，请参见链接：https：//github.com/junit-team/junit/wiki/入门。</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_mockito"><a class="anchor" href="#_mockito"></a> 145。莫基托</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Mockito是一个模拟框架。它比JUnit更进一步，它允许您测试对象之间的交互，而不必复制整个环境。您可以在其项目站点上找到有关Mockito的更多信息，链接为：https：//code.google.com/p/mockito/。</p>
</div>
<div class="paragraph">
<p>您可以使用Mockito在较小的单元上进行单元测试。例如，您可以模拟一个<code>org.apache.hadoop.hbase.Server</code>实例或<code>org.apache.hadoop.hbase.master.MasterServices</code>接口参考，而不是全面的<code>org.apache.hadoop.hbase.master.HMaster</code> 。</p>
</div>
<div class="paragraph">
<p>本示例以<a href="#unit.tests">unit.tests中</a>的示例代码为<a href="#unit.tests">基础</a> ，以测试<code>insertRecord</code>方法。</p>
</div>
<div class="paragraph">
<p>首先，将Mockito的依赖项添加到您的Maven POM文件中。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="xml"><span class="tag">&lt;dependency&gt;</span>
    <span class="tag">&lt;groupId&gt;</span>org.mockito<span class="tag">&lt;/groupId&gt;</span>
    <span class="tag">&lt;artifactId&gt;</span>mockito-all<span class="tag">&lt;/artifactId&gt;</span>
    <span class="tag">&lt;version&gt;</span>1.9.5<span class="tag">&lt;/version&gt;</span>
    <span class="tag">&lt;scope&gt;</span>test<span class="tag">&lt;/scope&gt;</span>
<span class="tag">&lt;/dependency&gt;</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>接下来，添加一个<code>@RunWith</code>注释到您的测试类，以指示它使用Mockito。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="annotation">@RunWith</span>(MockitoJUnitRunner.class)
<span class="directive">public</span> <span class="type">class</span> <span class="class">TestMyHBaseDAO</span>{
  <span class="annotation">@Mock</span>
  <span class="predefined-type">Configuration</span> config = HBaseConfiguration.create();
  <span class="annotation">@Mock</span>
  <span class="predefined-type">Connection</span> connection = ConnectionFactory.createConnection(config);
  <span class="annotation">@Mock</span>
  <span class="directive">private</span> Table table;
  <span class="annotation">@Captor</span>
  <span class="directive">private</span> ArgumentCaptor putCaptor;

  <span class="annotation">@Test</span>
  <span class="directive">public</span> <span class="type">void</span> testInsertRecord() <span class="directive">throws</span> <span class="exception">Exception</span> {
    <span class="comment">//return mock table when getTable is called</span>
    when(connection.getTable(TableName.valueOf(<span class="string"><span class="delimiter">&quot;</span><span class="content">tablename</span><span class="delimiter">&quot;</span></span>)).thenReturn(table);
    <span class="comment">//create test object and make a call to the DAO that needs testing</span>
    HBaseTestObj obj = <span class="keyword">new</span> HBaseTestObj();
    obj.setRowKey(<span class="string"><span class="delimiter">&quot;</span><span class="content">ROWKEY-1</span><span class="delimiter">&quot;</span></span>);
    obj.setData1(<span class="string"><span class="delimiter">&quot;</span><span class="content">DATA-1</span><span class="delimiter">&quot;</span></span>);
    obj.setData2(<span class="string"><span class="delimiter">&quot;</span><span class="content">DATA-2</span><span class="delimiter">&quot;</span></span>);
    MyHBaseDAO.insertRecord(table, obj);
    verify(table).put(putCaptor.capture());
    Put put = putCaptor.getValue();

    assertEquals(Bytes.toString(put.getRow()), obj.getRowKey());
    <span class="keyword">assert</span>(put.has(Bytes.toBytes(<span class="string"><span class="delimiter">&quot;</span><span class="content">CF</span><span class="delimiter">&quot;</span></span>), Bytes.toBytes(<span class="string"><span class="delimiter">&quot;</span><span class="content">CQ-1</span><span class="delimiter">&quot;</span></span>)));
    <span class="keyword">assert</span>(put.has(Bytes.toBytes(<span class="string"><span class="delimiter">&quot;</span><span class="content">CF</span><span class="delimiter">&quot;</span></span>), Bytes.toBytes(<span class="string"><span class="delimiter">&quot;</span><span class="content">CQ-2</span><span class="delimiter">&quot;</span></span>)));
    assertEquals(Bytes.toString(put.get(Bytes.toBytes(<span class="string"><span class="delimiter">&quot;</span><span class="content">CF</span><span class="delimiter">&quot;</span></span>),Bytes.toBytes(<span class="string"><span class="delimiter">&quot;</span><span class="content">CQ-1</span><span class="delimiter">&quot;</span></span>)).get(<span class="integer">0</span>).getValue()), <span class="string"><span class="delimiter">&quot;</span><span class="content">DATA-1</span><span class="delimiter">&quot;</span></span>);
    assertEquals(Bytes.toString(put.get(Bytes.toBytes(<span class="string"><span class="delimiter">&quot;</span><span class="content">CF</span><span class="delimiter">&quot;</span></span>),Bytes.toBytes(<span class="string"><span class="delimiter">&quot;</span><span class="content">CQ-2</span><span class="delimiter">&quot;</span></span>)).get(<span class="integer">0</span>).getValue()), <span class="string"><span class="delimiter">&quot;</span><span class="content">DATA-2</span><span class="delimiter">&quot;</span></span>);
  }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>此代码填充<code>HBaseTestObj</code>与<code>ROWKEY-1'',</code> DATA-1''，``DATA-2''作为值。然后将记录插入到模拟表中。将捕获DAO可能插入的Put，并测试值以验证它们是否符合您的期望。</p>
</div>
<div class="paragraph">
<p>此处的关键是在DAO外部管理Connection和Table实例的创建。这样您就可以干净地模拟它们并测试Puts，如上所示。同样，您现在可以扩展到其他操作，例如“获取”，“扫描”或“删除”。</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_mrunit"><a class="anchor" href="#_mrunit"></a> 146。MRUnit</h2>
<div class="sectionbody">
<div class="paragraph">
<p><a href="http://mrunit.apache.org/">Apache MRUnit</a>是一个库，可用于对MapReduce作业进行单元测试。您可以使用它以与其他MapReduce作业相同的方式测试HBase作业。</p>
</div>
<div class="paragraph">
<p>给定一个MapReduce作业，该作业将写入一个称为HBase的表<code>MyTest</code> ，其中有一个列族称为<code>CF</code> ，此类工作的简化程序如下所示：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="directive">public</span> <span class="type">class</span> <span class="class">MyReducer</span> <span class="directive">extends</span> TableReducer&lt;Text, Text, ImmutableBytesWritable&gt; {
   <span class="directive">public</span> <span class="directive">static</span> <span class="directive">final</span> <span class="type">byte</span><span class="type">[]</span> CF = <span class="string"><span class="delimiter">&quot;</span><span class="content">CF</span><span class="delimiter">&quot;</span></span>.getBytes();
   <span class="directive">public</span> <span class="directive">static</span> <span class="directive">final</span> <span class="type">byte</span><span class="type">[]</span> QUALIFIER = <span class="string"><span class="delimiter">&quot;</span><span class="content">CQ-1</span><span class="delimiter">&quot;</span></span>.getBytes();
   <span class="directive">public</span> <span class="type">void</span> reduce(Text key, <span class="predefined-type">Iterable</span>&lt;Text&gt; values, <span class="predefined-type">Context</span> context) <span class="directive">throws</span> <span class="exception">IOException</span>, <span class="exception">InterruptedException</span> {
     <span class="comment">//bunch of processing to extract data to be inserted, in our case, lets say we are simply</span>
     <span class="comment">//appending all the records we receive from the mapper for this particular</span>
     <span class="comment">//key and insert one record into HBase</span>
     <span class="predefined-type">StringBuffer</span> data = <span class="keyword">new</span> <span class="predefined-type">StringBuffer</span>();
     Put put = <span class="keyword">new</span> Put(Bytes.toBytes(key.toString()));
     <span class="keyword">for</span> (Text val : values) {
         data = data.append(val);
     }
     put.add(CF, QUALIFIER, Bytes.toBytes(data.toString()));
     <span class="comment">//write to HBase</span>
     context.write(<span class="keyword">new</span> ImmutableBytesWritable(Bytes.toBytes(key.toString())), put);
   }
 }</code></pre>
</div>
</div>
<div class="paragraph">
<p>要测试此代码，第一步是将MRUnit依赖项添加到Maven POM文件中。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="xml"><span class="tag">&lt;dependency&gt;</span>
   <span class="tag">&lt;groupId&gt;</span>org.apache.mrunit<span class="tag">&lt;/groupId&gt;</span>
   <span class="tag">&lt;artifactId&gt;</span>mrunit<span class="tag">&lt;/artifactId&gt;</span>
   <span class="tag">&lt;version&gt;</span>1.0.0 <span class="tag">&lt;/version&gt;</span>
   <span class="tag">&lt;scope&gt;</span>test<span class="tag">&lt;/scope&gt;</span>
<span class="tag">&lt;/dependency&gt;</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>接下来，在您的Reducer作业中使用MRUnit提供的ReducerDriver。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="directive">public</span> <span class="type">class</span> <span class="class">MyReducerTest</span> {
    ReduceDriver&lt;Text, Text, ImmutableBytesWritable, Writable&gt; reduceDriver;
    <span class="type">byte</span><span class="type">[]</span> CF = <span class="string"><span class="delimiter">&quot;</span><span class="content">CF</span><span class="delimiter">&quot;</span></span>.getBytes();
    <span class="type">byte</span><span class="type">[]</span> QUALIFIER = <span class="string"><span class="delimiter">&quot;</span><span class="content">CQ-1</span><span class="delimiter">&quot;</span></span>.getBytes();

    <span class="annotation">@Before</span>
    <span class="directive">public</span> <span class="type">void</span> setUp() {
      MyReducer reducer = <span class="keyword">new</span> MyReducer();
      reduceDriver = ReduceDriver.newReduceDriver(reducer);
    }

   <span class="annotation">@Test</span>
   <span class="directive">public</span> <span class="type">void</span> testHBaseInsert() <span class="directive">throws</span> <span class="exception">IOException</span> {
      <span class="predefined-type">String</span> strKey = <span class="string"><span class="delimiter">&quot;</span><span class="content">RowKey-1</span><span class="delimiter">&quot;</span></span>, strValue = <span class="string"><span class="delimiter">&quot;</span><span class="content">DATA</span><span class="delimiter">&quot;</span></span>, strValue1 = <span class="string"><span class="delimiter">&quot;</span><span class="content">DATA1</span><span class="delimiter">&quot;</span></span>,
strValue2 = <span class="string"><span class="delimiter">&quot;</span><span class="content">DATA2</span><span class="delimiter">&quot;</span></span>;
      <span class="predefined-type">List</span>&lt;Text&gt; list = <span class="keyword">new</span> <span class="predefined-type">ArrayList</span>&lt;Text&gt;();
      list.add(<span class="keyword">new</span> Text(strValue));
      list.add(<span class="keyword">new</span> Text(strValue1));
      list.add(<span class="keyword">new</span> Text(strValue2));
      <span class="comment">//since in our case all that the reducer is doing is appending the records that the mapper</span>
      <span class="comment">//sends it, we should get the following back</span>
      <span class="predefined-type">String</span> expectedOutput = strValue + strValue1 + strValue2;
     <span class="comment">//Setup Input, mimic what mapper would have passed</span>
      <span class="comment">//to the reducer and run test</span>
      reduceDriver.withInput(<span class="keyword">new</span> Text(strKey), list);
      <span class="comment">//run the reducer and get its output</span>
      <span class="predefined-type">List</span>&lt;Pair&lt;ImmutableBytesWritable, Writable&gt;&gt; result = reduceDriver.run();

      <span class="comment">//extract key from result and verify</span>
      assertEquals(Bytes.toString(result.get(<span class="integer">0</span>).getFirst().get()), strKey);

      <span class="comment">//extract value for CF/QUALIFIER and verify</span>
      Put a = (Put)result.get(<span class="integer">0</span>).getSecond();
      <span class="predefined-type">String</span> c = Bytes.toString(a.get(CF, QUALIFIER).get(<span class="integer">0</span>).getValue());
      assertEquals(expectedOutput,c );
   }

}</code></pre>
</div>
</div>
<div class="paragraph">
<p>您的MRUnit测试验证输出是否符合预期，插入HBase的Put值正确，并且ColumnFamily和ColumnQualifier值正确。</p>
</div>
<div class="paragraph">
<p>MRUnit包含一个MapperDriver来测试映射作业，您可以使用MRUnit来测试其他操作，包括从HBase读取，处理数据或写入HDFS，</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_integration_testing_with_a_hbase_mini_cluster"><a class="anchor" href="#_integration_testing_with_a_hbase_mini_cluster"></a> 147。与HBase Mini-Cluster的集成测试</h2>
<div class="sectionbody">
<div class="paragraph">
<p>HBase附带了HBaseTestingUtility，这使得使用<em class="firstterm">mini-cluster</em>编写集成测试变得容易。第一步是向您的Maven POM文件添加一些依赖项。检查版本以确保它们合适。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="xml"><span class="tag">&lt;dependency&gt;</span>
    <span class="tag">&lt;groupId&gt;</span>org.apache.hadoop<span class="tag">&lt;/groupId&gt;</span>
    <span class="tag">&lt;artifactId&gt;</span>hadoop-common<span class="tag">&lt;/artifactId&gt;</span>
    <span class="tag">&lt;version&gt;</span>2.0.0<span class="tag">&lt;/version&gt;</span>
    <span class="tag">&lt;type&gt;</span>test-jar<span class="tag">&lt;/type&gt;</span>
    <span class="tag">&lt;scope&gt;</span>test<span class="tag">&lt;/scope&gt;</span>
<span class="tag">&lt;/dependency&gt;</span>

<span class="tag">&lt;dependency&gt;</span>
    <span class="tag">&lt;groupId&gt;</span>org.apache.hbase<span class="tag">&lt;/groupId&gt;</span>
    <span class="tag">&lt;artifactId&gt;</span>hbase<span class="tag">&lt;/artifactId&gt;</span>
    <span class="tag">&lt;version&gt;</span>0.98.3<span class="tag">&lt;/version&gt;</span>
    <span class="tag">&lt;type&gt;</span>test-jar<span class="tag">&lt;/type&gt;</span>
    <span class="tag">&lt;scope&gt;</span>test<span class="tag">&lt;/scope&gt;</span>
<span class="tag">&lt;/dependency&gt;</span>

<span class="tag">&lt;dependency&gt;</span>
    <span class="tag">&lt;groupId&gt;</span>org.apache.hadoop<span class="tag">&lt;/groupId&gt;</span>
    <span class="tag">&lt;artifactId&gt;</span>hadoop-hdfs<span class="tag">&lt;/artifactId&gt;</span>
    <span class="tag">&lt;version&gt;</span>2.0.0<span class="tag">&lt;/version&gt;</span>
    <span class="tag">&lt;type&gt;</span>test-jar<span class="tag">&lt;/type&gt;</span>
    <span class="tag">&lt;scope&gt;</span>test<span class="tag">&lt;/scope&gt;</span>
<span class="tag">&lt;/dependency&gt;</span>

<span class="tag">&lt;dependency&gt;</span>
    <span class="tag">&lt;groupId&gt;</span>org.apache.hadoop<span class="tag">&lt;/groupId&gt;</span>
    <span class="tag">&lt;artifactId&gt;</span>hadoop-hdfs<span class="tag">&lt;/artifactId&gt;</span>
    <span class="tag">&lt;version&gt;</span>2.0.0<span class="tag">&lt;/version&gt;</span>
    <span class="tag">&lt;scope&gt;</span>test<span class="tag">&lt;/scope&gt;</span>
<span class="tag">&lt;/dependency&gt;</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>该代码表示用于在示出的插入件MyDAO一个集成测试<a href="#unit.tests">unit.tests</a> 。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="directive">public</span> <span class="type">class</span> <span class="class">MyHBaseIntegrationTest</span> {
    <span class="directive">private</span> <span class="directive">static</span> HBaseTestingUtility utility;
    <span class="type">byte</span><span class="type">[]</span> CF = <span class="string"><span class="delimiter">&quot;</span><span class="content">CF</span><span class="delimiter">&quot;</span></span>.getBytes();
    <span class="type">byte</span><span class="type">[]</span> QUALIFIER = <span class="string"><span class="delimiter">&quot;</span><span class="content">CQ-1</span><span class="delimiter">&quot;</span></span>.getBytes();

    <span class="annotation">@Before</span>
    <span class="directive">public</span> <span class="type">void</span> setup() <span class="directive">throws</span> <span class="exception">Exception</span> {
            utility = <span class="keyword">new</span> HBaseTestingUtility();
            utility.startMiniCluster();
    }

    <span class="annotation">@Test</span>
        <span class="directive">public</span> <span class="type">void</span> testInsert() <span class="directive">throws</span> <span class="exception">Exception</span> {
                HTableInterface table = utility.createTable(Bytes.toBytes(<span class="string"><span class="delimiter">&quot;</span><span class="content">MyTest</span><span class="delimiter">&quot;</span></span>),
                                Bytes.toBytes(<span class="string"><span class="delimiter">&quot;</span><span class="content">CF</span><span class="delimiter">&quot;</span></span>));
                HBaseTestObj obj = <span class="keyword">new</span> HBaseTestObj();
                obj.setRowKey(<span class="string"><span class="delimiter">&quot;</span><span class="content">ROWKEY-1</span><span class="delimiter">&quot;</span></span>);
                obj.setData1(<span class="string"><span class="delimiter">&quot;</span><span class="content">DATA-1</span><span class="delimiter">&quot;</span></span>);
                obj.setData2(<span class="string"><span class="delimiter">&quot;</span><span class="content">DATA-2</span><span class="delimiter">&quot;</span></span>);
                MyHBaseDAO.insertRecord(table, obj);
                Get get1 = <span class="keyword">new</span> Get(Bytes.toBytes(obj.getRowKey()));
                get1.addColumn(CF, CQ1);
                <span class="predefined-type">Result</span> result1 = table.get(get1);
                assertEquals(Bytes.toString(result1.getRow()), obj.getRowKey());
                assertEquals(Bytes.toString(result1.value()), obj.getData1());
                Get get2 = <span class="keyword">new</span> Get(Bytes.toBytes(obj.getRowKey()));
                get2.addColumn(CF, CQ2);
                <span class="predefined-type">Result</span> result2 = table.get(get2);
                assertEquals(Bytes.toString(result2.getRow()), obj.getRowKey());
                assertEquals(Bytes.toString(result2.value()), obj.getData2());
    }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>此代码创建一个HBase迷你集群并启动它。接下来，它创建一个名为<code>MyTest</code>一个专栏家庭<code>CF</code> 。插入一条记录，从同一张表执行Get操作，并验证插入。</p>
</div>
<div class="admonitionblock note">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-note" title="注意"></i>
</td>
<td class="content">启动迷你集群大约需要20到30秒，但这应该适合集成测试。
</td>
</tr>
</tbody></table>
</div>
<div class="paragraph">
<p>要在Microsoft Windows上使用HBase迷你群集，您需要使用Cygwin环境。</p>
</div>
<div class="paragraph">
<p>有关<a href="http://blog.sematext.com/2010/08/30/hbase-case-study-using-hbasetestingutility-for-local-testing-development/">HBaseTestingUtility</a>的更多信息，请参见<a href="http://blog.sematext.com/2010/08/30/hbase-case-study-using-hbasetestingutility-for-local-testing-development/">HBase案例研究：使用HBaseTestingUtility进行本地测试和开发</a> （2010）中的论文。</p>
</div>
</div>
</div>
<h1 id="zookeeper" class="sect0"><a class="anchor" href="#zookeeper"></a>动物园管理员</h1>
<div class="openblock partintro">
<div class="content">
<div class="paragraph">
<p>分布式Apache HBase安装取决于正在运行的ZooKeeper集群。所有参与的节点和客户端都需要能够访问正在运行的ZooKeeper集合。默认情况下，Apache HBase为您管理ZooKeeper“集群”。作为HBase启动/停止过程的一部分，它将启动和停止ZooKeeper合奏。您还可以独立于HBase管理ZooKeeper集成，只需将HBase指向它应使用的群集即可。要切换ZooKeeper的HBase管理，请使用<code>HBASE_MANAGES_ZK</code> <em>conf / hbase-env.sh中的</em>变量。此变量，默认为<code>true</code> ，告诉HBase作为HBase启动/停止过程的一部分，是否启动/停止ZooKeeper集成服务器。</p>
</div>
<div class="paragraph">
<p>当HBase管理ZooKeeper集合时，可以使用其本机<em>zoo.cfg</em>文件指定ZooKeeper配置，或者，更简单的选择是直接在<em>conf / hbase-site.xml中</em>指定ZooKeeper选项。ZooKeeper配置选项可以通过在<em>ZooBase hbase-site.xml</em> XML配置文件中设置属性来设置，方法是在ZooKeeper选项名称前添加前缀<code>hbase.zookeeper.property</code> 。例如， <code>clientPort</code> ZooKeeper中的设置可以通过设置<code>hbase.zookeeper.property.clientPort</code>属性。有关HBase使用的所有默认值（包括ZooKeeper配置），请参阅<a href="#hbase_default_configurations">hbase默认配置</a> 。寻找<code>hbase.zookeeper.property</code>字首。有关ZooKeeper配置的完整列表，请参见ZooKeeper的<em>zoo.cfg</em> 。HBase不附带<em>zoo.cfg，</em>因此您需要在相应的ZooKeeper下载中浏览<em>conf</em>目录。</p>
</div>
<div class="paragraph">
<p>您必须至少使用以下命令在<em>hbase-site.xml中</em>列出集成服务器： <code>hbase.zookeeper.quorum</code>属性。此属性默认为单个集合成员，位于<code>localhost</code>不适合完全分布式的HBase。（它仅绑定到本地计算机，远程客户端将无法连接）。</p>
</div>
<div class="admonitionblock note">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-note" title="注意"></i>
</td>
<td class="content">
<div class="title">我应该运行多少个ZooKeeper？</div>
<div class="paragraph">
<p>您可以运行仅包含1个节点的ZooKeeper集成，但在生产环境中，建议您运行3、5或7台计算机的ZooKeeper集成；合奏拥有的成员越多，则合奏对主机故障的容忍度就越高。另外，运行奇数台计算机。在ZooKeeper中，支持偶数个对等体，但是通常不使用它，因为偶数大小的集合成比例地需要比奇数大小的集合更多的对等方。例如，一个具有4个对等体的合奏需要3个成员以形成仲裁，而具有5个对等体的合奏也需要3个形成仲裁。因此，集合5允许2个对等方发生故障，因此比4集合的容错性更高，后者仅允许1个向下的对等体。</p>
</div>
<div class="paragraph">
<p>给每个ZooKeeper服务器大约1GB的RAM，并为其分配专用磁盘（最好使用专用磁盘来确保ZooKeeper性能良好）。对于负载非常重的群集，请在与RegionServer（DataNode和TaskTrackers）不同的机器上运行ZooKeeper服务器。</p>
</div>
</td>
</tr>
</tbody></table>
</div>
<div class="paragraph">
<p>例如，要让HBase在节点<em>rs {1,2,3,4,5} .example.com</em>上管理绑定到端口2222（默认值为2181）的ZooKeeper仲裁，请确保<code>HBASE_MANAGE_ZK</code>被注释掉或设置为<code>true</code>在<em>conf / hbase-env.sh中</em> ，然后编辑<em>conf / hbase-site.xml</em>并设置<code>hbase.zookeeper.property.clientPort</code>和<code>hbase.zookeeper.quorum</code> 。您还应该设置<code>hbase.zookeeper.property.dataDir</code>设置为默认值以外的其他值，因为默认值使ZooKeeper将数据保留在<em>/ tmp下</em> ，该值通常在系统重新启动时清除。在下面的示例中，我们让ZooKeeper坚持到<em>/ user / local / zookeeper</em> 。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">  &lt;configuration&gt;
    ...
    &lt;property&gt;
      &lt;name&gt;hbase.zookeeper.property.clientPort&lt;/name&gt;
      &lt;value&gt;<span class="integer">2222</span>&lt;/value&gt;
      &lt;description&gt;Property from ZooKeeper<span class="string"><span class="delimiter">'</span><span class="content">s config zoo.cfg.
      The port at which the clients will connect.
      &lt;/description&gt;
    &lt;/property&gt;
    &lt;property&gt;
      &lt;name&gt;hbase.zookeeper.quorum&lt;/name&gt;
      &lt;value&gt;rs1.example.com,rs2.example.com,rs3.example.com,rs4.example.com,rs5.example.com&lt;/value&gt;
      &lt;description&gt;Comma separated list of servers in the ZooKeeper Quorum.
      For example, &quot;host1.mydomain.com,host2.mydomain.com,host3.mydomain.com&quot;.
      By default this is set to localhost for local and pseudo-distributed modes
      of operation. For a fully-distributed setup, this should be set to a full
      list of ZooKeeper quorum servers. If HBASE_MANAGES_ZK is set in hbase-env.sh
      this is the list of servers which we will start/stop ZooKeeper on.
      &lt;/description&gt;
    &lt;/property&gt;
    &lt;property&gt;
      &lt;name&gt;hbase.zookeeper.property.dataDir&lt;/name&gt;
      &lt;value&gt;/usr/local/zookeeper&lt;/value&gt;
      &lt;description&gt;Property from ZooKeeper</span><span class="delimiter">'</span></span>s config zoo.cfg.
      The directory where the snapshot is stored.
      &lt;/description&gt;
    &lt;/property&gt;
    ...
  &lt;/configuration&gt;</code></pre>
</div>
</div>
<div class="admonitionblock caution">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-caution" title="警告"></i>
</td>
<td class="content">
<div class="title">我应该使用哪个版本的ZooKeeper？</div>
<div class="paragraph">
<p>版本越新越好。例如，某些人被<a href="https://issues.apache.org/jira/browse/ZOOKEEPER-1277">ZOOKEEPER-1277</a>咬伤。如果运行的是Zookeeper 3.5+，则可以通过在<em>hbase-site.xml中</em>启用<a href="#hbase.zookeeper.usemulti">hbase.zookeeper.useMulti</a> “，要求hbase使用新的multi操作。</p>
</div>
</td>
</tr>
</tbody></table>
</div>
<div class="admonitionblock caution">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-caution" title="警告"></i>
</td>
<td class="content">
<div class="title">ZooKeeper维护</div>
<div class="paragraph">
<p>确保设置“ <a href="http://zookeeper.apache.org/doc/r3.1.2/zookeeperAdmin.html#sc_maintenance">Zookeeper维护”中</a>描述的数据目录清除程序，否则几个月后您可能会遇到“有趣”的问题；也就是说，如果动物园管理员必须遍历成千上万条日志的目录，而该日志目录在领导者连任期间是不会执行的，则它可以开始丢弃会话-这个过程很少，但有时会因为机器掉落或打h而运行。</p>
</div>
</td>
</tr>
</tbody></table>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_using_existing_zookeeper_ensemble"><a class="anchor" href="#_using_existing_zookeeper_ensemble"></a> 148。使用现有的ZooKeeper合奏</h2>
<div class="sectionbody">
<div class="paragraph">
<p>要将HBase指向不由HBase管理的现有ZooKeeper群集，请设置<code>HBASE_MANAGES_ZK</code>在<em>conf / hbase-env.sh中</em>为false</p>
</div>
<div class="listingblock">
<div class="content">
<pre>  ...
  # Tell HBase whether it should manage its own instance of Zookeeper or not.
  export HBASE_MANAGES_ZK=false</pre>
</div>
</div>
<div class="paragraph">
<p>接下来，在<em>hbase-site.xml中</em>设置集合位置和客户端端口（如果非标准），或者将适当配置的<em>zoo.cfg</em>添加到HBase的<em>CLASSPATH中</em> 。与<em>hbase-site.xml中的</em>任何设置相比，HBase都更喜欢<em>zoo.cfg中</em>的配置。</p>
</div>
<div class="paragraph">
<p>当HBase管理ZooKeeper时，它将作为常规启动/停止脚本的一部分启动/停止ZooKeeper服务器。如果您想独立于HBase启动/停止运行ZooKeeper，则可以执行以下操作</p>
</div>
<div class="listingblock">
<div class="content">
<pre>${HBASE_HOME}/bin/hbase-daemons.sh {start,stop} zookeeper</pre>
</div>
</div>
<div class="paragraph">
<p>请注意，您可以通过这种方式使用HBase来启动与HBase无关的ZooKeeper集群。只要确保设置<code>HBASE_MANAGES_ZK</code>至<code>false</code>如果您希望它在整个HBase重新启动期间保持正常运行，以便在HBase关闭时不会导致ZooKeeper停机。</p>
</div>
<div class="paragraph">
<p>有关运行独特的ZooKeeper集群的更多信息，请参见《 ZooKeeper <a href="http://hadoop.apache.org/zookeeper/docs/current/zookeeperStarted.html">入门指南》</a> 。此外，请参阅<a href="http://wiki.apache.org/hadoop/ZooKeeper/FAQ#A7">ZooKeeper Wiki</a>或<a href="http://zookeeper.apache.org/doc/r3.3.3/zookeeperAdmin.html#sc_zkMulitServerSetup">ZooKeeper文档</a> ，以获取有关ZooKeeper大小调整的更多信息。</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="zk.sasl.auth"><a class="anchor" href="#zk.sasl.auth"></a> 149。ZooKeeper的SASL身份验证</h2>
<div class="sectionbody">
<div class="paragraph">
<p>较新版本的Apache HBase（> = 0.92）将支持连接到支持SASL身份验证的ZooKeeper Quorum（在Zookeeper 3.4.0或更高版本中可用）。</p>
</div>
<div class="paragraph">
<p>这描述了如何设置HBase与ZooKeeper Quorum相互认证。作为完整安全HBase配置（ <a href="https://issues.apache.org/jira/browse/HBASE-3025">HBASE-3025</a> ）的一部分，需要ZooKeeper / HBase相互认证（ <a href="https://issues.apache.org/jira/browse/HBASE-2418">HBASE-2418</a> ）。为了简化说明，本节将忽略所需的其他配置（安全HDFS和协处理器配置）。为了便于学习，建议从HBase管理的Zookeeper配置（而不是独立的Zookeeper仲裁）开始。</p>
</div>
<div class="sect2">
<h3 id="_operating_system_prerequisites"><a class="anchor" href="#_operating_system_prerequisites"></a> 149.1。操作系统先决条件</h3>
<div class="paragraph">
<p>您需要具有有效的Kerberos KDC设置。对于每个<code>$HOST</code>它将运行ZooKeeper服务器，您应该有一个原则<code>zookeeper/$HOST</code> 。对于每个这样的主机，添加一个服务密钥（使用<code>kadmin</code>要么<code>kadmin.local</code>工具的<code>ktadd</code>命令） <code>zookeeper/$HOST</code>并将此文件复制到<code>$HOST</code> ，并使其仅对将在其上运行zookeeper的用户可读<code>$HOST</code> 。请注意此文件的位置，我们将在下面将其用作<em>$ PATH_TO_ZOOKEEPER_KEYTAB</em> 。</p>
</div>
<div class="paragraph">
<p>同样，对于每个<code>$HOST</code>将运行HBase服务器（主服务器或区域服务器）的服务器，您应该有一个原则： <code>hbase/$HOST</code> 。对于每个主机，添加一个名为<em>hbase.keytab</em>的密钥表文件， <em>其中</em>包含用于<code>hbase/$HOST</code> ，将此文件复制到<code>$HOST</code> ，并使其仅对将在其上运行HBase服务的用户可读<code>$HOST</code> 。请注意该文件的位置，我们将在下面将其用作<em>$ PATH_TO_HBASE_KEYTAB</em> 。</p>
</div>
<div class="paragraph">
<p>每个将成为HBase客户端的用户也应被赋予Kerberos主体。通常，应为此主体分配一个只有该用户知道的密码（与HBase服务器中的密钥表文件相反）。客户委托人的委托人<code>maxrenewlife</code>应该设置为可以充分更新，以便用户可以完成其HBase客户端进程。例如，如果用户运行了一个耗时最多3天的长时间运行的HBase客户端进程，我们可能会在以下时间内创建该用户的主体<code>kadmin</code>与： <code>addprinc -maxrenewlife 3days</code> 。Zookeeper客户端和服务器库通过运行定期唤醒以进行刷新的线程来管理自己的故障单刷新。</p>
</div>
<div class="paragraph">
<p>在将运行HBase客户端的每个主机上（例如<code>hbase shell</code> ），将以下文件添加到HBase主目录的<em>conf</em>目录中：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">Client {
  com.sun.security.auth.module.Krb5LoginModule required
  useKeyTab=<span class="predefined-constant">false</span>
  useTicketCache=<span class="predefined-constant">true</span>;
};</code></pre>
</div>
</div>
<div class="paragraph">
<p>我们将在下面将此JAAS配置文件称为<em>$ CLIENT_CONF</em> 。</p>
</div>
</div>
<div class="sect2">
<h3 id="_hbase_managed_zookeeper_configuration"><a class="anchor" href="#_hbase_managed_zookeeper_configuration"></a> 149.2。HBase管理的Zookeeper配置</h3>
<div class="paragraph">
<p>在将要运行Zookeeper，主服务器或区域服务器的每个节点上，在该节点的<em>HBASE_HOME</em>目录的conf目录中创建一个<a href="http://docs.oracle.com/javase/1.4.2/docs/guide/security/jgss/tutorials/LoginConfigFile.html">JAAS</a>配置文件，如下所示：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">Server {
  com.sun.security.auth.module.Krb5LoginModule required
  useKeyTab=<span class="predefined-constant">true</span>
  keyTab=<span class="string"><span class="delimiter">&quot;</span><span class="content">$PATH_TO_ZOOKEEPER_KEYTAB</span><span class="delimiter">&quot;</span></span>
  storeKey=<span class="predefined-constant">true</span>
  useTicketCache=<span class="predefined-constant">false</span>
  principal=<span class="string"><span class="delimiter">&quot;</span><span class="content">zookeeper/$HOST</span><span class="delimiter">&quot;</span></span>;
};
Client {
  com.sun.security.auth.module.Krb5LoginModule required
  useKeyTab=<span class="predefined-constant">true</span>
  useTicketCache=<span class="predefined-constant">false</span>
  keyTab=<span class="string"><span class="delimiter">&quot;</span><span class="content">$PATH_TO_HBASE_KEYTAB</span><span class="delimiter">&quot;</span></span>
  principal=<span class="string"><span class="delimiter">&quot;</span><span class="content">hbase/$HOST</span><span class="delimiter">&quot;</span></span>;
};</code></pre>
</div>
</div>
<div class="paragraph">
<p><em>$ PATH_TO_HBASE_KEYTAB</em>和<em>$ PATH_TO_ZOOKEEPER_KEYTAB</em>文件是您在上面创建的文件，以及<code>$HOST</code>是该节点的主机名。</p>
</div>
<div class="paragraph">
<p>的<code>Server</code>部分将由Zookeeper仲裁服务器使用，而<code>Client</code> HBase主服务器和区域服务器将使用此部分。这个文件的路径应该被替换为在<em>hbase-env.sh</em>文本<em>$ HBASE_SERVER_CONF</em>下面的清单。</p>
</div>
<div class="paragraph">
<p>该文件的路径应代替下面的<em>hbase-env.sh中</em>的文本<em>$ CLIENT_CONF</em> 。</p>
</div>
<div class="paragraph">
<p>修改您的<em>hbase-env.sh</em>以包括以下内容：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bourne">export HBASE_OPTS=&quot;-Djava.security.auth.login.config=$CLIENT_CONF&quot;
export HBASE_MANAGES_ZK=true
export HBASE_ZOOKEEPER_OPTS=&quot;-Djava.security.auth.login.config=$HBASE_SERVER_CONF&quot;
export HBASE_MASTER_OPTS=&quot;-Djava.security.auth.login.config=$HBASE_SERVER_CONF&quot;
export HBASE_REGIONSERVER_OPTS=&quot;-Djava.security.auth.login.config=$HBASE_SERVER_CONF&quot;</code></pre>
</div>
</div>
<div class="paragraph">
<p>其中<em>$ HBASE_SERVER_CONF</em>和<em>$ CLIENT_CONF</em>是上面创建的JAAS配置文件的完整路径。</p>
</div>
<div class="paragraph">
<p>在将运行zookeeper，master或regionserver的每个节点上修改<em>hbase-site.xml</em> ，使其包含：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">&lt;configuration&gt;
  &lt;property&gt;
    &lt;name&gt;hbase.zookeeper.quorum&lt;/name&gt;
    &lt;value&gt;<span class="error">$</span>ZK_NODES&lt;/value&gt;
  &lt;/property&gt;
  &lt;property&gt;
    &lt;name&gt;hbase.cluster.distributed&lt;/name&gt;
    &lt;value&gt;<span class="predefined-constant">true</span>&lt;/value&gt;
  &lt;/property&gt;
  &lt;property&gt;
    &lt;name&gt;hbase.zookeeper.property.authProvider<span class="float">.1</span>&lt;/name&gt;
    &lt;value&gt;org.apache.zookeeper.server.auth.SASLAuthenticationProvider&lt;/value&gt;
  &lt;/property&gt;
  &lt;property&gt;
    &lt;name&gt;hbase.zookeeper.property.kerberos.removeHostFromPrincipal&lt;/name&gt;
    &lt;value&gt;<span class="predefined-constant">true</span>&lt;/value&gt;
  &lt;/property&gt;
  &lt;property&gt;
    &lt;name&gt;hbase.zookeeper.property.kerberos.removeRealmFromPrincipal&lt;/name&gt;
    &lt;value&gt;<span class="predefined-constant">true</span>&lt;/value&gt;
  &lt;/property&gt;
&lt;/configuration&gt;</code></pre>
</div>
</div>
<div class="paragraph">
<p>哪里<code>$ZK_NODES</code>是Zookeeper Quorum主机的主机名的逗号分隔列表。</p>
</div>
<div class="paragraph">
<p>通过在适当的主机上运行以下一个或多个命令集来启动hbase集群：</p>
</div>
<div class="listingblock">
<div class="content">
<pre>bin/hbase zookeeper start
bin/hbase master start
bin/hbase regionserver start</pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_external_zookeeper_configuration"><a class="anchor" href="#_external_zookeeper_configuration"></a> 149.3。外部Zookeeper配置</h3>
<div class="paragraph">
<p>添加一个如下的JAAS配置文件：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">Client {
  com.sun.security.auth.module.Krb5LoginModule required
  useKeyTab=<span class="predefined-constant">true</span>
  useTicketCache=<span class="predefined-constant">false</span>
  keyTab=<span class="string"><span class="delimiter">&quot;</span><span class="content">$PATH_TO_HBASE_KEYTAB</span><span class="delimiter">&quot;</span></span>
  principal=<span class="string"><span class="delimiter">&quot;</span><span class="content">hbase/$HOST</span><span class="delimiter">&quot;</span></span>;
};</code></pre>
</div>
</div>
<div class="paragraph">
<p><em>$ PATH_TO_HBASE_KEYTAB</em>是上面创建的用于在该主机上运行的HBase服务的密钥表，并且<code>$HOST</code>是该节点的主机名。将其放在HBase主目录的配置目录中。我们将在下面将该文件的完整路径名称为<em>$ HBASE_SERVER_CONF</em> 。</p>
</div>
<div class="paragraph">
<p>修改您的hbase-env.sh以包括以下内容：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bourne">export HBASE_OPTS=&quot;-Djava.security.auth.login.config=$CLIENT_CONF&quot;
export HBASE_MANAGES_ZK=false
export HBASE_MASTER_OPTS=&quot;-Djava.security.auth.login.config=$HBASE_SERVER_CONF&quot;
export HBASE_REGIONSERVER_OPTS=&quot;-Djava.security.auth.login.config=$HBASE_SERVER_CONF&quot;</code></pre>
</div>
</div>
<div class="paragraph">
<p>在将运行主服务器或区域服务器的每个节点上修改<em>hbase-site.xml</em> ，使其包含：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="xml"><span class="tag">&lt;configuration&gt;</span>
  <span class="tag">&lt;property&gt;</span>
    <span class="tag">&lt;name&gt;</span>hbase.zookeeper.quorum<span class="tag">&lt;/name&gt;</span>
    <span class="tag">&lt;value&gt;</span>$ZK_NODES<span class="tag">&lt;/value&gt;</span>
  <span class="tag">&lt;/property&gt;</span>
  <span class="tag">&lt;property&gt;</span>
    <span class="tag">&lt;name&gt;</span>hbase.cluster.distributed<span class="tag">&lt;/name&gt;</span>
    <span class="tag">&lt;value&gt;</span>true<span class="tag">&lt;/value&gt;</span>
  <span class="tag">&lt;/property&gt;</span>
<span class="tag">&lt;/configuration&gt;</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>哪里<code>$ZK_NODES</code>是Zookeeper Quorum主机的主机名的逗号分隔列表。</p>
</div>
<div class="paragraph">
<p>为每个包含以下内容的Zookeeper Quorum主机添加一个<em>zoo.cfg</em> ：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">authProvider<span class="float">.1</span>=org.apache.zookeeper.server.auth.SASLAuthenticationProvider
kerberos.removeHostFromPrincipal=<span class="predefined-constant">true</span>
kerberos.removeRealmFromPrincipal=<span class="predefined-constant">true</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>还要在每个这些主机上，创建一个JAAS配置文件，其中包含：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">Server {
  com.sun.security.auth.module.Krb5LoginModule required
  useKeyTab=<span class="predefined-constant">true</span>
  keyTab=<span class="string"><span class="delimiter">&quot;</span><span class="content">$PATH_TO_ZOOKEEPER_KEYTAB</span><span class="delimiter">&quot;</span></span>
  storeKey=<span class="predefined-constant">true</span>
  useTicketCache=<span class="predefined-constant">false</span>
  principal=<span class="string"><span class="delimiter">&quot;</span><span class="content">zookeeper/$HOST</span><span class="delimiter">&quot;</span></span>;
};</code></pre>
</div>
</div>
<div class="paragraph">
<p>哪里<code>$HOST</code>是每个Quorum主机的主机名。我们将在下面将此文件的完整路径名称为<em>$ ZK_SERVER_CONF</em> 。</p>
</div>
<div class="paragraph">
<p>通过以下步骤在每个Zookeeper Quorum主机上启动Zookeeper：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bourne">SERVER_JVMFLAGS=&quot;-Djava.security.auth.login.config=$ZK_SERVER_CONF&quot; bin/zkServer start</code></pre>
</div>
</div>
<div class="paragraph">
<p>通过在适当的节点上运行以下一个或多个命令集来启动HBase集群：</p>
</div>
<div class="listingblock">
<div class="content">
<pre>bin/hbase master start
bin/hbase regionserver start</pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_zookeeper_server_authentication_log_output"><a class="anchor" href="#_zookeeper_server_authentication_log_output"></a> 149.4。Zookeeper服务器身份验证日志输出</h3>
<div class="paragraph">
<p>如果上面的配置成功，您将在Zookeeper服务器日志中看到与以下内容类似的内容：</p>
</div>
<div class="listingblock">
<div class="content">
<pre>11/12/05 22:43:39 INFO zookeeper.Login: successfully logged in.
11/12/05 22:43:39 INFO server.NIOServerCnxnFactory: binding to port 0.0.0.0/0.0.0.0:2181
11/12/05 22:43:39 INFO zookeeper.Login: TGT refresh thread started.
11/12/05 22:43:39 INFO zookeeper.Login: TGT valid starting at:        Mon Dec 05 22:43:39 UTC 2011
11/12/05 22:43:39 INFO zookeeper.Login: TGT expires:                  Tue Dec 06 22:43:39 UTC 2011
11/12/05 22:43:39 INFO zookeeper.Login: TGT refresh sleeping until: Tue Dec 06 18:36:42 UTC 2011
..
11/12/05 22:43:59 INFO auth.SaslServerCallbackHandler:
  Successfully authenticated client: authenticationID=hbase/ip-10-166-175-249.us-west-1.compute.internal@HADOOP.LOCALDOMAIN;
  authorizationID=hbase/ip-10-166-175-249.us-west-1.compute.internal@HADOOP.LOCALDOMAIN.
11/12/05 22:43:59 INFO auth.SaslServerCallbackHandler: Setting authorizedID: hbase
11/12/05 22:43:59 INFO server.ZooKeeperServer: adding SASL authorization for authorizationID: hbase</pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_zookeeper_client_authentication_log_output"><a class="anchor" href="#_zookeeper_client_authentication_log_output"></a> 149.5。Zookeeper客户端身份验证日志输出</h3>
<div class="paragraph">
<p>在Zookeeper客户端（HBase主服务器或区域服务器）上，您应该看到类似于以下内容：</p>
</div>
<div class="listingblock">
<div class="content">
<pre>11/12/05 22:43:59 INFO zookeeper.ZooKeeper: Initiating client connection, connectString=ip-10-166-175-249.us-west-1.compute.internal:2181 sessionTimeout=180000 watcher=master:60000
11/12/05 22:43:59 INFO zookeeper.ClientCnxn: Opening socket connection to server /10.166.175.249:2181
11/12/05 22:43:59 INFO zookeeper.RecoverableZooKeeper: The identifier of this process is 14851@ip-10-166-175-249
11/12/05 22:43:59 INFO zookeeper.Login: successfully logged in.
11/12/05 22:43:59 INFO client.ZooKeeperSaslClient: Client will use GSSAPI as SASL mechanism.
11/12/05 22:43:59 INFO zookeeper.Login: TGT refresh thread started.
11/12/05 22:43:59 INFO zookeeper.ClientCnxn: Socket connection established to ip-10-166-175-249.us-west-1.compute.internal/10.166.175.249:2181, initiating session
11/12/05 22:43:59 INFO zookeeper.Login: TGT valid starting at:        Mon Dec 05 22:43:59 UTC 2011
11/12/05 22:43:59 INFO zookeeper.Login: TGT expires:                  Tue Dec 06 22:43:59 UTC 2011
11/12/05 22:43:59 INFO zookeeper.Login: TGT refresh sleeping until: Tue Dec 06 18:30:37 UTC 2011
11/12/05 22:43:59 INFO zookeeper.ClientCnxn: Session establishment complete on server ip-10-166-175-249.us-west-1.compute.internal/10.166.175.249:2181, sessionid = 0x134106594320000, negotiated timeout = 180000</pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_configuration_from_scratch"><a class="anchor" href="#_configuration_from_scratch"></a> 149.6。从头开始配置</h3>
<div class="paragraph">
<p>已在当前标准的Amazon Linux AMI上进行了测试。如上所述，首先设置KDC和主体。下一个结帐代码并运行健全性检查。</p>
</div>
<div class="listingblock">
<div class="content">
<pre>git clone https://gitbox.apache.org/repos/asf/hbase.git
cd hbase
mvn clean test -Dtest=TestZooKeeperACL</pre>
</div>
</div>
<div class="paragraph">
<p>然后如上所述配置HBase。手动编辑target / cached_classpath.txt（请参见下文）：</p>
</div>
<div class="listingblock">
<div class="content">
<pre>bin/hbase zookeeper &amp;
bin/hbase master &amp;
bin/hbase regionserver &amp;</pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_future_improvements"><a class="anchor" href="#_future_improvements"></a> 149.7。未来的改进</h3>
<div class="sect3">
<h4 id="_fix_target_cached_classpath_txt"><a class="anchor" href="#_fix_target_cached_classpath_txt"></a> 149.7.1。修复target / cached_classpath.txt</h4>
<div class="paragraph">
<p>您必须从中覆盖标准的hadoop-core jar文件<code>target/cached_classpath.txt</code>文件包含HADOOP-7070修复程序的版本。您可以使用以下脚本来执行此操作：</p>
</div>
<div class="listingblock">
<div class="content">
<pre>echo `find ~/.m2 -name "*hadoop-core*7070*SNAPSHOT.jar"` ':' `cat target/cached_classpath.txt` | sed 's/ //g' &gt; target/tmp.txt
mv target/tmp.txt target/cached_classpath.txt</pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_set_jaas_configuration_programmatically"><a class="anchor" href="#_set_jaas_configuration_programmatically"></a> 149.7.2。以编程方式设置JAAS配置</h4>
<div class="paragraph">
<p>这将避免需要单独的Hadoop罐来修复<a href="https://issues.apache.org/jira/browse/HADOOP-7070">HADOOP-7070</a> 。</p>
</div>
</div>
<div class="sect3">
<h4 id="_elimination_of_code_kerberos_removehostfromprincipal_code_and_kerberos_removerealmfromprincipal"><a class="anchor" href="#_elimination_of_code_kerberos_removehostfromprincipal_code_and_kerberos_removerealmfromprincipal"></a> 149.7.3。消除<code>kerberos.removeHostFromPrincipal</code>和`kerberos.removeRealmFromPrincipal`</h4>

</div>
</div>
</div>
</div>
<h1 id="community" class="sect0"><a class="anchor" href="#community"></a>社区</h1>
<div class="sect1">
<h2 id="_decisions"><a class="anchor" href="#_decisions"></a> 150。决定</h2>
<div class="sectionbody">
<div class="paragraph">
<div class="title">功能分支</div>
<p>功能分支很容易制作。您不必成为一个提交者。只需在开发人员的邮件列表中请求将分支的名称添加到JIRA中，然后提交者就会为您添加它。之后，您可以针对Apache HBase JIRA中的功能分支提出问题。您将代码保存在其他地方（应该公开，以便可以观察），并且可以根据进度更新开发邮件列表。当功能可以提交时，提交者进行3 +1次操作即可合并您的功能。参见<a href="http://search-hadoop.com/m/asM982C5FkS1">HBase，邮件＃dev-有关大型功能dev分支的想法</a></p>
</div>
<div id="patchplusonepolicy" class="paragraph">
<div class="title">补丁+1政策</div>
<p>以下政策是我们在09/2012年制定的。这是建议的政策，而不是硬性要求。我们想先尝试一下，看看是否可行，然后再将其铸成石头。</p>
</div>
<div class="paragraph">
<p>Apache HBase由<a href="https://issues.apache.org/jira/browse/HBASE#selectedTab=com.atlassian.jira.plugin.system.project%3Acomponents-panel">组件组成</a> 。组件具有一个或多个<a href="#owner">OWNER</a> 。有关<a href="https://issues.apache.org/jira/browse/HBASE#selectedTab=com.atlassian.jira.plugin.system.project%3Acomponents-panel">组件</a>的当前所有者，请参见<a href="https://issues.apache.org/jira/browse/HBASE#selectedTab=com.atlassian.jira.plugin.system.project%3Acomponents-panel">组件</a> JIRA页面上的“描述”字段。</p>
</div>
<div class="paragraph">
<p>提交之前，适合单个Apache HBase组件范围的修补程序至少需要该组件的所有者之一+1。如果没有所有者（忙碌或其他原因），那么非所有者的两个+1就足够了。</p>
</div>
<div class="paragraph">
<p>跨组件的修补程序至少需要两个+1才能提交，最好由x组件修补程序接触的组件的所有者+1（TODO：这需要加强，但我认为第一次通过是可以的）。</p>
</div>
<div class="paragraph">
<p>任何人对补丁的任何-1都会审查补丁；在解决-1的理由之前，不能提交它。</p>
</div>
<div id="hbase.fix.version.in.jira" class="paragraph">
<div class="title">如何在JIRA中设置修复版本以解决问题</div>
<p>解决问题时，这就是<a href="http://search-hadoop.com/m/azemIi5RCJ1">我们同意</a>在JIRA中设置版本的方式。如果主干将为0.98.0，则：</p>
</div>
<div class="ulist">
<ul>
<li>
<p>仅提交至中继线：标记为0.98</p>
</li>
<li>
<p>提交到0.95和躯干：标记0.98和0.95.x</p>
</li>
<li>
<p>分别输入0.94.x和0.95，然后加上躯干：用0.98、0.95.x和0.94.x标记</p>
</li>
<li>
<p>提交至89 fb：标记为89 fb。</p>
</li>
<li>
<p>提交网站修复：无版本</p>
</li>
</ul>
</div>
<div id="hbase.when.to.close.jira" class="paragraph">
<div class="title">有关何时将已解决的JIRA设置为已关闭的政策</div>
<p>我们<a href="http://search-hadoop.com/m/4cIKs1iwXMS1">同意</a> ，对于在“ <em>修订版本”</em>字段中列出多个发行<em>版</em>的问题，请关闭列出的任何版本发行中的问题；随后的问题更改必须在新的JIRA中进行。</p>
</div>
<div id="no.permanent.state.in.zk" class="paragraph">
<div class="title">ZooKeeper中只有瞬态！</div>
<p>您应该能够杀死zookeeper中的数据，并且hbase应该越过它重新创建zk内容。这是围绕这些部分的古老谚语。我们现在已经记下了。我们目前还违反了这一基本原则-复制至少使zk保持永久状态-但我们正在努力消除打破黄金法则的情况。</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="community.roles"><a class="anchor" href="#community.roles"></a> 151。社区角色</h2>
<div class="sectionbody">
<div id="owner" class="paragraph">
<div class="title">组件所有者/中尉</div>
<p>组件所有者在此Apache HBase JIRA <a href="https://issues.apache.org/jira/browse/HBASE#selectedTab=com.atlassian.jira.plugin.system.project%3Acomponents-panel">组件</a>页面的描述字段中列出。所有者在“说明”字段中列出，而不是在“组件负责人”字段中列出，因为后者仅允许我们列出一个人，而鼓励组件具有多个所有者。</p>
</div>
<div class="paragraph">
<p>所有者或中尉是自愿者，他们通常（但不一定）是其组件领域的专家，并且可以就他们认为Apache HBase组件应该如何发展制定议程。</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>所有者将尝试查看位于其组件范围内的补丁。</p>
</li>
<li>
<p>如果适用，如果所有者有议程，他们将发布其目标或驱动组件的设计</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>如果您想成为组件所有者的自愿者，只需编写开发人员列表，我们将为您注册。所有者不必是提交者。</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="hbase.commit.msg.format"><a class="anchor" href="#hbase.commit.msg.format"></a> 152。提交消息格式</h2>
<div class="sectionbody">
<div class="paragraph">
<p>我们<a href="http://search-hadoop.com/m/Gwxwl10cFHa1">同意</a>以下SVN提交消息格式：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">HBASE-xxxxx &lt;title&gt;. (&lt;contributor&gt;)</code></pre>
</div>
</div>
<div class="paragraph">
<p>如果进行提交的人是贡献者，则忽略“（ <contributor>）”元素。</contributor></p>
</div>
</div>
</div>
<h1 id="_appendix" class="sect0"><a class="anchor" href="#_appendix"></a>附录</h1>
<div class="sect1">
<h2 id="appendix_contributing_to_documentation"><a class="anchor" href="#appendix_contributing_to_documentation"></a>附录A：贡献文档</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Apache HBase项目欢迎您对该项目的各个方面做出贡献，包括文档。</p>
</div>
<div class="paragraph">
<p>在HBase中，文档包括以下领域，可能还包括其他领域：</p>
</div>
<div class="ulist">
<ul>
<li>
<p><a href="http://hbase.apache.org/book.html">HBase参考指南</a> （本书）</p>
</li>
<li>
<p><a href="http://hbase.apache.org/">HBase网站</a></p>
</li>
<li>
<p><a href="http://wiki.apache.org/hadoop/Hbase">HBase Wiki</a></p>
</li>
<li>
<p>API文档</p>
</li>
<li>
<p>命令行实用程序输出和帮助文本</p>
</li>
<li>
<p>Web UI字符串，显式帮助文本，上下文相关的字符串等</p>
</li>
<li>
<p>日志信息</p>
</li>
<li>
<p>源文件，配置文件和其他文件中的注释</p>
</li>
<li>
<p>将以上任何一种语言本地化为英语以外的目标语言</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>无论您要在哪个领域提供帮助，第一步几乎总是要下载（通常是通过克隆Git存储库）并熟悉HBase源代码。上面列表中唯一的例外是HBase Wiki，它是在线编辑的。有关下载和构建源的信息，请参阅<a href="#developer">developer</a> 。</p>
</div>
<div class="sect2">
<h3 id="_getting_access_to_the_wiki"><a class="anchor" href="#_getting_access_to_the_wiki"></a> A.1。获得对Wiki的访问</h3>
<div class="paragraph">
<p>HBase Wiki维护不完善，其许多内容已移至《 HBase参考指南》（本指南）中。但是，Wiki上的某些页面维护得很好，如果有一些自愿者愿意为Wiki提供帮助，那就太好了。要请求访问Wiki，请在<a href="https://wiki.apache.org/hadoop/Hbase?action=newaccount">https://wiki.apache.org/hadoop/Hbase?action=newaccount上</a>注册一个新帐户。与HBase提交者之一联系，后者可以授予您访问权限或将您推荐给可以的人。</p>
</div>
</div>
<div class="sect2">
<h3 id="_contributing_to_documentation_or_other_strings"><a class="anchor" href="#_contributing_to_documentation_or_other_strings"></a> A2。贡献文档或其他字符串</h3>
<div class="paragraph">
<p>如果您发现UI，实用程序，脚本，日志消息或其他地方的字符串中有错误，或者您认为某些事情可以变得更清晰，或者您认为文本需要添加到当前不存在的地方，则第一个步骤是提交JIRA。确保将组件设置为<code>Documentation</code>此外，还涉及其他任何组件。大多数组件具有一个或多个默认所有者，这些默认所有者监视那些队列中出现的新问题。不管您是否有能力修复该错误，都应该在发现错误的位置进行归档。</p>
</div>
<div class="paragraph">
<p>如果您想尝试修复新提交的错误，请将其分配给自己。您将需要将HBase Git存储库克隆到本地系统，并在那里解决问题。开发出潜在的修复程序后，将其提交以供审核。如果它解决了该问题并被视为一种改进，则HBase提交者之一将酌情将其提交到一个或多个分支。</p>
</div>
<div class="paragraph">
<div class="title">过程：提交补丁的建议工作流程</div>
<p>该过程比Git专业人员所需的过程更为详细，但此附录中已包含该过程，因此，不熟悉Git的人可以在学习过程中充满信心地为HBase做出贡献。</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>如果尚未这样做，请在本地克隆Git存储库。您只需要这样做一次。</p>
</li>
<li>
<p>通常，使用以下命令将远程更改拉入本地存储库<code>git pull</code>命令，而您的master分支已签出。</p>
</li>
<li>
<p>对于您处理的每个问题，请创建一个新分支。命名分支最有效的一种约定是给定分支的名称与它涉及的JIRA相同：</p>
<div class="listingblock">
<div class="content">
<pre>$ git checkout -b HBASE-123456</pre>
</div>
</div>
</li>
<li>
<p>在分支上进行建议的更改，并经常将更改提交到本地存储库。如果您需要切换到其他问题，请记住签出相应的分支。</p>
</li>
<li>
<p>准备好提交补丁程序时，首先请确保HBase可以干净构建并在修改后的分支中按预期方式运行。如果您对文档进行了更改，请确保通过运行以下文档来构建文档和网站<code>mvn clean site</code> 。</p>
<div class="admonitionblock note">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-note" title="注意"></i>
</td>
<td class="content">使用之前<code>site</code>首次定位时，请确保您至少构建了一次HBase，以便获取所需的所有Maven依赖项。
</td>
</tr>
</tbody></table>
</div>
<div class="listingblock">
<div class="content">
<pre>$ mvn clean install -DskipTests               # Builds HBase</pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre>$ mvn clean site -DskipTests                  # Builds the website and documentation</pre>
</div>
</div>
<div class="paragraph">
<p>如果发生任何错误，请解决。</p>
</div>
</li>
<li>
<p>如果您花费几天或几周的时间来实施您的修复程序，或者您知道所使用的代码区域最近进行了很多更改，请确保将分支基于远程主服务器进行更改，并避免任何冲突。提交补丁之前。</p>
<div class="listingblock">
<div class="content">
<pre>$ git checkout HBASE-123456
$ git rebase origin/master</pre>
</div>
</div>
</li>
<li>
<p>针对远程主服务器生成补丁。从git存储库的顶层运行以下命令（通常称为<code>hbase</code> ）：</p>
<div class="listingblock">
<div class="content">
<pre>$ git format-patch --stdout origin/master &gt; HBASE-123456.patch</pre>
</div>
</div>
<div class="paragraph">
<p>修补程序的名称应包含JIRA ID。查看补丁文件，以确保您没有意外更改任何其他文件，并且没有其他意外。如果满意，请将修补程序附加到JIRA，然后单击<b class="button">可用</b>的<b class="button">修补程序</b>按钮。审阅者将审阅您的补丁。如果您需要提交新版本的补丁，请将旧版本保留在JIRA上，并在新补丁的名称中添加一个版本号。</p>
</div>
</li>
<li>
<p>提交更改后，无需保留本地分支机构。相反，您应该运行<code>git pull</code>将新更改带入您的master分支。</p>
</li>
</ol>
</div>
</div>
<div class="sect2">
<h3 id="_editing_the_hbase_website"><a class="anchor" href="#_editing_the_hbase_website"></a> A.3。编辑HBase网站</h3>
<div class="paragraph">
<p>HBase网站的源位于HBase源中的<em>src / main / site /</em>目录中。在此目录中，各个页面的源位于<em>xdocs /</em>目录中，而这些页面中引用的<em>图像</em>位于<em>images /</em>目录中。此目录还存储《 HBase参考指南》中使用的映像。</p>
</div>
<div class="paragraph">
<p>该网站的页面使用称为xdoc的类似HTML的XML语言编写，该参考文献的链接为：http：//maven.apache.org/archives/maven-1.x/plugins/xdoc/reference/xdocs.html 。您可以在纯文本编辑器，IDE或XML编辑器（例如XML Mind XML Editor（XXE）或Oxygen XML Author）中编辑这些文件。</p>
</div>
<div class="paragraph">
<p>要预览您的更改，请使用mvn clean site -DskipTests命令构建网站。HTML输出位于<em>target / site /</em>目录中。对更改满意后，请按照“ <a href="#submit_doc_patch_procedure">提交文档补丁程序”中的步骤</a>提交补丁程序。</p>
</div>
</div>
<div class="sect2">
<h3 id="_hbase_reference_guide_style_guide_and_cheat_sheet"><a class="anchor" href="#_hbase_reference_guide_style_guide_and_cheat_sheet"></a> A.4。HBase参考指南样式指南和备忘单</h3>
<div class="paragraph">
<p>《 HBase参考指南》是用Asciidoc编写的，并使用<a href="http://asciidoctor.org">AsciiDoctor构建</a> 。随附以下备忘单供您参考。可从以下链接获得更多细致而全面的文档：http：//asciidoctor.org/docs/user-manual/。</p>
</div>
<table class="tableblock frame-all grid-all spread">
<caption class="title">表11。AsciiDoc备忘单</caption>
<colgroup>
<col style="width:33%">
<col style="width:33%">
<col style="width:33%">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">元素类型</th>
<th class="tableblock halign-left valign-top">所需的渲染</th>
<th class="tableblock halign-left valign-top">怎么做</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">一个段落</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">一个段落</p></td>
<td class="tableblock halign-left valign-top"><div><div id="toc" class="toc">
<div id="toctitle">内容</div>

</div>
<div class="paragraph">
<p>只需在顶部和底部键入一些带有空白行的文本即可。</p>
</div></div></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">在段落中添加换行符，而不添加空白行</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">手动换行</p></td>
<td class="tableblock halign-left valign-top"><div><div id="toc" class="toc">
<div id="toctitle">内容</div>

</div>
<div class="paragraph">
<p>这将在加号处打断+。或在整个段落前加上包含'[％hardbreaks]'的行</p>
</div></div></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">给任何东西一个标题</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">彩色斜体粗体不同大小的文本</p></td>
<td class="tableblock halign-left valign-top"><div><div id="toc" class="toc">
<div id="toctitle">内容</div>

</div>
</div></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">内联代码或命令</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">等宽</p></td>
<td class="tableblock halign-left valign-top"><div><div id="toc" class="toc">
<div id="toctitle">内容</div>

</div>
<div class="paragraph">
<p>文字</p>
</div></div></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">内联文字内容（键入的内容应与显示的内容完全一样）</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">大胆的单声道</p></td>
<td class="tableblock halign-left valign-top"><div><div id="toc" class="toc">
<div id="toctitle">内容</div>

</div>
<div class="paragraph">
<p>*`typethis` *</p>
</div></div></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">内联可替换内容（用您自己的值替换的内容）</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">粗体斜体单声道</p></td>
<td class="tableblock halign-left valign-top"><div><div id="toc" class="toc">
<div id="toctitle">内容</div>

</div>
<div class="paragraph">
<p>*_输入一些东西_*</p>
</div></div></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">带突出显示的代码块</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">等高线突出显示保留空间</p></td>
<td class="tableblock halign-left valign-top"><div><div id="toc" class="toc">
<div id="toctitle">内容</div>

</div>
<div class="literalblock">
<div class="content">
<pre>[source,java]
----
  myAwesomeCode() {
}
----</pre>
</div>
</div></div></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">来自单独文件的代码块</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">就像它是主文件的一部分一样包含在内</p></td>
<td class="tableblock halign-left valign-top"><div><div id="toc" class="toc">
<div id="toctitle">内容</div>

</div>
<div class="literalblock">
<div class="content">
<pre>[source,ruby]
----
include\::path/to/app.rb[]
----</pre>
</div>
</div></div></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">仅包括单独文件的一部分</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">类似于Javadoc</p></td>
<td class="tableblock halign-left valign-top"><div><div id="toc" class="toc">
<div id="toctitle">内容</div>

</div>
<div class="paragraph">
<p>参见链接：http：//asciidoctor.org/docs/user-manual/#by-tagged-regions</p>
</div></div></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">文件名，目录名，新术语</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">斜体</p></td>
<td class="tableblock halign-left valign-top"><div><div id="toc" class="toc">
<div id="toctitle">内容</div>

</div>
<div class="paragraph">
<p>_hbase-default.xml_</p>
</div></div></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">外部裸露网址</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">以URL作为链接文本的链接</p></td>
<td class="tableblock halign-left valign-top"><div><div id="toc" class="toc">
<div id="toctitle">内容</div>

</div>
<div class="listingblock">
<div class="content">
<pre>link:http://www.google.com</pre>
</div>
</div></div></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">带有文字的外部网址</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">具有任意链接文本的链接</p></td>
<td class="tableblock halign-left valign-top"><div><div id="toc" class="toc">
<div id="toctitle">内容</div>

</div>
<div class="listingblock">
<div class="content">
<pre>link:http://www.google.com[Google]</pre>
</div>
</div></div></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">创建一个内部锚点以进行交叉引用</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">没有呈现</p></td>
<td class="tableblock halign-left valign-top"><div><div id="toc" class="toc">
<div id="toctitle">内容</div>

</div>
<div class="listingblock">
<div class="content">
<pre>[[anchor_name]]</pre>
</div>
</div></div></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">使用默认标题交叉引用现有锚</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">内部超链接，如果有的话，使用元素标题，否则使用锚点名称</p></td>
<td class="tableblock halign-left valign-top"><div><div id="toc" class="toc">
<div id="toctitle">内容</div>

</div>
<div class="listingblock">
<div class="content">
<pre>&lt;&lt;anchor_name&gt;&gt;</pre>
</div>
</div></div></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">使用自定义文本交叉引用现有锚</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">使用任意文本的内部超链接</p></td>
<td class="tableblock halign-left valign-top"><div><div id="toc" class="toc">
<div id="toctitle">内容</div>

</div>
<div class="listingblock">
<div class="content">
<pre>&lt;&lt;anchor_name,Anchor Text&gt;&gt;</pre>
</div>
</div></div></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">块图像</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">带有替代文字的图片</p></td>
<td class="tableblock halign-left valign-top"><div><div id="toc" class="toc">
<div id="toctitle">内容</div>

</div>
<div class="listingblock">
<div class="content">
<pre>image::sunset.jpg[Alt Text]</pre>
</div>
</div>
<div class="paragraph">
<p>（将图像放在src / main / site / resources / images目录中）</p>
</div></div></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">内嵌图片</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">包含替代文字的图片，作为文字流的一部分</p></td>
<td class="tableblock halign-left valign-top"><div><div id="toc" class="toc">
<div id="toctitle">内容</div>

</div>
<div class="listingblock">
<div class="content">
<pre>image:sunset.jpg [Alt Text]</pre>
</div>
</div>
<div class="paragraph">
<p>（仅一个冒号）</p>
</div></div></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">链接到远程图像</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">显示在其他地方托管的图像</p></td>
<td class="tableblock halign-left valign-top"><div><div id="toc" class="toc">
<div id="toctitle">内容</div>

</div>
<div class="listingblock">
<div class="content">
<pre>image::http://inkscape.org/doc/examples/tux.svg[Tux,250,350]</pre>
</div>
</div>
<div class="paragraph">
<p>（要么<code>image:</code> ）</p>
</div></div></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">向图像添加尺寸或URL</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">要看</p></td>
<td class="tableblock halign-left valign-top"><div><div id="toc" class="toc">
<div id="toctitle">内容</div>

</div>
<div class="paragraph">
<p>在替代文字后面的方括号内，指定宽度，高度和/或link =“ http://my_link.com”</p>
</div></div></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">脚注</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">下标链接，带您到脚注</p></td>
<td class="tableblock halign-left valign-top"><div><div id="toc" class="toc">
<div id="toctitle">内容</div>

</div>
<div class="listingblock">
<div class="content">
<pre>Some text.footnote:[The footnote text.]</pre>
</div>
</div></div></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">无标题的便条或警告</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">训诫图像，然后是训诫</p></td>
<td class="tableblock halign-left valign-top"><div><div id="toc" class="toc">
<div id="toctitle">内容</div>

</div>
<div class="listingblock">
<div class="content">
<pre>NOTE:My note here</pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre>WARNING:My warning here</pre>
</div>
</div></div></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">复杂的音符</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">该注释具有标题和/或多个段落和/或代码块或列表等</p></td>
<td class="tableblock halign-left valign-top"><div><div id="toc" class="toc">
<div id="toctitle">内容</div>

</div>
<div class="literalblock">
<div class="content">
<pre>.The Title
[NOTE]
====
Here is the note text. Everything until the second set of four equals signs is part of the note.
----
some source code
----
====</pre>
</div>
</div></div></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">项目符号清单</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">项目符号列表</p></td>
<td class="tableblock halign-left valign-top"><div><div id="toc" class="toc">
<div id="toctitle">内容</div>

</div>
<div class="listingblock">
<div class="content">
<pre>* list item 1</pre>
</div>
</div>
<div class="paragraph">
<p>（请参阅<a href="http://asciidoctor.org/docs/user-manual/#unordered-lists" class="bare">http://asciidoctor.org/docs/user-manual/#unordered-lists</a> ）</p>
</div></div></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">编号清单</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">编号清单</p></td>
<td class="tableblock halign-left valign-top"><div><div id="toc" class="toc">
<div id="toctitle">内容</div>

</div>
<div class="listingblock">
<div class="content">
<pre>. list item 2</pre>
</div>
</div>
<div class="paragraph">
<p>（请参阅<a href="http://asciidoctor.org/docs/user-manual/#ordered-lists" class="bare">http://asciidoctor.org/docs/user-manual/#ordered-lists</a> ）</p>
</div></div></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">检查清单</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">选中或未选中的框</p></td>
<td class="tableblock halign-left valign-top"><div><div id="toc" class="toc">
<div id="toctitle">内容</div>

</div>
<div class="paragraph">
<p>已检查：</p>
</div>
<div class="listingblock">
<div class="content">
<pre>- [*]</pre>
</div>
</div>
<div class="paragraph">
<p>未选中：</p>
</div>
<div class="listingblock">
<div class="content">
<pre>- [ ]</pre>
</div>
</div></div></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">多级列表</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">项目符号或编号或组合</p></td>
<td class="tableblock halign-left valign-top"><div><div id="toc" class="toc">
<div id="toctitle">内容</div>

</div>
<div class="listingblock">
<div class="content">
<pre>. Numbered (1), at top level
* Bullet (2), nested under 1
* Bullet (3), nested under 1
. Numbered (4), at top level
* Bullet (5), nested under 4
** Bullet (6), nested under 5
- [x] Checked (7), at top level</pre>
</div>
</div></div></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">标签列表/变量列表</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">列表项标题或摘要，后跟内容</p></td>
<td class="tableblock halign-left valign-top"><div><div id="toc" class="toc">
<div id="toctitle">内容</div>

</div>
<div class="listingblock">
<div class="content">
<pre>Title:: content

Title::
  content</pre>
</div>
</div></div></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">侧边栏，引号或其他文本块</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">一段文本，其格式与默认格式不同</p></td>
<td class="tableblock halign-left valign-top"><div><div id="toc" class="toc">
<div id="toctitle">内容</div>

</div>
<div class="paragraph">
<p>使用不同的分隔符分隔，请参见链接：http：//asciidoctor.org/docs/user-manual/#built-in-blocks-summary。上面的一些示例使用定界符，例如....，----，====。</p>
</div>
<div class="literalblock">
<div class="content">
<pre>[example]
====
This is an example block.
====

[source]
----
This is a source block.
----

[note]
====
This is a note block.
====

[quote]
____
This is a quote block.
____</pre>
</div>
</div>
<div class="paragraph">
<p>如果要插入不断解释的原义Asciidoc内容，如有疑问，请在顶部和底部使用八个点作为分隔符。</p>
</div></div></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">嵌套部分</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">章，节，小节等</p></td>
<td class="tableblock halign-left valign-top"><div><div id="toc" class="toc">
<div id="toctitle">内容</div>

</div>
<div class="listingblock">
<div class="content">
<pre>= Book (or chapter if the chapter can be built alone, see the leveloffset info below)

== Chapter (or section if the chapter is standalone)

=== Section (or subsection, etc)

==== Subsection</pre>
</div>
</div>
<div class="paragraph">
<p>等等，最多6个级别（仔细考虑要比4个级别更深，也许您可以只为段落或列表加上标题）。请注意，您可以通过添加<code>:leveloffset:+1</code>宏指令直接在您的包含之前，然后立即将其重置为0。有关示例，请参见<em>book.adoc</em>源，因为这是本指南处理各章的方式。<strong>不要在序言，词汇表，附录或其他特殊类型的章节中使用它。</strong></p>
</div></div></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">包含另一个文件</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">包含内容，就好像它们是内联的一样</p></td>
<td class="tableblock halign-left valign-top"><div><div id="toc" class="toc">
<div id="toctitle">内容</div>

</div>
<div class="listingblock">
<div class="content">
<pre>include::[/path/to/file.adoc]</pre>
</div>
</div>
<div class="paragraph">
<p>有关大量示例。参见<em>book.adoc</em> 。</p>
</div></div></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">一张桌子</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">一张桌子</p></td>
<td class="tableblock halign-left valign-top"><div><div id="toc" class="toc">
<div id="toctitle">内容</div>

</div>
<div class="paragraph">
<p>参见<a href="http://asciidoctor.org/docs/user-manual/#tables" class="bare">http://asciidoctor.org/docs/user-manual/#tables</a> 。通常，行由换行符分隔，列由管道分隔</p>
</div></div></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">注释掉一行</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">渲染过程中跳过了一行</p></td>
<td class="tableblock halign-left valign-top"><div><div id="toc" class="toc">
<div id="toctitle">内容</div>

</div>
<div class="paragraph">
<p><code>// This line won’t show up</code></p>
</div></div></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">注释掉一个块</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">渲染期间跳过文件的一部分</p></td>
<td class="tableblock halign-left valign-top"><div><div id="toc" class="toc">
<div id="toctitle">内容</div>

</div>
<div class="listingblock">
<div class="content">
<pre>////
Nothing between the slashes will show up.
////</pre>
</div>
</div></div></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">突出显示文本以供审核</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">文字显示为黄色背景</p></td>
<td class="tableblock halign-left valign-top"><div><div id="toc" class="toc">
<div id="toctitle">内容</div>

</div>
<div class="listingblock">
<div class="content">
<pre>Test between #hash marks# is highlighted yellow.</pre>
</div>
</div></div></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="_auto_generated_content"><a class="anchor" href="#_auto_generated_content"></a> A.5。自动生成的内容</h3>
<div class="paragraph">
<p>《 HBase参考指南》的某些部分（尤其是<a href="#config.files">config.files</a> ）是自动生成的，因此文档的此区域与代码保持同步。这是通过XSLT转换完成的，您可以在源代码<em>src / main / xslt / configuration_to_asciidoc_chapter.xsl中进行检查</em> 。这<em>会将hbase-common / src / main / resources / hbase-default.xml</em>文件转换为Asciidoc输出，可以将其包含在《参考指南》中。有时，有必要添加配置参数或修改其描述。对源文件进行修改，它们将在重建时包含在《参考指南》中。</p>
</div>
<div class="paragraph">
<p>将来，将来可能还会从HBase源文件中自动生成其他类型的内容。</p>
</div>
</div>
<div class="sect2">
<h3 id="_images_in_the_hbase_reference_guide"><a class="anchor" href="#_images_in_the_hbase_reference_guide"></a> A.6。《 HBase参考指南》中的图像</h3>
<div class="paragraph">
<p>您可以在《 HBase参考指南》中包含图像。重要的是，如果可能的话，要包含图像标题，并始终显示替代文本。这使屏幕阅读器可以导航到图像，还可以为图像提供替代文本。以下是带有标题和替代文本的图像示例。注意双冒号。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="asciidoc">.My Image Title
image::sunset.jpg[Alt Text]</code></pre>
</div>
</div>
<div class="paragraph">
<p>这是带有替代文本的嵌入式图像的示例。注意单个冒号。嵌入式图像不能有标题。它们通常是小图像，例如GUI按钮。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="asciidoc">image:sunset.jpg[Alt Text]</code></pre>
</div>
</div>
<div class="paragraph">
<p>进行本地构建时，将映像保存到<em>src / main / site / resources / images /</em>目录。链接到图像时，请勿包括路径的目录部分。在构建输出期间，图像将被复制到适当的目标位置。</p>
</div>
<div class="paragraph">
<p>当您提交包含将图像添加到《 HBase参考指南》的补丁时，请将图像附加到JIRA。如果提交者询问将图像提交到何处，则应进入上述目录。</p>
</div>
</div>
<div class="sect2">
<h3 id="_adding_a_new_chapter_to_the_hbase_reference_guide"><a class="anchor" href="#_adding_a_new_chapter_to_the_hbase_reference_guide"></a> A.7。在《 HBase参考指南》中添加新的章节</h3>
<div class="paragraph">
<p>如果要将新章节添加到《 HBase参考指南》中，最简单的方法是复制现有章节文件，对其进行重命名，然后更改ID（在方括号中）和标题。章节位于<em>src / main / asciidoc / _chapters /</em>目录中。</p>
</div>
<div class="paragraph">
<p>删除现有内容并创建新内容。然后打开<em>src / main / asciidoc / book.adoc</em>文件，该文件是《 HBase参考指南》的主要文件，并复制现有的<code>include</code>元素以在适当的位置包含新章节。在创建补丁之前，请确保将新文件添加到Git存储库。</p>
</div>
<div class="paragraph">
<p>如有疑问，请检查如何包含其他文件。</p>
</div>
</div>
<div class="sect2">
<h3 id="_common_documentation_issues"><a class="anchor" href="#_common_documentation_issues"></a> A.8。常见文件问题</h3>
<div class="paragraph">
<p>以下文档问题经常出现。其中一些是首选项，但另一些则可能会产生神秘的构建错误或其他问题。</p>
</div>
<div class="qlist qanda">
<ol>
<li>
<p><em>隔离更改以便轻松进行审核。</em></p>
<p>即使整个格式的格式随时间降低，也请小心打印或重新格式化整个XML文件。如果需要重新格式化文件，请在不更改任何内容的单独JIRA中进行。注意，因为某些XML编辑器在打开新文件时会进行批量重新格式化，尤其是在编辑器中使用GUI模式时。</p>
</li>
<li>
<p><em>语法高亮</em></p>
<p>《 HBase参考指南》使用<code>coderay</code>用于语法突出显示。要为给定的代码清单启用语法突出显示，请使用以下类型的语法：</p>
<div class="literalblock">
<div class="content">
<pre>[source,xml]
----
&lt;name&gt;My Name&lt;/name&gt;
----</pre>
</div>
</div>
<div class="paragraph">
<p>支持几种语法类型。《 HBase参考指南》中最有趣的是<code>java</code> ， <code>xml</code> ， <code>sql</code>和<code>bash</code> 。</p>
</div>
</li>
</ol>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="faq"><a class="anchor" href="#faq"></a>附录B：常见问题</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_general"><a class="anchor" href="#_general"></a> B.1。一般</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">什么时候应该使用HBase？</dt>
<dd>
<p>请参阅“体系结构”一章中的<a href="#arch.overview">概述</a> 。</p>
</dd>
<dt class="hdlist1">还有其他HBase常见问题解答吗？</dt>
<dd>
<p>请参阅<a href="http://wiki.apache.org/hadoop/Hbase/FAQ">Wiki上的FAQ</a> ， <a href="http://wiki.apache.org/hadoop/Hbase/FAQ">HBase Wiki FAQ</a> 。</p>
</dd>
<dt class="hdlist1">HBase是否支持SQL？</dt>
<dd>
<p>并不是的。通过<a href="http://hive.apache.org/">Hive</a>对HBase的SQL式支持正在开发中，但是Hive基于MapReduce，通常不适合低延迟请求。有关HBase客户端的示例，请参见“ <a href="#datamodel">数据模型”</a>部分。</p>
</dd>
<dt class="hdlist1">如何找到NoSQL / HBase的示例？</dt>
<dd>
<p>请参阅《 <a href="#other.info">关于HBase的其他信息》中</a>的BigTable论文链接以及其他论文。</p>
</dd>
<dt class="hdlist1">HBase的历史是什么？</dt>
<dd>
<p>参见<a href="#hbase.history">hbase.history</a> 。</p>
</dd>
</dl>
</div>
</div>
<div class="sect2">
<h3 id="_upgrading"><a class="anchor" href="#_upgrading"></a> B.2。升级中</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">如何将Maven管理的项目从HBase 0.94升级到HBase 0.96+？</dt>
<dd>
<p>在HBase 0.96中，项目移至模块化结构。调整项目的依赖项以依赖于<code>hbase-client</code>模块或其他合适的模块，而不是单个JAR。您可以根据以下HBase的目标版本对Maven依赖度进行建模。有关更多信息，请参见第3.5节“从0.94.x升级到0.96.x”或第3.3节“从0.96.x升级到0.98.x”。</p>
<div class="listingblock">
<div class="title">HBase 0.98的Maven依赖关系</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="xml"><span class="tag">&lt;dependency&gt;</span>
  <span class="tag">&lt;groupId&gt;</span>org.apache.hbase<span class="tag">&lt;/groupId&gt;</span>
  <span class="tag">&lt;artifactId&gt;</span>hbase-client<span class="tag">&lt;/artifactId&gt;</span>
  <span class="tag">&lt;version&gt;</span>0.98.5-hadoop2<span class="tag">&lt;/version&gt;</span>
<span class="tag">&lt;/dependency&gt;</span></code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">HBase 0.96的Maven依赖关系</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="xml"><span class="tag">&lt;dependency&gt;</span>
  <span class="tag">&lt;groupId&gt;</span>org.apache.hbase<span class="tag">&lt;/groupId&gt;</span>
  <span class="tag">&lt;artifactId&gt;</span>hbase-client<span class="tag">&lt;/artifactId&gt;</span>
  <span class="tag">&lt;version&gt;</span>0.96.2-hadoop2<span class="tag">&lt;/version&gt;</span>
<span class="tag">&lt;/dependency&gt;</span></code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">HBase 0.94的Maven依赖关系</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="xml"><span class="tag">&lt;dependency&gt;</span>
  <span class="tag">&lt;groupId&gt;</span>org.apache.hbase<span class="tag">&lt;/groupId&gt;</span>
  <span class="tag">&lt;artifactId&gt;</span>hbase<span class="tag">&lt;/artifactId&gt;</span>
  <span class="tag">&lt;version&gt;</span>0.94.3<span class="tag">&lt;/version&gt;</span>
<span class="tag">&lt;/dependency&gt;</span></code></pre>
</div>
</div>
</dd>
</dl>
</div>
</div>
<div class="sect2">
<h3 id="_architecture_2"><a class="anchor" href="#_architecture_2"></a> B.3。建筑</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">HBase如何处理Region-RegionServer的分配和位置？</dt>
<dd>
<p>请参阅<a href="#regions.arch">地区</a> 。</p>
</dd>
</dl>
</div>
</div>
<div class="sect2">
<h3 id="_configuration_2"><a class="anchor" href="#_configuration_2"></a> B.4。组态</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">如何开始第一个集群？</dt>
<dd>
<p>请参阅<a href="#quickstart">快速入门-独立HBase</a> 。</p>
</dd>
<dt class="hdlist1">在哪里可以了解其余的配置选项？</dt>
<dd>
<p>请参阅<a href="#configuration">Apache HBase配置</a> 。</p>
</dd>
</dl>
</div>
</div>
<div class="sect2">
<h3 id="_schema_design_data_access"><a class="anchor" href="#_schema_design_data_access"></a> B.5。模式设计/数据访问</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">我应该如何在HBase中设计架构？</dt>
<dd>
<p>请参阅<a href="#datamodel">数据模型</a>和<a href="#schema">HBase与模式设计</a> 。</p>
</dd>
<dt class="hdlist1">如何在HBase中存储（填空）？</dt>
<dd>
<p>请参阅<a href="#supported.datatypes">支持的数据类型</a> 。</p>
</dd>
<dt class="hdlist1">如何处理HBase中的二级索引？</dt>
<dd>
<p>请参阅<a href="#secondary.indexes">二级索引和备用查询路径</a> 。</p>
</dd>
<dt class="hdlist1">我可以更改表的行键吗？</dt>
<dd>
<p>这是一个非常普遍的问题。你不能请参见行键的<a href="#changing.rowkeys">不变性</a> 。</p>
</dd>
<dt class="hdlist1">HBase支持哪些API？</dt>
<dd>
<p>请参阅<a href="#nonjava.jvm">与JVM通讯的</a> <a href="#datamodel">数据模型</a> ， <a href="#architecture.client">客户端</a>和<a href="#nonjava.jvm">非Java语言</a> 。</p>
</dd>
</dl>
</div>
</div>
<div class="sect2">
<h3 id="_mapreduce"><a class="anchor" href="#_mapreduce"></a> B.6。MapReduce</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">如何在HBase中使用MapReduce？</dt>
<dd>
<p>参见<a href="#mapreduce">HBase和MapReduce</a> 。</p>
</dd>
</dl>
</div>
</div>
<div class="sect2">
<h3 id="_performance_and_troubleshooting"><a class="anchor" href="#_performance_and_troubleshooting"></a> B.7。性能与故障排除</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">如何提高HBase群集性能？</dt>
<dd>
<p>请参阅<a href="#performance">Apache HBase性能调优</a> 。</p>
</dd>
<dt class="hdlist1">如何对HBase群集进行故障排除？</dt>
<dd>
<p>请参阅<a href="#trouble">对Apache HBase进行故障排除和调试</a> 。</p>
</dd>
</dl>
</div>
</div>
<div class="sect2">
<h3 id="_amazon_ec2"><a class="anchor" href="#_amazon_ec2"></a> B.8。亚马逊EC2</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">我正在Amazon EC2上运行HBase，并且...</dt>
<dd>
<p>EC2问题是一个特例。请参阅<a href="#trouble.ec2">Amazon EC2</a>和<a href="#perf.ec2">Amazon EC2</a> 。</p>
</dd>
</dl>
</div>
</div>
<div class="sect2">
<h3 id="_operations"><a class="anchor" href="#_operations"></a> B.9。运作方式</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">如何管理我的HBase集群？</dt>
<dd>
<p>请参阅<a href="#ops_mgt">Apache HBase操作管理</a> 。</p>
</dd>
<dt class="hdlist1">如何备份HBase群集？</dt>
<dd>
<p>请参阅<a href="#ops.backup">HBase备份</a> 。</p>
</dd>
</dl>
</div>
</div>
<div class="sect2">
<h3 id="_hbase_in_action"><a class="anchor" href="#_hbase_in_action"></a> B.10。运行中的HBase</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">在哪里可以找到有关HBase的有趣视频和演示文稿？</dt>
<dd>
<p>请参阅有关<a href="#other.info">HBase的其他信息</a> 。</p>
</dd>
</dl>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="hbck.in.depth"><a class="anchor" href="#hbck.in.depth"></a>附录C：hbck深度</h2>
<div class="sectionbody">
<div class="paragraph">
<p>HBaseFsck（hbck）是用于检查区域一致性和表完整性问题以及修复损坏的HBase的工具。它以两种基本模式工作-只读不一致标识模式和多阶段读写修复模式。</p>
</div>
<div class="sect2">
<h3 id="_running_hbck_to_identify_inconsistencies"><a class="anchor" href="#_running_hbck_to_identify_inconsistencies"></a> C.1。运行hbck以识别不一致</h3>
<div class="paragraph">
<p>要检查您的HBase集群是否损坏，请对HBase集群运行hbck：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bourne">$ ./bin/hbase hbck</code></pre>
</div>
</div>
<div class="paragraph">
<p>在命令输出的末尾，它会打印OK或告诉您当前存在的INCONSISTENCIES数量。您可能还需要运行run hbck几次，因为某些不一致可能是暂时的（例如，群集正在启动或区域正在拆分）。在操作上，如果它反复报告不一致，则可能需要定期运行hbck并设置警报（例如，通过nagios）。运行hbck会报告不一致列表，并简要列出受影响的区域和表。使用<code>-details</code>选项将报告更多详细信息，包括所有表中存在的所有拆分的代表性列表。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bourne">$ ./bin/hbase hbck -details</code></pre>
</div>
</div>
<div class="paragraph">
<p>如果只想知道某些表是否已损坏，则可以限制hbck以仅识别特定表中的不一致之处。例如，以下命令将仅尝试检查表TableFoo和TableBar。好处是hbck将在更少的时间内运行。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bourne">$ ./bin/hbase hbck TableFoo TableBar</code></pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_inconsistencies"><a class="anchor" href="#_inconsistencies"></a> C.2。不一致之处</h3>
<div class="paragraph">
<p>如果在运行几次后，仍然继续报告不一致，则可能是您损坏了。这些应该很少见，但是如果它们发生，则较新版本的HBase包括启用了自动修复选项的hbck工具。</p>
</div>
<div class="paragraph">
<p>有两个不变量，一旦违反，就会在HBase中造成不一致：</p>
</div>
<div class="ulist">
<ul>
<li>
<p>如果每个区域恰好在一个区域服务器上分配和部署，并且保持此状态的所有位置都一致，则HBase的区域一致性不变性将得到满足。</p>
</li>
<li>
<p>如果对于每个表，每个可能的行键都精确地解析为一个区域，则满足HBase的表完整性不变性。</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>修复通常分为三个阶段：一个是识别不一致的只读信息收集阶段，一个是恢复表完整性不变的表完整性修复阶段，最后是一个恢复区域一致性不变的区域一致性修复阶段。从0.90.0版本开始，hbck可以检测有关表完整性问题的子集的区域一致性问题报告。它还具有自动修复最常见的不一致，区域分配和部署一致性问题的功能。可以通过使用<code>-fix</code>命令行选项。如果在错误的服务器或多个区域服务器上打开区域，这些问题将关闭区域；如果区域服务器未打开，则这些问题还会将区域分配给区域服务器。</p>
</div>
<div class="paragraph">
<p>从HBase 0.90.7、0.92.2和0.94.0版本开始，引入了几个新的命令行选项，以帮助修复损坏的HBase。该hbck有时被称为``uberhbck''。uber hbck的每个特定版本都与同一主要版本的HBase兼容（0.90.7 uberhbck可以修复0.90.4）。但是，版本0.60.90.6和版本2.10.92.1可能需要重新启动主服务器或故障转移到备份主服务器。</p>
</div>
</div>
<div class="sect2">
<h3 id="_localized_repairs"><a class="anchor" href="#_localized_repairs"></a> C.3。局部维修</h3>
<div class="paragraph">
<p>修复损坏的HBase时，最好先修复最低风险的不一致。这些通常是区域一致性修复-局部单区域修复，仅修改内存中的数据，临时的动物园管理员数据或META表中的补丁孔。区域一致性要求HBase实例具有HDFS（.regioninfo文件）中区域数据的状态，hbase：meta表中区域的行以及区域服务器和主服务器上区域的部署/分配。修复区域一致性的选项包括：</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>-fixAssignments</code> （等于0.90 <code>-fix</code>选项）修复未分配，分配不正确或乘以分配的区域。</p>
</li>
<li>
<p><code>-fixMeta</code>当在HDFS中不存在相应区域时，它会删除元行；如果在HDFS中而不是在META中存在相应的区域，则添加新的元行。要解决部署和分配问题，您可以运行以下命令：</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bourne">$ ./bin/hbase hbck -fixAssignments</code></pre>
</div>
</div>
<div class="paragraph">
<p>要解决部署和分配问题以及修复不正确的元行，可以运行以下命令：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bourne">$ ./bin/hbase hbck -fixAssignments -fixMeta</code></pre>
</div>
</div>
<div class="paragraph">
<p>有几类表完整性问题属于低风险修复。前两个是简并（startkey == endkey）区域和向后区域（startkey> endkey）。通过将数据附加到临时目录（/ hbck / xxxx），可以自动处理这些文件。第三个低风险类别是hdfs区域漏洞。可以使用以下方法修复：</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>-fixHdfsHoles</code>用于在文件系统上构造新的空区域的选项。如果检测到孔，则可以使用-fixHdfsHoles，并且应包含-fixMeta和-fixAssignments以使新区域保持一致。</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bourne">$ ./bin/hbase hbck -fixAssignments -fixMeta -fixHdfsHoles</code></pre>
</div>
</div>
<div class="paragraph">
<p>由于这是常见的操作，因此我们添加了<code>-repairHoles</code>与上一个命令等效的标志：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bourne">$ ./bin/hbase hbck -repairHoles</code></pre>
</div>
</div>
<div class="paragraph">
<p>如果在这些步骤之后仍然存在不一致之处，则您很可能会遇到与孤立或重叠区域有关的表完整性问题。</p>
</div>
</div>
<div class="sect2">
<h3 id="_region_overlap_repairs"><a class="anchor" href="#_region_overlap_repairs"></a> C.4。区域重叠维修</h3>
<div class="paragraph">
<p>表完整性问题可能需要修复来解决重叠问题。这是一个冒险的操作，因为它需要修改文件系统，需要做出一些决策，并且可能需要一些手动步骤。对于这些维修，最好分析一个<code>hbck -details</code>运行，以便仅在检查确定的问题上隔离维修尝试。因为这样做比较危险，所以应使用一些防护措施来限制维修范围。警告：这是一个相对较新的技术，仅在联机但空闲的HBase实例上进行了测试（没有读/写）。在活跃的生产环境中使用风险自负！修复表完整性违规的选项包括：</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>-fixHdfsOrphans</code>用于``采用''缺少目录元数据文件（.regioninfo文件）的区域目录的选项。</p>
</li>
<li>
<p><code>-fixHdfsOverlaps</code>固定重叠区域的能力</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>修复重叠的区域时，可以通过两种方式在文件系统上修改区域的数据：1）通过将区域合并到更大的区域中或2）通过将数据移到``sideline''目录中来对区域进行旁边缘处理，以便稍后可以恢复数据。合并多个区域在技术上是正确的，但可能会导致一个非常大的区域，需要进行一系列昂贵的压实和拆分操作。在这些情况下，最好将与大多数其他区域（可能是最大范围）重叠的区域放在一边，以使合并可以更合理的规模进行。由于这些带有边线的区域已经以HBase的本机目录和HFile格式进行布局，因此可以使用HBase的批量加载机制来还原它们。默认的防护阈值是保守的。这些选项使您可以覆盖默认阈值并启用大区域边线功能。</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>-maxMerge <n></code>合并的最大重叠区域数</p>
</li>
<li>
<p><code>-sidelineBigOverlaps</code>如果重叠的区域超过了maxMerge，则边线尝试将与大多数其他区域重叠的区域放在边线旁。</p>
</li>
<li>
<p><code>-maxOverlapsToSideline <n></code>如果在较大的重叠区域旁，则最多在n个区域旁。</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>由于通常您只想修复表，因此可以使用此选项打开所有修复选项：</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>-repair</code>包括所有区域一致性选项，仅包括孔修复台完整性选项。</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>最后，有一些安全措施可以将修复仅限于特定的表。例如，以下命令将仅尝试检查和修复表TableFoo和TableBar。</p>
</div>
<div class="listingblock">
<div class="content">
<pre>$ ./bin/hbase hbck -repair TableFoo TableBar</pre>
</div>
</div>
<div class="sect3">
<h4 id="_special_cases_meta_is_not_properly_assigned"><a class="anchor" href="#_special_cases_meta_is_not_properly_assigned"></a> C.4.1。特殊情况：未正确分配元</h4>
<div class="paragraph">
<p>hbck也可以处理一些特殊情况。有时，元表的唯一区域不一致地分配或部署。在这种情况下， <code>-fixMetaOnly</code>可以尝试修复元分配的选项。</p>
</div>
<div class="listingblock">
<div class="content">
<pre>$ ./bin/hbase hbck -fixMetaOnly -fixAssignments</pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_special_cases_hbase_version_file_is_missing"><a class="anchor" href="#_special_cases_hbase_version_file_is_missing"></a> C.4.2。特殊情况：缺少HBase版本文件</h4>
<div class="paragraph">
<p>HBase文件系统上的数据需要版本文件才能启动。如果缺少此飞弹，则可以使用<code>-fixVersionFile</code>制造新的HBase版本文件的选项。假设您正在运行的hbck版本是适用于HBase群集的版本。</p>
</div>
</div>
<div class="sect3">
<h4 id="_special_case_root_and_meta_are_corrupt"><a class="anchor" href="#_special_case_root_and_meta_are_corrupt"></a> C.4.3。特殊情况：根和META损坏。</h4>
<div class="paragraph">
<p>最严重的损坏情况是ROOT或META损坏而HBase无法启动的情况。在这种情况下，您可以使用OfflineMetaRepair工具创建新的ROOT和META区域和表。该工具假定HBase处于脱机状态。然后，它将遍历现有的HBase主目录，并从文件系统中尽可能多地从区域元数据文件（.regioninfo文件）中加载信息。如果区域元数据具有适当的表完整性，则将其保留在原始根目录和元表目录的旁边，并使用指向区域目录及其数据的指针来构建新的目录。</p>
</div>
<div class="listingblock">
<div class="content">
<pre>$ ./bin/hbase org.apache.hadoop.hbase.util.hbck.OfflineMetaRepair</pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-note" title="注意"></i>
</td>
<td class="content">该工具不如uberhbck聪明，但是可以用来引导uberhbck可以完成的修复。如果该工具成功，则应该能够启动hbase并在必要时运行在线修复。
</td>
</tr>
</tbody></table>
</div>
</div>
<div class="sect3">
<h4 id="_special_cases_offline_split_parent"><a class="anchor" href="#_special_cases_offline_split_parent"></a> C.4.4。特殊情况：离线拆分父级</h4>
<div class="paragraph">
<p>分割区域后，离线父对象将被自动清理。有时，在清理父母之前，女儿地区会再次分裂。HBase可以按正确的顺序清理父母。但是，有时可能会有一些缠绵的离线父母分裂。它们位于META，HDFS中，并且尚未部署。但是HBase无法清理它们。在这种情况下，您可以使用<code>-fixSplitParents</code>选项以在META中将它们重置为联机且不拆分。因此，如果使用固定重叠区域选项，hbck可以将它们与其他区域合并。</p>
</div>
<div class="paragraph">
<p>该选项通常不应该使用，并且不在<code>-fixAll</code> 。</p>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="appendix_acl_matrix"><a class="anchor" href="#appendix_acl_matrix"></a>附录D：访问控制矩阵</h2>
<div class="sectionbody">
<div class="paragraph">
<p>以下矩阵显示了在HBase中执行操作所需的权限集。在使用表格之前，请通读有关如何解释表格的信息。</p>
</div>
<div class="paragraph">
<div class="title">解释ACL矩阵表</div>
<p>ACL矩阵表中使用以下约定：</p>
</div>
<div class="sect2">
<h3 id="_scopes"><a class="anchor" href="#_scopes"></a> D.1。范围</h3>
<div class="paragraph">
<p>权限的评估从最广泛的范围开始，一直到最窄的范围。</p>
</div>
<div class="paragraph">
<p>范围对应于数据模型的级别。从最宽到最窄，范围如下：</p>
</div>
<div class="ulist">
<div class="title">范围</div>
<ul>
<li>
<p>全球</p>
</li>
<li>
<p>命名空间（NS）</p>
</li>
<li>
<p>表</p>
</li>
<li>
<p>列族（CF）</p>
</li>
<li>
<p>列限定词（CQ）</p>
</li>
<li>
<p>细胞</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>例如，在表级别授予的权限将主导在列族，列限定符或单元级别进行的所有授予。用户可以在表中的任何位置执行授予所隐含的操作。在全局范围内授予的权限控制着所有人：始终允许用户在任何地方执行该操作。</p>
</div>
</div>
<div class="sect2">
<h3 id="_permissions"><a class="anchor" href="#_permissions"></a> D.2。权限</h3>
<div class="paragraph">
<p>可能的权限包括：</p>
</div>
<div class="ulist">
<div class="title">权限</div>
<ul>
<li>
<p>超级用户-属于“超级组”组且具有无限访问权限的特殊用户</p>
</li>
<li>
<p>管理员（A）</p>
</li>
<li>
<p>创建（C）</p>
</li>
<li>
<p>写（W）</p>
</li>
<li>
<p>读（R）</p>
</li>
<li>
<p>执行（X）</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>在大多数情况下，权限会以预期的方式工作，但需注意以下几点：</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">拥有写入权限并不意味着具有读取权限。</dt>
<dd>
<p>用户可能并且有时希望能够写入同一用户无法读取的数据。这样的示例之一是日志写入过程。</p>
</dd>
<dt class="hdlist1">每个用户均可读取<span class="systemitem">hbase：meta</span>表，而不考虑用户的其他授予或限制。</dt>
<dd>
<p>这是HBase正常运行的要求。</p>
</dd>
<dt class="hdlist1"><code>CheckAndPut</code>和<code>CheckAndDelete</code>如果用户没有写和读权限，则操作将失败。</dt>
<dt class="hdlist1"><code>Increment</code>和<code>Append</code>操作不需要读取访问权限。</dt>
<dt class="hdlist1">的<code>superuser</code> ，顾名思义，它有权执行所有可能的操作。</dt>
<dt class="hdlist1">对于标有*的操作，检查是在挂接后完成的，只有满足访问检查结果的子集才返回给用户。</dt>
<dd>
<p>下表按提供每个操作的接口排序。如果该表已过期，可以在<em>hbase-server / src / test / java / org / apache / hadoop / hbase / security / access / TestAccessController.java中</em>找到检查权限准确性的单元测试。访问控制本身可以在<em>hbase-server / src / main / java / org / apache / hadoop / hbase / security / access / AccessController.java中进行检查</em> 。</p>
</dd>
</dl>
</div>
<table class="tableblock frame-all grid-all spread">
<caption class="title">表12。ACL矩阵</caption>
<colgroup>
<col style="width:33%">
<col style="width:33%">
<col style="width:33%">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">接口</th>
<th class="tableblock halign-left valign-top">运作方式</th>
<th class="tableblock halign-left valign-top">权限</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">主</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">createTable</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">超级用户|全局（C）| NS（C）</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">修改表</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">超级用户|全局（A）|全局（C）| NS（A）| NS（C）| TableOwner |表（A）|表（C）</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">deleteTable</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">超级用户|全局（A）|全局（C）| NS（A）| NS（C）| TableOwner |表（A）|表（C）</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">截断表</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">超级用户|全局（A）|全局（C）| NS（A）| NS（C）| TableOwner |表（A）|表（C）</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">addColumn</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">超级用户|全局（A）|全局（C）| NS（A）| NS（C）| TableOwner |表（A）|表（C）</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">ModifyColumn</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">超级用户|全局（A）|全局（C）| NS（A）| NS（C）|表所有者|表（A）|表（C）|列（A）|列（C）</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">deleteColumn</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">超级用户|全局（A）|全局（C）| NS（A）| NS（C）|表所有者|表（A）|表（C）|列（A）|列（C）</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">enableTable</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">超级用户|全局（A）|全局（C）| NS（A）| NS（C）| TableOwner |表（A）|表（C）</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">disableTable</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">超级用户|全局（A）|全局（C）| NS（A）| NS（C）| TableOwner |表（A）|表（C）</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">disableAclTable</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">不允许</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">移动</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">超级用户|全局（A）| NS（A）| TableOwner |表（A）</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">分配</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">超级用户|全局（A）| NS（A）| TableOwner |表（A）</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">取消分配</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">超级用户|全局（A）| NS（A）| TableOwner |表（A）</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">regionOffline</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">超级用户|全局（A）| NS（A）| TableOwner |表（A）</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">平衡</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">超级用户|全局（A）</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">balanceSwitch</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">超级用户|全局（A）</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">关掉</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">超级用户|全局（A）</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">停止大师</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">超级用户|全局（A）</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">快照</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">超级用户|全局（A）| NS（A）| TableOwner |表（A）</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">listSnapshot</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">超级用户|全局（A）| SnapshotOwner</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">cloneSnapshot</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">超级用户|全局（A）|（SnapshotOwner和TableName匹配）</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">restoreSnapshot</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">超级用户|全局（A）| SnapshotOwner和（NS（A）| TableOwner |表（A））</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">deleteSnapshot</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">超级用户|全局（A）| SnapshotOwner</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">createNamespace</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">超级用户|全局（A）</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">deleteNamespace</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">超级用户|全局（A）</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">ModifyNamespace</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">超级用户|全局（A）</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">getNamespaceDescriptor</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">超级用户|全局（A）| NS（A）</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">listNamespaceDescriptors *</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">超级用户|全局（A）| NS（A）</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">刷新表</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">超级用户|全局（A）|全局（C）| NS（A）| NS（C）| TableOwner |表（A）|表（C）</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">getTableDescriptors *</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">超级用户|全局（A）|全局（C）| NS（A）| NS（C）| TableOwner |表（A）|表（C）</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">getTableNames *</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">超级用户| TableOwner |任何全局或表权限</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">setUserQuota（全局级别）</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">超级用户|全局（A）</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">setUserQuota（命名空间级别）</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">超级用户|全局（A）</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">setUserQuota（表级别）</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">超级用户|全局（A）| NS（A）| TableOwner |表（A）</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">setTableQuota</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">超级用户|全局（A）| NS（A）| TableOwner |表（A）</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">setNamespaceQuota</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">超级用户|全局（A）</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">区域</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">openRegion</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">超级用户|全局（A）</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">closeRegion</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">超级用户|全局（A）</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">齐平</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">超级用户|全局（A）|全局（C）| TableOwner |表（A）|表（C）</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">分裂</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">超级用户|全局（A）|表所有者|表所有者|表（A）</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">紧凑</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">超级用户|全局（A）|全局（C）| TableOwner |表（A）|表（C）</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">getClosestRowBefore</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">超级用户|全局（R）| NS（R）| TableOwner |表（R）| CF（R）| CQ（R）</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">getOp</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">超级用户|全局（R）| NS（R）| TableOwner |表（R）| CF（R）| CQ（R）</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">存在</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">超级用户|全局（R）| NS（R）| TableOwner |表（R）| CF（R）| CQ（R）</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">放</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">超级用户|全局（W）| NS（W）|表（W）| TableOwner | CF（W）| CQ（W）</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">删除</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">超级用户|全局（W）| NS（W）|表（W）| TableOwner | CF（W）| CQ（W）</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">batchMutate</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">超级用户|全局（W）| NS（W）| TableOwner |表（W）| CF（W）| CQ（W）</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">checkAndPut</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">超级用户|全局（RW）| NS（RW）|表所有者|表（RW）| CF（RW）| CQ（RW）</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">checkAndPutAfterRowLock</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">超级用户| global（R）| NS（R）| TableOwner | Table（R）| CF（R）| CQ（R）</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">checkAndDelete</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">超级用户|全局（RW）| NS（RW）|表所有者|表（RW）| CF（RW）| CQ（RW）</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">checkAndDeleteAfterRowLock</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">超级用户|全局（R）| NS（R）| TableOwner |表（R）| CF（R）| CQ（R）</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">crementColumnValue</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">超级用户|全局（W）| NS（W）| TableOwner |表（W）| CF（W）| CQ（W）</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">附加</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">超级用户|全局（W）| NS（W）| TableOwner |表（W）| CF（W）| CQ（W）</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">appendAfterRowLock</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">超级用户|全局（W）| NS（W）| TableOwner |表（W）| CF（W）| CQ（W）</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">增量</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">超级用户|全局（W）| NS（W）| TableOwner |表（W）| CF（W）| CQ（W）</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">增量后行锁定</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">超级用户|全局（W）| NS（W）| TableOwner |表（W）| CF（W）| CQ（W）</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">扫描仪打开</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">超级用户|全局（R）| NS（R）| TableOwner |表（R）| CF（R）| CQ（R）</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">下一个</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">超级用户|全局（R）| NS（R）| TableOwner |表（R）| CF（R）| CQ（R）</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">扫描仪关闭</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">超级用户|全局（R）| NS（R）| TableOwner |表（R）| CF（R）| CQ（R）</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bulkLoadHFile</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">超级用户|全局（C）|表所有者|表（C）| CF（C）</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">prepareBulkLoad</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">超级用户|全局（C）|表所有者|表（C）| CF（C）</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">cleanupBulkLoad</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">超级用户|全局（C）|表所有者|表（C）| CF（C）</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">终点</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">调用</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">超级用户|全局（X）| NS（X）| TableOwner |表（X）</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">存取控制器</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">授予（全球级别）</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">全局（A）</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">授予（命名空间级别）</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">全局（A）| NS（A）</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">补助金（表级）</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">全局（A）| NS（A）| TableOwner |表（A）| CF（A）| CQ（A）</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">撤销（全局级别）</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">全局（A）</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">撤消（命名空间级别）</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">全局（A）| NS（A）</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">撤销（表级）</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">全局（A）| NS（A）| TableOwner |表（A）| CF（A）| CQ（A）</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">getUserPermissions（全局级别）</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">全局（A）</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">getUserPermissions（命名空间级别）</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">全局（A）| NS（A）</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">getUserPermissions（表级别）</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">全局（A）| NS（A）| TableOwner |表（A）| CF（A）| CQ（A）</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">区域服务器</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">stopRegionServer</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">超级用户|全局（A）</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">mergeRegions</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">超级用户|全局（A）</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">rollWALWriterRequest</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">超级用户|全局（A）</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">复制日志条目</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">超级用户|全局（W）</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">RSGroup</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">addRSGroup</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">超级用户|全局（A）</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">balanceRSGroup</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">超级用户|全局（A）</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">getRSGroupInfo</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">超级用户|全局（A）</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">getRSGroupInfoOfTable</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">超级用户|全局（A）</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">getRSGroupOfServer</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">超级用户|全局（A）</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">listRSGroups</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">超级用户|全局（A）</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">moveServers</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">超级用户|全局（A）</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">moveServersAndTables</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">超级用户|全局（A）</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">移动表</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">超级用户|全局（A）</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">removeRSGroup</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">超级用户|全局（A）</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">removeServers</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">超级用户|全局（A）</p></td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
<div class="sect1">
<h2 id="compression"><a class="anchor" href="#compression"></a>附录E：HBase中的压缩和数据块编码</h2>
<div class="sectionbody">
<div class="admonitionblock note">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-note" title="注意"></i>
</td>
<td class="content">本节中提到的编解码器用于编码和解码数据块或行键。有关复制编解码器的信息，请参见<a href="#cluster.replication.preserving.tags">cluster.replication.preserving.tags</a> 。
</td>
</tr>
</tbody></table>
</div>
<div class="paragraph">
<p>本节中的某些信息来自有关HBase Development邮件列表的<a href="http://search-hadoop.com/m/lL12B1PFVhp1/v=threaded">讨论</a> 。</p>
</div>
<div class="paragraph">
<p>HBase支持可以在ColumnFamily上启用的几种不同的压缩算法。数据块编码尝试利用HBase的一些基本设计和模式来限制键中信息的重复，例如排序的行键和给定表的架构。压缩器可减少单元中较大的不透明字节数组的大小，并可显着减少存储未压缩数据所需的存储空间。</p>
</div>
<div class="paragraph">
<p>压缩器和数据块编码可以在同一ColumnFamily上一起使用。</p>
</div>
<div class="paragraph">
<div class="title">更改在压实后生效</div>
<p>如果更改ColumnFamily的压缩或编码，则更改将在压缩期间生效。</p>
</div>
<div class="paragraph">
<p>一些编解码器利用了Java内置的功能，例如GZip压缩。其他依赖本地库。本地库可能作为Hadoop的一部分提供，例如LZ4。在这种情况下，HBase仅需要访问适当的共享库。</p>
</div>
<div class="paragraph">
<p>首先需要安装其他编解码器，例如Google Snappy。某些编解码器的许可方式与HBase的许可冲突，因此无法作为HBase的一部分提供。</p>
</div>
<div class="paragraph">
<p>本节讨论与HBase一起使用和测试的常见编解码器。无论使用哪种编解码器，请务必测试它是否已正确安装并且在群集中的所有节点上都可用。为了确保编解码器在新部署的节点上可用，可能需要执行额外的操作步骤。您可以使用<a href="#compression.test">compression.test</a>实用程序来检查是否正确安装了给定的编解码器。</p>
</div>
<div class="paragraph">
<p>要将HBase配置为使用压缩器，请参见<a href="#compressor.install">compressor.install</a> 。要为ColumnFamily启用压缩器，请参见<a href="#changing.compression">changing.compression</a> 。要为ColumnFamily启用数据块编码，请参见<a href="#data.block.encoding.enable">data.block.encoding.enable</a> 。</p>
</div>
<div class="ulist">
<div class="title">块式压缩机</div>
<ul>
<li>
<p>没有</p>
</li>
<li>
<p>活泼的</p>
</li>
<li>
<p>LZO</p>
</li>
<li>
<p>LZ4</p>
</li>
<li>
<p>广州</p>
</li>
</ul>
</div>
<div class="dlist">
<div class="title">数据块编码类型</div>
<dl>
<dt class="hdlist1">字首</dt>
<dd>
<p>通常，键非常相似。具体而言，密钥通常共享一个公共前缀，并且仅在末尾有所不同。例如，一个关键可能是<code>RowKey:Family:Qualifier0</code>下一个键可能是<code>RowKey:Family:Qualifier1</code> 。
 <br>在Prefix编码中，添加了一个额外的列，用于保存当前密钥和上一个密钥之间共享的前缀长度。假设此处的第一个键与之前的键完全不同，则其前缀长度为0。</p>
<div class="paragraph">
<p>第二个键的前缀长度是<code>23</code> ，因为它们的前23个字符相同。</p>
</div>
<div class="paragraph">
<p>显然，如果密钥之间没有共同之处，那么前缀将不会带来太多好处。</p>
</div>
<div class="paragraph">
<p>下图显示了没有数据块编码的假设ColumnFamily。</p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/data_block_no_encoding.png" alt="数据块无编码">
</div>
<div class="title">图11。没有编码的ColumnFamily</div>
</div>
<div class="paragraph">
<p>这是带有前缀数据编码的相同数据。</p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/data_block_prefix_encoding.png" alt="数据块前缀编码">
</div>
<div class="title">图12。具有前缀编码的ColumnFamily</div>
</div>
</dd>
<dt class="hdlist1">差异</dt>
<dd>
<p>差异编码在前缀编码的基础上扩展。代替顺序地将密钥视为一个整体的字节序列，可以拆分每个密钥字段，以便可以更有效地压缩密钥的每个部分。</p>
<div class="paragraph">
<p>添加了两个新字段：时间戳记和类型。</p>
</div>
<div class="paragraph">
<p>如果ColumnFamily与上一行相同，则将其从当前行中省略。</p>
</div>
<div class="paragraph">
<p>如果键的长度，值的长度或类型与上一行相同，则省略该字段。</p>
</div>
<div class="paragraph">
<p>此外，为了提高压缩率，时间戳记将存储为前一行时间戳记的Diff，而不是全部存储。给定Prefix示例中的两个行键，并且在时间戳和相同类型上给出完全匹配，则第二行的值长度或类型都不需要存储，第二行的时间戳值仅为0，而不是完整的时间戳记。</p>
</div>
<div class="paragraph">
<p>默认情况下，Diff编码是禁用的，因为写入和扫描速度较慢，但是会缓存更多数据。</p>
</div>
<div class="paragraph">
<p>此图像显示了与先前图像相同的ColumnFamily，具有Diff编码。</p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/data_block_diff_encoding.png" alt="数据块差异编码">
</div>
<div class="title">图13。具有Diff编码的ColumnFamily</div>
</div>
</dd>
<dt class="hdlist1">快速差异</dt>
<dd>
<p>Fast Diff与Diff相似，但是使用了更快的实现。它还添加了另一个字段，该字段存储一个位以跟踪数据本身是否与上一行相同。如果是，则不会再次存储数据。</p>
<div class="paragraph">
<p>如果您有长键或多列，建议使用Fast Diff编解码器。</p>
</div>
<div class="paragraph">
<p>数据格式几乎与Diff编码相同，因此没有图像可以说明。</p>
</div>
</dd>
<dt class="hdlist1">前缀树</dt>
<dd>
<p>前缀树编码是HBase 0.96中的一项实验功能。它提供了与前缀，差异和快速差异编码器类似的内存节省，但以较低的编码速度为代价提供了更快的随机访问。</p>
</dd>
</dl>
</div>
<div class="paragraph">
<p>前缀树可能适用于具有高块高速缓存命中率的应用程序。它为行和列引入了新的“树”字段。行树字段包含与该行中的单元格相对应的偏移量/引用的列表。这样可以进行大量压缩。有关前缀树编码的更多详细信息，请参见<a href="https://issues.apache.org/jira/browse/HBASE-4676">HBASE-4676</a> 。</p>
</div>
<div class="paragraph">
<p>很难以图形方式说明前缀树，因此不包含图像。有关此数据结构的更多常规信息，请参阅Wikipedia文章<a href="http://en.wikipedia.org/wiki/Trie">Trie</a> 。</p>
</div>
<div class="paragraph">
<p>前缀树将在hbase-2.0.0中删除。这是一个很好的功能，但是吸收很少，没有得到积极维护。如果您对进行此编码感兴趣，请来编写开发人员列表。</p>
</div>
<div class="sect2">
<h3 id="_which_compressor_or_data_block_encoder_to_use"><a class="anchor" href="#_which_compressor_or_data_block_encoder_to_use"></a> E.1。使用哪种压缩器或数据块编码器</h3>
<div class="paragraph">
<p>使用的压缩或编解码器类型取决于数据的特征。选择错误的类型可能会导致您的数据占用更多空间而不是更少，并且可能会影响性能。</p>
</div>
<div class="paragraph">
<p>通常，您需要在较小的尺寸和更快的压缩/解压缩之间权衡选择。以下是一些常规准则，这些准则是从<a href="http://search-hadoop.com/m/lL12B1PFVhp1">文档指导中有关压缩和编解码器</a>的讨论扩展而来的。</p>
</div>
<div class="ulist">
<ul>
<li>
<p>如果您有长键（与值相比）或多列，请使用前缀编码器。建议使用FAST_DIFF，因为需要对前缀树编码进行更多测试。</p>
</li>
<li>
<p>如果值较大（并且未进行预压缩，例如图像），请使用数据块压缩器。</p>
</li>
<li>
<p>将GZIP用于不经常访问的<em class="firstterm">冷数据</em> 。GZIP压缩比Snappy或LZO占用更多的CPU资源，但提供更高的压缩率。</p>
</li>
<li>
<p>将Snappy或LZO用于经常访问的<em class="firstterm">热数据</em> 。Snappy和LZO比GZIP使用更少的CPU资源，但压缩率却不高。</p>
</li>
<li>
<p>在大多数情况下，默认情况下启用Snappy或LZO是一个不错的选择，因为它们的性能开销较低并且可以节省空间。</p>
</li>
<li>
<p>在Snappy于2011年由Google推出之前，LZO是默认设置。Snappy具有与LZO相似的质量，但表现出更好的性能。</p>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="hadoop.native.lib"><a class="anchor" href="#hadoop.native.lib"></a> E.2。在HBase中利用Hadoop本机库</h3>
<div class="paragraph">
<p>Hadoop共享库具有很多功能，包括压缩库和快速crc'ing。要使此功能可用于HBase，请执行以下操作。如果HBase / Hadoop无法找到本机库版本，它将退回到使用替代方案，否则，如果您要求使用显式压缩器且没有替代方案，则将彻底失败。</p>
</div>
<div class="paragraph">
<p>如果在HBase日志中看到以下内容，则表明HBase无法找到Hadoop本机库：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="integer">2014</span>-<span class="integer">08</span>-<span class="octal">07</span> <span class="integer">09</span>:<span class="integer">26</span>:<span class="integer">20</span>,<span class="integer">139</span> WARN  [main] util.NativeCodeLoader: Unable to load <span class="directive">native</span>-hadoop library <span class="keyword">for</span> your platform... using builtin-java classes where applicable</code></pre>
</div>
</div>
<div class="paragraph">
<p>如果库成功加载，则不会显示WARN消息。</p>
</div>
<div class="paragraph">
<p>让我们假设您的Hadoop带有适合您在其上运行HBase的平台的本机库。要检查HBase是否可使用Hadoop本机库，请运行以下工具（在Hadoop 2.1及更高版本中可用）：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="error">$</span> ./bin/hbase --config ~/conf_hbase org.apache.hadoop.util.NativeLibraryChecker
<span class="integer">2014</span>-<span class="integer">08</span>-<span class="integer">26</span> <span class="integer">13</span>:<span class="integer">15</span>:<span class="integer">38</span>,<span class="integer">717</span> WARN  [main] util.NativeCodeLoader: Unable to load <span class="directive">native</span>-hadoop library <span class="keyword">for</span> your platform... using builtin-java classes where applicable
Native library checking:
hadoop: <span class="predefined-constant">false</span>
zlib:   <span class="predefined-constant">false</span>
snappy: <span class="predefined-constant">false</span>
lz4:    <span class="predefined-constant">false</span>
bzip2:  <span class="predefined-constant">false</span>
<span class="integer">2014</span>-<span class="integer">08</span>-<span class="integer">26</span> <span class="integer">13</span>:<span class="integer">15</span>:<span class="integer">38</span>,<span class="integer">863</span> INFO  [main] util.ExitUtil: Exiting with status <span class="integer">1</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>上面显示了本地hadoop库在HBase上下文中不可用。</p>
</div>
<div class="paragraph">
<p>要解决上述问题，请在文件系统中将Hadoop和HBase停顿相邻时，将Hadoop本机库复制到本地或将它们链接到它们。您还可以通过设置<code>LD_LIBRARY_PATH</code>环境变量。</p>
</div>
<div class="paragraph">
<p>JVM查找本地库的位置是“取决于系统的”（请参阅<code>java.lang.System#loadLibrary(name)</code> ）。在Linux上，默认情况下将在<em>lib / native / PLATFORM</em>中查找<code>PLATFORM</code>是安装HBase的平台的标签。在本地linux机器上，这似乎是java属性的串联<code>os.name</code>和<code>os.arch</code>其次是32位还是64位。HBase启动时会打印出所有Java系统属性，因此请在日志中找到os.name和os.arch。例如：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">...
<span class="integer">2014</span>-<span class="integer">08</span>-<span class="octal">06</span> <span class="integer">15</span>:<span class="integer">27</span>:<span class="integer">22</span>,<span class="integer">853</span> INFO  [main] zookeeper.ZooKeeper: Client environment:os.name=Linux
<span class="integer">2014</span>-<span class="integer">08</span>-<span class="octal">06</span> <span class="integer">15</span>:<span class="integer">27</span>:<span class="integer">22</span>,<span class="integer">853</span> INFO  [main] zookeeper.ZooKeeper: Client environment:os.arch=amd64
...</code></pre>
</div>
</div>
<div class="paragraph">
<p>因此，在这种情况下，PLATFORM字符串为<code>Linux-amd64-64</code> 。复制Hadoop本机库或在<em>lib / native / Linux-amd64-64</em>处进行符号链接将确保找到它们。使用Hadoop <em>NativeLibraryChecker进行</em>检查。</p>
</div>
<div class="paragraph">
<p>这是如何使用指向Hadoop库的示例<code>LD_LIBRARY_PATH</code>环境变量：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="error">$</span> LD_LIBRARY_PATH=~/hadoop-<span class="float">2.5</span><span class="float">.0</span>-SNAPSHOT/lib/<span class="directive">native</span> ./bin/hbase --config ~/conf_hbase org.apache.hadoop.util.NativeLibraryChecker
<span class="integer">2014</span>-<span class="integer">08</span>-<span class="integer">26</span> <span class="integer">13</span>:<span class="integer">42</span>:<span class="integer">49</span>,<span class="integer">332</span> INFO  [main] bzip2.Bzip2Factory: Successfully loaded &amp; initialized <span class="directive">native</span>-bzip2 library system-<span class="directive">native</span>
<span class="integer">2014</span>-<span class="integer">08</span>-<span class="integer">26</span> <span class="integer">13</span>:<span class="integer">42</span>:<span class="integer">49</span>,<span class="integer">337</span> INFO  [main] zlib.ZlibFactory: Successfully loaded &amp; initialized <span class="directive">native</span>-zlib library
Native library checking:
hadoop: <span class="predefined-constant">true</span> /home/stack/hadoop-<span class="float">2.5</span><span class="float">.0</span>-SNAPSHOT/lib/<span class="directive">native</span>/libhadoop.so<span class="float">.1</span><span class="float">.0</span><span class="float">.0</span>
zlib:   <span class="predefined-constant">true</span> /lib64/libz.so<span class="float">.1</span>
snappy: <span class="predefined-constant">true</span> /usr/lib64/libsnappy.so<span class="float">.1</span>
lz4:    <span class="predefined-constant">true</span> revision:<span class="integer">99</span>
bzip2:  <span class="predefined-constant">true</span> /lib64/libbz2.so<span class="float">.1</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>启动HBase时，在<em>hbase-env.sh中</em>设置LD_LIBRARY_PATH环境变量。</p>
</div>
</div>
<div class="sect2">
<h3 id="_compressor_configuration_installation_and_use"><a class="anchor" href="#_compressor_configuration_installation_and_use"></a> E.3。压缩机的配置，安装和使用</h3>
<div class="sect3">
<h4 id="compressor.install"><a class="anchor" href="#compressor.install"></a> E.3.1。为压缩器配置HBase</h4>
<div class="paragraph">
<p>在HBase可以使用给定的压缩器之前，它的库必须可用。由于许可问题，在默认安装中，仅GZ压缩可用于HBase（通过本机Java库）。其他压缩库可通过与您的hadoop捆绑在一起的共享库获得。在HBase启动时，hadoop本机库需要可找到。看到</p>
</div>
<div class="paragraph">
<div class="title">主站上的压缩机支持</div>
<p>HBase 0.95中引入了新的配置设置，以检查主服务器以确定在其上安装和配置了哪些数据块编码器，并假定整个集群都配置相同。这个选项<code>hbase.master.check.compression</code> ，默认为<code>true</code> 。这可以防止在<a href="https://issues.apache.org/jira/browse/HBASE-6370">HBASE-6370中</a>描述的情况，在该情况下创建或修改表以支持区域服务器不支持的编解码器，从而导致需要很长时间才能发生的故障，并且难以调试。</p>
</div>
<div class="paragraph">
<p>如果<code>hbase.master.check.compression</code>启用后，即使主服务器未运行区域服务器，也需要在主服务器上安装并配置所有所需压缩器的库。</p>
</div>
<div class="paragraph">
<div class="title">通过本地库安装GZ支持</div>
<p>除非CLASSPATH上提供本地Hadoop库，否则HBase使用Java的内置GZip支持。建议将库添加到CLASSPATH的方法是设置环境变量<code>HBASE_LIBRARY_PATH</code>针对运行HBase的用户。如果本机库不可用并且使用了Java的GZIP， <code>Got brand-new compressor</code>报告将显示在日志中。参见<a href="#brand.new.compressor">brand.new.compressor</a> ）。</p>
</div>
<div id="lzo.compression" class="paragraph">
<div class="title">安装LZO支持</div>
<p>HBase无法与LZO一起使用，因为使用Apache软件许可证（ASL）的HBase与使用GPL许可证的LZO之间不兼容。有关为HBase配置LZO支持的信息，请参见“ <a href="http://wiki.apache.org/hadoop/UsingLzoCompression">使用LZO压缩”</a>维基页面。</p>
</div>
<div class="paragraph">
<p>如果您依赖LZO压缩，请考虑将您的RegionServer配置为在LZO不可用时无法启动。请参阅<a href="#hbase.regionserver.codecs">hbase.regionserver.codecs</a> 。</p>
</div>
<div id="lz4.compression" class="paragraph">
<div class="title">配置LZ4支持</div>
<p>LZ4支持与Hadoop捆绑在一起。启动HBase时，请确保可访问hadoop共享库（libhadoop.so）。配置平台（请参阅<a href="#hbase.native.platform">hbase.native.platform</a> ）后，可以从HBase到本机Hadoop库建立符号链接。假定两个软件安装在同一位置。例如，如果我的“平台”是Linux-amd64-64：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bourne">$ cd $HBASE_HOME
$ mkdir lib/native
$ ln -s $HADOOP_HOME/lib/native lib/native/Linux-amd64-64</code></pre>
</div>
</div>
<div class="paragraph">
<p>使用压缩工具检查是否在所有节点上都安装了LZ4。启动（或重新启动）HBase。之后，您可以创建和更改表以将LZ4用作压缩编解码器。</p>
</div>
<div class="listingblock">
<div class="content">
<pre>hbase(main):003:0&gt; alter 'TestTable', {NAME =&gt; 'info', COMPRESSION =&gt; 'LZ4'}</pre>
</div>
</div>
<div id="snappy.compression.installation" class="paragraph">
<div class="title">安装Snappy支持</div>
<p>由于许可问题，HBase不附带Snappy支持。您可以安装Snappy二进制文件（例如，通过在CentOS上使用yum install snappy）或从源代码构建Snappy。安装Snappy之后，搜索共享库，该库将称为<em>libsnappy.so。X</em> ，其中X是数字。如果是从源代码构建的，请将共享库复制到系统上的已知位置，例如<em>/ opt / snappy / lib /</em> 。</p>
</div>
<div class="paragraph">
<p>除了Snappy库之外，HBase还需要访问Hadoop共享库，该库将称为<em>libhadoop.so之类。XY</em> ，其中X和Y都是数字。记下Hadoop库的位置，或将其复制到Snappy库的相同位置。</p>
</div>
<div class="admonitionblock note">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-note" title="注意"></i>
</td>
<td class="content">
<div class="paragraph">
<p>Snappy和Hadoop库需要在群集的每个节点上都可用。请参阅<a href="#compression.test">compression.test</a>以了解如何测试这种情况。</p>
</div>
<div class="paragraph">
<p>请参阅<a href="#hbase.regionserver.codecs">hbase.regionserver.codecs</a>以配置您的RegionServer在给定的压缩器不可用时无法启动。</p>
</div>
</td>
</tr>
</tbody></table>
</div>
<div class="paragraph">
<p>这些库位置中的每一个都需要添加到环境变量中<code>HBASE_LIBRARY_PATH</code>适用于运行HBase的操作系统用户。您需要重新启动RegionServer才能使更改生效。</p>
</div>
<div id="compression.test" class="paragraph">
<div class="title">压缩测试</div>
<p>您可以使用CompressionTest工具来验证您的压缩器可用于HBase：</p>
</div>
<div class="listingblock">
<div class="content">
<pre> $ hbase org.apache.hadoop.hbase.util.CompressionTest hdfs://host/path/to/hbase snappy</pre>
</div>
</div>
<div id="hbase.regionserver.codecs" class="paragraph">
<div class="title">在RegionServer上实施压缩设置</div>
<p>您可以配置RegionServer，以便在错误配置压缩的情况下无法重启，方法是将选项hbase.regionserver.codecs添加到<em>hbase-site.xml</em> ，并将其值设置为逗号分隔的编解码器列表，能得到的。例如，如果将此属性设置为<code>lzo,gz</code> ，如果两个压缩器都不可用，则RegionServer将无法启动。这将防止在未正确配置编解码器的情况下将新服务器添加到群集。</p>
</div>
</div>
<div class="sect3">
<h4 id="changing.compression"><a class="anchor" href="#changing.compression"></a> E.3.2。在ColumnFamily上启用压缩</h4>
<div class="paragraph">
<p>要为ColumnFamily启用压缩，请使用<code>alter</code>命令。您无需重新创建表或复制数据。如果要更改编解码器，请确保在压缩所有旧的StoreFiles之前，旧的编解码器仍然可用。</p>
</div>
<div class="exampleblock">
<div class="title">例子51。使用HBaseShell对现有表的ColumnFamily启用压缩</div>
<div class="content">
<div class="listingblock">
<div class="content">
<pre>hbase&gt; disable 'test'
hbase&gt; alter 'test', {NAME =&gt; 'cf', COMPRESSION =&gt; 'GZ'}
hbase&gt; enable 'test'</pre>
</div>
</div>
</div>
</div>
<div class="exampleblock">
<div class="title">示例52。在ColumnFamily上创建带有压缩的新表</div>
<div class="content">
<div class="listingblock">
<div class="content">
<pre>hbase&gt; create 'test2', { NAME =&gt; 'cf2', COMPRESSION =&gt; 'SNAPPY' }</pre>
</div>
</div>
</div>
</div>
<div class="exampleblock">
<div class="title">示例53。验证ColumnFamily的压缩设置</div>
<div class="content">
<div class="listingblock">
<div class="content">
<pre>hbase&gt; describe 'test'
DESCRIPTION                                          ENABLED
 'test', {NAME =&gt; 'cf', DATA_BLOCK_ENCODING =&gt; 'NONE false
 ', BLOOMFILTER =&gt; 'ROW', REPLICATION_SCOPE =&gt; '0',
 VERSIONS =&gt; '1', COMPRESSION =&gt; 'GZ', MIN_VERSIONS
 =&gt; '0', TTL =&gt; 'FOREVER', KEEP_DELETED_CELLS =&gt; 'fa
 lse', BLOCKSIZE =&gt; '65536', IN_MEMORY =&gt; 'false', B
 LOCKCACHE =&gt; 'true'}
1 row(s) in 0.1070 seconds</pre>
</div>
</div>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_testing_compression_performance"><a class="anchor" href="#_testing_compression_performance"></a> E.3.3。测试压缩性能</h4>
<div class="paragraph">
<p>HBase包含一个名为LoadTestTool的工具，该工具提供了测试压缩性能的机制。您必须指定<code>-write</code>要么<code>-update-read</code>作为您的第一个参数，如果您未指定其他参数，则会为每个选项打印使用建议。</p>
</div>
<div class="exampleblock">
<div class="title">示例54LoadTestTool的用法</div>
<div class="content">
<div class="listingblock">
<div class="content">
<pre>$ bin/hbase org.apache.hadoop.hbase.util.LoadTestTool -h
usage: bin/hbase org.apache.hadoop.hbase.util.LoadTestTool &lt;options&gt;
Options:
 -batchupdate                 Whether to use batch as opposed to separate
                              updates for every column in a row
 -bloom &lt;arg&gt;                 Bloom filter type, one of [NONE, ROW, ROWCOL]
 -compression &lt;arg&gt;           Compression type, one of [LZO, GZ, NONE, SNAPPY,
                              LZ4]
 -data_block_encoding &lt;arg&gt;   Encoding algorithm (e.g. prefix compression) to
                              use for data blocks in the test column family, one
                              of [NONE, PREFIX, DIFF, FAST_DIFF, PREFIX_TREE].
 -encryption &lt;arg&gt;            Enables transparent encryption on the test table,
                              one of [AES]
 -generator &lt;arg&gt;             The class which generates load for the tool. Any
                              args for this class can be passed as colon
                              separated after class name
 -h,--help                    Show usage
 -in_memory                   Tries to keep the HFiles of the CF inmemory as far
                              as possible.  Not guaranteed that reads are always
                              served from inmemory
 -init_only                   Initialize the test table only, don't do any
                              loading
 -key_window &lt;arg&gt;            The 'key window' to maintain between reads and
                              writes for concurrent write/read workload. The
                              default is 0.
 -max_read_errors &lt;arg&gt;       The maximum number of read errors to tolerate
                              before terminating all reader threads. The default
                              is 10.
 -multiput                    Whether to use multi-puts as opposed to separate
                              puts for every column in a row
 -num_keys &lt;arg&gt;              The number of keys to read/write
 -num_tables &lt;arg&gt;            A positive integer number. When a number n is
                              speicfied, load test tool  will load n table
                              parallely. -tn parameter value becomes table name
                              prefix. Each table name is in format
                              &lt;tn&gt;_1...&lt;tn&gt;_n
 -read &lt;arg&gt;                  &lt;verify_percent&gt;[:&lt;#threads=20&gt;]
 -regions_per_server &lt;arg&gt;    A positive integer number. When a number n is
                              specified, load test tool will create the test
                              table with n regions per server
 -skip_init                   Skip the initialization; assume test table already
                              exists
 -start_key &lt;arg&gt;             The first key to read/write (a 0-based index). The
                              default value is 0.
 -tn &lt;arg&gt;                    The name of the table to read or write
 -update &lt;arg&gt;                &lt;update_percent&gt;[:&lt;#threads=20&gt;][:&lt;#whether to
                              ignore nonce collisions=0&gt;]
 -write &lt;arg&gt;                 &lt;avg_cols_per_key&gt;:&lt;avg_data_size&gt;[:&lt;#threads=20&gt;]
 -zk &lt;arg&gt;                    ZK quorum as comma-separated host names without
                              port numbers
 -zk_root &lt;arg&gt;               name of parent znode in zookeeper</pre>
</div>
</div>
</div>
</div>
<div class="exampleblock">
<div class="title">例子55。LoadTestTool的用法示例</div>
<div class="content">
<div class="listingblock">
<div class="content">
<pre>$ hbase org.apache.hadoop.hbase.util.LoadTestTool -write 1:10:100 -num_keys 1000000
          -read 100:30 -num_tables 1 -data_block_encoding NONE -tn load_test_tool_NONE</pre>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="data.block.encoding.enable"><a class="anchor" href="#data.block.encoding.enable"></a> 153。启用数据块编码</h2>
<div class="sectionbody">
<div class="paragraph">
<p>编解码器内置在HBase中，因此不需要额外的配置。通过设置<code>DATA_BLOCK_ENCODING</code>属性。在更改其DATA_BLOCK_ENCODING设置之前，请禁用该表。以下是使用HBase Shell的示例：</p>
</div>
<div class="exampleblock">
<div class="title">例子56。在表上启用数据块编码</div>
<div class="content">
<div class="listingblock">
<div class="content">
<pre>hbase&gt;  disable 'test'
hbase&gt; alter 'test', { NAME =&gt; 'cf', DATA_BLOCK_ENCODING =&gt; 'FAST_DIFF' }
Updating all regions with the new schema...
0/1 regions updated.
1/1 regions updated.
Done.
0 row(s) in 2.2820 seconds
hbase&gt; enable 'test'
0 row(s) in 0.1580 seconds</pre>
</div>
</div>
</div>
</div>
<div class="exampleblock">
<div class="title">例子57。验证ColumnFamily的数据块编码</div>
<div class="content">
<div class="listingblock">
<div class="content">
<pre>hbase&gt; describe 'test'
DESCRIPTION                                          ENABLED
 'test', {NAME =&gt; 'cf', DATA_BLOCK_ENCODING =&gt; 'FAST true
 _DIFF', BLOOMFILTER =&gt; 'ROW', REPLICATION_SCOPE =&gt;
 '0', VERSIONS =&gt; '1', COMPRESSION =&gt; 'GZ', MIN_VERS
 IONS =&gt; '0', TTL =&gt; 'FOREVER', KEEP_DELETED_CELLS =
 &gt; 'false', BLOCKSIZE =&gt; '65536', IN_MEMORY =&gt; 'fals
 e', BLOCKCACHE =&gt; 'true'}
1 row(s) in 0.0650 seconds</pre>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="sql"><a class="anchor" href="#sql"></a>附录F：基于HBase的SQL</h2>
<div class="sectionbody">
<div class="paragraph">
<p>以下项目为基于HBase的SQL提供了一些支持。</p>
</div>
<div class="sect2">
<h3 id="phoenix"><a class="anchor" href="#phoenix"></a> F.1。阿帕奇凤凰</h3>
<div class="paragraph">
<p><a href="http://phoenix.apache.org">阿帕奇凤凰</a></p>
</div>
</div>
<div class="sect2">
<h3 id="_trafodion"><a class="anchor" href="#_trafodion"></a> F.2。Trafodion</h3>
<div class="paragraph">
<p><a href="https://wiki.trafodion.org/">Trafodion：基于HBase的事务处理SQL</a></p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_ycsb"><a class="anchor" href="#_ycsb"></a>附录G：YCSB</h2>
<div class="sectionbody">
<div class="paragraph">
<p><a href="https://github.com/brianfrankcooper/YCSB/">YCSB：Yahoo!云服务基准</a>和HBase</p>
</div>
<div class="paragraph">
<p>待办事项：描述YCSB在建立适当的群集负载方面的表现如何。</p>
</div>
<div class="paragraph">
<p>待办事项：描述用于HBase的YCSB的设置。特别是，在开始运行之前，请预先分割表格。有关原因，请参见<a href="https://issues.apache.org/jira/browse/HBASE-4163">HBASE-4163为YCSB基准创建拆分策略，</a>以及有关如何执行的一些shell命令。</p>
</div>
<div class="paragraph">
<p>Ted Dunning重做了YCSB，因此对它进行了修饰并增加了用于验证工作负载的工具。参见<a href="https://github.com/tdunning/YCSB">Ted Dunning的YCSB</a> 。</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_hfile_format_2"><a class="anchor" href="#_hfile_format_2"></a>附录H：HFile格式</h2>
<div class="sectionbody">
<div class="paragraph">
<p>本附录描述了HFile格式的演变。</p>
</div>
<div class="sect2">
<h3 id="hfilev1"><a class="anchor" href="#hfilev1"></a> H.1。HBase文件格式（版本1）</h3>
<div class="paragraph">
<p>当我们将讨论对HFile格式的更改时，简要概述原始（HFile版本1）格式非常有用。</p>
</div>
<div class="sect3">
<h4 id="hfilev1.overview"><a class="anchor" href="#hfilev1.overview"></a> H.1.1。版本1概述</h4>
<div class="paragraph">
<p>版本1格式的HFile的结构如下：</p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/hfile.png" alt="HFile版本1">
</div>
<div class="title">图14。HFile V1格式</div>
</div>
</div>
<div class="sect3">
<h4 id="_block_index_format_in_version_1"><a class="anchor" href="#_block_index_format_in_version_1"></a> H.1.2。版本1中的块索引格式</h4>
<div class="paragraph">
<p>版本1中的块索引非常简单。对于每个条目，它包含：</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>偏移量（长）</p>
</li>
<li>
<p>未压缩大小（整数）</p>
</li>
<li>
<p>密钥（使用Bytes.writeByteArray编写的序列化字节数组）</p>
<div class="olist loweralpha">
<ol class="loweralpha" type="a">
<li>
<p>密钥长度为可变长度整数（VInt）</p>
</li>
<li>
<p>关键字节</p>
</li>
</ol>
</div>
</li>
</ol>
</div>
<div class="paragraph">
<p>块索引中的条目数存储在固定文件尾部中，并且必须传递给读取块索引的方法。版本1中的块索引的局限性之一是它不提供块的压缩大小，这对于解压缩是必需的。因此，HFile阅读器必须根据块之间的偏移量来推断此压缩大小。我们在版本2中修复了此限制，该版本存储磁盘上的块大小而不是未压缩大小，并从块头获取未压缩大小。</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="hfilev2"><a class="anchor" href="#hfilev2"></a> H.2。具有内联块的HBase文件格式（版本2）</h3>
<div class="paragraph">
<p>注意：此功能是HBase 0.92中引入的</p>
</div>
<div class="sect3">
<h4 id="_motivation"><a class="anchor" href="#_motivation"></a> H.2.1。动机</h4>
<div class="paragraph">
<p>我们发现有必要在由于区域服务器中的大型Bloom筛选器和块索引导致内存使用率高且启动时间慢之后，修改HFile格式。每个HFile，Bloom筛选器的大小可以达到100 MB，在20个区域内聚合时总计为2 GB。在同一组区域中，块索引的总大小可以增长到6 GB。直到区域的所有块索引数据都已加载，该区域才被视为已打开。大型Bloom过滤器会产生不同的性能问题：需要进行Bloom过滤器查找的第一个get请求将导致加载整个Bloom过滤器位阵列的延迟。</p>
</div>
<div class="paragraph">
<p>为了加快区域服务器的启动速度，我们将Bloom过滤器和块索引分成多个块，并在块填满时将其写出，这也减少了HFile writer的内存占用。在布隆过滤器的情况下，“填满一个块”意味着积累足够的键以有效地利用固定大小的位数组，而在块索引的情况下，我们积累所需大小的“索引块”。Bloom过滤器块和索引块（我们称为“内联块”）散布在数据块中，并且副作用是，我们不再像版本1中那样依靠块偏移量之间的差异来确定数据块长度。 。</p>
</div>
<div class="paragraph">
<p>HFile在设计上是一种低级文件格式，它不应处理特定于应用程序的细节，例如在StoreFile级别处理的Bloom过滤器。因此，我们将HFile中的Bloom过滤器块称为“内联”块。我们还为HFile提供了编写这些内联块的接口。</p>
</div>
<div class="paragraph">
<p>旨在减少区域服务器启动时间的另一种格式修改是使用连续的“打开时加载”部分，该部分必须在打开HFile时加载到内存中。当前，当HFile打开时，有单独的查找操作来读取预告片，数据/元索引和文件信息。要读取布隆过滤器，还有另外两个针对其“数据”和“元”部分的查找操作。在版本2中，我们寻求一次读取预告片，然后再次寻求读取从连续块中打开文件所需的所有其他内容。</p>
</div>
</div>
<div class="sect3">
<h4 id="hfilev2.overview"><a class="anchor" href="#hfilev2.overview"></a> H.2.2。版本2概述</h4>
<div class="paragraph">
<p>引入了上述功能的HBase版本同时读取版本1和2 HFile，但仅写入版本2 HFile。版本2 HFile的结构如下：</p>
</div>
<div class="paragraph">
<div class="title">HFile版本2结构</div>
<p><span class="image"><img src="images/hfilev2.png" alt="HFile版本2"></span></p>
</div>
</div>
<div class="sect3">
<h4 id="_unified_version_2_block_format"><a class="anchor" href="#_unified_version_2_block_format"></a> H.2.3。统一版本2块格式</h4>
<div class="paragraph">
<p>在版本2中，数据部分中的每个块都包含以下字段：</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>8个字节：块类型，等同于版本1的“魔术记录”的字节序列。支持的块类型为：</p>
<div class="olist loweralpha">
<ol class="loweralpha" type="a">
<li>
<p>DATA –数据块</p>
</li>
<li>
<p>LEAF_INDEX –多级块索引中的叶级索引块</p>
</li>
<li>
<p>BLOOM_CHUNK –布隆过滤块</p>
</li>
<li>
<p>META –元块（不再用于版本2中的Bloom过滤器）</p>
</li>
<li>
<p>INTERMEDIATE_INDEX –多级块索引中的中级索引块</p>
</li>
<li>
<p>ROOT_INDEX –多级块索引中的根级索引块</p>
</li>
<li>
<p>FILE_INFO –“文件信息”块，一个小键>元数据值映射</p>
</li>
<li>
<p>BLOOM_META –加载>打开>打开部分中的布隆过滤器元数据块</p>
</li>
<li>
<p>挂车–固定尺寸的文件挂车。与上述相反，这不是HFile v2块，而是固定大小（对于每个HFile版本）的数据结构</p>
</li>
<li>
<p>INDEX_V1 –此块类型仅用于旧版HFile v1块</p>
</li>
</ol>
</div>
</li>
<li>
<p>块数据的压缩大小，不包括标题（int）。</p>
<div class="paragraph">
<p>可用于在扫描HFile数据时跳过当前数据块。</p>
</div>
</li>
<li>
<p>块数据的未压缩大小，不包括标题（int）</p>
<div class="paragraph">
<p>如果压缩算法为NONE，则等于压缩后的大小</p>
</div>
</li>
<li>
<p>相同类型的前一个块的文件偏移量（长）</p>
<div class="paragraph">
<p>可用于查找上一个数据/索引块</p>
</div>
</li>
<li>
<p>压缩数据（如果压缩算法为NONE，则为未压缩数据）。</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>以下HFile节中使用了以上块的格式：</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">扫描块部分</dt>
<dd>
<p>该部分的名称之所以如此，是因为它包含顺序扫描HFile时需要读取的所有数据块。还包含叶子块索引和Bloom块块。</p>
</dd>
<dt class="hdlist1">非扫描区</dt>
<dd>
<p>本节仍包含统一格式的v2块，但在进行顺序扫描时不必读取它。本节包含“元”块和中间级索引块。</p>
</dd>
</dl>
</div>
<div class="paragraph">
<p>我们在版本2中支持“元”块的方式与版本1中所支持的方式相同，即使我们不再在这些块中存储Bloom过滤器数据也是如此。</p>
</div>
</div>
<div class="sect3">
<h4 id="_block_index_in_version_2"><a class="anchor" href="#_block_index_in_version_2"></a> H.2.4。版本2中的块索引</h4>
<div class="paragraph">
<p>HFile版本2中存在三种类型的块索引，以两种不同的格式（root和non-root）存储：</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>数据索引-版本2多级块索引，包括：</p>
<div class="olist loweralpha">
<ol class="loweralpha" type="a">
<li>
<p>版本2根索引，存储在文件的数据块索引部分</p>
</li>
<li>
<p>可选地，版本2中间级别以非％root格式存储在文件的数据索引部分中。如果存在叶级块，则只能存在中间级</p>
</li>
<li>
<p>（可选）版本2叶子级别，以非％root格式存储在数据块中</p>
</li>
</ol>
</div>
</li>
<li>
<p>元索引-仅版本2根索引格式，存储在文件的元索引部分中</p>
</li>
<li>
<p>Bloom索引-仅版本2根索引格式，作为Bloom过滤器元数据的一部分存储在“打开时加载”部分中。</p>
</li>
</ol>
</div>
</div>
<div class="sect3">
<h4 id="_root_block_index_format_in_version_2"><a class="anchor" href="#_root_block_index_format_in_version_2"></a> H.2.5。版本2中的根块索引格式</h4>
<div class="paragraph">
<p>此格式适用于：</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>版本2数据索引的根级别</p>
</li>
<li>
<p>版本2中的整个meta和Bloom索引始终是单级的。</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>版本2根索引块是具有以下格式的条目序列，类似于版本1块索引的条目，但存储磁盘大小而不是未压缩大小。</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>偏移量（长）</p>
<div class="paragraph">
<p>此偏移量可能指向数据块或更深层次的索引块。</p>
</div>
</li>
<li>
<p>磁盘大小（整数）</p>
</li>
<li>
<p>密钥（使用Bytes.writeByteArray存储的序列化字节数组）</p>
</li>
<li>
<p>密钥（VInt）</p>
</li>
<li>
<p>关键字节</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>单级版本2块索引仅包含一个根索引块。要读取版本2的根索引块，需要知道条目数。对于数据索引和元索引，条目数存储在预告片中，对于Bloom索引，其条目存储在复合Bloom过滤器元数据中。</p>
</div>
<div class="paragraph">
<p>对于多级块索引，除了上述数据结构之外，我们还将以下字段存储在HFile的“打开时加载”部分的根索引块中：</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>中叶索引块偏移</p>
</li>
<li>
<p>中间叶子块的磁盘大小（意味着叶子索引块包含对文件的``中间''数据块的引用）</p>
</li>
<li>
<p>中间叶级块中的中间键（在下面定义）的索引。</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>这些附加字段用于有效地检索HFile拆分中使用的HFile的中键，我们将其定义为块的第一个键，如果索引总数为（n – 1）/ 2，则从零开始。 HFile中的块为n。此定义与HFile版本1中确定中键的方式一致，并且通常是合理的，因为块的平均大小可能相同，但是我们对单个键/值对的大小没有任何估计。</p>
</div>
<div class="paragraph">
<p>编写版本2 HFile时，将跟踪每个叶级索引块指向的数据块总数。当我们完成写操作并确定了叶级块的总数时，很明显，哪个叶级块包含中键，并且上面列出的字段已计算出来。当读取HFile并请求中间键时，我们检索中间叶子索引块（可能从块缓存中获取），并从该叶子块内的适当位置获取中间键值。</p>
</div>
</div>
<div class="sect3">
<h4 id="_non_root_block_index_format_in_version_2"><a class="anchor" href="#_non_root_block_index_format_in_version_2"></a> H.2.6。版本2中的非根块索引格式</h4>
<div class="paragraph">
<p>此格式适用于版本2多级数据块索引的中间级和叶索引块。每个非根索引块的结构如下。</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>numEntries：条目数（整数）。</p>
</li>
<li>
<p>entryOffsets： <code>secondary index'' of offsets of entries in the block, to facilitate a quick binary search on the key (numEntries + 1 int values). The last value is the total length of all entries in this index block. For example, in a non-root index block with entry sizes 60, 80, 50 the</code> secondary index''将包含以下int数组：{0，60，140，190}。</p>
</li>
<li>
<p>参赛作品。每个条目包含：</p>
</li>
<li>
<p>文件中此条目引用的块的偏移量（长）</p>
</li>
<li>
<p>On>所引用块的磁盘大小（整数）</p>
</li>
<li>
<p>键。可以从entryOffsets计算长度。</p>
</li>
</ol>
</div>
</div>
<div class="sect3">
<h4 id="_bloom_filters_in_version_2"><a class="anchor" href="#_bloom_filters_in_version_2"></a> H.2.7。版本2中的Bloom过滤器</h4>
<div class="paragraph">
<p>与版本1相比，在版本2中，HFile Bloom筛选器元数据存储在HFile的“打开时加载”部分中，以便快速启动。</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>复合布隆过滤器。</p>
</li>
<li>
<p>布隆过滤器版本= 3（int）。过去曾经有一个DynamicByteBloomFilter类，其布隆过滤器版本号为2</p>
</li>
<li>
<p>所有复合Bloom过滤器块的总字节大小（长）</p>
</li>
<li>
<p>哈希函数数（整数</p>
</li>
<li>
<p>哈希函数的类型（整数）</p>
</li>
<li>
<p>插入到布隆过滤器中的总键数（长）</p>
</li>
<li>
<p>布隆过滤器中的最大键总数（长）</p>
</li>
<li>
<p>块数（整数）</p>
</li>
<li>
<p>用于布隆过滤器键的比较器类，使用Bytes.writeByteArray存储的UTF> 8编码字符串</p>
</li>
<li>
<p>版本2根块索引格式的Bloom块索引</p>
</li>
</ol>
</div>
</div>
<div class="sect3">
<h4 id="_file_info_format_in_versions_1_and_2"><a class="anchor" href="#_file_info_format_in_versions_1_and_2"></a> H.2.8。版本1和2中的文件信息格式</h4>
<div class="paragraph">
<p>文件信息块是一个序列化的<a href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/io/HbaseMapWritable.html">HbaseMapWritable</a> （本质上是一个从字节数组到字节数组的映射），带有以下键。StoreFile级别的逻辑为此添加了更多密钥。</p>
</div>
<table class="tableblock frame-all grid-all spread">
<colgroup>
<col style="width:50%">
<col style="width:50%">
</colgroup>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">hfile。LASTKEY</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">文件的最后一个键（字节数组）</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">hfile。AVG_KEY_LEN</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">文件中的平均密钥长度（整数）</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">hfile。AVG_VALUE_LEN</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">文件中的平均值长度（整数）</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p>文件信息格式在版本2中未更改。但是，我们将文件信息移到了文件的最后部分，可以在打开HFile时将其作为一个块加载。另外，我们不再将比较器存储在版本2文件信息中。相反，我们将其存储在固定文件预告片中。这是因为在解析HFile的“打开时加载”部分时，我们需要了解比较器。</p>
</div>
</div>
<div class="sect3">
<h4 id="_fixed_file_trailer_format_differences_between_versions_1_and_2"><a class="anchor" href="#_fixed_file_trailer_format_differences_between_versions_1_and_2"></a> H.2.9。版本1和版本2之间的固定文件尾随格式差异</h4>
<div class="paragraph">
<p>下表显示了版本1和版本2中固定文件预告片之间的公共字段和不同字段。请注意，拖车的大小因版本而异，因此仅在一个版本中被``固定''。但是，版本始终存储为文件中的最后四个字节的整数。</p>
</div>
<table class="tableblock frame-all grid-all spread">
<caption class="title">表13。HFile版本1和2之间的区别</caption>
<colgroup>
<col style="width:50%">
<col style="width:50%">
</colgroup>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">版本1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">版本2</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">文件信息偏移量（长）</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">数据索引偏移量（长）</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">loadOnOpenOffset（长整数）/打开文件时需要加载的节的偏移量。/</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">数据索引条目数（整数）</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">metaIndexOffset（长整数）/版本1读取器未使用此字段，因此我们从版本2中将其删除。/</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">uncompressedDataIndexSize（long）/整个数据块索引的总未压缩大小，包括根级别，中间级别和叶级别的块。/</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">元索引条目数（整数）</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">未压缩字节总数（长）</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">numEntries（int）</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">numEntries（长）</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">压缩编解码器：0 = LZO，1 = GZ，2 = NONE（int）</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">压缩编解码器：0 = LZO，1 = GZ，2 = NONE（int）</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">数据块索引中的级别数（整数）</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">firstDataBlockOffset（长整数）/第一个第一个数据块的偏移量。扫描时使用。/</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">lastDataBlockEnd（long）/最后一个键/值数据块之后的第一个字节的偏移量。扫描时，我们不需要超出此偏移量。/</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">版本：1（int）</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">版本：2（int）</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect3">
<h4 id="_getshortmidpointkey_an_optimization_for_data_index_block"><a class="anchor" href="#_getshortmidpointkey_an_optimization_for_data_index_block"></a> H.2.10。 getShortMidpointKey（数据索引块的优化）</h4>
<div class="paragraph">
<p>注意：此优化是在HBase 0.95+中引入的</p>
</div>
<div class="paragraph">
<p>HFiles包含许多块，这些块包含一系列已排序的单元格。每个单元都有一个密钥。为了节省读取单元时的IO，HFile还具有一个索引，该索引将单元的开始键映射到特定块开始的偏移量。在此优化之前，HBase将使用每个数据块中第一个单元格的密钥作为索引密钥。</p>
</div>
<div class="paragraph">
<p>在HBASE-7845中，我们生成一个新密钥，该密钥在字典上大于上一个块的最后一个密钥，而在字典上等于或小于当前块的开始密钥。尽管实际密钥可能很长，但此“伪密钥”或“虚拟密钥”可能要短得多。例如，如果前一个块的停止键是“ the quick brown fox”，当前块的开始键是“ the who”，则可以在我们的hfile索引中使用“ r”作为虚拟键。</p>
</div>
<div class="paragraph">
<p>这有两个好处：</p>
</div>
<div class="ulist">
<ul>
<li>
<p>拥有较短的键可以减少hfile索引的大小，（从而使我们可以在内存中保留更多的索引），并且</p>
</li>
<li>
<p>当目标密钥位于“虚拟密钥”和目标模块中第一个元素的密钥之间时，使用更接近上一个块的结束密钥的内容可以避免潜在的额外IO。</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>这种优化（由getShortMidpointKey方法实现）受到LevelDB的ByteWiseComparatorImpl :: FindShortestSeparator（）和FindShortSuccessor（）的启发。</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="hfilev3"><a class="anchor" href="#hfilev3"></a> H.3。具有安全性增强功能的HBase文件格式（版本3）</h3>
<div class="paragraph">
<p>注意：此功能是在HBase 0.98中引入的</p>
</div>
<div class="sect3">
<h4 id="hfilev3.motivation"><a class="anchor" href="#hfilev3.motivation"></a> H.3.1。动机</h4>
<div class="paragraph">
<p>HFile的版本3进行了一些更改，以简化静态加密和单元级元数据的管理（而单元级ACL和单元级可见性标签则需要进行更改）。有关更多信息，请参见<a href="#hbase.encryption.server">hbase.encryption.server</a> ， <a href="#hbase.tags">hbase.tags</a> ， <a href="#hbase.accesscontrol.configuration">hbase.accesscontrol.configuration</a>和<a href="#hbase.visibility.labels">hbase.visibility.labels</a> 。</p>
</div>
</div>
<div class="sect3">
<h4 id="hfilev3.overview"><a class="anchor" href="#hfilev3.overview"></a> H.3.2。总览</h4>
<div class="paragraph">
<p>引入了上述功能的HBase版本读取版本1、2和3中的HFile，但仅写入版本3 HFiles。第3版HFile的结构与第2版HFile相同。有关更多信息，请参见<a href="#hfilev2.overview">hfilev2.overview</a> 。</p>
</div>
</div>
<div class="sect3">
<h4 id="hvilev3.infoblock"><a class="anchor" href="#hvilev3.infoblock"></a> H.3.3。版本3中的文件信息块</h4>
<div class="paragraph">
<p>版本3向文件信息块中的保留键添加了另外两个信息。</p>
</div>
<table class="tableblock frame-all grid-all spread">
<colgroup>
<col style="width:50%">
<col style="width:50%">
</colgroup>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">hfile。MAX_TAGS_LEN</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">在此hfile中为任何单个单元格存储序列化标签所需的最大字节数（int）</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">hfile。TAGS_COMPRESSED</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">此hfile的块编码器是否压缩标签？（布尔值）。仅在hfile时存在。还存在MAX_TAGS_LEN。</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p>读取版本3 HFile时<code>MAX_TAGS_LEN</code>用于确定如何反序列化数据块中的单元。因此，使用者必须先读取文件的信息块，然后再读取任何数据块。</p>
</div>
<div class="paragraph">
<p>编写第3版HFile时，将memstore刷新到底层文件系统以及对数据块使用前缀树编码时，HBase将始终包含MAX_TAGS_LEN，如<a href="#compression">Compression中所述</a> 。</p>
</div>
<div class="paragraph">
<p>压缩现有文件时，默认编写器将省略<code>MAX_TAGS_LEN</code>如果所有选择的文件本身都不包含带有标签的单元格。</p>
</div>
<div class="paragraph">
<p>有关<a href="#compaction">压缩</a>文件选择算法的详细信息，请参见<a href="#compaction">压缩</a> 。</p>
</div>
</div>
<div class="sect3">
<h4 id="hfilev3.datablock"><a class="anchor" href="#hfilev3.datablock"></a> H.3.4。版本3中的数据块</h4>
<div class="paragraph">
<p>在HFile中，HBase单元作为<a href="#hfilev1.overview">键值</a>序列存储在数据块中（请参阅<a href="#hfilev1.overview">hfilev1.overview</a>或<a href="http://www.larsgeorge.com/2009/10/hbase-architecture-101-storage.html">Lars George对HBase Storage的出色介绍</a> ）。在版本3中，这些KeyValue可选地将包含一组0个或更多标记：</p>
</div>
<table class="tableblock frame-all grid-all spread">
<colgroup>
<col style="width:50%">
<col style="width:50%">
</colgroup>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">版本1和2，版本3，不含MAX_TAGS_LEN</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">第3版，带有MAX_TAGS_LEN</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top" colspan="2"><p class="tableblock">密钥长度（4个字节）</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top" colspan="2"><p class="tableblock">值长度（4个字节）</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top" colspan="2"><p class="tableblock">关键字节（可变）</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top" colspan="2"><p class="tableblock">值字节（可变）</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">标签长度（2个字节）</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">标签字节（可变）</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p>如果给定HFile的信息块包含以下项<code>MAX_TAGS_LEN</code>每个单元格都会包含该单元格标签的长度，即使该长度为零也是如此。实际标签按标签长度（2个字节），标签类型（1个字节），标签字节（可变）的顺序存储。单个标签字节的格式取决于标签类型。</p>
</div>
<div class="paragraph">
<p>请注意，对信息块内容的依赖意味着在读取任何数据块之前，您必须首先处理文件的信息块。这也意味着在写入数据块之前，您必须知道文件的信息块是否包含<code>MAX_TAGS_LEN</code> 。</p>
</div>
</div>
<div class="sect3">
<h4 id="hfilev3.fixedtrailer"><a class="anchor" href="#hfilev3.fixedtrailer"></a> H.3.5。版本3中的固定文件预告片</h4>
<div class="paragraph">
<p>用HFile版本3编写的固定文件预告片始终使用协议缓冲区进行序列化。此外，它向版本2的协议缓冲区（称为加密密钥）添加了一个可选字段。如果将HBase配置为加密HFile，则此字段将存储此特定HFile的数据加密密钥，并使用AES使用当前群集主密钥进行加密。有关更多信息，请参见<a href="#hbase.encryption.server">hbase.encryption.server</a> 。</p>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="other.info"><a class="anchor" href="#other.info"></a>附录一：有关HBase的其他信息</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="other.info.videos"><a class="anchor" href="#other.info.videos"></a> I.1。HBase视频</h3>
<div class="ulist">
<div class="title">HBase简介</div>
<ul>
<li>
<p>Todd Lipcon撰写的<a href="http://www.cloudera.com/content/cloudera/en/resources/library/presentation/chicago_data_summit_apache_hbase_an_introduction_todd_lipcon.html">HBase简介</a> （2011年芝加哥数据峰会）。</p>
</li>
<li>
<p>Todd Lipcon撰写的<a href="http://www.cloudera.com/videos/intorduction-hbase-todd-lipcon">HBase简介</a> （2010年）。
乔纳森·格雷（Jonathan Gray） <a href="http://www.cloudera.com/videos/hadoop-world-2011-presentation-video-building-realtime-big-data-services-at-facebook-with-hadoop-and-hbase">通过HBase在Facebook上构建实时服务</a> （Hadoop World 2011）。</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><a href="http://www.cloudera.com/videos/hw10_video_how_stumbleupon_built_and_advertising_platform_using_hbase_and_hadoop">HBase和Hadoop，</a>由JD Cryans <a href="http://www.cloudera.com/videos/hw10_video_how_stumbleupon_built_and_advertising_platform_using_hbase_and_hadoop">在StumbleUpon上混合实时处理和批处理</a> （Hadoop World 2010）。</p>
</div>
</div>
<div class="sect2">
<h3 id="other.info.pres"><a class="anchor" href="#other.info.pres"></a> I.2。HBase演示文稿（幻灯片）</h3>
<div class="paragraph">
<p>Lars George的<a href="http://www.cloudera.com/content/cloudera/en/resources/library/hadoopworld/hadoop-world-2011-presentation-video-advanced-hbase-schema-design.html">高级HBase Schema设计</a> （Hadoop World，2011年）。</p>
</div>
<div class="paragraph">
<p>Todd Lipcon撰写的<a href="http://www.slideshare.net/cloudera/chicago-data-summit-apache-hbase-an-introduction">HBase简介</a> （2011年芝加哥数据峰会）。</p>
</div>
<div class="paragraph">
<p><a href="http://www.slideshare.net/cloudera/hw09-practical-h-base-getting-the-most-from-your-h-base-install">充分利用HBase安装带来</a>的最大收益，作者：Ryan Rawson，Jonathan Gray（Hadoop世界，2009年）。</p>
</div>
</div>
<div class="sect2">
<h3 id="other.info.papers"><a class="anchor" href="#other.info.papers"></a> I.3。HBase论文</h3>
<div class="paragraph">
<p>Google的<a href="http://research.google.com/archive/bigtable.html">BigTable</a> （2006）。</p>
</div>
<div class="paragraph">
<p><a href="http://www.larsgeorge.com/2010/05/hbase-file-locality-in-hdfs.html">HBase和HDFS局部性</a> ，作者：Lars George（2010）。</p>
</div>
<div class="paragraph">
<p><a href="http://ianvarley.com/UT/MR/Varley_MastersReport_Full_2009-08-07.pdf">没有关系：</a> Ian Varley（2009） <a href="http://ianvarley.com/UT/MR/Varley_MastersReport_Full_2009-08-07.pdf">的非关系数据库</a>喜忧参半。</p>
</div>
</div>
<div class="sect2">
<h3 id="other.info.sites"><a class="anchor" href="#other.info.sites"></a> I.4。HBase站点</h3>
<div class="paragraph">
<p><a href="http://www.cloudera.com/blog/category/hbase/">Cloudera的HBase博客</a>具有许多指向有用的HBase信息的链接。</p>
</div>
<div class="ulist">
<ul>
<li>
<p><a href="http://www.cloudera.com/blog/2010/04/cap-confusion-problems-with-partition-tolerance/">CAP Confusion</a>是有关分布式存储系统背景信息的相关条目。</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><a href="http://wiki.apache.org/hadoop/HBase/HBasePresentations">HBase Wiki</a>的页面上有许多演示文稿。</p>
</div>
<div class="paragraph">
<p>来自DZone的<a href="http://refcardz.dzone.com/refcardz/hbase">HBase RefCard</a> 。</p>
</div>
</div>
<div class="sect2">
<h3 id="other.info.books"><a class="anchor" href="#other.info.books"></a> I.5。HBase书</h3>
<div class="paragraph">
<p><a href="http://shop.oreilly.com/product/0636920014348.do">HBase：</a> Lars George <a href="http://shop.oreilly.com/product/0636920014348.do">的权威指南</a> 。</p>
</div>
</div>
<div class="sect2">
<h3 id="other.info.books.hadoop"><a class="anchor" href="#other.info.books.hadoop"></a> I.6。Hadoop书籍</h3>
<div class="paragraph">
<p><a href="http://shop.oreilly.com/product/9780596521981.do">Hadoop：</a> Tom White <a href="http://shop.oreilly.com/product/9780596521981.do">的权威指南</a> 。</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="hbase.history"><a class="anchor" href="#hbase.history"></a>附录J：HBase历史</h2>
<div class="sectionbody">
<div class="ulist">
<ul>
<li>
<p>2006年：Google发表<a href="http://research.google.com/archive/bigtable.html">BigTable</a>论文。</p>
</li>
<li>
<p>2006年（年底）：HBase开发开始。</p>
</li>
<li>
<p>2008年：HBase成为Hadoop子项目。</p>
</li>
<li>
<p>2010年：HBase成为Apache顶级项目。</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect1">
<h2 id="asf"><a class="anchor" href="#asf"></a>附录K：HBase和Apache软件基金会</h2>
<div class="sectionbody">
<div class="paragraph">
<p>HBase是Apache Software Foundation中的一个项目，因此ASF有责任确保项目正常运行。</p>
</div>
<div class="sect2">
<h3 id="asf.devprocess"><a class="anchor" href="#asf.devprocess"></a> K.1。ASF开发流程</h3>
<div class="paragraph">
<p>有关ASF的结构（例如PMC，提交者，贡献者）的各种信息，有关贡献和参与的技巧以及ASF开源的工作方式，请参阅<a href="http://www.apache.org/dev/#committers">Apache开发过程页面</a> 。</p>
</div>
</div>
<div class="sect2">
<h3 id="asf.reporting"><a class="anchor" href="#asf.reporting"></a> K.2。ASF董事会报告</h3>
<div class="paragraph">
<p>每季度一次，ASF产品组合中的每个项目都会向ASF董事会提交报告。这是由HBase项目负责人和提交者完成的。有关更多信息，请参阅<a href="http://www.apache.org/foundation/board/reporting">ASF板报告</a> 。</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="orca"><a class="anchor" href="#orca"></a>附录L：Apache HBase Orca</h2>
<div class="sectionbody">
<div class="imageblock">
<div class="content">
<img src="images/jumping-orca_rotated_25percent.png" alt="跳跃的逆戟鲸旋转25％">
</div>
<div class="title">图15。Apache HBase Orca</div>
</div>
<div class="paragraph">
<p><a href="https://issues.apache.org/jira/browse/HBASE-4920">Orca是Apache HBase的吉祥物。</a> 请参阅NOTICES.txt。我们在这里获得的Orca徽标： <a href="http://www.vectorfree.com/jumping-orca" class="bare">http</a> : <a href="http://www.vectorfree.com/jumping-orca" class="bare">//www.vectorfree.com/jumping-orca</a>它是经过许可的知识共享署名3.0。请参阅<a href="https://creativecommons.org/licenses/by/3.0/us/" class="bare">https://creativecommons.org/licenses/by/3.0/us/</a>我们通过剥离彩色背景，将其反转然后旋转一些来更改徽标。</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="tracing"><a class="anchor" href="#tracing"></a>附录M：在HBase中启用类似Dapper的跟踪</h2>
<div class="sectionbody">
<div class="paragraph">
<p><a href="https://issues.apache.org/jira/browse/HBASE-6449">HBASE-6449</a>添加了对使用开源跟踪库<a href="http://github.com/cloudera/htrace">HTrace</a>通过HBase跟踪请求的支持。设置跟踪非常简单，但是当前它需要对客户端代码进行一些非常小的更改（删除此要求并不是很困难）。</p>
</div>
<div class="sect2">
<h3 id="tracing.spanreceivers"><a class="anchor" href="#tracing.spanreceivers"></a> M.1。跨度接收器</h3>
<div class="paragraph">
<p>跟踪系统通过收集称为“跨度”的结构中的信息来工作。您可以自行决定通过实施<code>SpanReceiver</code>接口，它定义了一种方法：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="directive">public</span> <span class="type">void</span> receiveSpan(Span span);</code></pre>
</div>
</div>
<div class="paragraph">
<p>每当跨度完成时，此方法就用作回调。HTrace允许您使用任意数量的SpanReceiver，因此您可以轻松地将跟踪信息发送到多个目的地。</p>
</div>
<div class="paragraph">
<p>通过将实现的类的完全限定的类名放入逗号分隔的列表，配置您想要给我们的SpanReceivers <code>SpanReceiver</code>在<em>hbase-site.xml</em>属性中： <code>hbase.trace.spanreceiver.classes</code> 。</p>
</div>
<div class="paragraph">
<p>HTrace包含一个<code>LocalFileSpanReceiver</code>它将所有跨度信息以基于JSON的格式写入本地文件。的<code>LocalFileSpanReceiver</code>在<em>hbase-site.xml中</em>查找<code>hbase.local-file-span-receiver.path</code>属性，其值描述节点应向其写入跨度信息的文件名。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">&lt;property&gt;
  &lt;name&gt;hbase.trace.spanreceiver.classes&lt;/name&gt;
  &lt;value&gt;org.htrace.impl.LocalFileSpanReceiver&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
  &lt;name&gt;hbase.local-file-span-receiver.path&lt;/name&gt;
  &lt;value&gt;/var/log/hbase/htrace.out&lt;/value&gt;
&lt;/property&gt;</code></pre>
</div>
</div>
<div class="paragraph">
<p>HTrace还提供<code>ZipkinSpanReceiver</code>将span转换为<a href="http://github.com/twitter/zipkin">Zipkin</a> span格式并将其发送到Zipkin服务器。为了使用此span接收器，您需要在集群中所有节点上将htrace-zipkin的jar安装到HBase的类路径中。</p>
</div>
<div class="paragraph">
<p><em>htrace-zipkin</em>已发布到Maven中央存储库。您可以从那里获取最新版本，也可以只在本地构建它，然后将其复制到所有节点，更改配置以使用zipkin接收器，分发新配置，然后（滚动）重新启动。</p>
</div>
<div class="paragraph">
<p>这是手动设置过程的示例。</p>
</div>
<div class="listingblock">
<div class="content">
<pre>$ git clone https://github.com/cloudera/htrace
$ cd htrace/htrace-zipkin
$ mvn compile assembly:single
$ cp target/htrace-zipkin-*-jar-with-dependencies.jar $HBASE_HOME/lib/
  # copy jar to all nodes...</pre>
</div>
</div>
<div class="paragraph">
<p>的<code>ZipkinSpanReceiver</code>在<em>hbase-site.xml中</em>查找<code>hbase.zipkin.collector-hostname</code>和<code>hbase.zipkin.collector-port</code>属性，其值描述将跨度信息发送到的Zipkin收集器服务器。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="xml"><span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>hbase.trace.spanreceiver.classes<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>org.htrace.impl.ZipkinSpanReceiver<span class="tag">&lt;/value&gt;</span>
<span class="tag">&lt;/property&gt;</span>
<span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>hbase.zipkin.collector-hostname<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>localhost<span class="tag">&lt;/value&gt;</span>
<span class="tag">&lt;/property&gt;</span>
<span class="tag">&lt;property&gt;</span>
  <span class="tag">&lt;name&gt;</span>hbase.zipkin.collector-port<span class="tag">&lt;/name&gt;</span>
  <span class="tag">&lt;value&gt;</span>9410<span class="tag">&lt;/value&gt;</span>
<span class="tag">&lt;/property&gt;</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>如果您不想使用随附的跨度接收器，建议您编写自己的接收器（看看<code>LocalFileSpanReceiver</code>例如）。如果您认为其他人将从您的接收器中受益，请提交JIRA或向<a href="http://github.com/cloudera/htrace">HTrace</a>发送拉取请求。</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="tracing.client.modifications"><a class="anchor" href="#tracing.client.modifications"></a> 154。客户修改</h2>
<div class="sectionbody">
<div class="paragraph">
<p>为了打开您的客户端代码中的跟踪，您必须对每个客户端进程一次初始化将发送跨度发送到接收器的模块。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="directive">private</span> SpanReceiverHost spanReceiverHost;

...

  Configuration conf = HBaseConfiguration.create();
  SpanReceiverHost spanReceiverHost = SpanReceiverHost.getInstance(conf);</code></pre>
</div>
</div>
<div class="paragraph">
<p>然后，您可以简单地在您认为有趣的请求之前开始跟踪范围，并在完成请求后将其关闭。例如，如果要跟踪所有的get操作，则可以更改此操作：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="predefined-type">Configuration</span> config = HBaseConfiguration.create();
<span class="predefined-type">Connection</span> connection = ConnectionFactory.createConnection(config);
Table table = connection.getTable(TableName.valueOf(<span class="string"><span class="delimiter">&quot;</span><span class="content">t1</span><span class="delimiter">&quot;</span></span>));
Get get = <span class="keyword">new</span> Get(Bytes.toBytes(<span class="string"><span class="delimiter">&quot;</span><span class="content">r1</span><span class="delimiter">&quot;</span></span>));
<span class="predefined-type">Result</span> res = table.get(get);</code></pre>
</div>
</div>
<div class="paragraph">
<p>变成：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">TraceScope ts = Trace.startSpan(<span class="string"><span class="delimiter">&quot;</span><span class="content">Gets</span><span class="delimiter">&quot;</span></span>, Sampler.ALWAYS);
<span class="keyword">try</span> {
  Table table = connection.getTable(TableName.valueOf(<span class="string"><span class="delimiter">&quot;</span><span class="content">t1</span><span class="delimiter">&quot;</span></span>));
  Get get = <span class="keyword">new</span> Get(Bytes.toBytes(<span class="string"><span class="delimiter">&quot;</span><span class="content">r1</span><span class="delimiter">&quot;</span></span>));
  <span class="predefined-type">Result</span> res = table.get(get);
} <span class="keyword">finally</span> {
  ts.close();
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>如果您想跟踪一半的“获取”操作，则可以传入：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="keyword">new</span> ProbabilitySampler(<span class="float">0.5</span>)</code></pre>
</div>
</div>
<div class="paragraph">
<p>替代<code>Sampler.ALWAYS</code>至<code>Trace.startSpan()</code> 。有关采样器的更多信息，请参见HTrace <em>自述文件</em> 。</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="tracing.client.shell"><a class="anchor" href="#tracing.client.shell"></a> 155。从HBase Shell进行跟踪</h2>
<div class="sectionbody">
<div class="paragraph">
<p>您可以使用trace命令跟踪来自HBase Shell的请求。 trace'start'命令打开跟踪，trace'stop'命令关闭跟踪。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">hbase(main):<span class="octal">001</span>:<span class="integer">0</span>&gt; trace <span class="string"><span class="delimiter">'</span><span class="content">start</span><span class="delimiter">'</span></span>
hbase(main):<span class="octal">002</span>:<span class="integer">0</span>&gt; put <span class="string"><span class="delimiter">'</span><span class="content">test</span><span class="delimiter">'</span></span>, <span class="string"><span class="delimiter">'</span><span class="content">row1</span><span class="delimiter">'</span></span>, <span class="string"><span class="delimiter">'</span><span class="content">f:</span><span class="delimiter">'</span></span>, <span class="string"><span class="delimiter">'</span><span class="content">val1</span><span class="delimiter">'</span></span>   <span class="error">#</span> traced commands
hbase(main):<span class="octal">003</span>:<span class="integer">0</span>&gt; trace <span class="string"><span class="delimiter">'</span><span class="content">stop</span><span class="delimiter">'</span></span></code></pre>
</div>
</div>
<div class="paragraph">
<p>跟踪“开始”和跟踪“停止”始终返回布尔值，该布尔值表示是否正在进行跟踪。结果，跟踪“停止”在suceess上返回false。跟踪“状态”仅在跟踪是否打开的情况下返回。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">hbase(main):<span class="octal">001</span>:<span class="integer">0</span>&gt; trace <span class="string"><span class="delimiter">'</span><span class="content">start</span><span class="delimiter">'</span></span>
=&gt; <span class="predefined-constant">true</span>

hbase(main):<span class="octal">002</span>:<span class="integer">0</span>&gt; trace <span class="string"><span class="delimiter">'</span><span class="content">status</span><span class="delimiter">'</span></span>
=&gt; <span class="predefined-constant">true</span>

hbase(main):<span class="octal">003</span>:<span class="integer">0</span>&gt; trace <span class="string"><span class="delimiter">'</span><span class="content">stop</span><span class="delimiter">'</span></span>
=&gt; <span class="predefined-constant">false</span>

hbase(main):<span class="octal">004</span>:<span class="integer">0</span>&gt; trace <span class="string"><span class="delimiter">'</span><span class="content">status</span><span class="delimiter">'</span></span>
=&gt; <span class="predefined-constant">false</span></code></pre>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="hbase.rpc"><a class="anchor" href="#hbase.rpc"></a>附录N：0.95 RPC规范</h2>
<div class="sectionbody">
<div class="paragraph">
<p>在0.95，所有的客户机/服务器通信与做<a href="https://developers.google.com/protocol-buffers/">protobuf'ed</a>消息，而不是与<a href="http://hadoop.apache.org/docs/current/api/org/apache/hadoop/io/Writable.html">Hadoop的Writables</a> 。因此，我们的RPC连线格式会更改。本文档介绍了客户端/服务器请求/响应协议以及我们的新RPC有线格式。</p>
</div>
<div class="paragraph">
<p>有关0.94及<a href="https://github.com/OpenTSDB/asynchbase/blob/master/src/HBaseRpc.java#L164">更高版本中RPC的内容</a> ，请参阅Benoit / Tsuna的<a href="https://github.com/OpenTSDB/asynchbase/blob/master/src/HBaseRpc.java#L164">非官方Hadoop / HBase RPC协议文档</a> 。有关我们如何达到此规范的更多背景信息，请参见<a href="https://docs.google.com/document/d/1WCKwgaLDqBw2vpux0jPsAu2WPTRISob7HGCO8YhfDTA/edit#">HBase RPC：WIP。</a></p>
</div>
<div class="sect2">
<h3 id="_goals"><a class="anchor" href="#_goals"></a> N.1。目标</h3>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>我们可以发展的线格式</p>
</li>
<li>
<p>一种不需要我们重写服务器核心或从根本上更改其当前体系结构的格式（供以后使用）。</p>
</li>
</ol>
</div>
</div>
<div class="sect2">
<h3 id="_todo"><a class="anchor" href="#_todo"></a> N.2。去做</h3>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>当前指定格式的问题列表，以及我们希望在版本2中使用的问题等。例如，如果要移动服务器异步或支持流传输/分块操作，我们必须更改什么？</p>
</li>
<li>
<p>原理图</p>
</li>
<li>
<p>简要描述线格式的语法。目前，我们拥有这些单词以及rpc protobuf idl的内容，但是来回的语法将有助于rpc的发展。此外，在客户端/服务器交互上的一些状态机将有助于理解（并确保正确的实现）。</p>
</li>
</ol>
</div>
</div>
<div class="sect2">
<h3 id="_rpc"><a class="anchor" href="#_rpc"></a> N.3。RPC</h3>
<div class="paragraph">
<p>客户端将发送有关连接建立的设置信息。此后，客户端针对远程服务器调用发送protobuf消息并接收protobuf消息的方法。通信是同步的。所有来回前后都带有一个整数，该整数具有请求/响应的总长度。（可选）可以将Cells（KeyValues）传递到后面的Cell块中的protobuf之外（因为<a href="https://docs.google.com/document/d/1WEtrq-JTIUhlnlnvA0oYRLp0F8MKpEBeBSCFcQiacdw/edit#">我们不能protobuf兆字节的KeyValues</a>或Cells）。这些CellBlock被编码并可以选择压缩。</p>
</div>
<div class="paragraph">
<p>有关所涉及的protobuf的更多详细信息，请参阅主干中的<a href="http://svn.apache.org/viewvc/hbase/trunk/hbase-protocol/src/main/protobuf/RPC.proto?view=markup">RPC.proto</a>文件。</p>
</div>
<div class="sect3">
<h4 id="_connection_setup"><a class="anchor" href="#_connection_setup"></a> N.3.1。连接设置</h4>
<div class="paragraph">
<p>客户端启动连接。</p>
</div>
<div class="sect4">
<h5 id="_client"><a class="anchor" href="#_client"></a>客户</h5>
<div class="paragraph">
<p>在建立连接时，客户端发送一个前导，后跟一个连接头。</p>
</div>
<div class="listingblock">
<div class="title"><pre class="CodeRay highlight"><code data-lang="java">&lt;MAGIC <span class="integer">4</span> <span class="type">byte</span> integer&gt; &lt;<span class="integer">1</span> <span class="type">byte</span> RPC <span class="predefined-type">Format</span> Version&gt; &lt;<span class="integer">1</span> <span class="type">byte</span> auth type&gt;</code></pre>
</div>
</div>
<div class="paragraph">
<p>我们需要auth方法规范。如果启用了身份验证，则在此处对连接头进行编码。</p>
</div>
<div class="paragraph">
<p>例如：HBas0x000x50 — MAGIC的4个字节—“ HBas” —加上一个字节的版本（在这种情况下为0）和一个字节的0x50（简单）。身份验证类型。</p>
</div>
<div class="paragraph">
<div class="title"><protobuf connectionheader="" message=""></protobuf></div>
<p>具有用户信息和``协议''以及客户端将使用发送CellBlocks的编码器和压缩。CellBlock编码器和压缩机在连接寿命内。CellBlock编码器实现org.apache.hadoop.hbase.codec。编解码器。然后，也可以压缩CellBlocks。压缩器实现org.apache.hadoop.io.compress。CompressionCodec。该protobuf是使用writeDelimited编写的，因此以序列化长度的pb varint开头</p>
</div>
</div>
<div class="sect4">
<h5 id="_server"><a class="anchor" href="#_server"></a>服务器</h5>
<div class="paragraph">
<p>客户端发送前导码和连接头后，如果成功建立连接，服务器将不响应。没有响应表示服务器已准备就绪，可以接受请求并发出响应。如果序言中的版本或认证不一致，或者服务器在解析序言时遇到问题，它将抛出org.apache.hadoop.hbase.ipc。FatalConnectionException解释该错误，然后将断开连接。如果连接头中的客户端（即连接序言后的protobuf消息）请求服务器不支持的服务或服务器不提供的编解码器，则再次抛出FatalConnectionException及其解释。</p>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_request"><a class="anchor" href="#_request"></a> N.3.2。请求</h4>
<div class="paragraph">
<p>设置连接后，客户端发出请求。服务器响应。</p>
</div>
<div class="paragraph">
<p>一个请求由一个protobuf RequestHeader和一个protobuf Message参数组成。标头包含方法名称以及（可选）可能跟随的可选CellBlock上的元数据。参数类型适合被调用的方法：即，如果我们正在执行getRegionInfo请求，则protobuf Message参数将是GetRegionInfoRequest的实例。响应将是GetRegionInfoResponse。可以选择使用CellBlock传递大量RPC数据：即Cells / KeyValues。</p>
</div>
<div class="sect4">
<h5 id="_request_parts"><a class="anchor" href="#_request_parts"></a>索取零件</h5>
<div class="paragraph">
<div class="title"><total length=""></total></div>
<p>该请求以一个int开头，该int保持其后的总长度。</p>
</div>
<div class="paragraph">
<div class="title"><protobuf requestheader="" message=""></protobuf></div>
<p>接下来是Cell块IFF上的call.id，trace.id和方法名称等，包括可选的元数据。数据在此pb消息中进行了内联协议存储，或者可选地包含在以下CellBlock中</p>
</div>
<div class="paragraph">
<div class="title"><protobuf param="" message=""></protobuf></div>
<p>如果调用的方法是getRegionInfo，则如果您研究客户端到Regionserver协议的服务描述符，则会发现请求在此位置发送了GetRegionInfoRequest protobuf Message参数。</p>
</div>
<div class="paragraph">
<div class="title"><cellblock></cellblock></div>
<p>编码并可选压缩的Cell块。</p>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_response"><a class="anchor" href="#_response"></a> N.3.3。响应</h4>
<div class="paragraph">
<p>与请求相同，它是一个protobuf ResponseHeader，后跟一个protobuf Message响应，其中Message响应类型适合所调用的方法。大量数据可能来自随后的CellBlock。</p>
</div>
<div class="sect4">
<h5 id="_response_parts"><a class="anchor" href="#_response_parts"></a>反应部分</h5>
<div class="paragraph">
<div class="title"><total length=""></total></div>
<p>响应以一个int开头，该int保持其后的总长度。</p>
</div>
<div class="paragraph">
<div class="title"><protobuf responseheader="" message=""></protobuf></div>
<p>将具有call.id等。如果处理失败，则将包含异常。可选地，在可选的IFF上包括元数据，随后是一个CellBlock。</p>
</div>
<div class="paragraph">
<div class="title"><protobuf response="" message=""></protobuf></div>
<p>返回或如果异常则为空。如果调用的方法是getRegionInfo，则如果研究客户端到区域服务器协议的服务描述符，则会发现该响应在此位置发送了GetRegionInfoResponse protobuf Message参数。</p>
</div>
<div class="paragraph">
<div class="title"><cellblock></cellblock></div>
<p>编码并可选压缩的Cell块。</p>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_exceptions"><a class="anchor" href="#_exceptions"></a> N.3.4。例外情况</h4>
<div class="paragraph">
<p>有两种不同的类型。有一个失败的请求，该请求封装在响应的响应头中。连接保持打开状态以接收新请求。第二种类型FatalConnectionException终止连接。</p>
</div>
<div class="paragraph">
<p>异常可以携带额外的信息。请参阅ExceptionResponse protobuf类型。它具有一个标志，指示禁止重试以及其他各种有效负载，以帮助提高客户端的响应能力。</p>
</div>
</div>
<div class="sect3">
<h4 id="_cellblocks"><a class="anchor" href="#_cellblocks"></a> N.3.5。细胞块</h4>
<div class="paragraph">
<p>这些未版本化。服务器可以执行编解码器，或者不能执行编解码器。如果说新版本的编解码器具有更严格的编码，请给它一个新的类名。编解码器将一直存在于服务器上，以便旧客户端可以连接。</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_notes_2"><a class="anchor" href="#_notes_2"></a> N.4。笔记</h3>
<div class="paragraph">
<div class="title">约束条件</div>
<p>在某种程度上，当前的有线格式（即，所有请求和响应都以长度开头）是由当前服务器的非异步体系结构决定的。</p>
</div>
<div class="paragraph">
<div class="title">一个胖的PB请求或标头+参数</div>
<p>我们先用pb标头，然后是pb param发出请求，然后是pb标头，然后是pb响应。执行标头+参数，而不是包含标头和参数内容的单个protobuf消息：</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>更接近我们目前拥有的</p>
</li>
<li>
<p>拥有一个单一的脂肪铅需要额外的复制，以将已经铅的参数放入脂肪请求铅的主体中（并获得相同的结果）</p>
</li>
<li>
<p>阅读参数之前，我们可以决定是否接受请求。例如，请求的优先级可能较低。照原样，由于当前已实现服务器，因此我们一口气读取了header + param，所以这是一个TODO。</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>优点是次要的。如果以后，发请求有明显的优势，以后可以推出v2。</p>
</div>
<div class="sect3">
<h4 id="rpc.configs"><a class="anchor" href="#rpc.configs"></a> N.4.1。RPC配置</h4>
<div class="paragraph">
<div class="title">CellBlock编解码器</div>
<p>启用默认以外的编解码器<code>KeyValueCodec</code> ，设定<code>hbase.client.rpc.codec</code>到要使用的编解码器类的名称。编解码器必须实现hbase的<code>Codec</code>接口。建立连接后，所有通过的单元格块都将与此编解码器一起发送。只要编解码器位于服务器的CLASSPATH上，服务器就会使用相同的编解码器返回单元格块（否则您将获得<code>UnsupportedCellCodecException</code> ）。</p>
</div>
<div class="paragraph">
<p>要更改默认编解码器，请设置<code>hbase.client.default.rpc.codec</code> 。</p>
</div>
<div class="paragraph">
<p>要完全禁用单元块并使用纯protobuf，请将默认设置为空字符串，并且不要在配置中指定编解码器。所以，设定<code>hbase.client.default.rpc.codec</code>到空字符串并且不设置<code>hbase.client.rpc.codec</code> 。这将导致客户端在未指定编解码器的情况下连接到服务器。如果服务器看不到编解码器，它将以纯protobuf返回所有响应。始终运行纯protobuf会比使用cellblock慢。</p>
</div>
<div class="paragraph">
<div class="title">压缩</div>
<p>使用hadoops压缩编解码器。要启用对传递的CellBlocks的压缩，请设置<code>hbase.client.rpc.compressor</code>到要使用的Compressor的名称。Compressor必须实现Hadoop的CompressionCodec接口。建立连接后，所有通过的单元块将被压缩发送。只要压缩器在其CLASSPATH上，服务器将返回使用同一压缩器压缩的单元块（否则您将获得<code>UnsupportedCompressionCodecException</code> ）。</p>
</div>
</div>
</div>
</div>
</div>
</div>
<div id="footnotes">
<hr>
<div class="footnote" id="_footnote_1">
<a href="#_footnoteref_1">1</a> 。请参阅<a href="http://docs.oracle.com/javase/specs/jls/se7/html/jls-13.html" class="bare">http://docs.oracle.com/javase/specs/jls/se7/html/jls-13.html</a> 。</div>
<div class="footnote" id="_footnote_2">
<a href="#_footnoteref_2">2</a> 。请注意，这表示可能会破坏的东西，而不是会破坏的东西。我们将/应该在发行说明中添加细节。
</div>
<div class="footnote" id="_footnote_3">
<a href="#_footnoteref_3">3</a> 。 comp_matrix_offline_upgrade_note，可能需要运行没有回滚的离线升级工具。我们通常仅支持将数据从主要版本X迁移到主要版本X + 1。
</div>
<div class="footnote" id="_footnote_4">
<a href="#_footnoteref_4">4</a> 。在HBase 0.96中重做了Metrics系统。有关详细信息，请参见Elliot Clark的“迁移到新度量标准热点-度量标准2”</div>
</div>
<div id="footer">
<div id="footer-text">版本1.5.0<br>上次更新时间2019-10-08 17:25:30 PDT</div>
</div>

</body></html>