<html class="no-js" ><!--<![endif]--><head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
        <title>Spark独立模式-Spark 3.0.0-预览文档</title>
        

        

        <link rel="stylesheet" href="css/bootstrap.min.css">
        <style>
            body {
                padding-top: 60px;
                padding-bottom: 40px;
            }
        </style>
        <meta name="viewport" content="width=device-width">
        <link rel="stylesheet" href="css/bootstrap-responsive.min.css">
        <link rel="stylesheet" href="css/main.css">

        <script src="js/vendor/modernizr-2.6.1-respond-1.1.0.min.js"></script>

        <link rel="stylesheet" href="css/pygments-default.css">

        
        <!-- Google analytics script -->
        <script type="text/javascript">
          var _gaq = _gaq || [];
          _gaq.push(['_setAccount', 'UA-32518208-2']);
          _gaq.push(['_trackPageview']);

          (function() {
            var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
            ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
            var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
          })();
        </script>
        

    </head>
    <body >
        <!--[if lt IE 7]>
            <p class="chromeframe">You are using an outdated browser. <a href="https://browsehappy.com/">Upgrade your browser today</a> or <a href="http://www.google.com/chromeframe/?redirect=true">install Google Chrome Frame</a> to better experience this site.</p>
        <![endif]-->

        <!-- This code is taken from http://twitter.github.com/bootstrap/examples/hero.html -->

        <div class="navbar navbar-fixed-top" id="topbar">
            <div class="navbar-inner">
                <div class="container">
                    <div class="brand"><a href="index.html"><img src="img/spark-logo-hd.png" style="height:50px"></a> <span class="version">3.0.0预览版</span>
                    </div>
                    <ul class="nav">
                        <!--TODO(andyk): Add class="active" attribute to li some how.-->
                        <li><a href="index.html">总览</a></li>

                        <li class="dropdown">
                            <a href="#" class="dropdown-toggle" data-toggle="dropdown">编程指南<b class="caret"></b></a>
                            <ul class="dropdown-menu">
                                <li><a href="quick-start.html">快速开始</a></li>
                                <li><a href="rdd-programming-guide.html">RDD，累加器，广播变量</a></li>
                                <li><a href="sql-programming-guide.html">SQL，数据框和数据集</a></li>
                                <li><a href="structured-streaming-programming-guide.html">结构化流</a></li>
                                <li><a href="streaming-programming-guide.html">火花流（DStreams）</a></li>
                                <li><a href="ml-guide.html">MLlib（机器学习）</a></li>
                                <li><a href="graphx-programming-guide.html">GraphX（图形处理）</a></li>
                                <li><a href="sparkr.html">SparkR（Spark上的R）</a></li>
                            </ul>
                        </li>

                        <li class="dropdown">
                            <a href="#" class="dropdown-toggle" data-toggle="dropdown">API文件<b class="caret"></b></a>
                            <ul class="dropdown-menu">
                                <li><a href="api/scala/index.html#org.apache.spark.package">斯卡拉</a></li>
                                <li><a href="api/java/index.html">爪哇</a></li>
                                <li><a href="api/python/index.html">蟒蛇</a></li>
                                <li><a href="api/R/index.html">[R</a></li>
                                <li><a href="api/sql/index.html">SQL，内置函数</a></li>
                            </ul>
                        </li>

                        <li class="dropdown">
                            <a href="#" class="dropdown-toggle" data-toggle="dropdown">部署中<b class="caret"></b></a>
                            <ul class="dropdown-menu">
                                <li><a href="cluster-overview.html">总览</a></li>
                                <li><a href="submitting-applications.html">提交申请</a></li>
                                <li class="divider"></li>
                                <li><a href="spark-standalone.html">Spark独立</a></li>
                                <li><a href="running-on-mesos.html">梅索斯</a></li>
                                <li><a href="running-on-yarn.html">纱</a></li>
                                <li><a href="running-on-kubernetes.html">Kubernetes</a></li>
                            </ul>
                        </li>

                        <li class="dropdown">
                            <a href="api.html" class="dropdown-toggle" data-toggle="dropdown">更多<b class="caret"></b></a>
                            <ul class="dropdown-menu">
                                <li><a href="configuration.html">组态</a></li>
                                <li><a href="monitoring.html">监控方式</a></li>
                                <li><a href="tuning.html">调音指南</a></li>
                                <li><a href="job-scheduling.html">作业调度</a></li>
                                <li><a href="security.html">安全</a></li>
                                <li><a href="hardware-provisioning.html">硬件配置</a></li>
                                <li><a href="migration-guide.html">迁移指南</a></li>
                                <li class="divider"></li>
                                <li><a href="building-spark.html">建筑火花</a></li>
                                <li><a href="https://spark.apache.org/contributing.html">为Spark贡献</a></li>
                                <li><a href="https://spark.apache.org/third-party-projects.html">第三方项目</a></li>
                            </ul>
                        </li>
                    </ul>
                    <!--<p class="navbar-text pull-right"><span class="version-text">v3.0.0-preview</span></p>-->
                </div>
            </div>
        </div>

        <div class="container-wrapper">

            
                <div class="content" id="content">
                    
                        <h1 class="title">Spark独立模式</h1>
                    

                    <ul id="markdown-toc">
  <li><a href="#security" id="markdown-toc-security">安全</a></li>
  <li><a href="#installing-spark-standalone-to-a-cluster" id="markdown-toc-installing-spark-standalone-to-a-cluster">将Spark Standalone安装到集群</a></li>
  <li><a href="#starting-a-cluster-manually" id="markdown-toc-starting-a-cluster-manually">手动启动集群</a></li>
  <li><a href="#cluster-launch-scripts" id="markdown-toc-cluster-launch-scripts">群集启动脚本</a></li>
  <li><a href="#resource-allocation-and-configuration-overview" id="markdown-toc-resource-allocation-and-configuration-overview">资源分配和配置概述</a></li>
  <li><a href="#connecting-an-application-to-the-cluster" id="markdown-toc-connecting-an-application-to-the-cluster">将应用程序连接到集群</a></li>
  <li><a href="#launching-spark-applications" id="markdown-toc-launching-spark-applications">启动Spark应用程序</a></li>
  <li><a href="#resource-scheduling" id="markdown-toc-resource-scheduling">资源调度</a></li>
  <li><a href="#executors-scheduling" id="markdown-toc-executors-scheduling">执行器调度</a></li>
  <li><a href="#monitoring-and-logging" id="markdown-toc-monitoring-and-logging">监控和记录</a></li>
  <li><a href="#running-alongside-hadoop" id="markdown-toc-running-alongside-hadoop">与Hadoop一起运行</a></li>
  <li><a href="#configuring-ports-for-network-security" id="markdown-toc-configuring-ports-for-network-security">配置网络安全端口</a></li>
  <li><a href="#high-availability" id="markdown-toc-high-availability">高可用性</a>    <ul>
      <li><a href="#standby-masters-with-zookeeper" id="markdown-toc-standby-masters-with-zookeeper">ZooKeeper的备用大师</a></li>
      <li><a href="#single-node-recovery-with-local-file-system" id="markdown-toc-single-node-recovery-with-local-file-system">使用本地文件系统进行单节点恢复</a></li>
    </ul>
  </li>
</ul>

<p>除了在Mesos或YARN集群管理器上运行之外，Spark还提供了一种简单的独立部署模式。您可以通过手动启动主服务器和工作服务器来手动启动独立集群，也可以使用我们提供的<a href="#cluster-launch-scripts">启动脚本</a> 。也可以在一台机器上运行这些守护程序进行测试。</p>

<h1 id="security">安全</h1>

<p>默认情况下，Spark中的安全性处于关闭状态。这可能意味着您默认情况下容易受到攻击。在运行Spark之前，请参阅<a href="security.html">Spark安全性</a>和本文档中的特定安全性部分。</p>

<h1 id="installing-spark-standalone-to-a-cluster">将Spark Standalone安装到集群</h1>

<p>要安装Spark Standalone模式，只需将Spark的编译版本放在集群上的每个节点上。您可以在每个发行版中获取Spark的预构建版本， <a href="building-spark.html">也可以自己构建</a> 。</p>

<h1 id="starting-a-cluster-manually">手动启动集群</h1>

<p>您可以通过执行以下操作来启动独立的主服务器：</p>

<pre><code>./sbin/start-master.sh
</code></pre>

<p>一旦启动，母版将打印出一个<code>spark://HOST:PORT</code>本身的URL，您可以使用该URL将工作人员连接到该URL，或将其作为“ master”参数传递给<code>SparkContext</code> 。您还可以在主机的Web UI上找到此URL，默认情况下为<a href="http://localhost:8080">http：// localhost：8080</a> 。</p>

<p>同样，您可以启动一个或多个工作人员，并通过以下方式将其连接到主节点：</p>

<pre><code>./sbin/start-slave.sh &lt;master-spark-URL&gt;
</code></pre>

<p>一旦开始工作，请查看主服务器的Web UI（默认为<a href="http://localhost:8080">http：// localhost：8080</a> ）。您应该看到那里列出了新节点，以及它的CPU和内存数量（操作系统还剩下1 GB）。</p>

<p>最后，可以将以下配置选项传递给主服务器和工作服务器：</p>

<table class="table">
  <tbody><tr><th style="width:21%">争论</th><th>含义</th></tr>
  <tr>
    <td><code>-h HOST</code> ，<code>--host HOST</code></td>
    <td>侦听的主机名</td>
  </tr>
  <tr>
    <td><code>-i HOST</code> ，<code>--ip HOST</code></td>
    <td>要监听的主机名（不建议使用，请使用-h或--host）</td>
  </tr>
  <tr>
    <td><code>-p PORT</code> ，<code>--port PORT</code></td>
    <td>用于侦听的服务端口（默认值：主服务器为7077，工作人员为随机）</td>
  </tr>
  <tr>
    <td><code>--webui-port PORT</code></td>
    <td>Web UI的端口（默认值：主用户8080，工作人员8081）</td>
  </tr>
  <tr>
    <td><code>-c CORES</code> ，<code>--cores CORES</code></td>
    <td>允许Spark应用程序在计算机上使用的总CPU内核数（默认值：全部可用）；仅在工人上</td>
  </tr>
  <tr>
    <td><code>-m MEM</code> ，<code>--memory MEM</code></td>
    <td>允许Spark应用程序在计算机上使用的内存总量，格式为1000M或2G（默认值：计算机的总RAM减去1 GiB）；仅在工人上</td>
  </tr>
  <tr>
    <td><code>-d DIR</code> ，<code>--work-dir DIR</code></td>
    <td>用于暂存空间和作业输出日志的目录（默认值：SPARK_HOME / work）；仅在工人上</td>
  </tr>
  <tr>
    <td><code>--properties-file FILE</code></td>
    <td>要加载的自定义Spark属性文件的路径（默认：conf / spark-defaults.conf）</td>
  </tr>
</tbody></table>

<h1 id="cluster-launch-scripts">群集启动脚本</h1>

<p>要使用启动脚本启动Spark独立集群，您应该在Spark目录中创建一个名为conf / slaves的文件，该文件必须包含要启动Spark Worker的所有计算机的主机名，每行一个。如果conf / slaves不存在，则启动脚本默认为单台计算机（localhost），这对于测试非常有用。注意，主计算机通过ssh访问每个工作计算机。默认情况下，ssh是并行运行的，并且需要设置无密码（使用私钥）访问权限。如果您没有无密码设置，则可以设置环境变量SPARK_SSH_FOREGROUND并为每个工作线程依次提供一个密码。</p>

<p>设置完此文件后，您可以基于Hadoop的部署脚本，使用以下Shell脚本启动或停止集群，该脚本可在Hadoop中找到<code>SPARK_HOME/sbin</code> ：</p>

<ul>
  <li><code>sbin/start-master.sh</code> -在执行脚本的计算机上启动主实例。</li>
  <li><code>sbin/start-slaves.sh</code> -在指定的每台计算机上启动工作程序实例<code>conf/slaves</code>文件。</li>
  <li><code>sbin/start-slave.sh</code> -在执行脚本的计算机上启动工作程序实例。</li>
  <li><code>sbin/start-all.sh</code> -如上所述，同时启动主管和许多工人。</li>
  <li><code>sbin/stop-master.sh</code> -停止通过<code>sbin/start-master.sh</code>脚本。</li>
  <li><code>sbin/stop-slave.sh</code> -停止执行脚本的计算机上的所有工作程序实例。</li>
  <li><code>sbin/stop-slaves.sh</code> -在指定的计算机上停止所有工作程序实例<code>conf/slaves</code>文件。</li>
  <li><code>sbin/stop-all.sh</code> -如上所述，停止主机和工人。</li>
</ul>

<p>请注意，这些脚本必须在要在其上运行Spark master的计算机上执行，而不是在本地计算机上执行。</p>

<p>您可以选择通过在以下环境中设置环境变量来进一步配置集群<code>conf/spark-env.sh</code> 。通过从<code>conf/spark-env.sh.template</code> ，然后<em>将其复制到所有工作计算机上，</em>以使设置生效。可以使用以下设置：</p>

<table class="table">
  <tbody><tr><th style="width:21%">环境变量</th><th>含义</th></tr>
  <tr>
    <td><code>SPARK_MASTER_HOST</code></td>
    <td>将主服务器绑定到特定的主机名或IP地址，例如公共主机名或IP地址。</td>
  </tr>
  <tr>
    <td><code>SPARK_MASTER_PORT</code></td>
    <td>在另一个端口上启动主服务器（默认：7077）。</td>
  </tr>
  <tr>
    <td><code>SPARK_MASTER_WEBUI_PORT</code></td>
    <td>主Web UI的端口（默认值：8080）。</td>
  </tr>
  <tr>
    <td><code>SPARK_MASTER_OPTS</code></td>
    <td>仅以“ -Dx = y”的形式应用于主服务器的配置属性（默认值：无）。请参阅下面的可能选项列表。</td>
  </tr>
  <tr>
    <td><code>SPARK_LOCAL_DIRS</code></td>
    <td>用于Spark中“临时”空间的目录，包括映射输出文件和存储在磁盘上的RDD。它应该在系统中的快速本地磁盘上。它也可以是不同磁盘上多个目录的逗号分隔列表。
    </td>
  </tr>
  <tr>
    <td><code>SPARK_WORKER_CORES</code></td>
    <td>允许Spark应用程序在计算机上使用的内核总数（默认值：所有可用内核）。</td>
  </tr>
  <tr>
    <td><code>SPARK_WORKER_MEMORY</code></td>
    <td>允许Spark应用程序在计算机上使用的内存总量，例如<code>1000m</code> ， <code>2g</code> （默认值：总内存减去1 GiB）；请注意，每个应用程序的<i>单独</i>内存都使用其<code>spark.executor.memory</code>属性。</td>
  </tr>
  <tr>
    <td><code>SPARK_WORKER_PORT</code></td>
    <td>在特定端口上启动Spark worker（默认：随机）。</td>
  </tr>
  <tr>
    <td><code>SPARK_WORKER_WEBUI_PORT</code></td>
    <td>辅助Web UI的端口（默认值：8081）。</td>
  </tr>
  <tr>
    <td><code>SPARK_WORKER_DIR</code></td>
    <td>要在其中运行应用程序的目录，其中将包括日志和暂存空间（默认值：SPARK_HOME / work）。</td>
  </tr>
  <tr>
    <td><code>SPARK_WORKER_OPTS</code></td>
    <td>仅以“ -Dx = y”的形式应用于工作程序的配置属性（默认值：无）。请参阅下面的可能选项列表。</td>
  </tr>
  <tr>
    <td><code>SPARK_DAEMON_MEMORY</code></td>
    <td>分配给Spark主守护程序和辅助守护程序本身的内存（默认值：1g）。</td>
  </tr>
  <tr>
    <td><code>SPARK_DAEMON_JAVA_OPTS</code></td>
    <td>Spark主服务器和辅助服务器守护程序的JVM选项本身以“ -Dx = y”的形式出现（默认值：无）。</td>
  </tr>
  <tr>
    <td><code>SPARK_DAEMON_CLASSPATH</code></td>
    <td>Spark主守护程序和辅助守护程序本身的类路径（默认值：无）。</td>
  </tr>
  <tr>
    <td><code>SPARK_PUBLIC_DNS</code></td>
    <td>Spark主服务器和辅助服务器的公共DNS名称（默认值：无）。</td>
  </tr>
</tbody></table>

<p><strong>注意：</strong>启动脚本当前不支持Windows。要在Windows上运行Spark集群，请手动启动master和worker。</p>

<p>SPARK_MASTER_OPTS支持以下系统属性：</p>

<table class="table">
<tbody><tr><th>物业名称</th><th>默认</th><th>含义</th></tr>
<tr>
  <td><code>spark.deploy.retainedApplications</code></td>
  <td>200</td>
  <td>显示的已完成申请的最大数量。较旧的应用程序将从UI中删除，以保持此限制。<br>
  </td>
</tr>
<tr>
  <td><code>spark.deploy.retainedDrivers</code></td>
  <td>200</td>
  <td>要显示的已完成驱动程序的最大数量。较旧的驱动程序将从UI删除，以保持此限制。<br>
  </td>
</tr>
<tr>
  <td><code>spark.deploy.spreadOut</code></td>
  <td>真正</td>
  <td>独立集群管理器是应将应用程序分布在各个节点上，还是应将它们合并到尽可能少的节点上。对于HDFS中的数据局部性而言，扩展通常更好，但对于计算密集型工作负载而言，整合更有效。<br>
  </td>
</tr>
<tr>
  <td><code>spark.deploy.defaultCores</code></td>
  <td>（无穷）</td>
  <td>如果未设置，以Spark独立模式提供给应用程序的默认内核数<code>spark.cores.max</code> 。如果未设置，则应用程序始终获得所有可用的内核，除非它们进行配置<code>spark.cores.max</code>他们自己。在共享群集上将此值设置得较低，以防止用户默认情况下抓取整个群集。<br>
  </td>
</tr>
<tr>
  <td><code>spark.deploy.maxExecutorRetries</code></td>
  <td>10</td>
  <td>对独立集群管理器删除有故障的应用程序之前可能发生的最大背对背执行器故障数的限制。如果应用程序具有正在运行的执行程序，则永远不会将其删除。如果应用程序遇到以下情况： <code>spark.deploy.maxExecutorRetries</code>连续出现故障，在这些故障之间没有执行程序成功开始运行，并且应用程序没有正在运行的执行程序，则独立集群管理器将删除该应用程序并将其标记为失败。要禁用此自动删除功能，请设置<code>spark.deploy.maxExecutorRetries</code>至<code>-1</code> 。
    <br>
  </td>
</tr>
<tr>
  <td><code>spark.worker.timeout</code></td>
  <td>60</td>
  <td>如果独立部署主服务器未接收到心跳信号，则该秒数之后该秒数将其视为丢失。
  </td>
</tr>
<tr>
  <td><code>spark.worker.resource.{resourceName}.amount</code></td>
  <td>（没有）</td>
  <td>要在工作程序上使用的特定资源的数量。
  </td>
</tr>
<tr>
  <td><code>spark.worker.resource.{resourceName}.discoveryScript</code></td>
  <td>（没有）</td>
  <td>资源发现脚本的路径，用于在工作程序启动时查找特定资源。脚本的输出应设置为<code>ResourceInformation</code>类。什么时候<code>spark.resources.coordinate.enable</code>如果关闭，发现脚本必须为在同一主机上运行的客户端模式下的工作程序和驱动程序分配不同的资源，以避免资源冲突。
  </td>
</tr>
<tr>
  <td><code>spark.worker.resourcesFile</code></td>
  <td>（没有）</td>
  <td>资源文件的路径，该文件用于在工作程序启动时查找各种资源。资源文件的内容应采用以下格式： <code>[[{"id":{"componentName": "spark.worker","resourceName":"gpu"},"addresses":["0","1","2"]}]]</code> 。什么时候<code>spark.resources.coordinate.enable</code>如果关闭，资源文件必须为在同一主机上运行的客户端模式下的工作程序和驱动程序分配不同的资源，以避免资源冲突。如果在资源文件中找不到特定资源，则将使用发现脚本来查找该资源。如果发现脚本也找不到资源，则工作服务器将无法启动。
  </td>
</tr>
</tbody></table>

<p>SPARK_WORKER_OPTS支持以下系统属性：</p>

<table class="table">
<tbody><tr><th>物业名称</th><th>默认</th><th>含义</th></tr>
<tr>
  <td><code>spark.worker.cleanup.enabled</code></td>
  <td>假</td>
  <td>启用定期清除worker /应用程序目录。请注意，这仅影响独立模式，因为YARN的工作原理不同。仅清除已停止的应用程序的目录。如果spark.shuffle.service.db.enabled为“ true”，则应启用此选项</td>
</tr>
<tr>
  <td><code>spark.worker.cleanup.interval</code></td>
  <td>1800（30分钟）</td>
  <td>控制工人清理本地计算机上旧的应用程序工作目录的时间间隔（以秒为单位）。
  </td>
</tr>
<tr>
  <td><code>spark.worker.cleanup.appDataTtl</code></td>
  <td>604800（7天，7 * 24 * 3600）</td>
  <td>在每个工作程序上保留应用程序工作目录的秒数。这是生存时间，应取决于您拥有的可用磁盘空间量。应用程序日志和jars被下载到每个应用程序工作目录。随着时间的推移，工作目录会迅速填满磁盘空间，尤其是如果您非常频繁地运行作业时。
  </td>
</tr>
<tr>
  <td><code>spark.shuffle.service.db.enabled</code></td>
  <td>真正</td>
  <td>将外部随机播放服务状态存储在本地磁盘上，以便在重新启动外部随机播放服务时，它将自动重新加载当前执行程序上的信息。这仅影响独立模式（纱线始终启用此行为）。您还应该启用<code>spark.worker.cleanup.enabled</code> ，以确保最终清除状态。将来可能会删除此配置。
  </td>
</tr>
<tr>
  <td><code>spark.storage.cleanupFilesAfterExecutorExit</code></td>
  <td>真正</td>
  <td>在执行程序退出后，启用工作目录的清理非混洗文件（例如临时混洗块，缓存的RDD /广播块，溢出文件等）。请注意，这与`spark.worker.cleanup.enabled`不重叠，因为它可以清除死掉执行者的本地目录中的非随机文件，而`spark.worker.cleanup.enabled`可以清除所有文件。 /停止和超时应用程序的子目录。这仅影响独立模式，将来可以添加对其他集群管理员的支持。
  </td>
</tr>
<tr>
  <td><code>spark.worker.ui.compressedLogFileLengthCacheSize</code></td>
  <td>100</td>
  <td>对于压缩日志文件，只能通过解压缩文件来计算未压缩文件。Spark缓存压缩日志文件的未压缩文件大小。此属性控制缓存大小。
  </td>
</tr>
</tbody></table>

<h1 id="resource-allocation-and-configuration-overview">资源分配和配置概述</h1>

<p>请确保已阅读<a href="configuration.html">配置页面</a>上的“自定义资源调度和配置概述”部分。本部分仅讨论资源调度的Spark Standalone特定方面。</p>

<p>Spark Standalone有2部分，第一部分是为Worker配置资源，第二部分是为特定应用程序分配资源。</p>

<p>用户必须配置工人以拥有一组可用资源，以便可以将它们分配给执行者。的<code>spark.worker.resource.{resourceName}.amount</code>用于控制工作人员分配的每个资源的数量。用户还必须指定<code>spark.worker.resourcesFile</code>要么<code>spark.worker.resource.{resourceName}.discoveryScript</code>指定工作者如何发现其分配的资源。请参阅上述说明，以了解哪种方法最适合您的设置。请注意<code>spark.resources.coordinate.enable</code>因为它表明Spark应该处理协调资源还是用户确保每个Worker都有单独的资源。另请注意，如果使用资源协调<code>spark.resources.dir</code>可用于指定用于协调的目录。</p>

<p>第二部分是在Spark Standalone上运行应用程序。标准Spark资源配置中的唯一特殊情况是在客户端模式下运行驱动程序时。对于客户端模式的驱动程序，用户可以通过以下方式指定其使用的资源<code>spark.driver.resourcesfile</code>要么<code>spark.driver.resources.{resourceName}.discoveryScript</code> 。如果驱动程序与其他驱动程序或工作程序在同一主机上运行，则有两种方法来确保它们不使用相同的资源。用户可以配置<code>spark.resources.coordinate.enable</code>并为所有驱动程序/工作人员提供相同的集合或资源，Spark将处理以确保每个驱动程序/工作人员具有单独的资源，或者用户可以确保资源文件或发现脚本仅返回不与其他驱动程序冲突的资源。在同一节点上运行的工作程序。</p>

<p>请注意，在提交应用程序时，用户无需指定发现脚本，因为Worker将使用为其分配的资源启动每个执行程序。</p>

<h1 id="connecting-an-application-to-the-cluster">将应用程序连接到集群</h1>

<p>要在Spark集群上运行应用程序，只需传递<code>spark://IP:PORT</code>母版的URL <a href="rdd-programming-guide.html#initializing-spark"><code>SparkContext</code>构造函数</a> 。</p>

<p>要针对集群运行交互式Spark Shell，请运行以下命令：</p>

<pre><code>./bin/spark-shell --master spark://IP:PORT
</code></pre>

<p>您还可以通过一个选项<code>--total-executor-cores <numCores></code>以控制spark-shell在群集上使用的核心数。</p>

<h1 id="launching-spark-applications">启动Spark应用程序</h1>

<p>的<a href="submitting-applications.html"><code>spark-submit</code>脚本</a>提供了将已编译的Spark应用程序提交到集群的最直接的方法。对于独立集群，Spark当前支持两种部署模式。在<code>client</code>模式，驱动程序以与提交应用程序的客户端相同的过程启动。在<code>cluster</code>但是，在这种方式下，驱动程序是从群集内的一个Worker进程中启动的，并且客户端进程在完成提交应用程序的职责而无需等待应用程序完成时立即退出。</p>

<p>如果您的应用程序是通过Spark提交启动的，则应用程序jar将自动分发到所有工作节点。对于您的应用程序所依赖的其他jar，您应该通过<code>--jars</code>使用逗号作为分隔符的标志（例如<code>--jars jar1,jar2</code> ）。要控制应用程序的配置或执行环境，请参见<a href="configuration.html">Spark配置</a> 。</p>

<p>此外，独立<code>cluster</code>模式支持使用非零退出代码退出的应用程序自动重新启动。要使用此功能，您可以传入<code>--supervise</code>标记为<code>spark-submit</code>启动应用程序时。然后，如果您希望终止反复失败的应用程序，则可以通过以下方法进行：</p>

<pre><code>./bin/spark-class org.apache.spark.deploy.Client kill &lt;master url&gt; &lt;driver ID&gt;
</code></pre>

<p>您可以通过独立的Master Web UI找到驱动程序ID，网址为： <code>http://<master url>:8080</code> 。</p>

<h1 id="resource-scheduling">资源调度</h1>

<p>独立群集模式当前仅支持跨应用程序的简单FIFO调度程序。但是，要允许多个并发用户，您可以控制每个应用程序将使用的最大资源数量。默认情况下，它将获取群集中的<em>所有</em>内核，这仅在您一次只运行一个应用程序时才有意义。您可以通过设置上限来限制内核数<code>spark.cores.max</code>在您的<a href="configuration.html#spark-properties">SparkConf中</a> 。例如：</p>

<figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span></span><span class="k">val</span> <span class="n">conf</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SparkConf</span><span class="o">()</span>
  <span class="o">.</span><span class="n">setMaster</span><span class="o">(...)</span>
  <span class="o">.</span><span class="n">setAppName</span><span class="o">(...)</span>
  <span class="o">.</span><span class="n">set</span><span class="o">(</span><span class="s">&quot;spark.cores.max&quot;</span><span class="o">,</span> <span class="s">&quot;10&quot;</span><span class="o">)</span>
<span class="k">val</span> <span class="n">sc</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SparkContext</span><span class="o">(</span><span class="n">conf</span><span class="o">)</span></code></pre></figure>

<p>另外，您可以配置<code>spark.deploy.defaultCores</code>在群集主进程上更改未设置的应用程序的默认设置<code>spark.cores.max</code>比无穷大的东西为此，请将以下内容添加到<code>conf/spark-env.sh</code> ：</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span></span><span class="nb">export</span> <span class="nv">SPARK_MASTER_OPTS</span><span class="o">=</span><span class="s2">&quot;-Dspark.deploy.defaultCores=&lt;value&gt;&quot;</span></code></pre></figure>

<p>这在用户可能未单独配置最大核心数的共享群集上很有用。</p>

<h1 id="executors-scheduling">执行器调度</h1>

<p>分配给每个执行程序的内核数是可配置的。什么时候<code>spark.executor.cores</code>如果显式设置，则当工作线程具有足够的核心和内存时，可以在同一工作线程上启动来自同一应用程序的多个执行程序。否则，默认情况下，每个执行程序都将获取工作程序上所有可用的内核，在这种情况下，在单个调度迭代中，每个应用程序上只能在每个工作程序上启动一个执行程序。</p>

<h1 id="monitoring-and-logging">监控和记录</h1>

<p>Spark的独立模式提供基于Web的用户界面来监视集群。主服务器和每个工作人员都有自己的Web UI，该Web UI显示群集和作业统计信息。默认情况下，您可以在端口8080上访问主服务器的Web UI。可以在配置文件中或通过命令行选项更改端口。</p>

<p>此外，每个作业的详细日志输出也将写入每个从属节点的工作目录（ <code>SPARK_HOME/work</code>默认）。您将为每个作业看到两个文件， <code>stdout</code>和<code>stderr</code> ，并将所有输出写入控制台。</p>

<h1 id="running-alongside-hadoop">与Hadoop一起运行</h1>

<p>您可以通过将Spark作为单独的服务在同一台计算机上启动，将其与现有Hadoop集群一起运行。要从Spark访问Hadoop数据，只需使用hdfs：// URL（通常是<code>hdfs://<namenode>:9000/path</code> ，但您可以在Hadoop Namenode的Web UI上找到正确的URL）。另外，您可以为Spark设置一个单独的群集，但仍然可以通过网络访问HDFS；这将比磁盘本地访问慢，但是如果您仍在同一局域网中运行（例如，在装有Hadoop的每个机架上放置几台Spark机器），则可能不必担心。</p>

<h1 id="configuring-ports-for-network-security">配置网络安全端口</h1>

<p>一般来说，Spark集群及其服务未部署在公共互联网上。它们通常是私有服务，并且只能在部署Spark的组织网络内访问。对Spark服务使用的主机和端口的访问应仅限于需要访问服务的原始主机。</p>

<p>这对于使用独立资源管理器的群集特别重要，因为它们不支持其他资源管理器所支持的细粒度访问控制。</p>

<p>有关要配置的端口的完整列表，请参阅<a href="security.html#configuring-ports-for-network-security">安全性页面</a> 。</p>

<h1 id="high-availability">高可用性</h1>

<p>默认情况下，独立的调度群集可以抵抗Worker的故障（Spark本身可以通过将其转移到其他Worker上来抵抗丢失的工作）。但是，调度程序使用主服务器来制定调度决策，这（默认情况下）会造成单点故障：如果主服务器崩溃，则无法创建新的应用程序。为了避免这种情况，我们有两个高可用性方案，下面将详细介绍。</p>

<h2 id="standby-masters-with-zookeeper">ZooKeeper的备用大师</h2>

<p><strong>总览</strong></p>

<p>利用ZooKeeper提供领导者选举和一些状态存储，您可以在连接到同一ZooKeeper实例的群集中启动多个Master。其中一位将当选为“领导人”，其他人将保持待机状态。如果当前领导者去世，将选出另一位主人，恢复原主人的状态，然后恢复计划。整个恢复过程（从第一个领导者下台起）应花费1-2分钟。请注意，此延迟仅影响计划<em>新</em>应用程序-主故障转移期间已在运行的应用程序不受影响。</p>

<p><a href="https://zookeeper.apache.org/doc/current/zookeeperStarted.html">在此处</a>了解有关ZooKeeper入门的更多信息。</p>

<p><strong>组态</strong></p>

<p>为了启用此恢复模式，您可以通过配置在spark-env中设置SPARK_DAEMON_JAVA_OPTS <code>spark.deploy.recoveryMode</code>以及相关的spark.deploy.zookeeper。*配置。有关这些配置的更多信息，请参阅<a href="configuration.html#deploy">配置文档</a></p>

<p>可能的陷阱：如果您的集群中有多个Master，但未能正确配置Master以使用ZooKeeper，则Master将无法彼此发现并认为他们都是领导者。这不会导致群集状态正常（因为所有Master都将独立调度）。</p>

<p><strong>细节</strong></p>

<p>设置ZooKeeper群集后，启用高可用性非常简单。只需在具有相同ZooKeeper配置（ZooKeeper URL和目录）的不同节点上启动多个主进程。母版可以随时添加和删除。</p>

<p>为了安排新的应用程序或将Worker添加到群集，他们需要知道当前领导者的IP地址。这可以通过简单地传递过去曾经传递过的大师列表来实现。例如，您可以启动SparkContext指向<code>spark://host1:port1,host2:port2</code> 。这将导致您的SparkContext尝试向两个Master进行注册-如果<code>host1</code>失败，此配置仍然是正确的，因为我们会找到新的领导者， <code>host2</code> 。</p>

<p>在“向主机注册”和正常操作之间有一个重要的区别。启动时，应用程序或工作程序需要能够找到当前的主管理员并进行注册。但是，一旦成功注册，它就会“在系统中”（即存储在ZooKeeper中）。如果发生故障转移，新领导者将与所有先前注册的应用程序和工作人员联系，以通知他们领导能力的变化，因此他们甚至不需要在启动时就知道新主服务器的存在。</p>

<p>由于此属性，可以随时创建新的Master，而您唯一需要担心的是， <em>新</em>应用程序和Workers可以找到它进行注册，以防它成为领导者。注册后，您将得到照顾。</p>

<h2 id="single-node-recovery-with-local-file-system">使用本地文件系统进行单节点恢复</h2>

<p><strong>总览</strong></p>

<p>ZooKeeper是实现生产级高可用性的最佳方法，但是如果您只想在主服务器出现故障时能够重新启动它，则FILESYSTEM模式可以解决这一问题。当应用程序和工作程序注册时，它们具有足够的状态写入提供的目录，以便可以在重新启动主进程时恢复它们。</p>

<p><strong>组态</strong></p>

<p>为了启用此恢复模式，可以使用以下配置在spark-env中设置SPARK_DAEMON_JAVA_OPTS：</p>

<table class="table">
  <tbody><tr><th style="width:21%">系统属性</th><th>含义</th></tr>
  <tr>
    <td><code>spark.deploy.recoveryMode</code></td>
    <td>设置为FILESYSTEM以启用单节点恢复模式（默认值：NONE）。</td>
  </tr>
  <tr>
    <td><code>spark.deploy.recoveryDirectory</code></td>
    <td>从主服务器的角度来看，Spark将存储恢复状态的目录。</td>
  </tr>
</tbody></table>

<p><strong>细节</strong></p>

<ul>
  <li>该解决方案可以与进程监视器/管理器（如<a href="https://mmonit.com/monit/">monit）一起使用</a> ，或者仅用于通过重新启动进行手动恢复。</li>
  <li>尽管文件系统恢复似乎比根本不进行任何恢复都直接好，但是对于某些开发或实验目的，此模式可能不是最佳的。特别是，通过stop-master.sh杀死主服务器不会清除其恢复状态，因此，每当您启动新的主服务器时，它将进入恢复模式。如果需要等待所有先前注册的Worker /客户端超时，这可能会使启动时间最多增加1分钟。</li>
  <li>虽然它不受官方支持，但您可以挂载NFS目录作为恢复目录。如果原始的Master节点完全死亡，则可以在其他节点上启动Master，这样可以正确恢复所有先前注册的Worker /应用程序（相当于ZooKeeper恢复）。但是，将来的应用程序必须能够找到新的Master，才能进行注册。</li>
</ul>


                </div>
            
             <!-- /container -->
        </div>

        <script src="js/vendor/jquery-3.4.1.min.js"></script>
        <script src="js/vendor/bootstrap.min.js"></script>
        <script src="js/vendor/anchor.min.js"></script>
        <script src="js/main.js"></script>

        <!-- MathJax Section -->
        <script type="text/x-mathjax-config">
            MathJax.Hub.Config({
                TeX: { equationNumbers: { autoNumber: "AMS" } }
            });
        </script>
        <script>
            // Note that we load MathJax this way to work with local file (file://), HTTP and HTTPS.
            // We could use "//cdn.mathjax...", but that won't support "file://".
            (function(d, script) {
                script = d.createElement('script');
                script.type = 'text/javascript';
                script.async = true;
                script.onload = function(){
                    MathJax.Hub.Config({
                        tex2jax: {
                            inlineMath: [ ["$", "$"], ["\\\\(","\\\\)"] ],
                            displayMath: [ ["$$","$$"], ["\\[", "\\]"] ],
                            processEscapes: true,
                            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre']
                        }
                    });
                };
                script.src = ('https:' == document.location.protocol ? 'https://' : 'http://') +
                    'cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js' +
                    '?config=TeX-AMS-MML_HTMLorMML';
                d.getElementsByTagName('head')[0].appendChild(script);
            }(document));
        </script>
    

</body></html>