<html class="no-js" ><head></head><body >﻿<!--<![endif]-->
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
        <title>在Kubernetes上运行Spark-Spark 3.0.0-预览文档</title>
        

        

        <link rel="stylesheet" href="css/bootstrap.min.css">
        <style>
            body {
                padding-top: 60px;
                padding-bottom: 40px;
            }
        </style>
        <meta name="viewport" content="width=device-width">
        <link rel="stylesheet" href="css/bootstrap-responsive.min.css">
        <link rel="stylesheet" href="css/main.css">

        <script src="js/vendor/modernizr-2.6.1-respond-1.1.0.min.js"></script>

        <link rel="stylesheet" href="css/pygments-default.css">

        
        <!-- Google analytics script -->
        <script type="text/javascript">
          var _gaq = _gaq || [];
          _gaq.push(['_setAccount', 'UA-32518208-2']);
          _gaq.push(['_trackPageview']);

          (function() {
            var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
            ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
            var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
          })();
        </script>
        

    
    
        <!--[if lt IE 7]>
            <p class="chromeframe">You are using an outdated browser. <a href="https://browsehappy.com/">Upgrade your browser today</a> or <a href="http://www.google.com/chromeframe/?redirect=true">install Google Chrome Frame</a> to better experience this site.</p>
        <![endif]-->

        <!-- This code is taken from http://twitter.github.com/bootstrap/examples/hero.html -->

        <div class="navbar navbar-fixed-top" id="topbar">
            <div class="navbar-inner">
                <div class="container">
                    <div class="brand"><a href="index.html"><img src="img/spark-logo-hd.png" style="height:50px"></a> <span class="version">3.0.0预览版</span>
                    </div>
                    <ul class="nav">
                        <!--TODO(andyk): Add class="active" attribute to li some how.-->
                        <li><a href="index.html">总览</a></li>

                        <li class="dropdown">
                            <a href="#" class="dropdown-toggle" data-toggle="dropdown">编程指南<b class="caret"></b></a>
                            <ul class="dropdown-menu">
                                <li><a href="quick-start.html">快速开始</a></li>
                                <li><a href="rdd-programming-guide.html">RDD，累加器，广播变量</a></li>
                                <li><a href="sql-programming-guide.html">SQL，数据框和数据集</a></li>
                                <li><a href="structured-streaming-programming-guide.html">结构化流</a></li>
                                <li><a href="streaming-programming-guide.html">火花流（DStreams）</a></li>
                                <li><a href="ml-guide.html">MLlib（机器学习）</a></li>
                                <li><a href="graphx-programming-guide.html">GraphX（图形处理）</a></li>
                                <li><a href="sparkr.html">SparkR（Spark上的R）</a></li>
                            </ul>
                        </li>

                        <li class="dropdown">
                            <a href="#" class="dropdown-toggle" data-toggle="dropdown">API文件<b class="caret"></b></a>
                            <ul class="dropdown-menu">
                                <li><a href="api/scala/index.html#org.apache.spark.package">斯卡拉</a></li>
                                <li><a href="api/java/index.html">爪哇</a></li>
                                <li><a href="api/python/index.html">蟒蛇</a></li>
                                <li><a href="api/R/index.html">[R</a></li>
                                <li><a href="api/sql/index.html">SQL，内置函数</a></li>
                            </ul>
                        </li>

                        <li class="dropdown">
                            <a href="#" class="dropdown-toggle" data-toggle="dropdown">部署中<b class="caret"></b></a>
                            <ul class="dropdown-menu">
                                <li><a href="cluster-overview.html">总览</a></li>
                                <li><a href="submitting-applications.html">提交申请</a></li>
                                <li class="divider"></li>
                                <li><a href="spark-standalone.html">Spark独立</a></li>
                                <li><a href="running-on-mesos.html">梅索斯</a></li>
                                <li><a href="running-on-yarn.html">纱</a></li>
                                <li><a href="running-on-kubernetes.html">Kubernetes</a></li>
                            </ul>
                        </li>

                        <li class="dropdown">
                            <a href="api.html" class="dropdown-toggle" data-toggle="dropdown">更多<b class="caret"></b></a>
                            <ul class="dropdown-menu">
                                <li><a href="configuration.html">组态</a></li>
                                <li><a href="monitoring.html">监控方式</a></li>
                                <li><a href="tuning.html">调音指南</a></li>
                                <li><a href="job-scheduling.html">作业调度</a></li>
                                <li><a href="security.html">安全</a></li>
                                <li><a href="hardware-provisioning.html">硬件配置</a></li>
                                <li><a href="migration-guide.html">迁移指南</a></li>
                                <li class="divider"></li>
                                <li><a href="building-spark.html">建筑火花</a></li>
                                <li><a href="https://spark.apache.org/contributing.html">为Spark贡献</a></li>
                                <li><a href="https://spark.apache.org/third-party-projects.html">第三方项目</a></li>
                            </ul>
                        </li>
                    </ul>
                    <!--<p class="navbar-text pull-right"><span class="version-text">v3.0.0-preview</span></p>-->
                </div>
            </div>
        </div>

        <div class="container-wrapper">

            
                <div class="content" id="content">
                    
                        <h1 class="title">在Kubernetes上运行Spark</h1>
                    

                    <ul id="markdown-toc">
  <li><a href="#security" id="markdown-toc-security">安全</a>    <ul>
      <li><a href="#user-identity" id="markdown-toc-user-identity">用户身份</a></li>
      <li><a href="#volume-mounts" id="markdown-toc-volume-mounts">体积安装</a></li>
    </ul>
  </li>
  <li><a href="#prerequisites" id="markdown-toc-prerequisites">先决条件</a></li>
  <li><a href="#how-it-works" id="markdown-toc-how-it-works">怎么运行的</a></li>
  <li><a href="#submitting-applications-to-kubernetes" id="markdown-toc-submitting-applications-to-kubernetes">向Kubernetes提交申请</a>    <ul>
      <li><a href="#docker-images" id="markdown-toc-docker-images">Docker映像</a></li>
      <li><a href="#cluster-mode" id="markdown-toc-cluster-mode">集群模式</a></li>
      <li><a href="#client-mode" id="markdown-toc-client-mode">客户端模式</a>        <ul>
          <li><a href="#client-mode-networking" id="markdown-toc-client-mode-networking">客户端模式网络</a></li>
          <li><a href="#client-mode-executor-pod-garbage-collection" id="markdown-toc-client-mode-executor-pod-garbage-collection">客户端模式执行器Pod垃圾回收</a></li>
          <li><a href="#authentication-parameters" id="markdown-toc-authentication-parameters">认证参数</a></li>
        </ul>
      </li>
      <li><a href="#dependency-management" id="markdown-toc-dependency-management">依赖管理</a></li>
      <li><a href="#secret-management" id="markdown-toc-secret-management">秘密管理</a></li>
      <li><a href="#pod-template" id="markdown-toc-pod-template">吊舱模板</a></li>
      <li><a href="#using-kubernetes-volumes" id="markdown-toc-using-kubernetes-volumes">使用Kubernetes卷</a></li>
      <li><a href="#local-storage" id="markdown-toc-local-storage">本地存储</a>        <ul>
          <li><a href="#using-ram-for-local-storage" id="markdown-toc-using-ram-for-local-storage">使用RAM进行本地存储</a></li>
        </ul>
      </li>
      <li><a href="#introspection-and-debugging" id="markdown-toc-introspection-and-debugging">内省和调试</a>        <ul>
          <li><a href="#accessing-logs" id="markdown-toc-accessing-logs">访问日志</a></li>
          <li><a href="#accessing-driver-ui" id="markdown-toc-accessing-driver-ui">访问驱动程序用户界面</a></li>
          <li><a href="#debugging" id="markdown-toc-debugging">调试</a></li>
        </ul>
      </li>
      <li><a href="#kubernetes-features" id="markdown-toc-kubernetes-features">Kubernetes功能</a>        <ul>
          <li><a href="#configuration-file" id="markdown-toc-configuration-file">配置文件</a></li>
          <li><a href="#contexts" id="markdown-toc-contexts">语境</a></li>
          <li><a href="#namespaces" id="markdown-toc-namespaces">命名空间</a></li>
          <li><a href="#rbac" id="markdown-toc-rbac">RBAC</a></li>
        </ul>
      </li>
      <li><a href="#spark-application-management" id="markdown-toc-spark-application-management">Spark应用程序管理</a></li>
      <li><a href="#future-work" id="markdown-toc-future-work">未来的工作</a></li>
    </ul>
  </li>
  <li><a href="#configuration" id="markdown-toc-configuration">组态</a>    <ul>
      <li><a href="#spark-properties" id="markdown-toc-spark-properties">火花特性</a></li>
    </ul>
  </li>
</ul>

<p>Spark可以在<a href="https://kubernetes.io">Kubernetes</a>管理的集群上运行。此功能利用已添加到Spark的本地Kubernetes调度程序。</p>

<p><strong>Kubernetes调度程序目前处于试验阶段。在将来的版本中，配置，容器映像和入口点可能会发生行为更改。</strong></p>

<h1 id="security">安全</h1>

<p>默认情况下，Spark中的安全性处于关闭状态。这可能意味着您默认情况下容易受到攻击。在运行Spark之前，请参阅<a href="security.html">Spark安全性</a>和下面的特定建议。</p>

<h2 id="user-identity">用户身份</h2>

<p>从项目构建的映像（如果Dockerfiles包含默认值） <a href="https://docs.docker.com/engine/reference/builder/#user"><code>USER</code></a>指令的默认UID为<code>185</code> 。这意味着生成的图像将作为容器内的此UID运行Spark进程。注重安全性的部署应考虑提供自定义映像<code>USER</code>指定其所需的非特权UID和GID的指令。生成的UID应该在其补充组中包括根组，以便能够运行Spark可执行文件。用户使用提供的内容构建自己的图像<code>docker-image-tool.sh</code>脚本可以使用<code>-u <uid></code>选项以指定所需的UID。</p>

<p>或者，可以使用<a href="#pod-template">Pod模板</a>功能添加带有以下内容的<a href="https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#volumes-and-file-systems">安全上下文</a> ： <code>runAsUser</code>到Spark提交的Pod。这可以用来覆盖<code>USER</code>图片本身中的指令。请记住，这需要您的用户的合作，因此对于共享环境可能不是合适的解决方案。如果集群管理员希望限制运行<a href="https://kubernetes.io/docs/concepts/policy/pod-security-policy/#users-and-groups">Pod</a>的用户，则应使用<a href="https://kubernetes.io/docs/concepts/policy/pod-security-policy/#users-and-groups">Pod安全策略</a> 。</p>

<h2 id="volume-mounts">体积安装</h2>

<p>如本文档后面所述，在<a href="#using-kubernetes-volumes">K8S</a>上<a href="#using-kubernetes-volumes">使用Kubernetes Volumes中的</a> Spark提供了一些配置选项，这些选项允许将某些卷类型安装到驱动程序和执行程序容器中。特别是它允许<a href="https://kubernetes.io/docs/concepts/storage/volumes/#hostpath"><code>hostPath</code></a> Kubernetes文档中描述的这些卷具有已知的安全漏洞。</p>

<p>群集管理员应使用<a href="https://kubernetes.io/docs/concepts/policy/pod-security-policy/">Pod安全策略</a>来限制挂载的能力<code>hostPath</code>量适合其环境。</p>

<h1 id="prerequisites">先决条件</h1>

<ul>
  <li>可运行的Spark 2.3或更高版本。</li>
  <li>版本> = 1.6的运行Kubernetes集群，使用<a href="https://kubernetes.io/docs/user-guide/prereqs/">kubectl</a>配置了对其的访问权限。如果还没有可用的Kubernetes集群，则可以使用<a href="https://kubernetes.io/docs/getting-started-guides/minikube/">minikube</a>在本地计算机上设置测试集群。
    <ul>
      <li>我们建议使用启用了DNS插件的最新版本的minikube。</li>
      <li>请注意，默认的minikube配置不足以运行Spark应用程序。我们建议使用3个CPU和4g内存，以便能够用一个执行程序来启动一个简单的Spark应用程序。</li>
    </ul>
  </li>
  <li>您必须具有适当的权限才能列出，创建，编辑和删除<a href="https://kubernetes.io/docs/user-guide/pods/">集群</a>中的<a href="https://kubernetes.io/docs/user-guide/pods/">Pod</a> 。您可以验证是否可以通过运行列出这些资源<code>kubectl auth can-i <list|create|edit|delete> pods</code> 。
    <ul>
      <li>必须允许驱动程序窗格使用的服务帐户凭据来创建窗格，服务和配置映射。</li>
    </ul>
  </li>
  <li>您必须在集群中配置<a href="https://kubernetes.io/docs/concepts/services-networking/dns-pod-service/">Kubernetes DNS</a> 。</li>
</ul>

<h1 id="how-it-works">怎么运行的</h1>

<p style="text-align:center">
  <img src="img/k8s-cluster-mode.png" title="Spark集群组件" alt="Spark集群组件">
</p>

<p><code>spark-submit</code>可以直接用于将Spark应用程序提交到Kubernetes集群。提交机制的工作方式如下：</p>

<ul>
  <li>Spark创建一个在<a href="https://kubernetes.io/docs/concepts/workloads/pods/pod/">Kubernetes容器中</a>运行的Spark驱动程序。</li>
  <li>驱动程序将创建执行程序，这些执行程序也将在Kubernetes Pod中运行并连接到它们，并执行应用程序代码。</li>
  <li>当应用程序完成时，执行程序Pod终止并被清理，但是驱动程序Pod保留日志并在Kubernetes API中保持“完成”状态，直到最终对其进行垃圾收集或手动清理为止。</li>
</ul>

<p>请注意，在完成状态，驾驶员舱<em>不</em>使用任何计算或存储资源。</p>

<p>驱动程序和执行程序容器调度由Kubernetes处理。与Kubernetes API的通信是通过fabric8完成的，我们目前正在运行<code>kubernetes-client</code>版<code>4.1.0</code> 。确保在添加基础结构时知道该版本。可以通过<a href="https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#nodeselector">节点选择器</a>使用其配置属性，在可用节点的子集上安排驱动程序和执行程序窗格。在将来的版本中，可能会使用更高级的调度提示，例如<a href="https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity">节点/吊舱关联性</a> 。</p>

<h1 id="submitting-applications-to-kubernetes">向Kubernetes提交申请</h1>

<h2 id="docker-images">Docker映像</h2>

<p>Kubernetes要求用户提供可以部署到Pod内的容器中的映像。映像被构建为在Kubernetes支持的容器运行时环境中运行。Docker是Kubernetes经常使用的容器运行时环境。Spark（从2.3版开始）附带了一个Dockerfile，可用于此目的，也可对其进行自定义以匹配单个应用程序的需求。可以在<code>kubernetes/dockerfiles/</code>目录。</p>

<p>Spark还附带了<code>bin/docker-image-tool.sh</code>该脚本可用于构建和发布与Kubernetes后端一起使用的Docker映像。</p>

<p>用法示例是：</p>

<pre><code class="language-bash">$ ./bin/docker-image-tool.sh -r &lt;repo&gt; -t my-tag build
$ ./bin/docker-image-tool.sh -r &lt;repo&gt; -t my-tag push
</code></pre>
<p>这将使用默认提供的项目进行构建<code>Dockerfiles</code> 。要查看更多可用于自定义此工具行为的选项，包括提供自定义<code>Dockerfiles</code> ，请运行<code>-h</code>旗。</p>

<p>默认<code>bin/docker-image-tool.sh</code>构建用于运行JVM作业的docker映像。您需要选择加入以构建其他语言绑定docker映像。</p>

<p>用法示例是</p>
<pre><code class="language-bash"># To build additional PySpark docker image
$ ./bin/docker-image-tool.sh -r &lt;repo&gt; -t my-tag -p ./kubernetes/dockerfiles/spark/bindings/python/Dockerfile build

# To build additional SparkR docker image
$ ./bin/docker-image-tool.sh -r &lt;repo&gt; -t my-tag -R ./kubernetes/dockerfiles/spark/bindings/R/Dockerfile build
</code></pre>

<h2 id="cluster-mode">集群模式</h2>

<p>要以群集模式启动Spark Pi，</p>

<pre><code class="language-bash">$ ./bin/spark-submit \
    --master k8s://https://&lt;k8s-apiserver-host&gt;:&lt;k8s-apiserver-port&gt; \
    --deploy-mode cluster \
    --name spark-pi \
    --class org.apache.spark.examples.SparkPi \
    --conf spark.executor.instances=5 \
    --conf spark.kubernetes.container.image=&lt;spark-image&gt; \
    local:///path/to/examples.jar
</code></pre>

<p>Spark主机，通过传递<code>--master</code>命令行参数<code>spark-submit</code>或通过设置<code>spark.master</code>在应用程序的配置中，必须是具有以下格式的URL <code>k8s://<api_server_url></code> 。在主字符串前面加上<code>k8s://</code>将导致Spark应用程序在Kubernetes集群上启动，并通过以下网址联系API服务器<code>api_server_url</code> 。如果URL中未指定HTTP协议，则默认为<code>https</code> 。例如，将母版设置为<code>k8s://example.com:443</code>等同于将其设置为<code>k8s://https://example.com:443</code> ，但要在其他端口上不使用TLS进行连接，则将主服务器设置为<code>k8s://http://example.com:8080</code> 。</p>

<p>在Kubernetes模式下，指定的Spark应用程序名称<code>spark.app.name</code>或者<code>--name</code>争论<code>spark-submit</code>默认情况下用于命名驱动程序和执行程序等创建的Kubernetes资源。因此，应用程序名称必须由小写字母数字字符组成， <code>-</code>和<code>.</code>并且必须以字母数字字符开头和结尾。</p>

<p>如果您有Kubernetes集群设置，发现apiserver URL的一种方法是通过执行<code>kubectl cluster-info</code> 。</p>

<pre><code class="language-bash">$ kubectl cluster-info
Kubernetes master is running at http://127.0.0.1:6443
</code></pre>

<p>在上面的示例中，特定的Kubernetes集群可以与<code>spark-submit</code>通过指定<code>--master k8s://http://127.0.0.1:6443</code>作为提交火花的参数。此外，还可以使用身份验证代理， <code>kubectl proxy</code>与Kubernetes API进行通信。</p>

<p>本地代理可以通过以下方式启动：</p>

<pre><code class="language-bash">$ kubectl proxy
</code></pre>

<p>如果本地代理运行在localhost：8001， <code>--master k8s://http://127.0.0.1:8001</code>可以用作spark-submit的参数。最后，请注意，在上面的示例中，我们使用以下方案指定了具有特定URI的jar <code>local://</code> 。该URI是Docker映像中已经存在的示例jar的位置。</p>

<h2 id="client-mode">客户端模式</h2>

<p>从Spark 2.4.0开始，可以在客户端模式下在Kubernetes上运行Spark应用程序。当您的应用程序在客户端模式下运行时，驱动程序可以在pod内或物理主机上运行。在客户端模式下运行应用程序时，建议考虑以下因素：</p>

<h3 id="client-mode-networking">客户端模式网络</h3>

<p>Spark执行程序必须能够通过主机名和可从Spark执行程序路由的端口连接到Spark驱动程序。Spark在客户端模式下工作所需的特定网络配置因设置而异。如果您在Kubernetes容器中运行驱动程序，则可以使用<a href="https://kubernetes.io/docs/concepts/services-networking/service/#headless-services">无头服务</a>使驱动程序容器可以通过稳定的主机名从执行程序进行路由。部署无头服务时，请确保服务的标签选择器仅与驱动程序容器匹配，而与其他容器不匹配；建议为您的驾驶舱分配足够唯一的标签，并在无头服务的标签选择器中使用该标签。通过指定驱动程序的主机名<code>spark.driver.host</code>和您的火花驱动程序的端口<code>spark.driver.port</code> 。</p>

<h3 id="client-mode-executor-pod-garbage-collection">客户端模式执行器Pod垃圾回收</h3>

<p>如果您在Pod中运行Spark驱动程序，强烈建议您进行设置<code>spark.kubernetes.driver.pod.name</code>那个豆荚的名字设置此属性后，Spark调度程序将使用<a href="https://kubernetes.io/docs/concepts/workloads/controllers/garbage-collection/">OwnerReference</a>部署执行程序容器，这又将确保一旦从群集中删除了驱动程序容器，所有应用程序的执行程序容器也将被删除。驱动程序将在由指定的名称空间中查找具有给定名称的Pod <code>spark.kubernetes.namespace</code> ，并且指向该容器的OwnerReference将添加到每个执行者容器的OwnerReferences列表中。小心避免将OwnerReference设置为实际上不是该驱动程序容器的容器，否则当删除错误的容器时，执行器可能会过早终止。</p>

<p>如果您的应用程序不在Pod内运行，或者<code>spark.kubernetes.driver.pod.name</code>当您的应用程序实际在Pod中运行时，未设置。请记住，当应用程序退出时，执行者Pod可能无法从群集中正确删除。Spark调度程序会尝试删除这些Pod，但是如果由于任何原因对API服务器的网络请求失败，这些Pod将保留在群集中。执行程序进程在无法到达驱动程序时应退出，因此执行程序窗格不应在应用程序退出后消耗群集中的计算资源（cpu和内存）。</p>

<h3 id="authentication-parameters">认证参数</h3>

<p>使用确切的前缀<code>spark.kubernetes.authenticate</code>客户端模式下的Kubernetes身份验证参数。</p>

<h2 id="dependency-management">依赖管理</h2>

<p>如果您的应用程序的依赖项全部托管在HDFS或HTTP服务器等远程位置，则可以通过其相应的远程URI来引用它们。同样，可以将应用程序依赖项预先安装到定制的Docker映像中。可以通过使用以下引用将这些依赖项添加到类路径中<code>local://</code> URI和/或设置<code>SPARK_EXTRA_CLASSPATH</code> Dockerfile中的环境变量。的<code>local://</code>在自定义Docker映像中引用依赖项时，也需要使用scheme <code>spark-submit</code> 。我们支持使用以下命令来自提交客户端本地文件系统的依赖项： <code>file://</code>方案或没有方案（使用完整路径），其中目标应为Hadoop兼容文件系统。使用S3的一个典型示例是通过传递以下选项：</p>

<pre><code>...
--packages com.amazonaws:aws-java-sdk:1.7.4,org.apache.hadoop:hadoop-aws:2.7.6
--conf spark.kubernetes.file.upload.path=s3a://&lt;s3-bucket&gt;/path
--conf spark.hadoop.fs.s3a.access.key=...
--conf spark.hadoop.fs.s3a.impl=org.apache.hadoop.fs.s3a.S3AFileSystem
--conf spark.hadoop.fs.s3a.fast.upload=true
--conf spark.hadoop.fs.s3a.secret.key=....
--conf spark.driver.extraJavaOptions=-Divy.cache.dir=/tmp -Divy.home=/tmp
file:///full/path/to/app.jar
</code></pre>
<p>该应用程序jar文件将上传到S3，然后在启动驱动程序时将其下载到驱动程序窗格并添加到其类路径中。Spark将在上传路径下生成一个带有随机名称的子目录，以避免与并行运行的Spark应用程序发生冲突。用户可以根据自己的需要管理创建的子目录。</p>

<p>应用程序jar支持客户端方案，并且属性指定了依赖项<code>spark.jars</code>和<code>spark.files</code> 。</p>

<p>重要提示：所有客户端依赖项都将使用平面目录结构上载到给定路径，因此文件名必须唯一，否则文件将被覆盖。另外，请确保在派生的k8s映像中，默认的ivy目录具有所需的访问权限，或如上所述进行设置更改。后者也很重要，如果您使用<code>--packages</code>在群集模式下。</p>

<h2 id="secret-management">秘密管理</h2>
<p>Kubernetes <a href="https://kubernetes.io/docs/concepts/configuration/secret/">Secrets</a>可用于为Spark应用程序提供凭据以访问安全服务。要将用户指定的机密安装到驱动程序容器中，用户可以使用表单的配置属性<code>spark.kubernetes.driver.secrets.[SecretName]=<mount path></code> 。同样，表单的配置属性<code>spark.kubernetes.executor.secrets.[SecretName]=<mount path></code>可用于将用户指定的机密装入执行程序容器。请注意，假定要安装的机密与驱动程序和执行程序容器的机密位于同一命名空间中。例如，挂载一个名为<code>spark-secret</code>上路<code>/etc/secrets</code>在驱动程序和执行程序容器中，将以下选项添加到<code>spark-submit</code>命令：</p>

<pre><code>--conf spark.kubernetes.driver.secrets.spark-secret=/etc/secrets
--conf spark.kubernetes.executor.secrets.spark-secret=/etc/secrets
</code></pre>

<p>要通过环境变量使用机密，请使用以下选项<code>spark-submit</code>命令：</p>
<pre><code>--conf spark.kubernetes.driver.secretKeyRef.ENV_NAME=name:key
--conf spark.kubernetes.executor.secretKeyRef.ENV_NAME=name:key
</code></pre>

<h2 id="pod-template">吊舱模板</h2>
<p>Kubernetes允许从<a href="https://kubernetes.io/docs/concepts/workloads/pods/pod-overview/#pod-templates">模板文件</a>定义Pod。Spark用户可以类似地使用模板文件来定义Spark配置不支持的驱动程序或执行程序pod配置。为此，请指定火花属性<code>spark.kubernetes.driver.podTemplateFile</code>和<code>spark.kubernetes.executor.podTemplateFile</code>指向可访问的本地文件<code>spark-submit</code>处理。为了允许驱动程序容器访问执行程序容器模板文件，该文件将在创建时自动安装到驱动程序容器中的卷上。解组这些模板文件后，Spark不会执行任何验证，而是依靠Kubernetes API服务器进行验证。</p>

<p>重要的是要注意，Spark会考虑某些Pod配置，因此Pod模板中的值将始终被Spark覆盖。因此，使用此功能的用户应注意，指定容器模板文件只能使Spark在容器构建过程中以模板容器开始，而不是空容器。有关详细信息，请参见将被spark覆盖的pod模板值的<a href="#pod-template-properties">完整列表</a> 。</p>

<p>Pod模板文件也可以定义多个容器。在这种情况下，您可以使用spark属性<code>spark.kubernetes.driver.podTemplateContainerName</code>和<code>spark.kubernetes.executor.podTemplateContainerName</code>指示应将哪个容器用作驱动程序或执行程序的基础。如果未指定，或者容器名称无效，Spark将假定列表中的第一个容器将是驱动程序或执行者容器。</p>

<h2 id="using-kubernetes-volumes">使用Kubernetes卷</h2>

<p>从Spark 2.4.0开始，用户可以将以下类型的Kubernetes <a href="https://kubernetes.io/docs/concepts/storage/volumes/">卷</a>挂载到驱动程序和执行程序容器中：</p>
<ul>
  <li><a href="https://kubernetes.io/docs/concepts/storage/volumes/#hostpath">hostPath</a> ：将主机节点文件系统中的文件或目录挂载到pod中。</li>
  <li><a href="https://kubernetes.io/docs/concepts/storage/volumes/#emptydir">emptyDir</a> ：将Pod分配给节点时创建的最初为空的卷。</li>
  <li><a href="https://kubernetes.io/docs/concepts/storage/volumes/#persistentvolumeclaim">persistentVolumeClaim</a> ：用于挂载<code>PersistentVolume</code>放入豆荚。</li>
</ul>

<p><strong>注：</strong>请参见<a href="#security">安全</a>这个文档相关卷安装安全问题的部分。</p>

<p>要将以上任何类型的卷安装到驱动程序窗格中，请使用以下配置属性：</p>

<pre><code>--conf spark.kubernetes.driver.volumes.[VolumeType].[VolumeName].mount.path=&lt;mount path&gt;
--conf spark.kubernetes.driver.volumes.[VolumeType].[VolumeName].mount.readOnly=&lt;true|false&gt;
--conf spark.kubernetes.driver.volumes.[VolumeType].[VolumeName].mount.subPath=&lt;mount subPath&gt;
</code></pre>

<p>特别， <code>VolumeType</code>可以是以下值之一： <code>hostPath</code> ， <code>emptyDir</code>和<code>persistentVolumeClaim</code> 。 <code>VolumeName</code>是您要用于该卷下的名称<code>volumes</code> Pod规范中的字段。</p>

<p>每种受支持的卷类型可能都有一些特定的配置选项，可以使用以下形式的配置属性来指定这些选项：</p>

<pre><code>spark.kubernetes.driver.volumes.[VolumeType].[VolumeName].options.[OptionName]=&lt;value&gt;
</code></pre>

<p>例如，a的声明名称<code>persistentVolumeClaim</code>卷名称<code>checkpointpvc</code>可以使用以下属性指定：</p>

<pre><code>spark.kubernetes.driver.volumes.persistentVolumeClaim.checkpointpvc.options.claimName=check-point-pvc-claim
</code></pre>

<p>用于将卷装载到执行程序容器中的配置属性使用前缀<code>spark.kubernetes.executor.</code>代替<code>spark.kubernetes.driver.</code> 。有关每种受支持的卷类型的可用选项的完整列表，请参阅下面的“ <a href="#spark-properties">Spark属性”</a>部分。</p>

<h2 id="local-storage">本地存储</h2>

<p>Spark支持使用卷在随机播放和其他操作期间溢出数据。要将卷用作本地存储，该卷的名称应以<code>spark-local-dir-</code> ， 例如：</p>

<pre><code>--conf spark.kubernetes.driver.volumes.[VolumeType].spark-local-dir-[VolumeName].mount.path=&lt;mount path&gt;
--conf spark.kubernetes.driver.volumes.[VolumeType].spark-local-dir-[VolumeName].mount.readOnly=false
</code></pre>

<p>如果未将任何卷设置为本地存储，Spark将在临时和其他操作期间使用临时暂存空间将数据溢出到磁盘上。当使用Kubernetes作为资源管理器时，将为每个列在其中的目录安装一个<a href="https://kubernetes.io/docs/concepts/storage/volumes/#emptydir">emptyDir</a>卷来创建<a href="https://kubernetes.io/docs/concepts/storage/volumes/#emptydir">Pod</a> <code>spark.local.dir</code>或环境变量<code>SPARK_LOCAL_DIRS</code> 。如果未明确指定目录，则将创建并适当配置默认目录。</p>

<p><code>emptyDir</code>卷使用Kubernetes的临时存储功能，并且不会在pod的生命周期内持续存在。</p>

<h3 id="using-ram-for-local-storage">使用RAM进行本地存储</h3>

<p><code>emptyDir</code>卷默认情况下将节点支持存储用于临时存储，此行为可能不适用于某些计算环境。例如，如果您的无盘节点通过网络安装了远程存储，那么让许多执行程序对此远程存储执行IO可能实际上会降低性能。</p>

<p>在这种情况下，可能需要设置<code>spark.kubernetes.local.dirs.tmpfs=true</code>在您的配置中，这将导致<code>emptyDir</code>要配置为的卷<code>tmpfs</code>即RAM支持的卷。像这样配置时，Spark的本地存储使用量将计入Pod的内存使用量，因此，您可能希望通过增加以下值来增加内存请求： <code>spark.kubernetes.memoryOverheadFactor</code>作为适当的。</p>

<h2 id="introspection-and-debugging">内省和调试</h2>

<p>这些是调查运行/已完成的Spark应用程序，监视进度并采取措施的不同方式。</p>

<h3 id="accessing-logs">访问日志</h3>

<p>可以使用Kubernetes API和<code>kubectl</code> CLI。当Spark应用程序运行时，可以使用以下命令从应用程序中流式传输日志：</p>

<pre><code class="language-bash">$ kubectl -n=&lt;namespace&gt; logs -f &lt;driver-pod-name&gt;
</code></pre>

<p>如果已安装在集群上，还可以通过<a href="https://kubernetes.io/docs/tasks/access-application-cluster/web-ui-dashboard/">Kubernetes仪表板</a>访问相同的日志。</p>

<h3 id="accessing-driver-ui">访问驱动程序用户界面</h3>

<p>可以使用以下命令在本地访问与任何应用程序关联的UI <a href="https://kubernetes.io/docs/tasks/access-application-cluster/port-forward-access-application-cluster/#forward-a-local-port-to-a-port-on-the-pod"><code>kubectl port-forward</code></a> 。</p>

<pre><code class="language-bash">$ kubectl port-forward &lt;driver-pod-name&gt; 4040:4040
</code></pre>

<p>然后，可以在以下位置访问Spark驱动程序UI <code>http://localhost:4040</code> 。</p>

<h3 id="debugging">调试</h3>

<p>可能有几种故障。如果Kubernetes API服务器拒绝来自spark-submit的请求，或者由于其他原因拒绝了连接，则提交逻辑应指示遇到的错误。但是，如果在应用程序运行期间出错，通常，最好的调查方法是通过Kubernetes CLI。</p>

<p>要获取有关围绕驱动程序窗格制定的调度决策的一些基本信息，可以运行：</p>

<pre><code class="language-bash">$ kubectl describe pod &lt;spark-driver-pod&gt;
</code></pre>

<p>如果pod遇到运行时错误，则可以使用以下方法进一步探测状态：</p>

<pre><code class="language-bash">$ kubectl logs &lt;spark-driver-pod&gt;
</code></pre>

<p>可以通过类似的方式检查失败的执行器容器的状态和日志。最后，删除驱动程序容器将清理整个spark应用程序，包括所有执行程序，关联的服务等。驱动程序容器可以视为Spark应用程序的Kubernetes表示形式。</p>

<h2 id="kubernetes-features">Kubernetes功能</h2>

<h3 id="configuration-file">配置文件</h3>

<p>您的Kubernetes配置文件通常位于<code>.kube/config</code>在您的主目录中或由<code>KUBECONFIG</code>环境变量。Kubernetes上的Spark将尝试使用此文件对用于与Kubernetes集群进行交互的Kubernetes客户端进行初始自动配置。提供了许多Spark配置属性，这些属性允许进一步自定义客户端配置，例如使用替代身份验证方法。</p>

<h3 id="contexts">语境</h3>

<p>Kubernetes配置文件可以包含多个上下文，这些上下文允许在不同的集群和/或用户身份之间切换。默认情况下，Kubernetes上的Spark将使用您当前的上下文（可以通过运行来检查<code>kubectl config current-context</code> ）进行Kubernetes客户端的初始自动配置时。</p>

<p>为了使用替代上下文，用户可以通过Spark配置属性指定所需的上下文<code>spark.kubernetes.context</code>例如<code>spark.kubernetes.context=minikube</code> 。</p>

<h3 id="namespaces">命名空间</h3>

<p>Kubernetes具有<a href="https://kubernetes.io/docs/concepts/overview/working-with-objects/namespaces/">名称空间</a>的概念。命名空间是在多个用户之间（通过资源配额）划分群集资源的方法。Kubernetes上的Spark可以使用名称空间来启动Spark应用程序。可以通过以下方式使用<code>spark.kubernetes.namespace</code>组态。</p>

<p>Kubernetes允许使用<a href="https://kubernetes.io/docs/concepts/policy/resource-quotas/">ResourceQuota</a>在单个名称空间上设置资源，对象数量等的限制。管理员可以结合使用命名空间和ResourceQuota，以控制运行Spark应用程序的Kubernetes集群中的共享和资源分配。</p>

<h3 id="rbac">RBAC</h3>

<p>在启用了<a href="https://kubernetes.io/docs/admin/authorization/rbac/">RBAC的</a> Kubernetes集群中，用户可以配置Kubernetes各种Spark所使用的Kubernetes RBAC角色和服务帐户，以访问Kubernetes API服务器。</p>

<p>Spark驱动程序容器使用Kubernetes服务帐户访问Kubernetes API服务器以创建和监视执行程序容器。驾驶员吊舱使用的服务帐户必须具有适当的权限，驾驶员才能进行其工作。具体来说，至少必须为服务帐户授予<a href="https://kubernetes.io/docs/admin/authorization/rbac/#role-and-clusterrole"><code>Role</code>要么<code>ClusterRole</code></a>允许驾驶员吊舱创建吊舱和服务。默认情况下，将自动为驾驶员吊舱分配<code>default</code>指定的名称空间中的服务帐户<code>spark.kubernetes.namespace</code> ，如果在创建广告连播时未指定任何服务帐户。</p>

<p>根据部署的Kubernetes的版本和设置，这<code>default</code>服务帐户可能具有或不具有允许驱动程序Pod在默认Kubernetes <a href="https://kubernetes.io/docs/admin/authorization/rbac/">RBAC</a>策略下创建Pod和服务的<a href="https://kubernetes.io/docs/admin/authorization/rbac/">角色</a> 。有时，用户可能需要指定具有正确角色的自定义服务帐户。Kubernetes上的Spark支持通过配置属性指定驱动程序pod使用的自定义服务帐户<code>spark.kubernetes.authenticate.driver.serviceAccountName=<service account name></code> 。例如，要使驾驶员吊舱使用<code>spark</code>服务帐户，用户只需将以下选项添加到<code>spark-submit</code>命令：</p>

<pre><code>--conf spark.kubernetes.authenticate.driver.serviceAccountName=spark
</code></pre>

<p>要创建自定义服务帐户，用户可以使用<code>kubectl create serviceaccount</code>命令。例如，以下命令创建一个服务帐户，名称为<code>spark</code> ：</p>

<pre><code class="language-bash">$ kubectl create serviceaccount spark
</code></pre>

<p>授予服务帐户<code>Role</code>要么<code>ClusterRole</code> ， 一种<code>RoleBinding</code>要么<code>ClusterRoleBinding</code>是必需的。创建一个<code>RoleBinding</code>要么<code>ClusterRoleBinding</code> ，用户可以使用<code>kubectl create rolebinding</code> （要么<code>clusterrolebinding</code>对于<code>ClusterRoleBinding</code> ）命令。例如，以下命令将创建一个<code>edit</code><code>ClusterRole</code>在里面<code>default</code>命名空间并将其授予<code>spark</code>上面创建的服务帐户：</p>

<pre><code class="language-bash">$ kubectl create clusterrolebinding spark-role --clusterrole=edit --serviceaccount=default:spark --namespace=default
</code></pre>

<p>请注意<code>Role</code>只能用于授予对单个名称空间内资源（如Pod）的访问权限，而<code>ClusterRole</code>可以用于授予对所有命名空间中群集范围内的资源（例如节点）以及命名空间资源（例如pod）的访问。对于Kubernetes上的Spark，由于驱动程序始终在同一名称空间中创建执行程序容器，因此<code>Role</code>尽管用户可以使用<code>ClusterRole</code>代替。有关RBAC授权以及如何为Pod配置Kubernetes服务帐户的更多信息，请参阅<a href="https://kubernetes.io/docs/admin/authorization/rbac/">使用RBAC授权</a>和为Pod <a href="https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/">配置服务帐户</a> 。</p>

<h2 id="spark-application-management">Spark应用程序管理</h2>

<p>Kubernetes通过集群模式下的spark-submit CLI工具提供了简单的应用程序管理。用户可以通过提供在提交作业时打印的提交ID来取消作业。提交ID遵循以下格式<code>namespace:driver-pod-name</code> 。如果用户省略了名称空间，则使用在当前k8s上下文中设置的名称空间。例如，如果用户设置了特定的命名空间，如下所示<code>kubectl config set-context minikube --namespace=spark</code>然后<code>spark</code>命名空间将默认使用。另一方面，如果没有将命名空间添加到特定上下文，则默认情况下将考虑所有命名空间。这意味着无论命名空间如何，操作都会影响与给定提交ID匹配的所有Spark应用程序。此外，用于应用程序管理的spark-submit使用与提交驱动程序相同的后端代码，因此相同的属性如<code>spark.kubernetes.context</code>等，可以重复使用。</p>

<p>例如：</p>
<pre><code class="language-bash">$ spark-submit --kill spark:spark-pi-1547948636094-driver --master k8s://https://192.168.2.8:8443
</code></pre>
<p>用户还可以使用以下命令列出应用程序状态<code>--status</code>旗：</p>

<pre><code class="language-bash">$ spark-submit --status spark:spark-pi-1547948636094-driver --master  k8s://https://192.168.2.8:8443
</code></pre>
<p>两种操作都支持全局模式。例如，用户可以运行：</p>
<pre><code class="language-bash">$ spark-submit --kill spark:spark-pi* --master  k8s://https://192.168.2.8:8443
</code></pre>
<p>上面的命令将杀死所有带有特定前缀的应用程序。</p>

<p>用户可以通过以下方式指定吊舱终止的宽限期<code>spark.kubernetes.appKillPodDeletionGracePeriod</code>属性，使用<code>--conf</code>作为提供它的方式（所有K8s Pod的默认值为<a href="https://kubernetes.io/docs/concepts/workloads/pods/pod">30秒</a> ）。</p>

<h2 id="future-work">未来的工作</h2>

<p>Kubernetes上有几种Spark功能目前正在使用或计划要使用。这些功能有望最终将其纳入spark-kubernetes集成的未来版本中。</p>

<p>其中一些包括：</p>

<ul>
  <li>动态资源分配和外部随机播放服务</li>
  <li>作业队列和资源管理</li>
</ul>

<h1 id="configuration">组态</h1>

<p>有关Spark配置的信息，请参阅<a href="configuration.html">配置页面</a> 。以下配置特定于Kubernetes上的Spark。</p>

<h4 id="spark-properties">火花特性</h4>

<table class="table">
<tbody><tr><th>物业名称</th><th>默认</th><th>含义</th></tr>
<tr>
  <td><code>spark.kubernetes.context</code></td>
  <td><code>(none)</code></td>
  <td>用户Kubernetes配置文件中的上下文，用于Kubernetes客户端库的初始自动配置。如果未指定，则使用用户当前上下文。<strong>注意：</strong>许多自动配置的设置可以通过使用其他Spark配置属性来覆盖，例如<code>spark.kubernetes.namespace</code> 。
  </td>
</tr>
<tr>
  <td><code>spark.kubernetes.namespace</code></td>
  <td><code>default</code></td>
  <td>将用于运行驱动程序和执行程序容器的名称空间。
  </td>
</tr>
<tr>
  <td><code>spark.kubernetes.container.image</code></td>
  <td><code>(none)</code></td>
  <td>用于Spark应用程序的容器映像。通常是这样的形式<code>example.com/repo/spark:v1.0.0</code> 。除非为每种不同的容器类型提供了明确的图像，否则此配置是必需的，并且必须由用户提供。
  </td>
</tr>
<tr>
  <td><code>spark.kubernetes.driver.container.image</code></td>
  <td><code>(value of spark.kubernetes.container.image)</code></td>
  <td>用于驱动程序的自定义容器映像。
  </td>
</tr>
<tr>
  <td><code>spark.kubernetes.executor.container.image</code></td>
  <td><code>(value of spark.kubernetes.container.image)</code></td>
  <td>供执行者使用的自定义容器映像。
  </td>
</tr>
<tr>
  <td><code>spark.kubernetes.container.image.pullPolicy</code></td>
  <td><code>IfNotPresent</code></td>
  <td>在Kubernetes中提取映像时使用的容器映像提取策略。
  </td>
</tr>
<tr>
  <td><code>spark.kubernetes.container.image.pullSecrets</code></td>
  <td><code></code></td>
  <td>用逗号分隔的Kubernetes机密列表，用于从私有映像注册表中提取映像。
  </td>
</tr>
<tr>
  <td><code>spark.kubernetes.allocation.batch.size</code></td>
  <td><code>5</code></td>
  <td>在每轮执行者Pod分配中一次要启动的Pod数。
  </td>
</tr>
<tr>
  <td><code>spark.kubernetes.allocation.batch.delay</code></td>
  <td><code>1s</code></td>
  <td>在每轮执行程序pod分配之间等待的时间。指定小于1秒的值可能会导致Spark驱动程序上的CPU使用率过高。
  </td>
</tr>
<tr>
  <td><code>spark.kubernetes.authenticate.submission.caCertFile</code></td>
  <td>（没有）</td>
  <td>启动驱动程序时用于通过TLS连接到Kubernetes API服务器的CA证书文件的路径。该文件必须位于提交计算机的磁盘上。将其指定为与URI相对的路径（即不提供方案）。在客户端模式下，使用<code>spark.kubernetes.authenticate.caCertFile</code>代替。
  </td>
</tr>
<tr>
  <td><code>spark.kubernetes.authenticate.submission.clientKeyFile</code></td>
  <td>（没有）</td>
  <td>启动驱动程序时用于根据Kubernetes API服务器进行身份验证的客户端密钥文件的路径。该文件必须位于提交计算机的磁盘上。将其指定为与URI相对的路径（即不提供方案）。在客户端模式下，使用<code>spark.kubernetes.authenticate.clientKeyFile</code>代替。
  </td>
</tr>
<tr>
  <td><code>spark.kubernetes.authenticate.submission.clientCertFile</code></td>
  <td>（没有）</td>
  <td>启动驱动程序时用于针对Kubernetes API服务器进行身份验证的客户端证书文件的路径。该文件必须位于提交计算机的磁盘上。将其指定为与URI相对的路径（即不提供方案）。在客户端模式下，使用<code>spark.kubernetes.authenticate.clientCertFile</code>代替。
  </td>
</tr>
<tr>
  <td><code>spark.kubernetes.authenticate.submission.oauthToken</code></td>
  <td>（没有）</td>
  <td>启动驱动程序时对Kubernetes API服务器进行身份验证时使用的OAuth令牌。请注意，与其他身份验证选项不同，它应该是用于身份验证的令牌的确切字符串值。在客户端模式下，使用<code>spark.kubernetes.authenticate.oauthToken</code>代替。
  </td>
</tr>
<tr>
  <td><code>spark.kubernetes.authenticate.submission.oauthTokenFile</code></td>
  <td>（没有）</td>
  <td>OAuth令牌文件的路径，其中包含在启动驱动程序时根据Kubernetes API服务器进行身份验证时使用的令牌。该文件必须位于提交计算机的磁盘上。将其指定为与URI相对的路径（即不提供方案）。在客户端模式下，使用<code>spark.kubernetes.authenticate.oauthTokenFile</code>代替。
  </td>
</tr>
<tr>
  <td><code>spark.kubernetes.authenticate.driver.caCertFile</code></td>
  <td>（没有）</td>
  <td>请求执行者时，用于通过TLS从驱动程序窗格通过TLS连接到Kubernetes API服务器的CA证书文件的路径。该文件必须位于提交计算机的磁盘上，并将被上传到驱动程序窗格。将其指定为与URI相对的路径（即不提供方案）。在客户端模式下，使用<code>spark.kubernetes.authenticate.caCertFile</code>代替。
  </td>
</tr>
<tr>
  <td><code>spark.kubernetes.authenticate.driver.clientKeyFile</code></td>
  <td>（没有）</td>
  <td>客户端密钥文件的路径，用于在请求执行程序时从驱动程序窗格对Kubernetes API服务器进行身份验证。该文件必须位于提交计算机的磁盘上，并将作为Kubernetes机密上载到驱动程序窗格。将其指定为与URI相对的路径（即不提供方案）。在客户端模式下，使用<code>spark.kubernetes.authenticate.clientKeyFile</code>代替。
  </td>
</tr>
<tr>
  <td><code>spark.kubernetes.authenticate.driver.clientCertFile</code></td>
  <td>（没有）</td>
  <td>客户端证书文件的路径，用于在请求执行者时从驱动程序窗格对Kubernetes API服务器进行身份验证。该文件必须位于提交计算机的磁盘上，并将作为Kubernetes机密上载到驱动程序窗格。将其指定为与URI相对的路径（即不提供方案）。在客户端模式下，使用<code>spark.kubernetes.authenticate.clientCertFile</code>代替。
  </td>
</tr>
<tr>
  <td><code>spark.kubernetes.authenticate.driver.oauthToken</code></td>
  <td>（没有）</td>
  <td>请求执行程序时从驱动程序窗格对Kubernetes API服务器进行身份验证时使用的OAuth令牌。请注意，与其他身份验证选项不同，这必须是用于身份验证的令牌的确切字符串值。该令牌值作为Kubernetes秘密上载到驱动程序窗格。在客户端模式下，使用<code>spark.kubernetes.authenticate.oauthToken</code>代替。
  </td>
</tr>
<tr>
  <td><code>spark.kubernetes.authenticate.driver.oauthTokenFile</code></td>
  <td>（没有）</td>
  <td>OAuth令牌文件的路径，其中包含在请求执行者时从驱动程序窗格对Kubernetes API服务器进行身份验证时使用的令牌。请注意，与其他身份验证选项不同，此文件必须包含用于身份验证的令牌的确切字符串值。此令牌值作为秘密上传到驱动程序窗格。在客户端模式下，使用<code>spark.kubernetes.authenticate.oauthTokenFile</code>代替。
  </td>
</tr>
<tr>
  <td><code>spark.kubernetes.authenticate.driver.mounted.caCertFile</code></td>
  <td>（没有）</td>
  <td>请求执行者时，用于通过TLS从驱动程序窗格通过TLS连接到Kubernetes API服务器的CA证书文件的路径。必须从驱动程序窗格访问此路径。将其指定为与URI相对的路径（即不提供方案）。在客户端模式下，使用<code>spark.kubernetes.authenticate.caCertFile</code>代替。
  </td>
</tr>
<tr>
  <td><code>spark.kubernetes.authenticate.driver.mounted.clientKeyFile</code></td>
  <td>（没有）</td>
  <td>客户端密钥文件的路径，用于在请求执行程序时从驱动程序窗格对Kubernetes API服务器进行身份验证。必须从驱动程序窗格访问此路径。将其指定为与URI相对的路径（即不提供方案）。在客户端模式下，使用<code>spark.kubernetes.authenticate.clientKeyFile</code>代替。
  </td>
</tr>
<tr>
  <td><code>spark.kubernetes.authenticate.driver.mounted.clientCertFile</code></td>
  <td>（没有）</td>
  <td>客户端证书文件的路径，用于在请求执行程序时从驱动程序窗格对Kubernetes API服务器进行身份验证。必须从驱动程序窗格访问此路径。将其指定为与URI相对的路径（即不提供方案）。在客户端模式下，使用<code>spark.kubernetes.authenticate.clientCertFile</code>代替。
  </td>
</tr>
<tr>
  <td><code>spark.kubernetes.authenticate.driver.mounted.oauthTokenFile</code></td>
  <td>（没有）</td>
  <td>请求执行者时从驱动程序窗格对Kubernetes API服务器进行身份验证时使用的包含OAuth令牌的文件的路径。必须从驱动程序窗格访问此路径。请注意，与其他身份验证选项不同，此文件必须包含用于身份验证的令牌的确切字符串值。在客户端模式下，使用<code>spark.kubernetes.authenticate.oauthTokenFile</code>代替。
  </td>
</tr>
<tr>
  <td><code>spark.kubernetes.authenticate.driver.serviceAccountName</code></td>
  <td><code>default</code></td>
  <td>运行驱动程序窗格时使用的服务帐户。当从API服务器请求执行者Pod时，驱动程序Pod使用此服务帐户。请注意，这不能与CA证书文件，客户端密钥文件，客户端证书文件和/或OAuth令牌一起指定。在客户端模式下，使用<code>spark.kubernetes.authenticate.serviceAccountName</code>代替。
  </td>
</tr>
<tr>
  <td><code>spark.kubernetes.authenticate.caCertFile</code></td>
  <td>（没有）</td>
  <td>在客户端模式下，当请求执行程序时，用于通过TLS连接到Kubernetes API服务器的CA证书文件的路径。将其指定为与URI相对的路径（即不提供方案）。
  </td>
</tr>
<tr>
  <td><code>spark.kubernetes.authenticate.clientKeyFile</code></td>
  <td>（没有）</td>
  <td>在客户端模式下，为客户端密钥文件的路径，用于在请求执行程序时根据Kubernetes API服务器进行身份验证。将其指定为与URI相对的路径（即不提供方案）。
  </td>
</tr>
<tr>
  <td><code>spark.kubernetes.authenticate.clientCertFile</code></td>
  <td>（没有）</td>
  <td>在客户端模式下，为客户端cert文件的路径，用于在请求执行者时针对Kubernetes API服务器进行身份验证。将其指定为与URI相对的路径（即不提供方案）。
  </td>
</tr>
<tr>
  <td><code>spark.kubernetes.authenticate.oauthToken</code></td>
  <td>（没有）</td>
  <td>在客户端模式下，当请求执行者对Kubernetes API服务器进行身份验证时要使用的OAuth令牌。请注意，与其他身份验证选项不同，这必须是用于身份验证的令牌的确切字符串值。
  </td>
</tr>
<tr>
  <td><code>spark.kubernetes.authenticate.oauthTokenFile</code></td>
  <td>（没有）</td>
  <td>在客户端模式下，指向包含OAuth令牌的文件的路径，该令牌将在请求执行者时针对Kubernetes API服务器进行身份验证时使用。
  </td>
</tr>
<tr>
  <td><code>spark.kubernetes.driver.label.[LabelName]</code></td>
  <td>（没有）</td>
  <td>添加标签由<code>LabelName</code>到驾驶员吊舱。例如， <code>spark.kubernetes.driver.label.something=true</code> 。请注意，Spark还为驱动程序窗格添加了自己的标签，以进行簿记。
  </td>
</tr>
<tr>
  <td><code>spark.kubernetes.driver.annotation.[AnnotationName]</code></td>
  <td>（没有）</td>
  <td>添加由指定的注释<code>AnnotationName</code>到驾驶员吊舱。例如， <code>spark.kubernetes.driver.annotation.something=true</code> 。
  </td>
</tr>
<tr>
  <td><code>spark.kubernetes.executor.label.[LabelName]</code></td>
  <td>（没有）</td>
  <td>添加标签由<code>LabelName</code>到执行者吊舱。例如， <code>spark.kubernetes.executor.label.something=true</code> 。请注意，Spark还将其自己的标签添加到执行者窗格以进行簿记。
  </td>
</tr>
<tr>
  <td><code>spark.kubernetes.executor.annotation.[AnnotationName]</code></td>
  <td>（没有）</td>
  <td>添加由指定的注释<code>AnnotationName</code>到执行者吊舱。例如， <code>spark.kubernetes.executor.annotation.something=true</code> 。
  </td>
</tr>
<tr>
  <td><code>spark.kubernetes.driver.pod.name</code></td>
  <td>（没有）</td>
  <td>驱动程序窗格的名称。在群集模式下，如果未设置，则将驱动程序容器名称设置为当前时间戳后缀为“ spark.app.name”，以避免名称冲突。在客户端模式下，如果您的应用程序在Pod中运行，则强烈建议将其设置为驱动程序在其中运行的Pod的名称。在客户端模式下设置此值可使驱动程序成为其执行程序容器的所有者，这又使群集可以对执行程序容器进行垃圾收集。
  </td>
</tr>
<tr>
  <td><code>spark.kubernetes.executor.lostCheck.maxAttempts</code></td>
  <td><code>10</code></td>
  <td>驾驶员尝试确定特定执行者损失原因的次数。丢失原因用于确定执行器失败是由于框架还是应用程序错误引起的，而框架或应用程序错误又决定是将执行器删除和替换，还是置于调试失败的状态。
  </td>
</tr>
<tr>
  <td><code>spark.kubernetes.submission.waitAppCompletion</code></td>
  <td><code>true</code></td>
  <td>在集群模式下，是否等待应用程序完成后再退出启动程序进程。更改为false时，启动器在启动Spark作业时具有“即发即弃”的行为。
  </td>
</tr>
<tr>
  <td><code>spark.kubernetes.report.interval</code></td>
  <td><code>1s</code></td>
  <td>集群模式下当前Spark作业状态的报告之间的间隔。
  </td>
</tr>
<tr>
  <td><code>spark.kubernetes.driver.request.cores</code></td>
  <td>（没有）</td>
  <td>为驱动程序窗格指定cpu请求。值符合Kubernetes <a href="https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/#meaning-of-cpu">约定</a> 。示例值包括0.1，500米，1.5％，5等，具有的中记录CPU单元的定义<a href="https://kubernetes.io/docs/tasks/configure-pod-container/assign-cpu-resource/#cpu-units">CPU单位</a> 。这优先于<code>spark.driver.cores</code>用于指定驱动程序pod cpu请求（如果已设置）。
  </td>
</tr>
<tr>
  <td><code>spark.kubernetes.driver.limit.cores</code></td>
  <td>（没有）</td>
  <td>为驱动程序窗格指定硬性cpu <a href="https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/#resource-requests-and-limits-of-pod-and-container">限制</a> 。
  </td>
</tr>
<tr>
  <td><code>spark.kubernetes.executor.request.cores</code></td>
  <td>（没有）</td>
  <td>为每个执行程序pod指定cpu请求。值符合Kubernetes <a href="https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/#meaning-of-cpu">约定</a> 。示例值包括0.1，500米，1.5％，5等，具有的中记录CPU单元的定义<a href="https://kubernetes.io/docs/tasks/configure-pod-container/assign-cpu-resource/#cpu-units">CPU单位</a> 。这与<code>spark.executor.cores</code> ：仅用于并且优先于<code>spark.executor.cores</code>用于指定执行程序pod cpu请求（如果已设置）。任务并行性（例如，执行者可以同时运行的任务数）不受此影响。
  </td>
</tr>
<tr>
  <td><code>spark.kubernetes.executor.limit.cores</code></td>
  <td>（没有）</td>
  <td>为为Spark应用程序启动的每个执行程序容器指定一个硬cpu <a href="https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/#resource-requests-and-limits-of-pod-and-container">限制</a> 。
  </td>
</tr>
<tr>
  <td><code>spark.kubernetes.node.selector.[labelKey]</code></td>
  <td>（没有）</td>
  <td>使用键将其添加到驱动程序窗格和执行程序窗格的节点选择器中<code>labelKey</code>并将该值作为配置的值。例如，设置<code>spark.kubernetes.node.selector.identifier</code>至<code>myIdentifier</code>将导致驱动程序窗格和执行程序具有带有键的节点选择器<code>identifier</code>和价值<code>myIdentifier</code> 。通过使用此前缀设置多个配置，可以添加多个节点选择器键。
  </td>
</tr>
<tr>
  <td><code>spark.kubernetes.driverEnv.[EnvironmentVariableName]</code></td>
  <td>（没有）</td>
  <td>添加环境变量指定<code>EnvironmentVariableName</code>到驱动程序过程。用户可以指定多个以设置多个环境变量。
  </td>
</tr>
<tr>
  <td><code>spark.kubernetes.driver.secrets.[SecretName]</code></td>
  <td>（没有）</td>
  <td>添加名为的<a href="https://kubernetes.io/docs/concepts/configuration/secret/">Kubernetes Secret</a> <code>SecretName</code>到值中指定的路径上的驱动程序窗格。例如， <code>spark.kubernetes.driver.secrets.spark-secret=/etc/secrets</code> 。
  </td>
</tr>
<tr>
  <td><code>spark.kubernetes.executor.secrets.[SecretName]</code></td>
  <td>（没有）</td>
  <td>添加名为的<a href="https://kubernetes.io/docs/concepts/configuration/secret/">Kubernetes Secret</a> <code>SecretName</code>值中指定的路径上的执行程序窗格。例如， <code>spark.kubernetes.executor.secrets.spark-secret=/etc/secrets</code> 。
  </td>
</tr>
<tr>
  <td><code>spark.kubernetes.driver.secretKeyRef.[EnvName]</code></td>
  <td>（没有）</td>
  <td>作为名称为EnvName（区分大小写）的环境变量添加到驱动程序容器中，该值由key引用<code>key</code>在引用的<a href="https://kubernetes.io/docs/concepts/configuration/secret/#using-secrets-as-environment-variables">Kubernetes Secret</a>的数据中。例如， <code>spark.kubernetes.driver.secretKeyRef.ENV_VAR=spark-secret:key</code> 。
  </td>
</tr>
<tr>
  <td><code>spark.kubernetes.executor.secretKeyRef.[EnvName]</code></td>
  <td>（没有）</td>
  <td>将名称为EnvName（区分大小写）的环境变量作为环境变量添加到执行器容器中，该值由键引用<code>key</code>在引用的<a href="https://kubernetes.io/docs/concepts/configuration/secret/#using-secrets-as-environment-variables">Kubernetes Secret</a>的数据中。例如， <code>spark.kubernetes.executor.secrets.ENV_VAR=spark-secret:key</code> 。
  </td>
</tr>   
<tr>
  <td><code>spark.kubernetes.driver.volumes.[VolumeType].[VolumeName].mount.path</code></td>
  <td>（没有）</td>
  <td>添加名为的<a href="https://kubernetes.io/docs/concepts/storage/volumes/">Kubernetes卷</a> <code>VolumeName</code>的<code>VolumeType</code>在值指定的路径上键入驱动程序窗格。例如， <code>spark.kubernetes.driver.volumes.persistentVolumeClaim.checkpointpvc.mount.path=/checkpoint</code> 。
  </td>
</tr>
<tr>
  <td><code>spark.kubernetes.driver.volumes.[VolumeType].[VolumeName].mount.subPath</code></td>
  <td>（没有）</td>
  <td>指定要从卷装入驱动程序容器的<a href="https://kubernetes.io/docs/concepts/storage/volumes/#using-subpath">子路径</a> 。
   <code>spark.kubernetes.driver.volumes.persistentVolumeClaim.checkpointpvc.mount.subPath=checkpoint</code> 。
  </td>
</tr>
<tr>
  <td><code>spark.kubernetes.driver.volumes.[VolumeType].[VolumeName].mount.readOnly</code></td>
  <td>（没有）</td>
  <td>指定安装的卷是否为只读。例如， <code>spark.kubernetes.driver.volumes.persistentVolumeClaim.checkpointpvc.mount.readOnly=false</code> 。
  </td>
</tr>
<tr>
  <td><code>spark.kubernetes.driver.volumes.[VolumeType].[VolumeName].options.[OptionName]</code></td>
  <td>（没有）</td>
  <td>配置传递给Kubernetes的<a href="https://kubernetes.io/docs/concepts/storage/volumes/">Kubernetes Volume</a>选项<code>OptionName</code>作为具有指定值的键，必须符合Kubernetes选项格式。例如， <code>spark.kubernetes.driver.volumes.persistentVolumeClaim.checkpointpvc.options.claimName=spark-pvc-claim</code> 。
  </td>
</tr>
<tr>
  <td><code>spark.kubernetes.executor.volumes.[VolumeType].[VolumeName].mount.path</code></td>
  <td>（没有）</td>
  <td>添加名为的<a href="https://kubernetes.io/docs/concepts/storage/volumes/">Kubernetes卷</a> <code>VolumeName</code>的<code>VolumeType</code>在值中指定的路径上键入执行程序窗格。例如， <code>spark.kubernetes.executor.volumes.persistentVolumeClaim.checkpointpvc.mount.path=/checkpoint</code> 。
  </td>
</tr>
<tr>
  <td><code>spark.kubernetes.executor.volumes.[VolumeType].[VolumeName].mount.subPath</code></td>
  <td>（没有）</td>
  <td>指定要从卷装入执行程序容器的<a href="https://kubernetes.io/docs/concepts/storage/volumes/#using-subpath">子路径</a> 。
   <code>spark.kubernetes.executor.volumes.persistentVolumeClaim.checkpointpvc.mount.subPath=checkpoint</code> 。
  </td>
</tr>
<tr>
  <td><code>spark.kubernetes.executor.volumes.[VolumeType].[VolumeName].mount.readOnly</code></td>
  <td>假</td>
  <td>指定安装的卷是否为只读。例如， <code>spark.kubernetes.executor.volumes.persistentVolumeClaim.checkpointpvc.mount.readOnly=false</code> 。
  </td>
</tr>
<tr>
  <td><code>spark.kubernetes.executor.volumes.[VolumeType].[VolumeName].options.[OptionName]</code></td>
  <td>（没有）</td>
  <td>配置传递给Kubernetes的<a href="https://kubernetes.io/docs/concepts/storage/volumes/">Kubernetes Volume</a>选项<code>OptionName</code>作为具有指定值的键。例如， <code>spark.kubernetes.executor.volumes.persistentVolumeClaim.checkpointpvc.options.claimName=spark-pvc-claim</code> 。
  </td>
</tr>
<tr>
  <td><code>spark.kubernetes.local.dirs.tmpfs</code></td>
  <td><code>false</code></td>
  <td>配置<code>emptyDir</code>用于支持的卷<code>SPARK_LOCAL_DIRS</code>在Spark驱动程序和执行程序窗格中使用<code>tmpfs</code>支持，即RAM。有关此内容的更多讨论，请参见本页前面的<a href="#local-storage">本地存储</a> 。
  </td>
</tr>
<tr>
  <td><code>spark.kubernetes.memoryOverheadFactor</code></td>
  <td><code>0.1</code></td>
  <td>这将设置将内存分配给非JVM内存的内存开销因子，其中包括堆外内存分配，非JVM任务和各种系统进程。对于基于JVM的作业，该值将默认为0.10，对于非JVM作业，此值将默认为0.40。之所以这样做，是因为非JVM任务需要更多的非JVM堆空间，并且此类任务通常会因“内存开销超出”错误而失败。这会以更高的默认值提示此错误。
  </td>
</tr>
<tr>
  <td><code>spark.kubernetes.pyspark.pythonVersion</code></td>
  <td><code>"3"</code></td>
  <td>这将设置用于运行驱动程序和执行程序容器的docker映像的主要Python版本。可以是2或3。
  </td>
</tr>
<tr>
  <td><code>spark.kubernetes.kerberos.krb5.path</code></td>
  <td><code>(none)</code></td>
  <td>指定要在Kerberos交互的驱动程序和执行程序上安装的krb5.conf文件的本地位置。重要的是要注意，定义的KDC必须从容器内部可见。
  </td>
</tr>
<tr>
  <td><code>spark.kubernetes.kerberos.krb5.configMapName</code></td>
  <td><code>(none)</code></td>
  <td>指定包含krb5.conf文件的ConfigMap的名称，该名称将被安装在驱动程序和执行程序上以进行Kerberos交互。定义的KDC必须从容器内部可见。ConfigMap也必须与驱动程序和执行程序容器的名称空间相同。
  </td>
</tr>
<tr>
  <td><code>spark.kubernetes.hadoop.configMapName</code></td>
  <td><code>(none)</code></td>
  <td>指定包含HADOOP_CONF_DIR文件的ConfigMap的名称，以将其挂载在用于自定义Hadoop配置的驱动程序和执行程序上。
  </td>
</tr>
<tr>
  <td><code>spark.kubernetes.kerberos.tokenSecret.name</code></td>
  <td><code>(none)</code></td>
  <td>指定存储现有委派令牌的机密名称。这消除了作业用户提供任何用于启动作业的kerberos凭证的需要。
  </td>
</tr>
<tr>
  <td><code>spark.kubernetes.kerberos.tokenSecret.itemKey</code></td>
  <td><code>(none)</code></td>
  <td>指定存储现有委派令牌的数据的项目密钥。这消除了作业用户提供任何用于启动作业的kerberos凭证的需要。
  </td>
</tr>
<tr>
  <td><code>spark.kubernetes.driver.podTemplateFile</code></td>
  <td>（没有）</td>
  <td>指定包含驱动程序<a href="#pod-template">窗格模板</a>的本地文件。例如<code>spark.kubernetes.driver.podTemplateFile=/path/to/driver-pod-template.yaml</code>
  </td>
</tr>
<tr>
  <td><code>spark.kubernetes.driver.podTemplateContainerName</code></td>
  <td>（没有）</td>
  <td>在给定的<a href="#pod-template">pod模板中</a>指定用作驱动程序基础的容器名称。例如<code>spark.kubernetes.driver.podTemplateContainerName=spark-driver</code>
  </td>
</tr>
<tr>
  <td><code>spark.kubernetes.executor.podTemplateFile</code></td>
  <td>（没有）</td>
  <td>指定包含执行程序<a href="#pod-template">窗格模板</a>的本地文件。例如<code>spark.kubernetes.executor.podTemplateFile=/path/to/executor-pod-template.yaml</code>
  </td>
</tr>
<tr>
  <td><code>spark.kubernetes.executor.podTemplateContainerName</code></td>
  <td>（没有）</td>
  <td>在给定的<a href="#pod-template">pod模板中</a>指定要用作执行程序基础的容器名称。例如<code>spark.kubernetes.executor.podTemplateContainerName=spark-executor</code>
  </td>
</tr>
<tr>
  <td><code>spark.kubernetes.executor.deleteOnTermination</code></td>
  <td>真正</td>
  <td>指定在失败或正常终止的情况下是否应删除执行程序容器。
  </td>
</tr>
<tr>
  <td><code>spark.kubernetes.submission.connectionTimeout</code></td>
  <td>10000</td>
  <td>kubernetes客户端用于启动驱动程序的连接超时（以毫秒为单位）。
  </td>
</tr>
<tr>
  <td><code>spark.kubernetes.submission.requestTimeout</code></td>
  <td>10000</td>
  <td>请求超时（以毫秒为单位），以供kubernetes客户端用于启动驱动程序。
  </td>
</tr>
<tr>
  <td><code>spark.kubernetes.driver.connectionTimeout</code></td>
  <td>10000</td>
  <td>驱动程序中的kubernetes客户端在请求执行程序时使用的连接超时（以毫秒为单位）。
  </td>
</tr>
<tr>
  <td><code>spark.kubernetes.driver.requestTimeout</code></td>
  <td>10000</td>
  <td>请求超时的毫秒数，供驱动程序中的kubernetes客户端请求执行程序时使用。
  </td>
</tr>
<tr>  
  <td><code>spark.kubernetes.appKillPodDeletionGracePeriod</code></td>
  <td>（没有）</td>
  <td>使用spark-submit删除Spark应用程序时，以秒为单位指定宽限期。
  </td>
</tr>
<tr>
  <td><code>spark.kubernetes.file.upload.path</code></td>
  <td>（没有）</td>
  <td>在集群模式下在spark提交端存储文件的路径。例如：<code>spark.kubernetes.file.upload.path=s3a://
<s3-bucket>
 /path</code> File should specified as 
 <code>file://path/to/file </code> or absolute path. </td> </tr> </table> #### Pod template properties See the below table for the full list of pod specifications that will be overwritten by spark. ### Pod Metadata 
 <table class="table"> 
  <tbody>
   <tr>
    <th>Pod metadata key</th>
    <th>Modified value</th>
    <th>Description</th>
   </tr> 
   <tr> 
    <td>name</td> 
    <td>Value of <code>spark.kubernetes.driver.pod.name</code></td> 
    <td> The driver pod name will be overwritten with either the configured or default value of <code>spark.kubernetes.driver.pod.name</code>. The executor pod names will be unaffected. </td> 
   </tr> 
   <tr> 
    <td>namespace</td> 
    <td>Value of <code>spark.kubernetes.namespace</code></td> 
    <td> Spark makes strong assumptions about the driver and executor namespaces. Both driver and executor namespaces will be replaced by either the configured or default spark conf value. </td> 
   </tr> 
   <tr> 
    <td>labels</td> 
    <td>Adds the labels from <code>spark.kubernetes.{driver,executor}.label.*</code></td> 
    <td> Spark will add additional labels specified by the spark configuration. </td> 
   </tr> 
   <tr> 
    <td>annotations</td> 
    <td>Adds the annotations from <code>spark.kubernetes.{driver,executor}.annotation.*</code></td> 
    <td> Spark will add additional annotations specified by the spark configuration. </td> 
   </tr> 
  </tbody>
 </table> ### Pod Spec 
 <table class="table"> 
  <tbody>
   <tr>
    <th>Pod spec key</th>
    <th>Modified value</th>
    <th>Description</th>
   </tr> 
   <tr> 
    <td>imagePullSecrets</td> 
    <td>Adds image pull secrets from <code>spark.kubernetes.container.image.pullSecrets</code></td> 
    <td> Additional pull secrets will be added from the spark configuration to both executor pods. </td> 
   </tr> 
   <tr> 
    <td>nodeSelector</td> 
    <td>Adds node selectors from <code>spark.kubernetes.node.selector.*</code></td> 
    <td> Additional node selectors will be added from the spark configuration to both executor pods. </td> 
   </tr> 
   <tr> 
    <td>restartPolicy</td> 
    <td><code>"never"</code></td> 
    <td> Spark assumes that both drivers and executors never restart. </td> 
   </tr> 
   <tr> 
    <td>serviceAccount</td> 
    <td>Value of <code>spark.kubernetes.authenticate.driver.serviceAccountName</code></td> 
    <td> Spark will override <code>serviceAccount</code> with the value of the spark configuration for only driver pods, and only if the spark configuration is specified. Executor pods will remain unaffected. </td> 
   </tr> 
   <tr> 
    <td>serviceAccountName</td> 
    <td>Value of <code>spark.kubernetes.authenticate.driver.serviceAccountName</code></td> 
    <td> Spark will override <code>serviceAccountName</code> with the value of the spark configuration for only driver pods, and only if the spark configuration is specified. Executor pods will remain unaffected. </td> 
   </tr> 
   <tr> 
    <td>volumes</td> 
    <td>Adds volumes from <code>spark.kubernetes.{driver,executor}.volumes.[VolumeType].[VolumeName].mount.path</code></td> 
    <td> Spark will add volumes as specified by the spark conf, as well as additional volumes necessary for passing spark conf and pod template files. </td> 
   </tr> 
  </tbody>
 </table> ### Container spec The following affect the driver and executor containers. All other containers in the pod spec will be unaffected. 
 <table class="table"> 
  <tbody>
   <tr>
    <th>Container spec key</th>
    <th>Modified value</th>
    <th>Description</th>
   </tr> 
   <tr> 
    <td>env</td> 
    <td>Adds env variables from <code>spark.kubernetes.driverEnv.[EnvironmentVariableName]</code></td> 
    <td> Spark will add driver env variables from <code>spark.kubernetes.driverEnv.[EnvironmentVariableName]</code>, and executor env variables from <code>spark.executorEnv.[EnvironmentVariableName]</code>. </td> 
   </tr> 
   <tr> 
    <td>image</td> 
    <td>Value of <code>spark.kubernetes.{driver,executor}.container.image</code></td> 
    <td> The image will be defined by the spark configurations. </td> 
   </tr> 
   <tr> 
    <td>imagePullPolicy</td> 
    <td>Value of <code>spark.kubernetes.container.image.pullPolicy</code></td> 
    <td> Spark will override the pull policy for both driver and executors. </td> 
   </tr> 
   <tr> 
    <td>name</td> 
    <td>See description.</code></td> 
    <td> The container name will be assigned by spark ("spark-kubernetes-driver" for the driver container, and "executor" for each executor container) if not defined by the pod template. If the container is defined by the template, the template's name will be used. </td> 
   </tr> 
   <tr> 
    <td>resources</td> 
    <td>See description</td> 
    <td> The cpu limits are set by <code>spark.kubernetes.{driver,executor}.limit.cores</code>. The cpu is set by <code>spark.{driver,executor}.cores</code>. The memory request and limit are set by summing the values of <code>spark.{driver,executor}.memory</code> and <code>spark.{driver,executor}.memoryOverhead</code>. Other resource limits are set by <code>spark.{driver,executor}.resources.{resourceName}.*</code> configs. </td> 
   </tr> 
   <tr> 
    <td>volumeMounts</td> 
    <td>Add volumes from <code>spark.kubernetes.driver.volumes.[VolumeType].[VolumeName].mount.{path,readOnly}</code></td> 
    <td> Spark will add volumes as specified by the spark conf, as well as additional volumes necessary for passing spark conf and pod template files. </td> 
   </tr> 
  </tbody>
 </table> ### Resource Allocation and Configuration Overview Please make sure to have read the Custom Resource Scheduling and Configuration Overview section on the [configuration page](configuration.html). This section only talks about the Kubernetes specific aspects of resource scheduling. The user is responsible to properly configuring the Kubernetes cluster to have the resources available and ideally isolate each resource per container so that a resource is not shared between multiple containers. If the resource is not isolated the user is responsible for writing a discovery script so that the resource is not shared between containers. See the Kubernetes documentation for specifics on configuring Kubernetes with [custom resources](https://kubernetes.io/docs/concepts/extend-kubernetes/compute-storage-net/device-plugins/). Spark automatically handles translating the Spark configs 
 <code>spark.{driver/executor}.resource.{resourceType}</code> into the kubernetes configs as long as the Kubernetes resource type follows the Kubernetes device plugin format of `vendor-domain/resourcetype`. The user must specify the vendor using the 
 <code>spark.{driver/executor}.resource.{resourceType}.vendor</code> config. The user does not need to explicitly add anything if you are using Pod templates. For reference and an example, you can see the Kubernetes documentation for scheduling [GPUs](https://kubernetes.io/docs/tasks/manage-gpus/scheduling-gpus/). Spark only supports setting the resource limits. Kubernetes does not tell Spark the addresses of the resources allocated to each container. For that reason, the user must specify a discovery script that gets run by the executor on startup to discover what resources are available to that executor. You can find an example scripts in `examples/src/main/scripts/getGpusResources.sh`. The script must have execute permissions set and the user should setup permissions to not allow malicious users to modify it. The script should write to STDOUT a JSON string in the format of the ResourceInformation class. This has the resource name and an array of resource addresses available to just that executor. 
</s3-bucket></code></td></tr></tbody></table>


                </div>
            
             <!-- /container -->
        </div>

        <script src="js/vendor/jquery-3.4.1.min.js"></script>
        <script src="js/vendor/bootstrap.min.js"></script>
        <script src="js/vendor/anchor.min.js"></script>
        <script src="js/main.js"></script>

        <!-- MathJax Section -->
        <script type="text/x-mathjax-config">
            MathJax.Hub.Config({
                TeX: { equationNumbers: { autoNumber: "AMS" } }
            });
        </script>
        <script>
            // Note that we load MathJax this way to work with local file (file://), HTTP and HTTPS.
            // We could use "//cdn.mathjax...", but that won't support "file://".
            (function(d, script) {
                script = d.createElement('script');
                script.type = 'text/javascript';
                script.async = true;
                script.onload = function(){
                    MathJax.Hub.Config({
                        tex2jax: {
                            inlineMath: [ ["$", "$"], ["\\\\(","\\\\)"] ],
                            displayMath: [ ["$$","$$"], ["\\[", "\\]"] ],
                            processEscapes: true,
                            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre']
                        }
                    });
                };
                script.src = ('https:' == document.location.protocol ? 'https://' : 'http://') +
                    'cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js' +
                    '?config=TeX-AMS-MML_HTMLorMML';
                d.getElementsByTagName('head')[0].appendChild(script);
            }(document));
        </script>
    

</body></html>