<html class="no-js" ><!--<![endif]--><head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
        <title>作业计划-Spark 3.0.0-预览文档</title>
        

        

        <link rel="stylesheet" href="css/bootstrap.min.css">
        <style>
            body {
                padding-top: 60px;
                padding-bottom: 40px;
            }
        </style>
        <meta name="viewport" content="width=device-width">
        <link rel="stylesheet" href="css/bootstrap-responsive.min.css">
        <link rel="stylesheet" href="css/main.css">

        <script src="js/vendor/modernizr-2.6.1-respond-1.1.0.min.js"></script>

        <link rel="stylesheet" href="css/pygments-default.css">

        
        <!-- Google analytics script -->
        <script type="text/javascript">
          var _gaq = _gaq || [];
          _gaq.push(['_setAccount', 'UA-32518208-2']);
          _gaq.push(['_trackPageview']);

          (function() {
            var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
            ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
            var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
          })();
        </script>
        

    </head>
    <body >
        <!--[if lt IE 7]>
            <p class="chromeframe">You are using an outdated browser. <a href="https://browsehappy.com/">Upgrade your browser today</a> or <a href="http://www.google.com/chromeframe/?redirect=true">install Google Chrome Frame</a> to better experience this site.</p>
        <![endif]-->

        <!-- This code is taken from http://twitter.github.com/bootstrap/examples/hero.html -->

        <div class="navbar navbar-fixed-top" id="topbar">
            <div class="navbar-inner">
                <div class="container">
                    <div class="brand"><a href="index.html"><img src="img/spark-logo-hd.png" style="height:50px"></a> <span class="version">3.0.0预览版</span>
                    </div>
                    <ul class="nav">
                        <!--TODO(andyk): Add class="active" attribute to li some how.-->
                        <li><a href="index.html">总览</a></li>

                        <li class="dropdown">
                            <a href="#" class="dropdown-toggle" data-toggle="dropdown">编程指南<b class="caret"></b></a>
                            <ul class="dropdown-menu">
                                <li><a href="quick-start.html">快速开始</a></li>
                                <li><a href="rdd-programming-guide.html">RDD，累加器，广播变量</a></li>
                                <li><a href="sql-programming-guide.html">SQL，数据框和数据集</a></li>
                                <li><a href="structured-streaming-programming-guide.html">结构化流</a></li>
                                <li><a href="streaming-programming-guide.html">火花流（DStreams）</a></li>
                                <li><a href="ml-guide.html">MLlib（机器学习）</a></li>
                                <li><a href="graphx-programming-guide.html">GraphX（图形处理）</a></li>
                                <li><a href="sparkr.html">SparkR（Spark上的R）</a></li>
                            </ul>
                        </li>

                        <li class="dropdown">
                            <a href="#" class="dropdown-toggle" data-toggle="dropdown">API文件<b class="caret"></b></a>
                            <ul class="dropdown-menu">
                                <li><a href="api/scala/index.html#org.apache.spark.package">斯卡拉</a></li>
                                <li><a href="api/java/index.html">爪哇</a></li>
                                <li><a href="api/python/index.html">蟒蛇</a></li>
                                <li><a href="api/R/index.html">[R</a></li>
                                <li><a href="api/sql/index.html">SQL，内置函数</a></li>
                            </ul>
                        </li>

                        <li class="dropdown">
                            <a href="#" class="dropdown-toggle" data-toggle="dropdown">部署中<b class="caret"></b></a>
                            <ul class="dropdown-menu">
                                <li><a href="cluster-overview.html">总览</a></li>
                                <li><a href="submitting-applications.html">提交申请</a></li>
                                <li class="divider"></li>
                                <li><a href="spark-standalone.html">Spark独立</a></li>
                                <li><a href="running-on-mesos.html">梅索斯</a></li>
                                <li><a href="running-on-yarn.html">纱</a></li>
                                <li><a href="running-on-kubernetes.html">Kubernetes</a></li>
                            </ul>
                        </li>

                        <li class="dropdown">
                            <a href="api.html" class="dropdown-toggle" data-toggle="dropdown">更多<b class="caret"></b></a>
                            <ul class="dropdown-menu">
                                <li><a href="configuration.html">组态</a></li>
                                <li><a href="monitoring.html">监控方式</a></li>
                                <li><a href="tuning.html">调音指南</a></li>
                                <li><a href="job-scheduling.html">作业调度</a></li>
                                <li><a href="security.html">安全</a></li>
                                <li><a href="hardware-provisioning.html">硬件配置</a></li>
                                <li><a href="migration-guide.html">迁移指南</a></li>
                                <li class="divider"></li>
                                <li><a href="building-spark.html">建筑火花</a></li>
                                <li><a href="https://spark.apache.org/contributing.html">为Spark贡献</a></li>
                                <li><a href="https://spark.apache.org/third-party-projects.html">第三方项目</a></li>
                            </ul>
                        </li>
                    </ul>
                    <!--<p class="navbar-text pull-right"><span class="version-text">v3.0.0-preview</span></p>-->
                </div>
            </div>
        </div>

        <div class="container-wrapper">

            
                <div class="content" id="content">
                    
                        <h1 class="title">作业调度</h1>
                    

                    <ul id="markdown-toc">
  <li><a href="#overview" id="markdown-toc-overview">总览</a></li>
  <li><a href="#scheduling-across-applications" id="markdown-toc-scheduling-across-applications">跨应用程序调度</a>    <ul>
      <li><a href="#dynamic-resource-allocation" id="markdown-toc-dynamic-resource-allocation">动态资源分配</a>        <ul>
          <li><a href="#configuration-and-setup" id="markdown-toc-configuration-and-setup">配置和设置</a></li>
          <li><a href="#resource-allocation-policy" id="markdown-toc-resource-allocation-policy">资源分配政策</a>            <ul>
              <li><a href="#request-policy" id="markdown-toc-request-policy">要求政策</a></li>
              <li><a href="#remove-policy" id="markdown-toc-remove-policy">删除政策</a></li>
            </ul>
          </li>
          <li><a href="#graceful-decommission-of-executors" id="markdown-toc-graceful-decommission-of-executors">执行者的优雅退役</a></li>
        </ul>
      </li>
    </ul>
  </li>
  <li><a href="#scheduling-within-an-application" id="markdown-toc-scheduling-within-an-application">在应用程序内调度</a>    <ul>
      <li><a href="#fair-scheduler-pools" id="markdown-toc-fair-scheduler-pools">公平的调度程序池</a></li>
      <li><a href="#default-behavior-of-pools" id="markdown-toc-default-behavior-of-pools">池的默认行为</a></li>
      <li><a href="#configuring-pool-properties" id="markdown-toc-configuring-pool-properties">配置池属性</a></li>
      <li><a href="#scheduling-using-jdbc-connections" id="markdown-toc-scheduling-using-jdbc-connections">使用JDBC连接进行调度</a></li>
    </ul>
  </li>
</ul>

<h1 id="overview">总览</h1>

<p>Spark具有用于在计算之间调度资源的多种功能。首先，回想一下，如<a href="cluster-overview.html">集群模式概述中所述</a> ，每个Spark应用程序（SparkContext实例）运行一组独立的执行程序进程。运行Spark的集群管理器提供了<a href="#scheduling-across-applications">跨应用程序调度的功能</a> 。其次， <em>在</em>每个Spark应用程序中，如果多个“作业”（Spark操作）是由不同的线程提交的，则它们可能同时运行。如果您的应用程序通过网络处理请求，则这很常见。Spark包含一个<a href="#scheduling-within-an-application">公平的调度程序，</a>用于调度每个SparkContext中的资源。</p>

<h1 id="scheduling-across-applications">跨应用程序调度</h1>

<p>在集群上运行时，每个Spark应用程序都会获得一组独立的执行器JVM，它们仅运行该应用程序的任务并存储数据。如果多个用户需要共享您的集群，则有不同的选项来管理分配，具体取决于集群管理器。</p>

<p>所有群集管理器上可用的最简单的选项是资源的<em>静态分区</em> 。通过这种方法，将为每个应用程序分配最大的可用资源，并在整个使用期间保留这些资源。这是Spark的<a href="spark-standalone.html">独立</a>模式和<a href="running-on-yarn.html">YARN</a>模式以及<a href="running-on-mesos.html#mesos-run-modes">粗粒度的Mesos模式中使用的方法</a> 。可以根据集群类型如下配置资源分配：</p>

<ul>
  <li><strong>独立模式：</strong>默认情况下，提交到独立模式集群的应用程序将以FIFO（先进先出）顺序运行，并且每个应用程序将尝试使用所有可用节点。您可以通过设置以下参数来限制应用程序使用的节点数： <code>spark.cores.max</code>配置属性，或通过以下方式更改未设置此设置的应用程序的默认设置： <code>spark.deploy.defaultCores</code> 。最后，除了控制核心，每个应用程序的<code>spark.executor.memory</code>设置控制其内存使用。</li>
  <li><strong>Mesos：</strong>要在Mesos上使用静态分区，请设置<code>spark.mesos.coarse</code>配置属性为<code>true</code> ，并可以选择设置<code>spark.cores.max</code>以独立模式限制每个应用程序的资源份额。您还应该设置<code>spark.executor.memory</code>控制执行程序的内存。</li>
  <li><strong>纱：</strong> <code>--num-executors</code> Spark YARN客户端的选项控制它将在集群上分配多少执行程序（ <code>spark.executor.instances</code>作为配置属性），而<code>--executor-memory</code> （ <code>spark.executor.memory</code>配置属性）和<code>--executor-cores</code> （ <code>spark.executor.cores</code>配置属性）控制每个执行者的资源。有关更多信息，请参见<a href="running-on-yarn.html">YARN Spark属性</a> 。</li>
</ul>

<p>Mesos上可用的第二个选项是CPU内核的<em>动态共享</em> 。在这种模式下，每个Spark应用程序仍具有固定且独立的内存分配（由<code>spark.executor.memory</code> ），但是当应用程序不在计算机上运行任务时，其他应用程序可能会在这些内核上运行任务。当您期望大量不太活跃的应用程序（例如来自不同用户的shell会话）时，此模式很有用。但是，这样做带来的风险是可预测的延迟较小，因为应用程序需要花一些时间才能在一个节点上获得核心。要使用此模式，只需使用<code>mesos://</code>网址和设置<code>spark.mesos.coarse</code>虚假。</p>

<p>请注意，当前没有任何一种模式可提供跨应用程序的内存共享。如果您想以这种方式共享数据，我们建议运行一个服务器应用程序，该应用程序可以通过查询相同的RDD来服务多个请求。</p>

<h2 id="dynamic-resource-allocation">动态资源分配</h2>

<p>Spark提供了一种机制，可以根据工作负载动态调整应用程序占用的资源。这意味着，如果不再使用资源，您的应用程序可以将资源返还给群集，并在有需求时再次请求它们。如果多个应用程序共享您的Spark集群中的资源，则此功能特别有用。</p>

<p>默认情况下，此功能是禁用的，并且在所有粗粒度集群管理器上都可用，即<a href="spark-standalone.html">独立模式</a> ， <a href="running-on-yarn.html">YARN模式</a>和<a href="running-on-mesos.html#mesos-run-modes">Mesos粗粒度模式</a> 。</p>

<h3 id="configuration-and-setup">配置和设置</h3>

<p>使用此功能有两个要求。首先，您的应用程序必须设置<code>spark.dynamicAllocation.enabled</code>至<code>true</code> 。其次，您必须在同一集群中的每个工作节点上设置<em>外部洗牌服务</em>并进行设置<code>spark.shuffle.service.enabled</code>在您的应用程序中为true。外部随机播放服务的目的是允许执行者被删除而不会删除执行者编写的随机播放文件（ <a href="job-scheduling.html#graceful-decommission-of-executors">下面将</a>详细介绍）。设置此服务的方式因群集管理器而异：</p>

<p>在独立模式下，只需以<code>spark.shuffle.service.enabled</code>调成<code>true</code> 。</p>

<p>在Mesos粗粒度模式下，运行<code>$SPARK_HOME/sbin/start-mesos-shuffle-service.sh</code>在所有从节点上<code>spark.shuffle.service.enabled</code>调成<code>true</code> 。例如，您可以通过马拉松这样做。</p>

<p>在YARN模式下，请按照<a href="running-on-yarn.html#configuring-the-external-shuffle-service">此处</a>的说明进行操作。</p>

<p>所有其他相关配置是可选的，并且在<code>spark.dynamicAllocation.*</code>和<code>spark.shuffle.service.*</code>命名空间。有关更多详细信息，请参阅<a href="configuration.html#dynamic-allocation">配置页面</a> 。</p>

<h3 id="resource-allocation-policy">资源分配政策</h3>

<p>从较高的层次上讲，Spark应该在不再使用执行者时放弃他们，并在需要它们时收购他们。由于没有确定的方法可以预测即将被删除的执行程序是否将在不久的将来运行任务，或者即将被添加的新执行程序实际上将处于空闲状态，因此我们需要一组启发式方法来确定何时删除并要求执行人。</p>

<h4 id="request-policy">要求政策</h4>

<p>启用了动态分配的Spark应用程序在有待调度的待处理任务时会请求其他执行者。这种情况必然意味着现有的执行者集合不足以同时使所有已提交但尚未完成的任务饱和。</p>

<p>Spark全面要求执行者。当有待处理的任务时，将触发实际请求<code>spark.dynamicAllocation.schedulerBacklogTimeout</code>秒，然后每隔一秒触发一次<code>spark.dynamicAllocation.sustainedSchedulerBacklogTimeout</code>如果待处理任务队列仍然存在，则此时间为秒。此外，每轮请求的执行者数量与上一轮相比呈指数增长。例如，一个应用程序将在第一轮中添加1个执行器，然后在随后的轮中添加2、4、8，依此类推。</p>

<p>采取指数增长政策的动机是双重的。首先，应用程序应在开始时就谨慎地请求执行者，以防万一，事实证明只有几个额外的执行者就足够了。这呼应了TCP缓慢启动的理由。其次，如果事实证明确实需要许多执行程序，则应用程序应能够及时提高其资源使用率。</p>

<h4 id="remove-policy">删除政策</h4>

<p>删除执行程序的策略要简单得多。Spark应用程序在闲置时间超过<code>spark.dynamicAllocation.executorIdleTimeout</code>秒。请注意，在大多数情况下，此条件与请求条件是互斥的，因为如果仍有待调度的任务要调度，则执行程序不应闲置。</p>

<h3 id="graceful-decommission-of-executors">执行者的优雅退役</h3>

<p>在动态分配之前，Spark执行程序会在失败时或在关联的应用程序也已退出时退出。在这两种情况下，都不再需要与执行程序关联的所有状态，并且可以安全地将其丢弃。但是，通过动态分配，当显式删除执行程序时，应用程序仍在运行。如果应用程序尝试访问存储在执行程序中或由执行程序编写的状态，则它必须执行重新计算状态。因此，Spark需要一种机制，通过在删除执行程序之前保留其状态来优雅地停用该执行程序。</p>

<p>此要求对于随机播放尤其重要。在重排期间，Spark执行程序首先将其自己的映射输出写入本地磁盘，然后在其他执行程序尝试获取这些文件时充当这些文件的服务器。如果出现散乱的任务（其运行时间比其同伴更长），则动态分配可能会在重排完成之前删除执行程序，在这种情况下，必须重新计算该执行程序写入的重排文件。</p>

<p>保留随机播放文件的解决方案是使用外部随机播放服务，该服务也在Spark 1.2中引入。该服务指的是一个长期运行的进程，该进程独立于Spark应用程序及其执行程序在群集的每个节点上运行。如果启用该服务，Spark执行程序将从该服务而不是从彼此获取随机播放文件。这意味着由执行者编写的任何混洗状态都可以在执行者的生命周期之外继续提供。</p>

<p>除了编写随机播放文件外，执行程序还可以将数据缓存在磁盘或内存中。但是，当删除执行程序时，将不再访问所有缓存的数据。为了减轻这种情况，默认情况下，永远不会删除包含缓存数据的执行程序。您可以使用以下方式配置此行为<code>spark.dynamicAllocation.cachedExecutorIdleTimeout</code> 。在将来的版本中，缓存的数据可能会通过堆外存储来保留，其本质上类似于通过外部随机播放服务来保留随机播放文件的方式。</p>

<h1 id="scheduling-within-an-application">在应用程序内调度</h1>

<p>在给定的Spark应用程序（SparkContext实例）中，如果多个并行作业是从单独的线程提交的，则它们可以同时运行。在本节中，“工作”指的是Spark动作（例如<code>save</code> ， <code>collect</code> ）以及需要运行以评估该操作的所有任务。Spark的调度程序是完全线程安全的，并支持此用例，以启用可处理多个请求（例如，针对多个用户的查询）的应用程序。</p>

<p>默认情况下，Spark的调度程序以FIFO方式运行作业。每个作业都分为“阶段”（例如，映射和简化阶段），第一个作业在所有可用资源上都具有优先级，而其各个阶段都有要启动的任务，则第二个作业具有优先级，依此类推。队列不需要使用整个集群，以后的作业可以立即开始运行，但是如果队列开头的作业很大，则以后的作业可能会大大延迟。</p>

<p>从Spark 0.8开始，还可以配置作业之间的公平共享。在公平共享下，Spark以“循环”方式在作业之间分配任务，以便所有作业都获得大致相等的群集资源份额。这意味着在运行长作业时提交的短作业可以立即开始接收资源，并且仍然获得良好的响应时间，而无需等待长作业完成。此模式最适合多用户设置。</p>

<p>要启用公平的计划程序，只需设置<code>spark.scheduler.mode</code>财产<code>FAIR</code>在配置SparkContext时：</p>

<figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span></span><span class="k">val</span> <span class="n">conf</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SparkConf</span><span class="o">().</span><span class="n">setMaster</span><span class="o">(...).</span><span class="n">setAppName</span><span class="o">(...)</span>
<span class="n">conf</span><span class="o">.</span><span class="n">set</span><span class="o">(</span><span class="s">&quot;spark.scheduler.mode&quot;</span><span class="o">,</span> <span class="s">&quot;FAIR&quot;</span><span class="o">)</span>
<span class="k">val</span> <span class="n">sc</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SparkContext</span><span class="o">(</span><span class="n">conf</span><span class="o">)</span></code></pre></figure>

<h2 id="fair-scheduler-pools">公平的调度程序池</h2>

<p>公平调度程序还支持将作业分组到<em>池中</em> ，并为每个池设置不同的调度选项（例如权重）。例如，这对于为更重要的作业创建“高优先级”池或将每个用户的作业分组在一起并为<em>用户提供</em>相等的份额而不管他们有多少并发作业，而不是给<em>作业</em>相等的份额很有用。该方法以<a href="http://hadoop.apache.org/docs/current/hadoop-yarn/hadoop-yarn-site/FairScheduler.html">Hadoop Fair Scheduler</a>为模型。</p>

<p>无需任何干预，新提交的作业将进入<em>默认池</em> ，但是可以通过添加以下选项来设置作业的池<code>spark.scheduler.pool</code>提交它们的线程中SparkContext的“本地属性”。这样做如下：</p>

<figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span></span><span class="c1">// Assuming sc is your SparkContext variable</span>
<span class="n">sc</span><span class="o">.</span><span class="n">setLocalProperty</span><span class="o">(</span><span class="s">&quot;spark.scheduler.pool&quot;</span><span class="o">,</span> <span class="s">&quot;pool1&quot;</span><span class="o">)</span></code></pre></figure>

<p>设置此本地属性后，该线程内提交的<em>所有</em>作业（通过调用该线程来<code>RDD.save</code> ， <code>count</code> ， <code>collect</code>等）将使用此池名称。该设置是按线程设置的，以使一个线程轻松代表同一用户运行多个作业。如果您想清除与线程关联的池，只需调用：</p>

<figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span></span><span class="n">sc</span><span class="o">.</span><span class="n">setLocalProperty</span><span class="o">(</span><span class="s">&quot;spark.scheduler.pool&quot;</span><span class="o">,</span> <span class="kc">null</span><span class="o">)</span></code></pre></figure>

<h2 id="default-behavior-of-pools">池的默认行为</h2>

<p>默认情况下，每个池都获得群集的相等份额（也与默认池中每个作业的份额相等），但是在每个池中，作业以FIFO顺序运行。例如，如果为每个用户创建一个池，则意味着每个用户将获得集群的平等份额，并且每个用户的查询将按顺序运行，而不是随后的查询从该用户的较早查询中获取资源。</p>

<h2 id="configuring-pool-properties">配置池属性</h2>

<p>特定池的属性也可以通过配置文件进行修改。每个池支持三个属性：</p>

<ul>
  <li><code>schedulingMode</code> ：这可以是FIFO或FAIR，以控制池中的作业是彼此排在后面（默认），还是公平地共享池的资源。</li>
  <li><code>weight</code> ：此操作控制群集相对于其他池的池在群集中的份额。默认情况下，所有池的权重均为1。例如，如果将特定池的权重设置为2，则它将获得比其他活动池多2倍的资源。设置较高的权重（例如1000）还可以在池之间实现<em>优先级</em> -本质上，权重1000的池总是在作业处于活动状态时首先启动任务。</li>
  <li><code>minShare</code> ：除了总的重量之外，还可以为每个池分配管理员希望拥有的<em>最小份额</em> （作为CPU核心数）。公平调度程序始终尝试满足所有活动池的最小份额，然后根据权重重新分配额外资源。的<code>minShare</code>因此，属性可以是确保池始终快速获取特定数量的资源（例如10个核心）而又不为其余群集提供高优先级的另一种方法。默认情况下，每个池的<code>minShare</code>是0。</li>
</ul>

<p>可以通过创建XML文件来设置池属性，类似于<code>conf/fairscheduler.xml.template</code> ，或者放置一个名为<code>fairscheduler.xml</code>在类路径或设置上<code>spark.scheduler.allocation.file</code> <a href="configuration.html#spark-properties">SparkConf中的</a>属性。</p>

<figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span></span><span class="n">conf</span><span class="o">.</span><span class="n">set</span><span class="o">(</span><span class="s">&quot;spark.scheduler.allocation.file&quot;</span><span class="o">,</span> <span class="s">&quot;/path/to/file&quot;</span><span class="o">)</span></code></pre></figure>

<p>XML文件的格式仅仅是<code><pool></code>每个池的元素，其中各种设置包含不同的元素。例如：</p>

<figure class="highlight"><pre><code class="language-xml" data-lang="xml"><span></span><span class="cp">&lt;?xml version=&quot;1.0&quot;?&gt;</span>
<span class="nt">&lt;allocations&gt;</span>
  <span class="nt">&lt;pool</span> <span class="na">name=</span><span class="s">&quot;production&quot;</span><span class="nt">&gt;</span>
    <span class="nt">&lt;schedulingMode&gt;</span>FAIR<span class="nt">&lt;/schedulingMode&gt;</span>
    <span class="nt">&lt;weight&gt;</span>1<span class="nt">&lt;/weight&gt;</span>
    <span class="nt">&lt;minShare&gt;</span>2<span class="nt">&lt;/minShare&gt;</span>
  <span class="nt">&lt;/pool&gt;</span>
  <span class="nt">&lt;pool</span> <span class="na">name=</span><span class="s">&quot;test&quot;</span><span class="nt">&gt;</span>
    <span class="nt">&lt;schedulingMode&gt;</span>FIFO<span class="nt">&lt;/schedulingMode&gt;</span>
    <span class="nt">&lt;weight&gt;</span>2<span class="nt">&lt;/weight&gt;</span>
    <span class="nt">&lt;minShare&gt;</span>3<span class="nt">&lt;/minShare&gt;</span>
  <span class="nt">&lt;/pool&gt;</span>
<span class="nt">&lt;/allocations&gt;</span></code></pre></figure>

<p>完整的示例也可以在<code>conf/fairscheduler.xml.template</code> 。请注意，未在XML文件中配置的任何池都将简单地获得所有设置（调度模式FIFO，权重1和minShare 0）的默认值。</p>

<h2 id="scheduling-using-jdbc-connections">使用JDBC连接进行调度</h2>
<p>要为JDBC客户端会话设置<a href="job-scheduling.html#fair-scheduler-pools">Fair Scheduler</a>池，用户可以设置<code>spark.sql.thriftserver.scheduler.pool</code>变量：</p>

<figure class="highlight"><pre><code class="language-sql" data-lang="sql"><span></span><span class="k">SET</span> <span class="n">spark</span><span class="p">.</span><span class="k">sql</span><span class="p">.</span><span class="n">thriftserver</span><span class="p">.</span><span class="n">scheduler</span><span class="p">.</span><span class="n">pool</span><span class="o">=</span><span class="n">accounting</span><span class="p">;</span></code></pre></figure>



                </div>
            
             <!-- /container -->
        </div>

        <script src="js/vendor/jquery-3.4.1.min.js"></script>
        <script src="js/vendor/bootstrap.min.js"></script>
        <script src="js/vendor/anchor.min.js"></script>
        <script src="js/main.js"></script>

        <!-- MathJax Section -->
        <script type="text/x-mathjax-config">
            MathJax.Hub.Config({
                TeX: { equationNumbers: { autoNumber: "AMS" } }
            });
        </script>
        <script>
            // Note that we load MathJax this way to work with local file (file://), HTTP and HTTPS.
            // We could use "//cdn.mathjax...", but that won't support "file://".
            (function(d, script) {
                script = d.createElement('script');
                script.type = 'text/javascript';
                script.async = true;
                script.onload = function(){
                    MathJax.Hub.Config({
                        tex2jax: {
                            inlineMath: [ ["$", "$"], ["\\\\(","\\\\)"] ],
                            displayMath: [ ["$$","$$"], ["\\[", "\\]"] ],
                            processEscapes: true,
                            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre']
                        }
                    });
                };
                script.src = ('https:' == document.location.protocol ? 'https://' : 'http://') +
                    'cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js' +
                    '?config=TeX-AMS-MML_HTMLorMML';
                d.getElementsByTagName('head')[0].appendChild(script);
            }(document));
        </script>
    

</body></html>