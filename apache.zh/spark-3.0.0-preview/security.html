<html class="no-js" ><!--<![endif]--><head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
        <title>安全性-Spark 3.0.0-预览文档</title>
        

        

        <link rel="stylesheet" href="css/bootstrap.min.css">
        <style>
            body {
                padding-top: 60px;
                padding-bottom: 40px;
            }
        </style>
        <meta name="viewport" content="width=device-width">
        <link rel="stylesheet" href="css/bootstrap-responsive.min.css">
        <link rel="stylesheet" href="css/main.css">

        <script src="js/vendor/modernizr-2.6.1-respond-1.1.0.min.js"></script>

        <link rel="stylesheet" href="css/pygments-default.css">

        
        <!-- Google analytics script -->
        <script type="text/javascript">
          var _gaq = _gaq || [];
          _gaq.push(['_setAccount', 'UA-32518208-2']);
          _gaq.push(['_trackPageview']);

          (function() {
            var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
            ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
            var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
          })();
        </script>
        

    </head>
    <body >
        <!--[if lt IE 7]>
            <p class="chromeframe">You are using an outdated browser. <a href="https://browsehappy.com/">Upgrade your browser today</a> or <a href="http://www.google.com/chromeframe/?redirect=true">install Google Chrome Frame</a> to better experience this site.</p>
        <![endif]-->

        <!-- This code is taken from http://twitter.github.com/bootstrap/examples/hero.html -->

        <div class="navbar navbar-fixed-top" id="topbar">
            <div class="navbar-inner">
                <div class="container">
                    <div class="brand"><a href="index.html"><img src="img/spark-logo-hd.png" style="height:50px"></a> <span class="version">3.0.0预览版</span>
                    </div>
                    <ul class="nav">
                        <!--TODO(andyk): Add class="active" attribute to li some how.-->
                        <li><a href="index.html">总览</a></li>

                        <li class="dropdown">
                            <a href="#" class="dropdown-toggle" data-toggle="dropdown">编程指南<b class="caret"></b></a>
                            <ul class="dropdown-menu">
                                <li><a href="quick-start.html">快速开始</a></li>
                                <li><a href="rdd-programming-guide.html">RDD，累加器，广播变量</a></li>
                                <li><a href="sql-programming-guide.html">SQL，数据框和数据集</a></li>
                                <li><a href="structured-streaming-programming-guide.html">结构化流</a></li>
                                <li><a href="streaming-programming-guide.html">火花流（DStreams）</a></li>
                                <li><a href="ml-guide.html">MLlib（机器学习）</a></li>
                                <li><a href="graphx-programming-guide.html">GraphX（图形处理）</a></li>
                                <li><a href="sparkr.html">SparkR（Spark上的R）</a></li>
                            </ul>
                        </li>

                        <li class="dropdown">
                            <a href="#" class="dropdown-toggle" data-toggle="dropdown">API文件<b class="caret"></b></a>
                            <ul class="dropdown-menu">
                                <li><a href="api/scala/index.html#org.apache.spark.package">斯卡拉</a></li>
                                <li><a href="api/java/index.html">爪哇</a></li>
                                <li><a href="api/python/index.html">蟒蛇</a></li>
                                <li><a href="api/R/index.html">[R</a></li>
                                <li><a href="api/sql/index.html">SQL，内置函数</a></li>
                            </ul>
                        </li>

                        <li class="dropdown">
                            <a href="#" class="dropdown-toggle" data-toggle="dropdown">部署中<b class="caret"></b></a>
                            <ul class="dropdown-menu">
                                <li><a href="cluster-overview.html">总览</a></li>
                                <li><a href="submitting-applications.html">提交申请</a></li>
                                <li class="divider"></li>
                                <li><a href="spark-standalone.html">Spark独立</a></li>
                                <li><a href="running-on-mesos.html">梅索斯</a></li>
                                <li><a href="running-on-yarn.html">纱</a></li>
                                <li><a href="running-on-kubernetes.html">Kubernetes</a></li>
                            </ul>
                        </li>

                        <li class="dropdown">
                            <a href="api.html" class="dropdown-toggle" data-toggle="dropdown">更多<b class="caret"></b></a>
                            <ul class="dropdown-menu">
                                <li><a href="configuration.html">组态</a></li>
                                <li><a href="monitoring.html">监控方式</a></li>
                                <li><a href="tuning.html">调音指南</a></li>
                                <li><a href="job-scheduling.html">作业调度</a></li>
                                <li><a href="security.html">安全</a></li>
                                <li><a href="hardware-provisioning.html">硬件配置</a></li>
                                <li><a href="migration-guide.html">迁移指南</a></li>
                                <li class="divider"></li>
                                <li><a href="building-spark.html">建筑火花</a></li>
                                <li><a href="https://spark.apache.org/contributing.html">为Spark贡献</a></li>
                                <li><a href="https://spark.apache.org/third-party-projects.html">第三方项目</a></li>
                            </ul>
                        </li>
                    </ul>
                    <!--<p class="navbar-text pull-right"><span class="version-text">v3.0.0-preview</span></p>-->
                </div>
            </div>
        </div>

        <div class="container-wrapper">

            
                <div class="content" id="content">
                    
                        <h1 class="title">火花安全</h1>
                    

                    <ul id="markdown-toc">
  <li><a href="#spark-security-things-you-need-to-know" id="markdown-toc-spark-security-things-you-need-to-know">Spark安全性：您需要知道的事情</a></li>
  <li><a href="#spark-rpc-communication-protocol-between-spark-processes" id="markdown-toc-spark-rpc-communication-protocol-between-spark-processes">Spark RPC（Spark进程之间的通信协议）</a>    <ul>
      <li><a href="#authentication" id="markdown-toc-authentication">认证方式</a>        <ul>
          <li><a href="#yarn" id="markdown-toc-yarn">纱</a></li>
          <li><a href="#kubernetes" id="markdown-toc-kubernetes">Kubernetes</a></li>
        </ul>
      </li>
      <li><a href="#encryption" id="markdown-toc-encryption">加密</a></li>
    </ul>
  </li>
  <li><a href="#local-storage-encryption" id="markdown-toc-local-storage-encryption">本地存储加密</a></li>
  <li><a href="#web-ui" id="markdown-toc-web-ui">网页界面</a>    <ul>
      <li><a href="#authentication-and-authorization" id="markdown-toc-authentication-and-authorization">认证与授权</a></li>
      <li><a href="#spark-history-server-acls" id="markdown-toc-spark-history-server-acls">Spark History Server ACL</a></li>
      <li><a href="#ssl-configuration" id="markdown-toc-ssl-configuration">SSL配置</a></li>
      <li><a href="#preparing-the-key-stores" id="markdown-toc-preparing-the-key-stores">准备密钥库</a>        <ul>
          <li><a href="#yarn-mode" id="markdown-toc-yarn-mode">纱线模式</a></li>
          <li><a href="#standalone-mode" id="markdown-toc-standalone-mode">独立模式</a></li>
          <li><a href="#mesos-mode" id="markdown-toc-mesos-mode">Mesos模式</a></li>
        </ul>
      </li>
      <li><a href="#http-security-headers" id="markdown-toc-http-security-headers">HTTP安全标头</a></li>
    </ul>
  </li>
  <li><a href="#configuring-ports-for-network-security" id="markdown-toc-configuring-ports-for-network-security">配置网络安全端口</a>    <ul>
      <li><a href="#standalone-mode-only" id="markdown-toc-standalone-mode-only">仅独立模式</a></li>
      <li><a href="#all-cluster-managers" id="markdown-toc-all-cluster-managers">所有集群管理者</a></li>
    </ul>
  </li>
  <li><a href="#kerberos" id="markdown-toc-kerberos">的Kerberos</a>    <ul>
      <li><a href="#long-running-applications" id="markdown-toc-long-running-applications">长期运行的应用程序</a>        <ul>
          <li><a href="#using-a-keytab" id="markdown-toc-using-a-keytab">使用密钥表</a></li>
          <li><a href="#using-a-ticket-cache" id="markdown-toc-using-a-ticket-cache">使用票证缓存</a></li>
        </ul>
      </li>
      <li><a href="#secure-interaction-with-kubernetes" id="markdown-toc-secure-interaction-with-kubernetes">与Kubernetes的安全交互</a></li>
    </ul>
  </li>
  <li><a href="#event-logging" id="markdown-toc-event-logging">事件记录</a></li>
  <li><a href="#persisting-driver-logs-in-client-mode" id="markdown-toc-persisting-driver-logs-in-client-mode">在客户端模式下保留驱动程序日志</a></li>
</ul>

<h1 id="spark-security-things-you-need-to-know">Spark安全性：您需要知道的事情</h1>

<p>默认情况下，Spark中的安全性处于关闭状态。这可能意味着您默认情况下容易受到攻击。Spark支持多种部署类型，每一种都支持不同级别的安全性。并非所有部署类型在所有环境中都将是安全的，并且默认情况下没有一种是安全的。确保评估您的环境，Spark支持什么，并采取适当的措施来保护您的Spark部署。</p>

<p>有许多不同类型的安全问题。Spark不一定能防止万物。下面列出了Spark支持的一些功能。还请检查部署文档，以了解用于特定于部署的设置的部署类型。任何未记录的内容，Spark不支持。</p>

<h1 id="spark-rpc-communication-protocol-between-spark-processes">Spark RPC（Spark进程之间的通信协议）</h1>

<h2 id="authentication">认证方式</h2>

<p>Spark当前支持使用共享密钥对RPC通道进行身份验证。可以通过设置<code>spark.authenticate</code>配置参数。</p>

<p>用于生成和分发共享机密的确切机制是特定于部署的。除非以下指定，否则必须通过设置<code>spark.authenticate.secret</code>配置选项。在这种情况下，所有Spark应用程序和后台程序都共享相同的机密，这限制了这些部署的安全性，尤其是在多租户群集上。</p>

<p>REST提交服务器和MesosClusterDispatcher不支持身份验证。您应确保对REST API和MesosClusterDispatcher的所有网络访问（默认情况下分别为端口6066和7077）仅限于可信任提交作业的主机。</p>

<h3 id="yarn">纱</h3>

<p>对于<a href="running-on-yarn.html">YARN上的</a> Spark，Spark将自动处理共享密钥的生成和分发。每个应用程序将使用唯一的共享机密。对于YARN，此功能依赖于启用YARN RPC加密来确保机密分发的安全性。</p>

<h3 id="kubernetes">Kubernetes</h3>

<p>在Kubernetes上，Spark还将自动生成每个应用程序唯一的身份验证密钥。机密会使用环境变量传播到执行程序容器。这意味着可以在运行Spark应用程序的名称空间中列出pod的任何用户也可以看到其身份验证密码。Kubernetes管理员应正确设置访问控制规则，以确保Spark身份验证是安全的。</p>

<table class="table">
<tbody><tr><th>物业名称</th><th>默认</th><th>含义</th></tr>
<tr>
  <td><code>spark.authenticate</code></td>
  <td>假</td>
  <td>Spark是否验证其内部连接。</td>
</tr>
<tr>
  <td><code>spark.authenticate.secret</code></td>
  <td>没有</td>
  <td>密钥用于身份验证。有关何时应设置此配置的信息，请参见上文。
  </td>
</tr>
</tbody></table>

<p>或者，可以使用用户安装到其pod中的文件和Kubernetes机密来安装身份验证机密。</p>

<table class="table">
<tbody><tr><th>物业名称</th><th>默认</th><th>含义</th></tr>
<tr>
  <td><code>spark.authenticate.secret.file</code></td>
  <td>没有</td>
  <td>指向用于保护连接的密钥的路径。确保已安全生成文件内容。除非其他设置覆盖此文件，否则此文件将同时加载到驱动程序和执行程序上（请参见下文）。
  </td>
</tr>
<tr>
  <td><code>spark.authenticate.secret.driver.file</code></td>
  <td>的价值<code>spark.authenticate.secret.file</code></td>
  <td>指定时，将覆盖Spark驱动程序读取以加载机密的位置。在客户端模式下，当Pod与运行驱动程序的节点中的机密文件的位置可能不同时，此选项很有用。指定后， <code>spark.authenticate.secret.executor.file</code>必须指定，以便驱动程序和执行程序都可以使用文件来加载密钥。确保驱动程序上文件的内容与执行程序上文件的内容相同。
  </td>
</tr>
<tr>
  <td><code>spark.authenticate.secret.executor.file</code></td>
  <td>的价值<code>spark.authenticate.secret.file</code></td>
  <td>指定后，将覆盖Spark执行程序读取以加载机密的位置。在客户端模式下很有用，当秘密文件的位置在Pod中与运行驱动程序的节点不同时。指定后， <code>spark.authenticate.secret.driver.file</code>必须指定，以便驱动程序和执行程序都可以使用文件来加载密钥。确保驱动程序上文件的内容与执行程序上文件的内容相同。
  </td>
</tr>
</tbody></table>

<p>请注意，使用文件时，Spark不会为您将这些文件装载到容器中。您有责任确保将秘密文件安全地部署到您的容器中，并确保驱动程序的秘密文件与执行者的秘密文件一致。</p>

<h2 id="encryption">加密</h2>

<p>Spark支持RPC连接的基于AES的加密。要启用加密，还必须启用并正确配置RPC身份验证。AES加密使用<a href="https://commons.apache.org/proper/commons-crypto/">Apache Commons Crypto</a>库，Spark的配置系统允许高级用户访问该库的配置。</p>

<p>还支持基于SASL的加密，尽管应将其视为已弃用。与2.2.0之前的Spark版本中的洗牌服务进行通讯时，仍然需要使用此功能。</p>

<p>下表描述了可用于配置此功能的不同选项。</p>

<table class="table">
<tbody><tr><th>物业名称</th><th>默认</th><th>含义</th></tr>
<tr>
  <td><code>spark.network.crypto.enabled</code></td>
  <td>假</td>
  <td>启用基于AES的RPC加密，包括2.2.0中添加的新身份验证协议。
  </td>
</tr>
<tr>
  <td><code>spark.network.crypto.keyLength</code></td>
  <td>128</td>
  <td>要生成的加密密钥的长度（以位为单位）。有效值为128、192和256。
  </td>
</tr>
<tr>
  <td><code>spark.network.crypto.keyFactoryAlgorithm</code></td>
  <td>PBKDF2WithHmacSHA1</td>
  <td>生成加密密钥时使用的密钥工厂算法。应该是javax.crypto支持的算法之一。正在使用的JRE中的SecretKeyFactory类。
  </td>
</tr>
<tr>
  <td><code>spark.network.crypto.config.*</code></td>
  <td>没有</td>
  <td>commons-crypto库的配置值，例如要使用的密码实现。配置名称应为commons-crypto配置的名称，且不包含<code>commons.crypto</code>字首。
  </td>
</tr>
<tr>
  <td><code>spark.network.crypto.saslFallback</code></td>
  <td>真正</td>
  <td>如果使用Spark内部机制的身份验证失败，是否退回SASL身份验证。当应用程序连接到不支持内部Spark身份验证协议的旧洗牌服务时，此功能很有用。在随机播放服务方面，禁用此功能将阻止较旧的客户端进行身份验证。
  </td>
</tr>
<tr>
  <td><code>spark.authenticate.enableSaslEncryption</code></td>
  <td>假</td>
  <td>启用基于SASL的加密通信。
  </td>
</tr>
<tr>
  <td><code>spark.network.sasl.serverAlwaysEncrypt</code></td>
  <td>假</td>
  <td>使用SASL身份验证禁用端口的未加密连接。这将拒绝来自已启用身份验证但不请求基于SASL加密的客户端的连接。
  </td>
</tr>
</tbody></table>

<h1 id="local-storage-encryption">本地存储加密</h1>

<p>Spark支持加密写入本地磁盘的临时数据。这涵盖了随机文件，随机溢出和存储在磁盘上的数据块（用于缓存和广播变量）。它不涉及使用API等应用程序对应用程序生成的输出数据进行加密<code>saveAsHadoopFile</code>要么<code>saveAsTable</code> 。它还可能不包括用户明确创建的临时文件。</p>

<p>以下设置涵盖为写入磁盘的数据启用加密：</p>

<table class="table">
<tbody><tr><th>物业名称</th><th>默认</th><th>含义</th></tr>
<tr>
  <td><code>spark.io.encryption.enabled</code></td>
  <td>假</td>
  <td>启用本地磁盘I / O加密。目前支持除Mesos之外的所有模式。强烈建议使用此功能时启用RPC加密。
  </td>
</tr>
<tr>
  <td><code>spark.io.encryption.keySizeBits</code></td>
  <td>128</td>
  <td>IO加密密钥大小（以位为单位）。支持的值为128、192和256。
  </td>
</tr>
<tr>
  <td><code>spark.io.encryption.keygen.algorithm</code></td>
  <td>HmacSHA1</td>
  <td>生成IO加密密钥时使用的算法。Java密码体系结构体系结构标准算法名称文档的KeyGenerator部分中介绍了受支持的算法。
  </td>
</tr>
<tr>
  <td><code>spark.io.encryption.commons.config.*</code></td>
  <td>没有</td>
  <td>commons-crypto库的配置值，例如要使用的密码实现。配置名称应为commons-crypto配置的名称，且不包含<code>commons.crypto</code>字首。
  </td>
</tr>
</tbody></table>

<h1 id="web-ui">网页界面</h1>

<h2 id="authentication-and-authorization">认证与授权</h2>

<p>使用<a href="https://docs.oracle.com/javaee/6/api/javax/servlet/Filter.html">javax servlet过滤器</a>完成对Web UI的身份验证。您将需要一个过滤器，该过滤器实现要部署的身份验证方法。Spark不提供任何内置的身份验证筛选器。</p>

<p>当存在身份验证过滤器时，Spark还支持对UI的访问控制。可以为每个应用程序配置自己的单独访问控制列表（ACL）。Spark区分“查看”权限（允许查看应用程序的UI）和“修改”权限（可以执行诸如在正在运行的应用程序中杀死作业的操作）的权限。</p>

<p>可以为用户或组配置ACL。配置条目接受以逗号分隔的列表作为输入，这意味着可以为多个用户或组赋予所需的特权。如果您在共享群集上运行并且有一组管理员或开发人员需要监视自己可能尚未启动的应用程序，则可以使用此功能。通配符（ <code>*</code> ）添加到特定的ACL意味着所有用户都将拥有各自的特权。默认情况下，仅将提交应用程序的用户添加到ACL中。</p>

<p>组成员资格是通过使用可配置的组映射提供程序建立的。映射器是使用<code>spark.user.groups.mapping</code> config选项，如下表所述。</p>

<p>以下选项控制Web UI的身份验证：</p>

<table class="table">
<tbody><tr><th>物业名称</th><th>默认</th><th>含义</th></tr>
<tr>
  <td><code>spark.ui.filters</code></td>
  <td>没有</td>
  <td>请参阅<a href="configuration.html#spark-ui">Spark UI</a>配置以了解如何配置过滤器。
  </td>
</tr>
<tr>
  <td><code>spark.acls.enable</code></td>
  <td>假</td>
  <td>是否应启用UI ACL。如果启用，它将检查用户是否具有查看或修改应用程序的访问权限。请注意，这要求对用户进行身份验证，因此，如果未安装身份验证过滤器，则此选项不会执行任何操作。
  </td>
</tr>
<tr>
  <td><code>spark.admin.acls</code></td>
  <td>没有</td>
  <td>以逗号分隔的具有查看和修改对Spark应用程序访问权限的用户的列表。
  </td>
</tr>
<tr>
  <td><code>spark.admin.acls.groups</code></td>
  <td>没有</td>
  <td>以逗号分隔的具有查看和修改对Spark应用程序访问权限的组的列表。
  </td>
</tr>
<tr>
  <td><code>spark.modify.acls</code></td>
  <td>没有</td>
  <td>对Spark应用程序具有修改访问权限的用户的逗号分隔列表。
  </td>
</tr>
<tr>
  <td><code>spark.modify.acls.groups</code></td>
  <td>没有</td>
  <td>以逗号分隔的具有对Spark应用程序的修改访问权的组列表。
  </td>
</tr>
<tr>
  <td><code>spark.ui.view.acls</code></td>
  <td>没有</td>
  <td>具有对Spark应用程序的查看访问权的用户的逗号分隔列表。
  </td>
</tr>
<tr>
  <td><code>spark.ui.view.acls.groups</code></td>
  <td>没有</td>
  <td>对Spark应用程序具有查看访问权限的组的逗号分隔列表。
  </td>
</tr>
<tr>
  <td><code>spark.user.groups.mapping</code></td>
  <td><code>org.apache.spark.security.ShellBasedGroupsMappingProvider</code></td>
  <td>用户的组列表由特征定义的组映射服务确定<code>org.apache.spark.security.GroupMappingServiceProvider</code> ，可以通过此属性进行配置。

    <br>默认情况下，使用基于Unix Shell的实现，该实现从主机OS收集此信息。<br><em>注意：</em>此实现仅支持基于Unix / Linux的环境。当前<b>不</b>支持Windows环境。但是，可以通过实现上述特征来支持新的平台/协议。
  </td>
</tr>
</tbody></table>

<p>在YARN上，在提交应用程序时将视图和修改ACL提供给YARN服务，并通过YARN接口控制谁拥有各自的特权。</p>

<h2 id="spark-history-server-acls">Spark History Server ACL</h2>

<p>使用Servlet过滤器，以与常规应用程序相同的方式启用SHS Web UI的身份验证。</p>

<p>为了在SHS中启用授权，使用了一些其他选项：</p>

<table class="table">
<tbody><tr><th>物业名称</th><th>默认</th><th>含义</th></tr>
<tr>
  <td><code>spark.history.ui.acls.enable</code></td>
  <td>假</td>
  <td>指定是否应检查ACL以授权用户查看历史服务器中的应用程序。如果启用，则无论单个应用程序设置了什么，都将执行访问控制检查。 <code>spark.ui.acls.enable</code> 。应用程序所有者将始终有权查看自己的应用程序以及通过以下方式指定的任何用户<code>spark.ui.view.acls</code>和通过指定的组<code>spark.ui.view.acls.groups</code>运行该应用程序时，还将有权查看该应用程序。如果禁用，则不会对通过历史记录服务器可用的任何应用程序UI进行访问控制检查。
  </td>
</tr>
<tr>
  <td><code>spark.history.ui.admin.acls</code></td>
  <td>没有</td>
  <td>对历史服务器中的所有Spark应用程序具有查看访问权限的用户的逗号分隔列表。
  </td>
</tr>
<tr>
  <td><code>spark.history.ui.admin.acls.groups</code></td>
  <td>没有</td>
  <td>具有对历史服务器中所有Spark应用程序的视图访问权限的组的逗号分隔列表。
  </td>
</tr>
</tbody></table>

<p>SHS使用相同的选项将组映射提供程序配置为常规应用程序。在这种情况下，组映射提供程序将通过SHS应用于所有UI服务器，并且各个应用程序配置将被忽略。</p>

<h2 id="ssl-configuration">SSL配置</h2>

<p>SSL的配置是按层次组织的。用户可以配置将用于所有受支持的通信协议的默认SSL设置，除非它们被协议特定的设置覆盖。这样，用户可以轻松地为所有协议提供通用设置，而无需禁用单独配置每个协议的功能。下表描述了SSL配置名称空间：</p>

<table class="table">
  <tbody><tr>
    <th>配置命名空间</th>
    <th>零件</th>
  </tr>
  <tr>
    <td><code>spark.ssl</code></td>
    <td>默认的SSL配置。这些值将应用于下面的所有命名空间，除非在命名空间级别上明确覆盖。
    </td>
  </tr>
  <tr>
    <td><code>spark.ssl.ui</code></td>
    <td>Spark应用程序Web UI</td>
  </tr>
  <tr>
    <td><code>spark.ssl.standalone</code></td>
    <td>独立的主/工人Web UI</td>
  </tr>
  <tr>
    <td><code>spark.ssl.historyServer</code></td>
    <td>历史记录服务器Web UI</td>
  </tr>
</tbody></table>

<p>可用SSL选项的完整分类可以在下面找到。的<code>${ns}</code>占位符应替换为上述名称空间之一。</p>

<table class="table">
<tbody><tr><th>物业名称</th><th>默认</th><th>含义</th></tr>
  <tr>
    <td><code>${ns}.enabled</code></td>
    <td>假</td>
    <td>启用SSL。启用后， <code>${ns}.ssl.protocol</code>是必须的。</td>
  </tr>
  <tr>
    <td><code>${ns}.port</code></td>
    <td>没有</td>
    <td>SSL服务将侦听的端口。

      <br>必须在特定的名称空间配置中定义端口。读取此配置时，将忽略默认名称空间。

      <br>如果未设置，则SSL端口将从同一服务的非SSL端口派生。值为“ 0”将使服务绑定到临时端口。
    </td>
  </tr>
  <tr>
    <td><code>${ns}.enabledAlgorithms</code></td>
    <td>没有</td>
    <td>逗号分隔的密码列表。JVM必须支持指定的密码。<br>协议的参考列表可以在Java安全指南的“ JSSE密码套件名称”部分中找到。Java 8的列表可以在<a href="https://docs.oracle.com/javase/8/docs/technotes/guides/security/StandardNames.html#ciphersuites">此</a>页面上找到。

      <br>注意：如果未设置，则将使用JRE的默认密码套件。
    </td>
  </tr>
  <tr>
    <td><code>${ns}.keyPassword</code></td>
    <td>没有</td>
    <td>密钥存储区中私钥的密码。
    </td>
  </tr>
  <tr>
    <td><code>${ns}.keyStore</code></td>
    <td>没有</td>
    <td>密钥库文件的路径。该路径可以是绝对路径，也可以是相对于启动该进程的目录的路径。
    </td>
  </tr>
  <tr>
    <td><code>${ns}.keyStorePassword</code></td>
    <td>没有</td>
    <td>密钥存储区的密码。</td>
  </tr>
  <tr>
    <td><code>${ns}.keyStoreType</code></td>
    <td>JKS</td>
    <td>密钥库的类型。</td>
  </tr>
  <tr>
    <td><code>${ns}.protocol</code></td>
    <td>没有</td>
    <td>使用的TLS协议。JVM必须支持该协议。<br>协议的参考列表可以在Java安全性指南的“其他JSSE标准名称”部分中找到。对于Java 8，可以在<a href="https://docs.oracle.com/javase/8/docs/technotes/guides/security/StandardNames.html#jssenames">此</a>页面上找到列表。
    </td>
  </tr>
  <tr>
    <td><code>${ns}.needClientAuth</code></td>
    <td>假</td>
    <td>是否要求客户端认证。</td>
  </tr>
  <tr>
    <td><code>${ns}.trustStore</code></td>
    <td>没有</td>
    <td>信任库文件的路径。该路径可以是绝对路径，也可以是相对于启动该进程的目录的路径。
    </td>
  </tr>
  <tr>
    <td><code>${ns}.trustStorePassword</code></td>
    <td>没有</td>
    <td>信任库的密码。</td>
  </tr>
  <tr>
    <td><code>${ns}.trustStoreType</code></td>
    <td>JKS</td>
    <td>信任库的类型。</td>
  </tr>
</tbody></table>

<p>Spark还支持检索<code>${ns}.keyPassword</code> ， <code>${ns}.keyStorePassword</code>和<code>${ns}.trustStorePassword</code>来自<a href="https://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-common/CredentialProviderAPI.html">Hadoop凭证提供者</a> 。用户可以将密码存储到凭证文件中，并使其可以由不同的组件访问，例如：</p>

<pre><code>hadoop credential create spark.ssl.keyPassword -value password \
    -provider jceks://hdfs@nn1.example.com:9001/user/backup/ssl.jceks
</code></pre>

<p>要配置凭据提供程序的位置，请设置<code>hadoop.security.credential.provider.path</code> Spark使用的Hadoop配置中的config选项，例如：</p>

<pre><code>  &lt;property&gt;
    &lt;name&gt;hadoop.security.credential.provider.path&lt;/name&gt;
    &lt;value&gt;jceks://hdfs@nn1.example.com:9001/user/backup/ssl.jceks&lt;/value&gt;
  &lt;/property&gt;
</code></pre>

<p>或通过SparkConf“ spark.hadoop.hadoop.security.credential.provider.path = jceks：//hdfs@nn1.example.com：9001 / user / backup / ssl.jceks”。</p>

<h2 id="preparing-the-key-stores">准备密钥库</h2>

<p>密钥库可以通过以下方式生成<code>keytool</code>程序。<a href="https://docs.oracle.com/javase/8/docs/technotes/tools/unix/keytool.html">此处</a>提供了该工具的Java 8参考文档。为Spark Standalone部署模式配置密钥存储和信任存储的最基本步骤如下：</p>

<ul>
  <li>为每个节点生成密钥对</li>
  <li>将密钥对的公钥导出到每个节点上的文件中</li>
  <li>将所有导出的公钥导入单个信任库</li>
  <li>将信任库分发到群集节点</li>
</ul>

<h3 id="yarn-mode">纱线模式</h3>

<p>要将本地信任存储或密钥存储文件提供给以群集模式运行的驱动程序，可以使用以下命令将其与应用程序一起分发<code>--files</code>命令行参数（或等效参数） <code>spark.files</code>组态）。这些文件将放置在驱动程序的工作目录中，因此TLS配置应仅引用没有绝对路径的文件名。</p>

<p>以这种方式分配本地密钥存储可能需要将文件暂存到HDFS（或群集使用的其他类似的分布式文件系统）中，因此建议在配置底层文件系统时要考虑安全性（例如，通过启用身份验证和有线加密） ）。</p>

<h3 id="standalone-mode">独立模式</h3>

<p>用户需要为主服务器和工作人员提供密钥存储和配置选项。必须通过在其中附加适当的Java系统属性来设置它们<code>SPARK_MASTER_OPTS</code>和在<code>SPARK_WORKER_OPTS</code>环境变量，或者只是在<code>SPARK_DAEMON_JAVA_OPTS</code> 。</p>

<p>用户可以允许执行者使用从工作进程继承的SSL设置。可以通过设置<code>spark.ssl.useNodeLocalConf</code>至<code>true</code> 。在这种情况下，不会使用用户在客户端上提供的设置。</p>

<h3 id="mesos-mode">Mesos模式</h3>

<p>Mesos 1.3.0及更高版本的支持<code>Secrets</code>原语既是基于文件的秘密又是基于环境的秘密。Spark允许使用以下命令规范基于文件和基于环境变量的机密<code>spark.mesos.driver.secret.filenames</code>和<code>spark.mesos.driver.secret.envkeys</code> ， 分别。</p>

<p>根据秘密存储的不同，可以通过引用或值将秘密传递给后端<code>spark.mesos.driver.secret.names</code>和<code>spark.mesos.driver.secret.values</code>配置属性。</p>

<p>引用类型的机密由机密存储服务，并按名称引用，例如<code>/mysecret</code> 。值类型的机密在命令行上传递，并转换为它们相应的文件或环境变量。</p>

<h2 id="http-security-headers">HTTP安全标头</h2>

<p>可以将Apache Spark配置为包括HTTP标头，以帮助防止跨站点脚本（XSS），跨框架脚本（XFS），MIME嗅探，以及实施HTTP严格传输安全性。</p>

<table class="table">
<tbody><tr><th>物业名称</th><th>默认</th><th>含义</th></tr>
<tr>
  <td><code>spark.ui.xXssProtection</code></td>
  <td><code>1; mode=block</code></td>
  <td>HTTP X-XSS-Protection响应标头的值。您可以从下面选择适当的值：<ul>
      <li><code>0</code> （禁用XSS过滤）</li>
      <li><code>1</code> （启用XSS过滤。如果检测到跨站点脚本攻击，浏览器将对页面进行清理。）</li>
      <li><code>1; mode=block</code> （启用XSS过滤。如果检测到攻击，浏览器将阻止呈现页面。）</li>
    </ul>
  </td>
</tr>
<tr>
  <td><code>spark.ui.xContentTypeOptions.enabled</code></td>
  <td><code>true</code></td>
  <td>启用后，X-Content-Type-Options HTTP响应标头将设置为“ nosniff”。
  </td>
  </tr>
<tr>
  <td><code>spark.ui.strictTransportSecurity</code></td>
  <td>没有</td>
  <td>HTTP严格传输安全性（HSTS）响应标头的值。您可以从下面选择合适的值并进行设置<code>expire-time</code>相应地。仅在启用SSL / TLS时使用此选项。
    <ul>
      <li><code>max-age=<expire-time></code></li>
      <li><code>max-age=<expire-time>; includeSubDomains</code></li>
      <li><code>max-age=<expire-time>; preload</code></li>
    </ul>
  </td>
</tr>
</tbody></table>

<h1 id="configuring-ports-for-network-security">配置网络安全端口</h1>

<p>一般来说，Spark集群及其服务未部署在公共互联网上。它们通常是私有服务，并且只能在部署Spark的组织网络内访问。对Spark服务使用的主机和端口的访问应仅限于需要访问服务的原始主机。</p>

<p>以下是Spark用于其通信的主要端口以及如何配置这些端口。</p>

<h2 id="standalone-mode-only">仅独立模式</h2>

<table class="table">
  <tbody><tr>
    <th>从</th><th>至</th><th>默认端口</th><th>目的</th><th>配置设定</th><th>笔记</th>
  </tr>
  <tr>
    <td>浏览器</td>
    <td>独立大师</td>
    <td>8080</td>
    <td>网页界面</td>
    <td><code>spark.master.ui.port /<br> SPARK_MASTER_WEBUI_PORT</code></td>
    <td>基于码头。仅独立模式。</td>
  </tr>
  <tr>
    <td>浏览器</td>
    <td>单工</td>
    <td>8081</td>
    <td>网页界面</td>
    <td><code>spark.worker.ui.port /<br> SPARK_WORKER_WEBUI_PORT</code></td>
    <td>基于码头。仅独立模式。</td>
  </tr>
  <tr>
    <td>司机/<br>单工</td>
    <td>独立大师</td>
    <td>7077</td>
    <td>将作业提交到集群/<br>加入集群</td>
    <td><code>SPARK_MASTER_PORT</code></td>
    <td>设置为“ 0”以随机选择端口。仅独立模式。</td>
  </tr>
  <tr>
    <td>外部服务</td>
    <td>独立大师</td>
    <td>6066</td>
    <td>通过REST API将作业提交到集群</td>
    <td><code>spark.master.rest.port</code></td>
    <td>使用<code>spark.master.rest.enabled</code>启用/禁用此服务。仅独立模式。</td>
  </tr>
  <tr>
    <td>独立大师</td>
    <td>单工</td>
    <td>（随机）</td>
    <td>安排执行者</td>
    <td><code>SPARK_WORKER_PORT</code></td>
    <td>设置为“ 0”以随机选择端口。仅独立模式。</td>
  </tr>
</tbody></table>

<h2 id="all-cluster-managers">所有集群管理者</h2>

<table class="table">
  <tbody><tr>
    <th>从</th><th>至</th><th>默认端口</th><th>目的</th><th>配置设定</th><th>笔记</th>
  </tr>
  <tr>
    <td>浏览器</td>
    <td>应用</td>
    <td>4040</td>
    <td>网页界面</td>
    <td><code>spark.ui.port</code></td>
    <td>基于码头</td>
  </tr>
  <tr>
    <td>浏览器</td>
    <td>历史记录服务器</td>
    <td>18080</td>
    <td>网页界面</td>
    <td><code>spark.history.ui.port</code></td>
    <td>基于码头</td>
  </tr>
  <tr>
    <td>执行者/<br>独立大师</td>
    <td>司机</td>
    <td>（随机）</td>
    <td>连接到应用程序/<br>通知执行人状态变更</td>
    <td><code>spark.driver.port</code></td>
    <td>设置为“ 0”以随机选择端口。</td>
  </tr>
  <tr>
    <td>执行器/驱动器</td>
    <td>执行器/驱动器</td>
    <td>（随机）</td>
    <td>块管理器端口</td>
    <td><code>spark.blockManager.port</code></td>
    <td>通过ServerSocketChannel的原始套接字</td>
  </tr>
</tbody></table>

<h1 id="kerberos">的Kerberos</h1>

<p>Spark支持在使用Kerberos进行身份验证的环境中提交应用程序。在大多数情况下，Spark在对支持Kerberos的服务进行身份验证时依赖于当前登录用户的凭据。可以通过使用以下工具登录已配置的KDC来获取此类凭据： <code>kinit</code> 。</p>

<p>与基于Hadoop的服务通话时，Spark需要获取委托令牌，以便非本地进程可以进行身份验证。Spark附带了对HDFS和其他Hadoop文件系统Hive和HBase的支持。</p>

<p>使用Hadoop文件系统（例如HDFS或WebHDFS）时，Spark将为托管用户主目录的服务获取相关令牌。</p>

<p>如果HBase位于应用程序的类路径中，并且HBase配置已启用Kerberos身份验证，则将获得HBase令牌（ <code>hbase.security.authentication=kerberos</code> ）。</p>

<p>同样，如果Hive在类路径中，则将获得Hive令牌，并且配置中包含用于远程元存储服务的URI（ <code>hive.metastore.uris</code>不为空）。</p>

<p>如果应用程序需要与其他安全的Hadoop文件系统交互，则需要在启动时将其URI明确提供给Spark。这是通过将它们列出在<code>spark.kerberos.access.hadoopFileSystems</code>属性，在下面的配置部分中进行介绍。</p>

<p>Spark还使用Java服务机制支持自定义委托令牌提供程序（请参阅<code>java.util.ServiceLoader</code> ）。的实现<code>org.apache.spark.security.HadoopDelegationTokenProvider</code>可以通过在jar的相应文件中列出它们的名称，使Spark可以使用它们<code>META-INF/services</code>目录。</p>

<p>当前仅在YARN和Mesos模式下支持委托令牌支持。请参阅特定于部署的页面以获取更多信息。</p>

<p>以下选项为该功能提供了更细粒度的控制：</p>

<table class="table">
<tbody><tr><th>物业名称</th><th>默认</th><th>含义</th></tr>
<tr>
  <td><code>spark.security.credentials.${service}.enabled</code></td>
  <td><code>true</code></td>
  <td>控制启用安全性后是否获取服务的凭据。默认情况下，在配置所有受支持服务的凭据时，将检索这些凭据，但是，如果某种行为与正在运行的应用程序发生冲突，则可以禁用该行为。
  </td>
</tr>
<tr>
  <td><code>spark.kerberos.access.hadoopFileSystems</code></td>
  <td>（没有）</td>
  <td>您的Spark应用程序将要访问的安全Hadoop文件系统的列表，以逗号分隔。例如， <code>spark.kerberos.access.hadoopFileSystems=hdfs://nn1.com:8032,hdfs://nn2.com:8032, webhdfs://nn3.com:50070</code> 。Spark应用程序必须有权访问列出的文件系统，并且必须正确配置Kerberos才能访问它们（在同一领域或在受信任领域）。Spark为每个文件系统获取安全令牌，以便Spark应用程序可以访问那些远程Hadoop文件系统。
  </td>
</tr>
</tbody></table>

<h2 id="long-running-applications">长期运行的应用程序</h2>

<p>如果长时间运行的应用程序的运行时间超过了需要访问的服务中配置的最大委托令牌生存期，则可能会遇到问题。</p>

<p>此功能并非在所有地方都可用。特别是，它仅在YARN和Kubernetes（客户端和群集模式）上以及使用客户端模式的Mesos上实现。</p>

<p>Spark支持自动为这些应用程序创建新令牌。有两种方法可以启用此功能。</p>

<h3 id="using-a-keytab">使用密钥表</h3>

<p>通过为Spark提供主体和密钥表（例如，使用<code>spark-submit</code>与<code>--principal</code>和<code>--keytab</code>参数），应用程序将维护有效的Kerberos登录名，该登录名可用于无限期地检索委托令牌。</p>

<p>请注意，在集群模式下使用密钥表时，会将其复制到运行Spark驱动程序的计算机上。对于YARN，这意味着将HDFS用作密钥表的暂存区域，因此强烈建议至少使用加密保护YARN和HDFS。</p>

<h3 id="using-a-ticket-cache">使用票证缓存</h3>

<p>通过设置<code>spark.kerberos.renewal.credentials</code>至<code>ccache</code>在Spark的配置中，本地Kerberos票证缓存将用于身份验证。Spark将在其可更新的生命周期内更新票证，但是在过期后，需要获取新票证（例如，通过运行<code>kinit</code> ）。</p>

<p>用户可以维护Spark可以使用的更新的票证缓存。</p>

<p>票证缓存的位置可以通过设置<code>KRB5CCNAME</code>环境变量。</p>

<h2 id="secure-interaction-with-kubernetes">与Kubernetes的安全交互</h2>

<p>在与Kerberos背后的基于Hadoop的服务进行交谈时，应注意，Spark需要获取委托令牌，以便非本地进程可以进行身份验证。Kubernetes中的这些委托令牌存储在驱动程序及其执行程序共享的秘密中。这样，可以通过三种方式提交Kerberos作业：</p>

<p>在所有情况下，您都必须定义环境变量： <code>HADOOP_CONF_DIR</code>要么<code>spark.kubernetes.hadoop.configMapName.</code></p>

<p>同样重要的是，必须从容器内部看到KDC。</p>

<p>如果用户希望使用包含Hadoop配置文件的远程HADOOP_CONF目录，则可以通过设置<code>spark.kubernetes.hadoop.configMapName</code>到预先存在的ConfigMap。</p>

<ol>
  <li>提交$ kinit将TGT存储在本地票证缓存中：<pre><code class="language-bash">/usr/bin/kinit -kt &lt;keytab_file&gt; &lt;username&gt;/&lt;krb5 realm&gt;
/opt/spark/bin/spark-submit \
 --deploy-mode cluster \
 --class org.apache.spark.examples.HdfsTest \
 --master k8s://&lt;KUBERNETES_MASTER_ENDPOINT&gt; \
 --conf spark.executor.instances=1 \
 --conf spark.app.name=spark-hdfs \
 --conf spark.kubernetes.container.image=spark:latest \
 --conf spark.kubernetes.kerberos.krb5.path=/etc/krb5.conf \
 local:///opt/spark/examples/jars/spark-examples_&lt;VERSION&gt;.jar \
 &lt;HDFS_FILE_LOCATION&gt;
</code></pre>
  </li>
  <li>使用本地Keytab和主体提交<pre><code class="language-bash">/opt/spark/bin/spark-submit \
 --deploy-mode cluster \
 --class org.apache.spark.examples.HdfsTest \
 --master k8s://&lt;KUBERNETES_MASTER_ENDPOINT&gt; \
 --conf spark.executor.instances=1 \
 --conf spark.app.name=spark-hdfs \
 --conf spark.kubernetes.container.image=spark:latest \
 --conf spark.kerberos.keytab=&lt;KEYTAB_FILE&gt; \
 --conf spark.kerberos.principal=&lt;PRINCIPAL&gt; \
 --conf spark.kubernetes.kerberos.krb5.path=/etc/krb5.conf \
 local:///opt/spark/examples/jars/spark-examples_&lt;VERSION&gt;.jar \
 &lt;HDFS_FILE_LOCATION&gt;
</code></pre>
  </li>
  <li>使用预先填充的机密提交，其中包含名称空间中已经存在的委托令牌<pre><code class="language-bash">/opt/spark/bin/spark-submit \
 --deploy-mode cluster \
 --class org.apache.spark.examples.HdfsTest \
 --master k8s://&lt;KUBERNETES_MASTER_ENDPOINT&gt; \
 --conf spark.executor.instances=1 \
 --conf spark.app.name=spark-hdfs \
 --conf spark.kubernetes.container.image=spark:latest \
 --conf spark.kubernetes.kerberos.tokenSecret.name=&lt;SECRET_TOKEN_NAME&gt; \
 --conf spark.kubernetes.kerberos.tokenSecret.itemKey=&lt;SECRET_ITEM_KEY&gt; \
 --conf spark.kubernetes.kerberos.krb5.path=/etc/krb5.conf \
 local:///opt/spark/examples/jars/spark-examples_&lt;VERSION&gt;.jar \
 &lt;HDFS_FILE_LOCATION&gt;
</code></pre>
  </li>
</ol>

<p>3b。像（3）中一样提交，但是指定了预先创建的krb5 ConfigMap和预先创建的<code>HADOOP_CONF_DIR</code> ConfigMap</p>
<pre><code class="language-bash">/opt/spark/bin/spark-submit \
    --deploy-mode cluster \
    --class org.apache.spark.examples.HdfsTest \
    --master k8s://&lt;KUBERNETES_MASTER_ENDPOINT&gt; \
    --conf spark.executor.instances=1 \
    --conf spark.app.name=spark-hdfs \
    --conf spark.kubernetes.container.image=spark:latest \
    --conf spark.kubernetes.kerberos.tokenSecret.name=&lt;SECRET_TOKEN_NAME&gt; \
    --conf spark.kubernetes.kerberos.tokenSecret.itemKey=&lt;SECRET_ITEM_KEY&gt; \
    --conf spark.kubernetes.hadoop.configMapName=&lt;HCONF_CONFIG_MAP_NAME&gt; \
    --conf spark.kubernetes.kerberos.krb5.configMapName=&lt;KRB_CONFIG_MAP_NAME&gt; \
    local:///opt/spark/examples/jars/spark-examples_&lt;VERSION&gt;.jar \
    &lt;HDFS_FILE_LOCATION&gt;
</code></pre>
<h1 id="event-logging">事件记录</h1>

<p>如果您的应用程序正在使用事件日志记录，则事件日志所在的目录（ <code>spark.eventLog.dir</code> ）应在适当的权限下手动创建。为了保护日志文件，目录权限应设置为<code>drwxrwxrwxt</code> 。目录的所有者和组应与运行Spark History Server的超级用户相对应。</p>

<p>这将允许所有用户写入目录，但将阻止非特权用户读取，删除或重命名文件，除非他们拥有该文件。事件日志文件将由Spark创建并具有权限，这样只有用户和组才具有读写访问权限。</p>

<h1 id="persisting-driver-logs-in-client-mode">在客户端模式下保留驱动程序日志</h1>

<p>如果您的应用程序持续存在，则驱动程序会通过启用以下命令以客户端模式登录<code>spark.driver.log.persistToDfs.enabled</code> ，驱动程序日志所在的目录（ <code>spark.driver.log.dfsDir</code> ）应在适当的权限下手动创建。为了保护日志文件，目录权限应设置为<code>drwxrwxrwxt</code> 。目录的所有者和组应与运行Spark History Server的超级用户相对应。</p>

<p>这将允许所有用户写入目录，但将阻止非特权用户读取，删除或重命名文件，除非他们拥有该文件。驱动程序日志文件将由Spark创建并具有权限，这样只有用户和组才具有读写访问权限。</p>


                </div>
            
             <!-- /container -->
        </div>

        <script src="js/vendor/jquery-3.4.1.min.js"></script>
        <script src="js/vendor/bootstrap.min.js"></script>
        <script src="js/vendor/anchor.min.js"></script>
        <script src="js/main.js"></script>

        <!-- MathJax Section -->
        <script type="text/x-mathjax-config">
            MathJax.Hub.Config({
                TeX: { equationNumbers: { autoNumber: "AMS" } }
            });
        </script>
        <script>
            // Note that we load MathJax this way to work with local file (file://), HTTP and HTTPS.
            // We could use "//cdn.mathjax...", but that won't support "file://".
            (function(d, script) {
                script = d.createElement('script');
                script.type = 'text/javascript';
                script.async = true;
                script.onload = function(){
                    MathJax.Hub.Config({
                        tex2jax: {
                            inlineMath: [ ["$", "$"], ["\\\\(","\\\\)"] ],
                            displayMath: [ ["$$","$$"], ["\\[", "\\]"] ],
                            processEscapes: true,
                            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre']
                        }
                    });
                };
                script.src = ('https:' == document.location.protocol ? 'https://' : 'http://') +
                    'cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js' +
                    '?config=TeX-AMS-MML_HTMLorMML';
                d.getElementsByTagName('head')[0].appendChild(script);
            }(document));
        </script>
    

</body></html>