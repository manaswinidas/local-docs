<html class="no-js" ><!--<![endif]--><head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
        <title>调整-Spark 3.0.0-预览文档</title>
        
          <meta name="description" content="Tuning and performance optimization guide for Spark 3.0.0-preview">
        

        

        <link rel="stylesheet" href="css/bootstrap.min.css">
        <style>
            body {
                padding-top: 60px;
                padding-bottom: 40px;
            }
        </style>
        <meta name="viewport" content="width=device-width">
        <link rel="stylesheet" href="css/bootstrap-responsive.min.css">
        <link rel="stylesheet" href="css/main.css">

        <script src="js/vendor/modernizr-2.6.1-respond-1.1.0.min.js"></script>

        <link rel="stylesheet" href="css/pygments-default.css">

        
        <!-- Google analytics script -->
        <script type="text/javascript">
          var _gaq = _gaq || [];
          _gaq.push(['_setAccount', 'UA-32518208-2']);
          _gaq.push(['_trackPageview']);

          (function() {
            var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
            ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
            var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
          })();
        </script>
        

    </head>
    <body >
        <!--[if lt IE 7]>
            <p class="chromeframe">You are using an outdated browser. <a href="https://browsehappy.com/">Upgrade your browser today</a> or <a href="http://www.google.com/chromeframe/?redirect=true">install Google Chrome Frame</a> to better experience this site.</p>
        <![endif]-->

        <!-- This code is taken from http://twitter.github.com/bootstrap/examples/hero.html -->

        <div class="navbar navbar-fixed-top" id="topbar">
            <div class="navbar-inner">
                <div class="container">
                    <div class="brand"><a href="index.html"><img src="img/spark-logo-hd.png" style="height:50px"></a> <span class="version">3.0.0预览版</span>
                    </div>
                    <ul class="nav">
                        <!--TODO(andyk): Add class="active" attribute to li some how.-->
                        <li><a href="index.html">总览</a></li>

                        <li class="dropdown">
                            <a href="#" class="dropdown-toggle" data-toggle="dropdown">编程指南<b class="caret"></b></a>
                            <ul class="dropdown-menu">
                                <li><a href="quick-start.html">快速开始</a></li>
                                <li><a href="rdd-programming-guide.html">RDD，累加器，广播变量</a></li>
                                <li><a href="sql-programming-guide.html">SQL，数据框和数据集</a></li>
                                <li><a href="structured-streaming-programming-guide.html">结构化流</a></li>
                                <li><a href="streaming-programming-guide.html">火花流（DStreams）</a></li>
                                <li><a href="ml-guide.html">MLlib（机器学习）</a></li>
                                <li><a href="graphx-programming-guide.html">GraphX（图形处理）</a></li>
                                <li><a href="sparkr.html">SparkR（Spark上的R）</a></li>
                            </ul>
                        </li>

                        <li class="dropdown">
                            <a href="#" class="dropdown-toggle" data-toggle="dropdown">API文件<b class="caret"></b></a>
                            <ul class="dropdown-menu">
                                <li><a href="api/scala/index.html#org.apache.spark.package">斯卡拉</a></li>
                                <li><a href="api/java/index.html">爪哇</a></li>
                                <li><a href="api/python/index.html">蟒蛇</a></li>
                                <li><a href="api/R/index.html">[R</a></li>
                                <li><a href="api/sql/index.html">SQL，内置函数</a></li>
                            </ul>
                        </li>

                        <li class="dropdown">
                            <a href="#" class="dropdown-toggle" data-toggle="dropdown">部署中<b class="caret"></b></a>
                            <ul class="dropdown-menu">
                                <li><a href="cluster-overview.html">总览</a></li>
                                <li><a href="submitting-applications.html">提交申请</a></li>
                                <li class="divider"></li>
                                <li><a href="spark-standalone.html">Spark独立</a></li>
                                <li><a href="running-on-mesos.html">梅索斯</a></li>
                                <li><a href="running-on-yarn.html">纱</a></li>
                                <li><a href="running-on-kubernetes.html">Kubernetes</a></li>
                            </ul>
                        </li>

                        <li class="dropdown">
                            <a href="api.html" class="dropdown-toggle" data-toggle="dropdown">更多<b class="caret"></b></a>
                            <ul class="dropdown-menu">
                                <li><a href="configuration.html">组态</a></li>
                                <li><a href="monitoring.html">监控方式</a></li>
                                <li><a href="tuning.html">调音指南</a></li>
                                <li><a href="job-scheduling.html">作业调度</a></li>
                                <li><a href="security.html">安全</a></li>
                                <li><a href="hardware-provisioning.html">硬件配置</a></li>
                                <li><a href="migration-guide.html">迁移指南</a></li>
                                <li class="divider"></li>
                                <li><a href="building-spark.html">建筑火花</a></li>
                                <li><a href="https://spark.apache.org/contributing.html">为Spark贡献</a></li>
                                <li><a href="https://spark.apache.org/third-party-projects.html">第三方项目</a></li>
                            </ul>
                        </li>
                    </ul>
                    <!--<p class="navbar-text pull-right"><span class="version-text">v3.0.0-preview</span></p>-->
                </div>
            </div>
        </div>

        <div class="container-wrapper">

            
                <div class="content" id="content">
                    
                        <h1 class="title">调整火花</h1>
                    

                    <ul id="markdown-toc">
  <li><a href="#data-serialization" id="markdown-toc-data-serialization">数据序列化</a></li>
  <li><a href="#memory-tuning" id="markdown-toc-memory-tuning">内存调优</a>    <ul>
      <li><a href="#memory-management-overview" id="markdown-toc-memory-management-overview">内存管理概述</a></li>
      <li><a href="#determining-memory-consumption" id="markdown-toc-determining-memory-consumption">确定内存消耗</a></li>
      <li><a href="#tuning-data-structures" id="markdown-toc-tuning-data-structures">调整数据结构</a></li>
      <li><a href="#serialized-rdd-storage" id="markdown-toc-serialized-rdd-storage">序列化RDD存储</a></li>
      <li><a href="#garbage-collection-tuning" id="markdown-toc-garbage-collection-tuning">垃圾收集优化</a></li>
    </ul>
  </li>
  <li><a href="#other-considerations" id="markdown-toc-other-considerations">其他注意事项</a>    <ul>
      <li><a href="#level-of-parallelism" id="markdown-toc-level-of-parallelism">并行度</a></li>
      <li><a href="#memory-usage-of-reduce-tasks" id="markdown-toc-memory-usage-of-reduce-tasks">减少任务的内存使用</a></li>
      <li><a href="#broadcasting-large-variables" id="markdown-toc-broadcasting-large-variables">广播大变量</a></li>
      <li><a href="#data-locality" id="markdown-toc-data-locality">数据局部性</a></li>
    </ul>
  </li>
  <li><a href="#summary" id="markdown-toc-summary">摘要</a></li>
</ul>

<p>由于大多数Spark计算的内存性质，Spark程序可能会受到群集中任何资源（CPU，网络带宽或内存）的瓶颈。通常，如果数据适合内存，则瓶颈是网络带宽，但是有时，您还需要进行一些调整，例如<a href="rdd-programming-guide.html#rdd-persistence">以序列化形式存储RDD</a> ，以减少内存使用量。本指南将涵盖两个主要主题：数据序列化，这对于良好的网络性能至关重要，并且还可以减少内存使用，以及内存调整。我们还概述了几个较小的主题。</p>

<h1 id="data-serialization">数据序列化</h1>

<p>序列化在任何分布式应用程序的性能中都起着重要作用。将对象序列化为慢速格式或占用大量字节的格式将大大减慢计算速度。通常，这是您应该优化Spark应用程序的第一件事。Spark旨在在便利性（允许您在操作中使用任何Java类型）和性能之间取得平衡。它提供了两个序列化库：</p>

<ul>
  <li><a href="https://docs.oracle.com/javase/8/docs/api/java/io/Serializable.html">Java序列化</a> ：默认情况下，Spark使用Java的序列化对象<code>ObjectOutputStream</code>框架，并且可以与您创建的实现了任何类的类一起使用<a href="https://docs.oracle.com/javase/8/docs/api/java/io/Serializable.html"><code>java.io.Serializable</code></a> 。您还可以通过扩展扩展来更紧密地控制序列化的性能<a href="https://docs.oracle.com/javase/8/docs/api/java/io/Externalizable.html"><code>java.io.Externalizable</code></a> 。Java序列化很灵活，但是通常很慢，并且导致许多类的序列化格式很大。</li>
  <li><a href="https://github.com/EsotericSoftware/kryo">Kryo序列化</a> ：Spark还可以使用Kryo库（版本4）更快地序列化对象。与Java序列化（通常多达10倍）相比，Kryo显着更快，更紧凑，但不支持全部<code>Serializable</code>类型，并要求您预先<em>注册</em>要在程序中使用的类，以实现最佳性能。</li>
</ul>

<p>您可以通过使用<a href="configuration.html#spark-properties">SparkConf</a>初始化作业并调用来切换为使用Kryo。 <code>conf.set("spark.serializer", "org.apache.spark.serializer.KryoSerializer")</code> 。此设置配置了不仅用于在工作节点之间改组数据而且还在将RDD序列化到磁盘时使用的序列化器。Kryo不是默认值的唯一原因是由于自定义注册要求，但是我们建议在任何网络密集型应用程序中尝试使用它。从Spark 2.0.0开始，在对具有简单类型，简单类型的数组或字符串类型的RDD进行改组时，我们在内部使用Kryo序列化器。</p>

<p>Spark自动为<a href="https://github.com/twitter/chill">Twitter chill</a>库的AllScalaRegistrar中涵盖的许多常用Scala核心类包括Kryo序列化器。</p>

<p>要在Kryo中注册自己的自定义类，请使用<code>registerKryoClasses</code>方法。</p>

<figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span></span><span class="k">val</span> <span class="n">conf</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SparkConf</span><span class="o">().</span><span class="n">setMaster</span><span class="o">(...).</span><span class="n">setAppName</span><span class="o">(...)</span>
<span class="n">conf</span><span class="o">.</span><span class="n">registerKryoClasses</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="n">classOf</span><span class="o">[</span><span class="kt">MyClass1</span><span class="o">],</span> <span class="n">classOf</span><span class="o">[</span><span class="kt">MyClass2</span><span class="o">]))</span>
<span class="k">val</span> <span class="n">sc</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SparkContext</span><span class="o">(</span><span class="n">conf</span><span class="o">)</span></code></pre></figure>

<p><a href="https://github.com/EsotericSoftware/kryo">Kryo文档</a>介绍了更高级的注册选项，例如添加自定义序列化代码。</p>

<p>如果您的物体很大，则可能还需要增加<code>spark.kryoserializer.buffer</code> <a href="configuration.html#compression-and-serialization">配置</a>该值必须足够大以容纳要序列化的<em>最大</em>对象。</p>

<p>最后，如果您不注册自定义类，Kryo仍然可以工作，但必须将完整的类名与每个对象一起存储，这很浪费。</p>

<h1 id="memory-tuning">内存调优</h1>

<p>有三个方面的考虑在调整内存使用情况：内存通过你的对象使用<em>量</em> （你可能希望你的整个数据集，以适应在内存中），访问这些对象的<em>成本</em> ，和<em>垃圾收集</em>的开销（如果你有高成交条款）。</p>

<p>默认情况下，Java对象的访问速度很快，但与其字段中的“原始”数据相比，它们很容易消耗2-5倍的空间。这是由于以下几个原因：</p>

<ul>
  <li>每个不同的Java对象都有一个“对象标头”，它大约16个字节，并包含诸如指向其类的指针之类的信息。对于其中数据很少的对象（比如说一个<code>Int</code>字段），它可以大于数据。</li>
  <li>爪哇<code>String</code>在原始字符串数据上大约有40个字节的开销（因为它们将其存储在一个<code>Char</code>并保留额外的数据（例如长度），并由于以下原因将每个字符存储为<em>两个</em>字节<code>String</code>的UTF-16编码的内部用法。因此，一个10个字符的字符串可以轻松消耗60个字节。</li>
  <li>常见的收集类，例如<code>HashMap</code>和<code>LinkedList</code> ，请使用链接的数据结构，其中每个条目都有一个“包装器”对象（例如， <code>Map.Entry</code> ）。该对象不仅具有标题，而且具有指向列表中下一个对象的指针（通常每个指针8个字节）。</li>
  <li>基本类型的集合通常将它们存储为“盒装”对象，例如<code>java.lang.Integer</code> 。</li>
</ul>

<p>本节将首先概述Spark中的内存管理，然后讨论用户可以采取的特定策略，以更有效地使用其应用程序中的内存。特别是，我们将描述如何确定对象的内存使用情况以及如何通过更改数据结构或以串行化格式存储数据来改善对象的使用情况。然后，我们将介绍调整Spark的缓存大小和Java垃圾收集器。</p>

<h2 id="memory-management-overview">内存管理概述</h2>

<p>Spark中的内存使用情况大体上属于以下两种类别之一：执行和存储。执行内存是指用于洗牌，联接，排序和聚合的计算的内存，而存储内存是指用于在集群中缓存和传播内部数据的内存。在Spark中，执行和存储共享一个统一的区域（M）。当不使用执行内存时，存储可以获取所有可用内存，反之亦然。如果有必要，执行可能会驱逐存储，但只有在总存储内存使用率下降到某个阈值（R）以下时，才可以执行该操作。换一种说法， <code>R</code>描述其中的一个子区域<code>M</code>从未驱逐出缓存块的地方。由于实现的复杂性，存储可能无法退出执行。</p>

<p>这种设计确保了几种理想的性能。首先，不使用缓存的应用程序可以将整个空间用于执行，从而避免了不必要的磁盘溢出。其次，确实使用缓存的应用程序可以保留最小的存储空间（R），以免其数据块被逐出。最后，这种方法可为各种工作负载提供合理的即用即用性能，而无需用户了解如何在内部划分内存。</p>

<p>尽管有两种相关的配置，但典型用户无需调整它们，因为默认值适用于大多数工作负载：</p>

<ul>
  <li><code>spark.memory.fraction</code>表示的大小<code>M</code> （JVM堆空间-300MiB）的一部分（默认值为0.6）。其余的空间（40％）保留用于用户数据结构，Spark中的内部元数据，并在记录稀疏和异常大的情况下防止OOM错误。</li>
  <li><code>spark.memory.storageFraction</code>表示的大小<code>R</code>只是<code>M</code> （默认值为0.5）。
<code>R</code>是其中的存储空间<code>M</code>缓存的块不受执行驱逐。</li>
</ul>

<p>的价值<code>spark.memory.fraction</code>应该进行设置，以便在JVM的旧版本或“长期使用的”一代中舒适地适应此堆空间量。有关详细信息，请参见下面有关高级GC调整的讨论。</p>

<h2 id="determining-memory-consumption">确定内存消耗</h2>

<p>确定数据集所需的内存消耗量的最佳方法是创建一个RDD，将其放入缓存中，然后查看Web UI中的“ Storage”页面。该页面将告诉您RDD占用了多少内存。</p>

<p>要估计特定对象的内存消耗，请使用<code>SizeEstimator</code>的<code>estimate</code>方法。这对于试验不同的数据布局以减少内存使用量以及确定广播变量将在每个执行程序堆上占用的空间量很有用。</p>

<h2 id="tuning-data-structures">调整数据结构</h2>

<p>减少内存消耗的第一种方法是避免使用Java功能，这些功能会增加开销，例如基于指针的数据结构和包装对象。做这件事有很多种方法：</p>

<ol>
  <li>设计数据结构，使其更喜欢对象数组和原始类型，而不是标准的Java或Scala集合类（例如<code>HashMap</code> ）。<a href="http://fastutil.di.unimi.it">fastutil</a>库为与Java标准库兼容的原始类型提供了方便的收集类。</li>
  <li>尽可能避免使用带有许多小对象和指针的嵌套结构。</li>
  <li>考虑使用数字ID或枚举对象代替键的字符串。</li>
  <li>如果您的RAM少于32 GiB，则设置JVM标志<code>-XX:+UseCompressedOops</code>使指针为四个字节而不是八个字节。您可以在以下位置添加这些选项<a href="configuration.html#environment-variables"><code>spark-env.sh</code></a> 。</li>
</ol>

<h2 id="serialized-rdd-storage">序列化RDD存储</h2>

<p>当您的对象仍然太大而无法进行优化存储时，减少内存使用的一种更简单的方法是使用<a href="rdd-programming-guide.html#rdd-persistence">RDD持久性API中</a>的序列化StorageLevels以<em>序列化</em>形式存储它们，例如<code>MEMORY_ONLY_SER</code> 。然后，Spark将每个RDD分区存储为一个大字节数组。由于必须动态地反序列化每个对象，因此以串行形式存储数据的唯一缺点是访问时间较慢。如果您想以序列化的形式缓存数据，我们强烈建议<a href="#data-serialization">使用Kryo</a> ，因为它导致的大小比Java序列化（当然也比原始Java对象）小。</p>

<h2 id="garbage-collection-tuning">垃圾收集优化</h2>

<p>如果您在程序存储的RDD方面有较大的“搅动”，则JVM垃圾回收可能会成为问题。（在只读取一次RDD然后对其执行许多操作的程序中，这通常不是问题。）当Java需要驱逐旧对象为新对象腾出空间时，它将需要遍历所有Java对象并找到未使用的对象。这里要记住的要点是， <em>垃圾回收的成本与Java对象的数量成正比</em> ，因此使用对象较少的数据结构（例如， <code>Int</code>而不是<code>LinkedList</code> ）可大大降低此费用。更好的方法是如上所述以序列化的形式持久化对象：现在，每个RDD分区只有<em>一个</em>对象（字节数组）。在尝试其他技术之前，首先尝试使用GC解决问题的方法是使用<a href="#serialized-rdd-storage">序列化缓存</a> 。</p>

<p>由于任务的工作内存（运行任务所需的空间量）与节点上缓存的RDD之间的干扰，GC也会成为问题。我们将讨论如何控制分配给RDD缓存的空间以减轻这种情况。</p>

<p><strong>衡量GC的影响</strong></p>

<p>GC调整的第一步是收集有关垃圾收集发生频率和花费GC时间的统计信息。这可以通过添加<code>-verbose:gc -XX:+PrintGCDetails -XX:+PrintGCTimeStamps</code> Java选项。（有关将Java选项传递给Spark作业的信息，请参阅<a href="configuration.html#Dynamically-Loading-Spark-Properties">配置指南</a> 。）下次运行Spark作业时，每次发生垃圾收集时，您都会在工作日志中看到打印的消息。请注意，这些日志将位于您群集的工作节点上（在<code>stdout</code>文件放在其工作目录中）， <em>而不是</em>驱动程序上。</p>

<p><strong>高级GC调整</strong></p>

<p>为了进一步调整垃圾回收，我们首先需要了解有关JVM中内存管理的一些基本信息：</p>

<ul>
  <li>
    <p>Java Heap空间分为Young和Old两个区域。年轻一代用于保存寿命短的对象，而老一代则用于寿命更长的对象。</p>
  </li>
  <li>
    <p>年轻一代又分为三个区域[Eden，Survivor1，Survivor2]。</p>
  </li>
  <li>
    <p>垃圾收集过程的简化描述：当Eden已满时，将在Eden上运行次要GC，并将来自Eden和Survivor1的活动对象复制到Survivor2。幸存者区域被交换。如果对象足够旧或Survivor2已满，则将其移到“旧”。最后，当Old接近满时，将调用完整的GC。</p>
  </li>
</ul>

<p>在Spark中进行GC调整的目标是确保在旧一代中仅存储长寿命的RDD，并确保新世代具有足够的大小以存储短寿命的对象。这将有助于避免完整的GC收集任务执行期间创建的临时对象。可能有用的一些步骤是：</p>

<ul>
  <li>
    <p>通过收集GC统计信息检查是否有太多垃圾回收。如果在任务完成之前多次调用一个完整的GC，则意味着没有足够的内存来执行任务。</p>
  </li>
  <li>
    <p>如果次要集合太多，但主要GC却不多，则为Eden分配更多的内存将有所帮助。您可以将Eden的大小设置为每个任务将需要多少内存的过高估计。如果确定伊甸园的大小为<code>E</code> ，然后您可以使用选项设置年轻代的大小<code>-Xmn=4/3*E</code> 。（按4/3比例放大也是为了考虑幸存者区域使用的空间。）</p>
  </li>
  <li>
    <p>在打印的GC统计信息中，如果OldGen即将满，请通过降低以下参数来减少用于缓存的内存量： <code>spark.memory.fraction</code> ;与减慢任务执行速度相比，缓存较少的对象更好。或者，考虑减小Young代的大小。这意味着降低<code>-Xmn</code>如果您已如上设置。如果不是，请尝试更改JVM的值。 <code>NewRatio</code>参数。许多JVM将此默认值设置为2，这意味着旧代占据了堆的2/3。它应该足够大，以使该分数超过<code>spark.memory.fraction</code> 。</p>
  </li>
  <li>
    <p>尝试使用G1GC垃圾收集器<code>-XX:+UseG1GC</code> 。在垃圾收集成为瓶颈的某些情况下，它可以提高性能。请注意，对于较大的执行程序堆大小，使用以下命令增加<a href="http://www.oracle.com/technetwork/articles/java/g1gc-1984535.html">G1区域大小</a>可能很重要<code>-XX:G1HeapRegionSize</code></p>
  </li>
  <li>
    <p>例如，如果您的任务是从HDFS读取数据，则可以使用从HDFS读取的数据块的大小来估算任务使用的内存量。注意，解压缩块的大小通常是块大小的2或3倍。因此，如果我们希望拥有3或4个任务的工作空间，并且HDFS块大小为128 MiB，则可以估计Eden的大小为<code>4*3*128MiB</code> 。</p>
  </li>
  <li>
    <p>使用新设置监视垃圾回收所花费的频率和时间如何变化。</p>
  </li>
</ul>

<p>我们的经验表明，GC调整的效果取决于您的应用程序和可用内存量。在线上描述<a href="https://docs.oracle.com/javase/8/docs/technotes/guides/vm/gctuning/index.html">了更多的调优选项</a> ，但从总体上讲，管理完整GC的频率可以帮助减少开销。</p>

<p>可以通过设置指定执行程序的GC调整标志<code>spark.executor.defaultJavaOptions</code>要么<code>spark.executor.extraJavaOptions</code>在作业的配置中。</p>

<h1 id="other-considerations">其他注意事项</h1>

<h2 id="level-of-parallelism">并行度</h2>

<p>除非您为每个操作设置足够高的并行度，否则群集将无法充分利用。Spark会根据文件大小自动设置要在每个文件上运行的“映射”任务的数量（尽管您可以通过可选参数来控制它） <code>SparkContext.textFile</code>等等），以及分布式“减少”操作，例如<code>groupByKey</code>和<code>reduceByKey</code> ，它使用最大的父RDD分区数。您可以将并行性级别作为第二个参数传递（请参见<a href="api/scala/index.html#org.apache.spark.rdd.PairRDDFunctions"><code>spark.PairRDDFunctions</code></a>文档），或设置config属性<code>spark.default.parallelism</code>更改默认值。通常，我们建议集群中每个CPU内核执行2-3个任务。</p>

<h2 id="memory-usage-of-reduce-tasks">减少任务的内存使用</h2>

<p>有时，您会收到OutOfMemoryError的原因不是因为您的RDD不能容纳在内存中，而是因为您其中一项任务的工作集，例如其中的reduce任务之一。 <code>groupByKey</code> ，太大。Spark的随机播放操作（ <code>sortByKey</code> ， <code>groupByKey</code> ， <code>reduceByKey</code> ， <code>join</code>等）在每个任务中建立一个哈希表来执行分组，该哈希表通常可能很大。此处最简单的解决方法是<em>提高并行度</em> ，以使每个任务的输入集更小。Spark可以高效地支持短至200 ms的任务，因为它可以在多个任务中重用一个执行器JVM，并且任务启动成本低，因此您可以安全地将并行级别提高到集群中核心的数量以上。</p>

<h2 id="broadcasting-large-variables">广播大变量</h2>

<p>使用中提供的<a href="rdd-programming-guide.html#broadcast-variables">广播功能</a> <code>SparkContext</code>可以大大减少每个序列化任务的大小，以及在集群上启动作业的成本。如果您的任务使用驱动程序中的任何大对象（例如，静态查找表），请考虑将其转换为广播变量。Spark在主服务器上打印每个任务的序列化大小，因此您可以查看它来确定任务是否太大；通常，大于20 KiB的任务可能值得优化。</p>

<h2 id="data-locality">数据局部性</h2>

<p>数据局部性可能会对Spark作业的性能产生重大影响。如果数据和对其进行操作的代码在一起，则计算速度往往会很快。但是，如果代码和数据是分开的，那么一个必须移到另一个。通常，从一个地方到另一个地方传送序列化代码要比块数据更快，因为代码大小比数据小得多。Spark围绕此数据本地性一般原则构建调度。</p>

<p>数据局部性是数据与处理它的代码之间的接近程度。根据数据的当前位置，可分为多个级别。从最远到最远的顺序：</p>

<ul>
  <li><code>PROCESS_LOCAL</code>数据与正在运行的代码位于同一JVM中。这是最好的位置</li>
  <li><code>NODE_LOCAL</code>数据在同一节点上。示例可能在同一节点上的HDFS中，或者在同一节点上的另一执行程序中。这比慢一点<code>PROCESS_LOCAL</code>因为数据必须在流程之间传输</li>
  <li><code>NO_PREF</code>可以从任何地方快速访问数据，并且不受位置限制</li>
  <li><code>RACK_LOCAL</code>数据在同一服务器机架上。数据位于同一机架上的另一台服务器上，因此通常需要通过单个交换机通过网络发送</li>
  <li><code>ANY</code>数据在网络上的其他位置，而不是在同一机架中</li>
</ul>

<p>Spark倾向于在最佳位置级别安排所有任务，但这并不总是可能的。在任何空闲执行器上没有未处理数据的情况下，Spark会切换到较低的本地级别。有两种选择：a）等待繁忙的CPU释放以在同一服务器上启动数据任务，或b）立即在需要将数据移动到更远的地方启动新任务。</p>

<p>Spark通常要做的是稍等一下，以期释放繁忙的CPU。一旦超时到期，它将开始将数据从较远的地方移至空闲的CPU。每个级别之间的回退等待超时可以单独配置，也可以一起配置在一个参数中。看到<code>spark.locality</code>有关详细信息，请参阅<a href="configuration.html#scheduling">配置页面</a>上的参数。如果您的任务很长并且位置不佳，则应增加这些设置，但是默认设置通常效果很好。</p>

<h1 id="summary">摘要</h1>

<p>这是一个简短的指南，指出了在调整Spark应用程序时应了解的主要问题-最重要的是数据序列化和内存调整。对于大多数程序，切换到Kryo序列化并以序列化形式保留数据将解决大多数常见的性能问题。随时在<a href="https://spark.apache.org/community.html">Spark邮件列表中</a>询问其他调优最佳实践。</p>


                </div>
            
             <!-- /container -->
        </div>

        <script src="js/vendor/jquery-3.4.1.min.js"></script>
        <script src="js/vendor/bootstrap.min.js"></script>
        <script src="js/vendor/anchor.min.js"></script>
        <script src="js/main.js"></script>

        <!-- MathJax Section -->
        <script type="text/x-mathjax-config">
            MathJax.Hub.Config({
                TeX: { equationNumbers: { autoNumber: "AMS" } }
            });
        </script>
        <script>
            // Note that we load MathJax this way to work with local file (file://), HTTP and HTTPS.
            // We could use "//cdn.mathjax...", but that won't support "file://".
            (function(d, script) {
                script = d.createElement('script');
                script.type = 'text/javascript';
                script.async = true;
                script.onload = function(){
                    MathJax.Hub.Config({
                        tex2jax: {
                            inlineMath: [ ["$", "$"], ["\\\\(","\\\\)"] ],
                            displayMath: [ ["$$","$$"], ["\\[", "\\]"] ],
                            processEscapes: true,
                            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre']
                        }
                    });
                };
                script.src = ('https:' == document.location.protocol ? 'https://' : 'http://') +
                    'cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js' +
                    '?config=TeX-AMS-MML_HTMLorMML';
                d.getElementsByTagName('head')[0].appendChild(script);
            }(document));
        </script>
    

</body></html>