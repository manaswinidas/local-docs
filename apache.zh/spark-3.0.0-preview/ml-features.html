<html class="no-js" ><head></head><body >﻿<!--<![endif]-->
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
        <title>提取，转换和选择特征-Spark 3.0.0-预览文档</title>
        

        

        <link rel="stylesheet" href="css/bootstrap.min.css">
        <style>
            body {
                padding-top: 60px;
                padding-bottom: 40px;
            }
        </style>
        <meta name="viewport" content="width=device-width">
        <link rel="stylesheet" href="css/bootstrap-responsive.min.css">
        <link rel="stylesheet" href="css/main.css">

        <script src="js/vendor/modernizr-2.6.1-respond-1.1.0.min.js"></script>

        <link rel="stylesheet" href="css/pygments-default.css">

        
        <!-- Google analytics script -->
        <script type="text/javascript">
          var _gaq = _gaq || [];
          _gaq.push(['_setAccount', 'UA-32518208-2']);
          _gaq.push(['_trackPageview']);

          (function() {
            var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
            ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
            var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
          })();
        </script>
        

    
    
        <!--[if lt IE 7]>
            <p class="chromeframe">You are using an outdated browser. <a href="https://browsehappy.com/">Upgrade your browser today</a> or <a href="http://www.google.com/chromeframe/?redirect=true">install Google Chrome Frame</a> to better experience this site.</p>
        <![endif]-->

        <!-- This code is taken from http://twitter.github.com/bootstrap/examples/hero.html -->

        <div class="navbar navbar-fixed-top" id="topbar">
            <div class="navbar-inner">
                <div class="container">
                    <div class="brand"><a href="index.html"><img src="img/spark-logo-hd.png" style="height:50px"></a> <span class="version">3.0.0预览版</span>
                    </div>
                    <ul class="nav">
                        <!--TODO(andyk): Add class="active" attribute to li some how.-->
                        <li><a href="index.html">总览</a></li>

                        <li class="dropdown">
                            <a href="#" class="dropdown-toggle" data-toggle="dropdown">编程指南<b class="caret"></b></a>
                            <ul class="dropdown-menu">
                                <li><a href="quick-start.html">快速开始</a></li>
                                <li><a href="rdd-programming-guide.html">RDD，累加器，广播变量</a></li>
                                <li><a href="sql-programming-guide.html">SQL，数据框和数据集</a></li>
                                <li><a href="structured-streaming-programming-guide.html">结构化流</a></li>
                                <li><a href="streaming-programming-guide.html">火花流（DStreams）</a></li>
                                <li><a href="ml-guide.html">MLlib（机器学习）</a></li>
                                <li><a href="graphx-programming-guide.html">GraphX（图形处理）</a></li>
                                <li><a href="sparkr.html">SparkR（Spark上的R）</a></li>
                            </ul>
                        </li>

                        <li class="dropdown">
                            <a href="#" class="dropdown-toggle" data-toggle="dropdown">API文件<b class="caret"></b></a>
                            <ul class="dropdown-menu">
                                <li><a href="api/scala/index.html#org.apache.spark.package">斯卡拉</a></li>
                                <li><a href="api/java/index.html">爪哇</a></li>
                                <li><a href="api/python/index.html">蟒蛇</a></li>
                                <li><a href="api/R/index.html">[R</a></li>
                                <li><a href="api/sql/index.html">SQL，内置函数</a></li>
                            </ul>
                        </li>

                        <li class="dropdown">
                            <a href="#" class="dropdown-toggle" data-toggle="dropdown">部署中<b class="caret"></b></a>
                            <ul class="dropdown-menu">
                                <li><a href="cluster-overview.html">总览</a></li>
                                <li><a href="submitting-applications.html">提交申请</a></li>
                                <li class="divider"></li>
                                <li><a href="spark-standalone.html">Spark独立</a></li>
                                <li><a href="running-on-mesos.html">梅索斯</a></li>
                                <li><a href="running-on-yarn.html">纱</a></li>
                                <li><a href="running-on-kubernetes.html">Kubernetes</a></li>
                            </ul>
                        </li>

                        <li class="dropdown">
                            <a href="api.html" class="dropdown-toggle" data-toggle="dropdown">更多<b class="caret"></b></a>
                            <ul class="dropdown-menu">
                                <li><a href="configuration.html">组态</a></li>
                                <li><a href="monitoring.html">监控方式</a></li>
                                <li><a href="tuning.html">调音指南</a></li>
                                <li><a href="job-scheduling.html">作业调度</a></li>
                                <li><a href="security.html">安全</a></li>
                                <li><a href="hardware-provisioning.html">硬件配置</a></li>
                                <li><a href="migration-guide.html">迁移指南</a></li>
                                <li class="divider"></li>
                                <li><a href="building-spark.html">建筑火花</a></li>
                                <li><a href="https://spark.apache.org/contributing.html">为Spark贡献</a></li>
                                <li><a href="https://spark.apache.org/third-party-projects.html">第三方项目</a></li>
                            </ul>
                        </li>
                    </ul>
                    <!--<p class="navbar-text pull-right"><span class="version-text">v3.0.0-preview</span></p>-->
                </div>
            </div>
        </div>

        <div class="container-wrapper">

            
                
                    <div class="left-menu-wrapper">
    <div class="left-menu">
        <h3><a href="ml-guide.html">MLlib：主要指南</a></h3>
        
<ul>

    <li>
        <a href="ml-statistics.html">基本统计</a>
    </li>
    
    

    <li>
        <a href="ml-datasource.html">数据源</a>
    </li>
    
    

    <li>
        <a href="ml-pipeline.html">流水线</a>
    </li>
    
    

    <li>
        <a href="ml-features.html">
            
                <b>提取，转换和选择特征</b>
            
        </a>
    </li>
    
    

    <li>
        <a href="ml-classification-regression.html">分类与回归</a>
    </li>
    
    

    <li>
        <a href="ml-clustering.html">聚类</a>
    </li>
    
    

    <li>
        <a href="ml-collaborative-filtering.html">协同过滤</a>
    </li>
    
    

    <li>
        <a href="ml-frequent-pattern-mining.html">频繁模式挖掘</a>
    </li>
    
    

    <li>
        <a href="ml-tuning.html">模型选择和调整</a>
    </li>
    
    

    <li>
        <a href="ml-advanced.html">进阶主题</a>
    </li>
    
    

</ul>

        <h3><a href="mllib-guide.html">MLlib：基于RDD的API指南</a></h3>
        
<ul>

    <li>
        <a href="mllib-data-types.html">资料类型</a>
    </li>
    
    

    <li>
        <a href="mllib-statistics.html">基本统计</a>
    </li>
    
    

    <li>
        <a href="mllib-classification-regression.html">分类与回归</a>
    </li>
    
    

    <li>
        <a href="mllib-collaborative-filtering.html">协同过滤</a>
    </li>
    
    

    <li>
        <a href="mllib-clustering.html">聚类</a>
    </li>
    
    

    <li>
        <a href="mllib-dimensionality-reduction.html">降维</a>
    </li>
    
    

    <li>
        <a href="mllib-feature-extraction.html">特征提取和转换</a>
    </li>
    
    

    <li>
        <a href="mllib-frequent-pattern-mining.html">频繁模式挖掘</a>
    </li>
    
    

    <li>
        <a href="mllib-evaluation-metrics.html">评估指标</a>
    </li>
    
    

    <li>
        <a href="mllib-pmml-model-export.html">PMML模型导出</a>
    </li>
    
    

    <li>
        <a href="mllib-optimization.html">优化（开发人员）</a>
    </li>
    
    

</ul>

    </div>
</div>
                
                <input id="nav-trigger" class="nav-trigger" type="checkbox" checked>
                <label for="nav-trigger"></label>
                <div class="content-with-sidebar" id="content">
                    
                        <h1 class="title">提取，转换和选择特征</h1>
                    

                    <p>本节涵盖使用功能的算法，大致分为以下几类：</p>

<ul>
  <li>提取：从“原始”数据中提取特征</li>
  <li>转换：缩放，转换或修改特征</li>
  <li>选择：从更大的功能集中选择一个子集</li>
  <li>局部敏感哈希（LSH）：此类算法将特征转换的各个方面与其他算法结合在一起。</li>
</ul>

<p><strong>目录</strong></p>

<ul id="markdown-toc">
  <li><a href="#feature-extractors" id="markdown-toc-feature-extractors">特征提取器</a>    <ul>
      <li><a href="#tf-idf" id="markdown-toc-tf-idf">特遣部队</a></li>
      <li><a href="#word2vec" id="markdown-toc-word2vec">Word2Vec</a></li>
      <li><a href="#countvectorizer" id="markdown-toc-countvectorizer">CountVectorizer</a></li>
      <li><a href="#featurehasher" id="markdown-toc-featurehasher">FeatureHasher</a></li>
    </ul>
  </li>
  <li><a href="#feature-transformers" id="markdown-toc-feature-transformers">功能变压器</a>    <ul>
      <li><a href="#tokenizer" id="markdown-toc-tokenizer">分词器</a></li>
      <li><a href="#stopwordsremover" id="markdown-toc-stopwordsremover">StopWordsRemover</a></li>
      <li><a href="#n-gram" id="markdown-toc-n-gram">$ n $克</a></li>
      <li><a href="#binarizer" id="markdown-toc-binarizer">二值化器</a></li>
      <li><a href="#pca" id="markdown-toc-pca">PCA</a></li>
      <li><a href="#polynomialexpansion" id="markdown-toc-polynomialexpansion">多项式展开</a></li>
      <li><a href="#discrete-cosine-transform-dct" id="markdown-toc-discrete-cosine-transform-dct">离散余弦变换（DCT）</a></li>
      <li><a href="#stringindexer" id="markdown-toc-stringindexer">字符串索引器</a></li>
      <li><a href="#indextostring" id="markdown-toc-indextostring">IndexToString</a></li>
      <li><a href="#onehotencoder" id="markdown-toc-onehotencoder">OneHotEncoder</a></li>
      <li><a href="#vectorindexer" id="markdown-toc-vectorindexer">VectorIndexer</a></li>
      <li><a href="#interaction" id="markdown-toc-interaction">相互作用</a></li>
      <li><a href="#normalizer" id="markdown-toc-normalizer">归一化</a></li>
      <li><a href="#standardscaler" id="markdown-toc-standardscaler">标准缩放器</a></li>
      <li><a href="#robustscaler" id="markdown-toc-robustscaler">健壮的洁牙机</a></li>
      <li><a href="#minmaxscaler" id="markdown-toc-minmaxscaler">MinMaxScaler</a></li>
      <li><a href="#maxabsscaler" id="markdown-toc-maxabsscaler">MaxAbsScaler</a></li>
      <li><a href="#bucketizer" id="markdown-toc-bucketizer">铲斗机</a></li>
      <li><a href="#elementwiseproduct" id="markdown-toc-elementwiseproduct">Elementwise产品</a></li>
      <li><a href="#sqltransformer" id="markdown-toc-sqltransformer">SQLTransformer</a></li>
      <li><a href="#vectorassembler" id="markdown-toc-vectorassembler">VectorAssembler</a></li>
      <li><a href="#vectorsizehint" id="markdown-toc-vectorsizehint">VectorSizeHint</a></li>
      <li><a href="#quantilediscretizer" id="markdown-toc-quantilediscretizer">分位数离散器</a></li>
      <li><a href="#imputer" id="markdown-toc-imputer">不通</a></li>
    </ul>
  </li>
  <li><a href="#feature-selectors" id="markdown-toc-feature-selectors">功能选择器</a>    <ul>
      <li><a href="#vectorslicer" id="markdown-toc-vectorslicer">VectorSlicer</a></li>
      <li><a href="#rformula" id="markdown-toc-rformula">公式</a></li>
      <li><a href="#chisqselector" id="markdown-toc-chisqselector">ChiSqSelector</a></li>
    </ul>
  </li>
  <li><a href="#locality-sensitive-hashing" id="markdown-toc-locality-sensitive-hashing">局部敏感哈希</a>    <ul>
      <li><a href="#lsh-operations" id="markdown-toc-lsh-operations">LSH运作</a>        <ul>
          <li><a href="#feature-transformation" id="markdown-toc-feature-transformation">特征转换</a></li>
          <li><a href="#approximate-similarity-join" id="markdown-toc-approximate-similarity-join">近似相似度加入</a></li>
          <li><a href="#approximate-nearest-neighbor-search" id="markdown-toc-approximate-nearest-neighbor-search">近似最近邻居搜索</a></li>
        </ul>
      </li>
      <li><a href="#lsh-algorithms" id="markdown-toc-lsh-algorithms">LSH算法</a>        <ul>
          <li><a href="#bucketed-random-projection-for-euclidean-distance" id="markdown-toc-bucketed-random-projection-for-euclidean-distance">欧氏距离的桶式随机投影</a></li>
          <li><a href="#minhash-for-jaccard-distance" id="markdown-toc-minhash-for-jaccard-distance">贾卡距离的MinHash</a></li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h1 id="feature-extractors">特征提取器</h1>

<h2 id="tf-idf">特遣部队</h2>

<p><a href="http://en.wikipedia.org/wiki/Tf%E2%80%93idf">术语频率逆文档频率（TF-IDF）</a>是一种特征向量化方法，广泛用于文本挖掘中，以反映术语对语料库中文档的重要性。用一个词来表示<code>$t$</code> ，文档由<code>$d$</code>和语料库<code>$D$</code> 。词频<code>$TF(t, d)$</code>是该词的次数<code>$t$</code>出现在文件中<code>$d$</code> ，而文件频率<code>$DF(t, D)$</code>是包含术语的文档数<code>$t$</code> 。如果我们仅使用术语频率来衡量重要性，则很容易过分强调那些经常出现但几乎没有有关文档的信息的术语，例如“一个”，“该”和“属于”。如果术语经常出现在整个语料库中，则表示该术语不包含有关特定文档的特殊信息。反向文档频率是一个术语提供多少信息的数字度量： <code>\[ IDF(t, D) = \log \frac{|D| + 1}{DF(t, D) + 1}, \]</code>哪里<code>$|D|$</code>是语料库中文档的总数。由于使用对数，因此如果一个术语出现在所有文档中，则其IDF值将变为0。请注意，应用了平滑项来避免对主体外的项除以零。TF-IDF度量只是TF和IDF的乘积： <code>\[ TFIDF(t, d, D) = TF(t, d) \cdot IDF(t, D). \]</code>术语频率和文档频率的定义有几种变体。在MLlib中，我们将TF和IDF分开以使其灵活。</p>

<p><strong>TF</strong> ：两者<code>HashingTF</code>和<code>CountVectorizer</code>可用于生成频率向量。</p>

<p><code>HashingTF</code>是一个<code>Transformer</code>它采用术语集并将这些集转换为固定长度的特征向量。在文本处理中，“一组术语”可能是一袋单词。
<code>HashingTF</code>利用<a href="http://en.wikipedia.org/wiki/Feature_hashing">哈希技巧</a> 。通过应用哈希函数将原始特征映射到索引（项）。此处使用的哈希函数是<a href="https://en.wikipedia.org/wiki/MurmurHash">MurmurHash 3</a> 。然后根据映射的索引计算词频。这种方法避免了需要计算全局项到索引图的情况，这对于大型语料库可能是昂贵的，但是它会遭受潜在的哈希冲突，即哈希后不同的原始特征可能变成相同的术语。为了减少冲突的机会，我们可以增加目标特征的维数，即哈希表的存储桶数。由于使用散列值的简单模来确定向量索引，因此建议使用2的幂作为特征维，否则特征将不会均匀地映射到向量索引。默认特征尺寸为<code>$2^{18} = 262,144$</code> 。可选的二进制切换参数控制项频率计数。设置为true时，所有非零频率计数都设置为1。这对于模拟二进制计数而非整数计数的离散概率模型特别有用。</p>

<p><code>CountVectorizer</code>将文本文档转换为术语计数向量。有关更多详细信息，请参考<a href="ml-features.html#countvectorizer">CountVectorizer</a> 。</p>

<p><strong>IDF</strong> ： <code>IDF</code>是一个<code>Estimator</code>适合数据集并产生一个<code>IDFModel</code> 。的<code>IDFModel</code>接受特征向量（通常从<code>HashingTF</code>要么<code>CountVectorizer</code> ）并缩放每个功能。直观地，它会减少在语料库中经常出现的特征的权重。</p>

<p><strong>注意：</strong> <code>spark.ml</code>不提供用于文本分割的工具。我们将用户推荐给<a href="http://nlp.stanford.edu/">Stanford NLP Group</a>和<a href="https://github.com/scalanlp/chalk">scalanlp / chalk</a> 。</p>

<p><strong>例子</strong></p>

<p>在下面的代码段中，我们从一组句子开始。我们使用<code>Tokenizer</code> 。对于每个句子（单词袋），我们使用<code>HashingTF</code>将句子散列为特征向量我们用<code>IDF</code>重新缩放特征向量；使用文本作为特征时，通常可以提高性能。然后，我们的特征向量可以传递给学习算法。</p>

<div class="codetabs">
<div data-lang="scala">

    <p>有关API的更多详细信息，请参考<a href="api/scala/index.html#org.apache.spark.ml.feature.HashingTF">HashingTF Scala文档</a>和<a href="api/scala/index.html#org.apache.spark.ml.feature.IDF">IDF Scala文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">org.apache.spark.ml.feature.</span><span class="o">{</span><span class="nc">HashingTF</span><span class="o">,</span> <span class="nc">IDF</span><span class="o">,</span> <span class="nc">Tokenizer</span><span class="o">}</span>

<span class="k">val</span> <span class="n">sentenceData</span> <span class="k">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="o">(</span><span class="nc">Seq</span><span class="o">(</span>
  <span class="o">(</span><span class="mf">0.0</span><span class="o">,</span> <span class="s">&quot;Hi I heard about Spark&quot;</span><span class="o">),</span>
  <span class="o">(</span><span class="mf">0.0</span><span class="o">,</span> <span class="s">&quot;I wish Java could use case classes&quot;</span><span class="o">),</span>
  <span class="o">(</span><span class="mf">1.0</span><span class="o">,</span> <span class="s">&quot;Logistic regression models are neat&quot;</span><span class="o">)</span>
<span class="o">)).</span><span class="n">toDF</span><span class="o">(</span><span class="s">&quot;label&quot;</span><span class="o">,</span> <span class="s">&quot;sentence&quot;</span><span class="o">)</span>

<span class="k">val</span> <span class="n">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">().</span><span class="n">setInputCol</span><span class="o">(</span><span class="s">&quot;sentence&quot;</span><span class="o">).</span><span class="n">setOutputCol</span><span class="o">(</span><span class="s">&quot;words&quot;</span><span class="o">)</span>
<span class="k">val</span> <span class="n">wordsData</span> <span class="k">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">transform</span><span class="o">(</span><span class="n">sentenceData</span><span class="o">)</span>

<span class="k">val</span> <span class="n">hashingTF</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">HashingTF</span><span class="o">()</span>
  <span class="o">.</span><span class="n">setInputCol</span><span class="o">(</span><span class="s">&quot;words&quot;</span><span class="o">).</span><span class="n">setOutputCol</span><span class="o">(</span><span class="s">&quot;rawFeatures&quot;</span><span class="o">).</span><span class="n">setNumFeatures</span><span class="o">(</span><span class="mi">20</span><span class="o">)</span>

<span class="k">val</span> <span class="n">featurizedData</span> <span class="k">=</span> <span class="n">hashingTF</span><span class="o">.</span><span class="n">transform</span><span class="o">(</span><span class="n">wordsData</span><span class="o">)</span>
<span class="c1">// alternatively, CountVectorizer can also be used to get term frequency vectors</span>

<span class="k">val</span> <span class="n">idf</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">IDF</span><span class="o">().</span><span class="n">setInputCol</span><span class="o">(</span><span class="s">&quot;rawFeatures&quot;</span><span class="o">).</span><span class="n">setOutputCol</span><span class="o">(</span><span class="s">&quot;features&quot;</span><span class="o">)</span>
<span class="k">val</span> <span class="n">idfModel</span> <span class="k">=</span> <span class="n">idf</span><span class="o">.</span><span class="n">fit</span><span class="o">(</span><span class="n">featurizedData</span><span class="o">)</span>

<span class="k">val</span> <span class="n">rescaledData</span> <span class="k">=</span> <span class="n">idfModel</span><span class="o">.</span><span class="n">transform</span><span class="o">(</span><span class="n">featurizedData</span><span class="o">)</span>
<span class="n">rescaledData</span><span class="o">.</span><span class="n">select</span><span class="o">(</span><span class="s">&quot;label&quot;</span><span class="o">,</span> <span class="s">&quot;features&quot;</span><span class="o">).</span><span class="n">show</span><span class="o">()</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / scala / org / apache / spark / examples / ml / TfIdfExample.scala”中找到完整的示例代码。</small></div>
  </div>

<div data-lang="java">

    <p>有关API的更多详细信息，请参考<a href="api/java/org/apache/spark/ml/feature/HashingTF.html">HashingTF Java文档</a>和<a href="api/java/org/apache/spark/ml/feature/IDF.html">IDF Java文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">java.util.Arrays</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">java.util.List</span><span class="o">;</span>

<span class="kn">import</span> <span class="nn">org.apache.spark.ml.feature.HashingTF</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.ml.feature.IDF</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.ml.feature.IDFModel</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.ml.feature.Tokenizer</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.Dataset</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.Row</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.RowFactory</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.SparkSession</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.DataTypes</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.Metadata</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.StructField</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.StructType</span><span class="o">;</span>

<span class="n">List</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">data</span> <span class="o">=</span> <span class="n">Arrays</span><span class="o">.</span><span class="na">asList</span><span class="o">(</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mf">0.0</span><span class="o">,</span> <span class="s">&quot;Hi I heard about Spark&quot;</span><span class="o">),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mf">0.0</span><span class="o">,</span> <span class="s">&quot;I wish Java could use case classes&quot;</span><span class="o">),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mf">1.0</span><span class="o">,</span> <span class="s">&quot;Logistic regression models are neat&quot;</span><span class="o">)</span>
<span class="o">);</span>
<span class="n">StructType</span> <span class="n">schema</span> <span class="o">=</span> <span class="k">new</span> <span class="n">StructType</span><span class="o">(</span><span class="k">new</span> <span class="n">StructField</span><span class="o">[]{</span>
  <span class="k">new</span> <span class="n">StructField</span><span class="o">(</span><span class="s">&quot;label&quot;</span><span class="o">,</span> <span class="n">DataTypes</span><span class="o">.</span><span class="na">DoubleType</span><span class="o">,</span> <span class="kc">false</span><span class="o">,</span> <span class="n">Metadata</span><span class="o">.</span><span class="na">empty</span><span class="o">()),</span>
  <span class="k">new</span> <span class="n">StructField</span><span class="o">(</span><span class="s">&quot;sentence&quot;</span><span class="o">,</span> <span class="n">DataTypes</span><span class="o">.</span><span class="na">StringType</span><span class="o">,</span> <span class="kc">false</span><span class="o">,</span> <span class="n">Metadata</span><span class="o">.</span><span class="na">empty</span><span class="o">())</span>
<span class="o">});</span>
<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">sentenceData</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="na">createDataFrame</span><span class="o">(</span><span class="n">data</span><span class="o">,</span> <span class="n">schema</span><span class="o">);</span>

<span class="n">Tokenizer</span> <span class="n">tokenizer</span> <span class="o">=</span> <span class="k">new</span> <span class="n">Tokenizer</span><span class="o">().</span><span class="na">setInputCol</span><span class="o">(</span><span class="s">&quot;sentence&quot;</span><span class="o">).</span><span class="na">setOutputCol</span><span class="o">(</span><span class="s">&quot;words&quot;</span><span class="o">);</span>
<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">wordsData</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="na">transform</span><span class="o">(</span><span class="n">sentenceData</span><span class="o">);</span>

<span class="kt">int</span> <span class="n">numFeatures</span> <span class="o">=</span> <span class="mi">20</span><span class="o">;</span>
<span class="n">HashingTF</span> <span class="n">hashingTF</span> <span class="o">=</span> <span class="k">new</span> <span class="n">HashingTF</span><span class="o">()</span>
  <span class="o">.</span><span class="na">setInputCol</span><span class="o">(</span><span class="s">&quot;words&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">setOutputCol</span><span class="o">(</span><span class="s">&quot;rawFeatures&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">setNumFeatures</span><span class="o">(</span><span class="n">numFeatures</span><span class="o">);</span>

<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">featurizedData</span> <span class="o">=</span> <span class="n">hashingTF</span><span class="o">.</span><span class="na">transform</span><span class="o">(</span><span class="n">wordsData</span><span class="o">);</span>
<span class="c1">// alternatively, CountVectorizer can also be used to get term frequency vectors</span>

<span class="n">IDF</span> <span class="n">idf</span> <span class="o">=</span> <span class="k">new</span> <span class="n">IDF</span><span class="o">().</span><span class="na">setInputCol</span><span class="o">(</span><span class="s">&quot;rawFeatures&quot;</span><span class="o">).</span><span class="na">setOutputCol</span><span class="o">(</span><span class="s">&quot;features&quot;</span><span class="o">);</span>
<span class="n">IDFModel</span> <span class="n">idfModel</span> <span class="o">=</span> <span class="n">idf</span><span class="o">.</span><span class="na">fit</span><span class="o">(</span><span class="n">featurizedData</span><span class="o">);</span>

<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">rescaledData</span> <span class="o">=</span> <span class="n">idfModel</span><span class="o">.</span><span class="na">transform</span><span class="o">(</span><span class="n">featurizedData</span><span class="o">);</span>
<span class="n">rescaledData</span><span class="o">.</span><span class="na">select</span><span class="o">(</span><span class="s">&quot;label&quot;</span><span class="o">,</span> <span class="s">&quot;features&quot;</span><span class="o">).</span><span class="na">show</span><span class="o">();</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / java / org / apache / spark / examples / ml / JavaTfIdfExample.java”中找到完整的示例代码。</small></div>
  </div>

<div data-lang="python">

    <p>有关API的更多详细信息，请参考<a href="api/python/pyspark.ml.html#pyspark.ml.feature.HashingTF">HashingTF Python文档</a>和<a href="api/python/pyspark.ml.html#pyspark.ml.feature.IDF">IDF Python文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pyspark.ml.feature</span> <span class="kn">import</span> <span class="n">HashingTF</span><span class="p">,</span> <span class="n">IDF</span><span class="p">,</span> <span class="n">Tokenizer</span>

<span class="n">sentenceData</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">([</span>
    <span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="s2">&quot;Hi I heard about Spark&quot;</span><span class="p">),</span>
    <span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="s2">&quot;I wish Java could use case classes&quot;</span><span class="p">),</span>
    <span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="s2">&quot;Logistic regression models are neat&quot;</span><span class="p">)</span>
<span class="p">],</span> <span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">,</span> <span class="s2">&quot;sentence&quot;</span><span class="p">])</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">(</span><span class="n">inputCol</span><span class="o">=</span><span class="s2">&quot;sentence&quot;</span><span class="p">,</span> <span class="n">outputCol</span><span class="o">=</span><span class="s2">&quot;words&quot;</span><span class="p">)</span>
<span class="n">wordsData</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">sentenceData</span><span class="p">)</span>

<span class="n">hashingTF</span> <span class="o">=</span> <span class="n">HashingTF</span><span class="p">(</span><span class="n">inputCol</span><span class="o">=</span><span class="s2">&quot;words&quot;</span><span class="p">,</span> <span class="n">outputCol</span><span class="o">=</span><span class="s2">&quot;rawFeatures&quot;</span><span class="p">,</span> <span class="n">numFeatures</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">featurizedData</span> <span class="o">=</span> <span class="n">hashingTF</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">wordsData</span><span class="p">)</span>
<span class="c1"># alternatively, CountVectorizer can also be used to get term frequency vectors</span>

<span class="n">idf</span> <span class="o">=</span> <span class="n">IDF</span><span class="p">(</span><span class="n">inputCol</span><span class="o">=</span><span class="s2">&quot;rawFeatures&quot;</span><span class="p">,</span> <span class="n">outputCol</span><span class="o">=</span><span class="s2">&quot;features&quot;</span><span class="p">)</span>
<span class="n">idfModel</span> <span class="o">=</span> <span class="n">idf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">featurizedData</span><span class="p">)</span>
<span class="n">rescaledData</span> <span class="o">=</span> <span class="n">idfModel</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">featurizedData</span><span class="p">)</span>

<span class="n">rescaledData</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s2">&quot;label&quot;</span><span class="p">,</span> <span class="s2">&quot;features&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / python / ml / tf_idf_example.py”中找到完整的示例代码。</small></div>
  </div>
</div>

<h2 id="word2vec">Word2Vec</h2>

<p><code>Word2Vec</code>是一个<code>Estimator</code>它采用代表文档的单词序列并训练<code>Word2VecModel</code> 。该模型将每个单词映射到唯一的固定大小的向量。的<code>Word2VecModel</code>使用文档中所有单词的平均值将每个文档转换为向量；然后，可以将此向量用作预测，文档相似度计算等的<a href="mllib-feature-extraction.html#word2vec">功能</a> 。有关更多详细信息，请参考<a href="mllib-feature-extraction.html#word2vec">Word2Vec上</a>的<a href="mllib-feature-extraction.html#word2vec">MLlib用户指南</a> 。</p>

<p><strong>例子</strong></p>

<p>在下面的代码段中，我们从一组文档开始，每个文档都由一个单词序列表示。对于每个文档，我们将其转换为特征向量。然后可以将该特征向量传递给学习算法。</p>

<div class="codetabs">
<div data-lang="scala">

    <p>有关API的更多详细信息，请参考<a href="api/scala/index.html#org.apache.spark.ml.feature.Word2Vec">Word2Vec Scala文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">org.apache.spark.ml.feature.Word2Vec</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.linalg.Vector</span>
<span class="k">import</span> <span class="nn">org.apache.spark.sql.Row</span>

<span class="c1">// Input data: Each row is a bag of words from a sentence or document.</span>
<span class="k">val</span> <span class="n">documentDF</span> <span class="k">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="o">(</span><span class="nc">Seq</span><span class="o">(</span>
  <span class="s">&quot;Hi I heard about Spark&quot;</span><span class="o">.</span><span class="n">split</span><span class="o">(</span><span class="s">&quot; &quot;</span><span class="o">),</span>
  <span class="s">&quot;I wish Java could use case classes&quot;</span><span class="o">.</span><span class="n">split</span><span class="o">(</span><span class="s">&quot; &quot;</span><span class="o">),</span>
  <span class="s">&quot;Logistic regression models are neat&quot;</span><span class="o">.</span><span class="n">split</span><span class="o">(</span><span class="s">&quot; &quot;</span><span class="o">)</span>
<span class="o">).</span><span class="n">map</span><span class="o">(</span><span class="nc">Tuple1</span><span class="o">.</span><span class="n">apply</span><span class="o">)).</span><span class="n">toDF</span><span class="o">(</span><span class="s">&quot;text&quot;</span><span class="o">)</span>

<span class="c1">// Learn a mapping from words to Vectors.</span>
<span class="k">val</span> <span class="n">word2Vec</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Word2Vec</span><span class="o">()</span>
  <span class="o">.</span><span class="n">setInputCol</span><span class="o">(</span><span class="s">&quot;text&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">setOutputCol</span><span class="o">(</span><span class="s">&quot;result&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">setVectorSize</span><span class="o">(</span><span class="mi">3</span><span class="o">)</span>
  <span class="o">.</span><span class="n">setMinCount</span><span class="o">(</span><span class="mi">0</span><span class="o">)</span>
<span class="k">val</span> <span class="n">model</span> <span class="k">=</span> <span class="n">word2Vec</span><span class="o">.</span><span class="n">fit</span><span class="o">(</span><span class="n">documentDF</span><span class="o">)</span>

<span class="k">val</span> <span class="n">result</span> <span class="k">=</span> <span class="n">model</span><span class="o">.</span><span class="n">transform</span><span class="o">(</span><span class="n">documentDF</span><span class="o">)</span>
<span class="n">result</span><span class="o">.</span><span class="n">collect</span><span class="o">().</span><span class="n">foreach</span> <span class="o">{</span> <span class="k">case</span> <span class="nc">Row</span><span class="o">(</span><span class="n">text</span><span class="k">:</span> <span class="kt">Seq</span><span class="o">[</span><span class="k">_</span><span class="o">],</span> <span class="n">features</span><span class="k">:</span> <span class="kt">Vector</span><span class="o">)</span> <span class="k">=&gt;</span>
  <span class="n">println</span><span class="o">(</span><span class="s">s&quot;Text: [</span><span class="si">${</span><span class="n">text</span><span class="o">.</span><span class="n">mkString</span><span class="o">(</span><span class="s">&quot;, &quot;</span><span class="o">)</span><span class="si">}</span><span class="s">] =&gt; \nVector: </span><span class="si">$features</span><span class="s">\n&quot;</span><span class="o">)</span> <span class="o">}</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / scala / org / apache / spark / examples / ml / Word2VecExample.scala”中找到完整的示例代码。</small></div>
  </div>

<div data-lang="java">

    <p>有关API的更多详细信息，请参考<a href="api/java/org/apache/spark/ml/feature/Word2Vec.html">Word2Vec Java文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">java.util.Arrays</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">java.util.List</span><span class="o">;</span>

<span class="kn">import</span> <span class="nn">org.apache.spark.ml.feature.Word2Vec</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.ml.feature.Word2VecModel</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.ml.linalg.Vector</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.Dataset</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.Row</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.RowFactory</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.SparkSession</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.*</span><span class="o">;</span>

<span class="c1">// Input data: Each row is a bag of words from a sentence or document.</span>
<span class="n">List</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">data</span> <span class="o">=</span> <span class="n">Arrays</span><span class="o">.</span><span class="na">asList</span><span class="o">(</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="n">Arrays</span><span class="o">.</span><span class="na">asList</span><span class="o">(</span><span class="s">&quot;Hi I heard about Spark&quot;</span><span class="o">.</span><span class="na">split</span><span class="o">(</span><span class="s">&quot; &quot;</span><span class="o">))),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="n">Arrays</span><span class="o">.</span><span class="na">asList</span><span class="o">(</span><span class="s">&quot;I wish Java could use case classes&quot;</span><span class="o">.</span><span class="na">split</span><span class="o">(</span><span class="s">&quot; &quot;</span><span class="o">))),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="n">Arrays</span><span class="o">.</span><span class="na">asList</span><span class="o">(</span><span class="s">&quot;Logistic regression models are neat&quot;</span><span class="o">.</span><span class="na">split</span><span class="o">(</span><span class="s">&quot; &quot;</span><span class="o">)))</span>
<span class="o">);</span>
<span class="n">StructType</span> <span class="n">schema</span> <span class="o">=</span> <span class="k">new</span> <span class="n">StructType</span><span class="o">(</span><span class="k">new</span> <span class="n">StructField</span><span class="o">[]{</span>
  <span class="k">new</span> <span class="n">StructField</span><span class="o">(</span><span class="s">&quot;text&quot;</span><span class="o">,</span> <span class="k">new</span> <span class="n">ArrayType</span><span class="o">(</span><span class="n">DataTypes</span><span class="o">.</span><span class="na">StringType</span><span class="o">,</span> <span class="kc">true</span><span class="o">),</span> <span class="kc">false</span><span class="o">,</span> <span class="n">Metadata</span><span class="o">.</span><span class="na">empty</span><span class="o">())</span>
<span class="o">});</span>
<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">documentDF</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="na">createDataFrame</span><span class="o">(</span><span class="n">data</span><span class="o">,</span> <span class="n">schema</span><span class="o">);</span>

<span class="c1">// Learn a mapping from words to Vectors.</span>
<span class="n">Word2Vec</span> <span class="n">word2Vec</span> <span class="o">=</span> <span class="k">new</span> <span class="n">Word2Vec</span><span class="o">()</span>
  <span class="o">.</span><span class="na">setInputCol</span><span class="o">(</span><span class="s">&quot;text&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">setOutputCol</span><span class="o">(</span><span class="s">&quot;result&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">setVectorSize</span><span class="o">(</span><span class="mi">3</span><span class="o">)</span>
  <span class="o">.</span><span class="na">setMinCount</span><span class="o">(</span><span class="mi">0</span><span class="o">);</span>

<span class="n">Word2VecModel</span> <span class="n">model</span> <span class="o">=</span> <span class="n">word2Vec</span><span class="o">.</span><span class="na">fit</span><span class="o">(</span><span class="n">documentDF</span><span class="o">);</span>
<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">result</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="na">transform</span><span class="o">(</span><span class="n">documentDF</span><span class="o">);</span>

<span class="k">for</span> <span class="o">(</span><span class="n">Row</span> <span class="n">row</span> <span class="o">:</span> <span class="n">result</span><span class="o">.</span><span class="na">collectAsList</span><span class="o">())</span> <span class="o">{</span>
  <span class="n">List</span><span class="o">&lt;</span><span class="n">String</span><span class="o">&gt;</span> <span class="n">text</span> <span class="o">=</span> <span class="n">row</span><span class="o">.</span><span class="na">getList</span><span class="o">(</span><span class="mi">0</span><span class="o">);</span>
  <span class="n">Vector</span> <span class="n">vector</span> <span class="o">=</span> <span class="o">(</span><span class="n">Vector</span><span class="o">)</span> <span class="n">row</span><span class="o">.</span><span class="na">get</span><span class="o">(</span><span class="mi">1</span><span class="o">);</span>
  <span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">&quot;Text: &quot;</span> <span class="o">+</span> <span class="n">text</span> <span class="o">+</span> <span class="s">&quot; =&gt; \nVector: &quot;</span> <span class="o">+</span> <span class="n">vector</span> <span class="o">+</span> <span class="s">&quot;\n&quot;</span><span class="o">);</span>
<span class="o">}</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / java / org / apache / spark / examples / ml / JavaWord2VecExample.java”中找到完整的示例代码。</small></div>
  </div>

<div data-lang="python">

    <p>有关API的更多详细信息，请参考<a href="api/python/pyspark.ml.html#pyspark.ml.feature.Word2Vec">Word2Vec Python文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pyspark.ml.feature</span> <span class="kn">import</span> <span class="n">Word2Vec</span>

<span class="c1"># Input data: Each row is a bag of words from a sentence or document.</span>
<span class="n">documentDF</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">([</span>
    <span class="p">(</span><span class="s2">&quot;Hi I heard about Spark&quot;</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="p">),</span> <span class="p">),</span>
    <span class="p">(</span><span class="s2">&quot;I wish Java could use case classes&quot;</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="p">),</span> <span class="p">),</span>
    <span class="p">(</span><span class="s2">&quot;Logistic regression models are neat&quot;</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="p">),</span> <span class="p">)</span>
<span class="p">],</span> <span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">])</span>

<span class="c1"># Learn a mapping from words to Vectors.</span>
<span class="n">word2Vec</span> <span class="o">=</span> <span class="n">Word2Vec</span><span class="p">(</span><span class="n">vectorSize</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">minCount</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">inputCol</span><span class="o">=</span><span class="s2">&quot;text&quot;</span><span class="p">,</span> <span class="n">outputCol</span><span class="o">=</span><span class="s2">&quot;result&quot;</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">word2Vec</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">documentDF</span><span class="p">)</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">documentDF</span><span class="p">)</span>
<span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">result</span><span class="o">.</span><span class="n">collect</span><span class="p">():</span>
    <span class="n">text</span><span class="p">,</span> <span class="n">vector</span> <span class="o">=</span> <span class="n">row</span>
    <span class="k">print</span><span class="p">(</span><span class="s2">&quot;Text: [</span><span class="si">%s</span><span class="s2">] =&gt; </span><span class="se">\n</span><span class="s2">Vector: </span><span class="si">%s</span><span class="se">\n</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="s2">&quot;, &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">text</span><span class="p">),</span> <span class="nb">str</span><span class="p">(</span><span class="n">vector</span><span class="p">)))</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / python / ml / word2vec_example.py”中找到完整的示例代码。</small></div>
  </div>
</div>

<h2 id="countvectorizer">CountVectorizer</h2>

<p><code>CountVectorizer</code>和<code>CountVectorizerModel</code>旨在帮助将文本文档的集合转换为令牌计数的向量。如果没有先验字典， <code>CountVectorizer</code>可以用作<code>Estimator</code>提取词汇表，并生成一个<code>CountVectorizerModel</code> 。该模型为词汇表上的文档生成稀疏表示，然后可以将其传递给其他算法，例如LDA。</p>

<p>在试穿过程中， <code>CountVectorizer</code>将选择顶部<code>vocabSize</code>整个语料库中按词频排列的单词。可选参数<code>minDF</code>通过指定一个单词必须出现在词汇表中的最小数量（或<1.0，如果小于1.0），也会影响拟合过程。另一个可选的二进制切换参数控制输出向量。如果设置为true，则所有非零计数都设置为1。这对于模拟二进制计数而非整数计数的离散概率模型特别有用。</p>

<p><strong>例子</strong></p>

<p>假设我们有以下带有列的DataFrame <code>id</code>和<code>texts</code> ：</p>

<pre><code> id | texts
----|----------
 0  | Array("a", "b", "c")
 1  | Array("a", "b", "b", "c", "a")
</code></pre>

<p>每行<code>texts</code>是Array [String]类型的文档。调用适合<code>CountVectorizer</code>产生一个<code>CountVectorizerModel</code>带有词汇（a，b，c）。然后，转换后的输出列“ vector”包含：</p>

<pre><code> id | texts                           | vector
----|---------------------------------|---------------
 0  | Array("a", "b", "c")            | (3,[0,1,2],[1.0,1.0,1.0])
 1  | Array("a", "b", "b", "c", "a")  | (3,[0,1,2],[2.0,2.0,1.0])
</code></pre>

<p>每个向量代表整个词汇表中文档的标记计数。</p>

<div class="codetabs">
<div data-lang="scala">

    <p>有关该API的更多详细信息，请参考<a href="api/scala/index.html#org.apache.spark.ml.feature.CountVectorizer">CountVectorizer Scala文档</a>和<a href="api/scala/index.html#org.apache.spark.ml.feature.CountVectorizerModel">CountVectorizerModel Scala文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">org.apache.spark.ml.feature.</span><span class="o">{</span><span class="nc">CountVectorizer</span><span class="o">,</span> <span class="nc">CountVectorizerModel</span><span class="o">}</span>

<span class="k">val</span> <span class="n">df</span> <span class="k">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="o">(</span><span class="nc">Seq</span><span class="o">(</span>
  <span class="o">(</span><span class="mi">0</span><span class="o">,</span> <span class="nc">Array</span><span class="o">(</span><span class="s">&quot;a&quot;</span><span class="o">,</span> <span class="s">&quot;b&quot;</span><span class="o">,</span> <span class="s">&quot;c&quot;</span><span class="o">)),</span>
  <span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="nc">Array</span><span class="o">(</span><span class="s">&quot;a&quot;</span><span class="o">,</span> <span class="s">&quot;b&quot;</span><span class="o">,</span> <span class="s">&quot;b&quot;</span><span class="o">,</span> <span class="s">&quot;c&quot;</span><span class="o">,</span> <span class="s">&quot;a&quot;</span><span class="o">))</span>
<span class="o">)).</span><span class="n">toDF</span><span class="o">(</span><span class="s">&quot;id&quot;</span><span class="o">,</span> <span class="s">&quot;words&quot;</span><span class="o">)</span>

<span class="c1">// fit a CountVectorizerModel from the corpus</span>
<span class="k">val</span> <span class="n">cvModel</span><span class="k">:</span> <span class="kt">CountVectorizerModel</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">CountVectorizer</span><span class="o">()</span>
  <span class="o">.</span><span class="n">setInputCol</span><span class="o">(</span><span class="s">&quot;words&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">setOutputCol</span><span class="o">(</span><span class="s">&quot;features&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">setVocabSize</span><span class="o">(</span><span class="mi">3</span><span class="o">)</span>
  <span class="o">.</span><span class="n">setMinDF</span><span class="o">(</span><span class="mi">2</span><span class="o">)</span>
  <span class="o">.</span><span class="n">fit</span><span class="o">(</span><span class="n">df</span><span class="o">)</span>

<span class="c1">// alternatively, define CountVectorizerModel with a-priori vocabulary</span>
<span class="k">val</span> <span class="n">cvm</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">CountVectorizerModel</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">&quot;a&quot;</span><span class="o">,</span> <span class="s">&quot;b&quot;</span><span class="o">,</span> <span class="s">&quot;c&quot;</span><span class="o">))</span>
  <span class="o">.</span><span class="n">setInputCol</span><span class="o">(</span><span class="s">&quot;words&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">setOutputCol</span><span class="o">(</span><span class="s">&quot;features&quot;</span><span class="o">)</span>

<span class="n">cvModel</span><span class="o">.</span><span class="n">transform</span><span class="o">(</span><span class="n">df</span><span class="o">).</span><span class="n">show</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / scala / org / apache / spark / examples / ml / CountVectorizerExample.scala”中找到完整的示例代码。</small></div>
  </div>

<div data-lang="java">

    <p>有关该API的更多详细信息，请参考<a href="api/java/org/apache/spark/ml/feature/CountVectorizer.html">CountVectorizer Java文档</a>和<a href="api/java/org/apache/spark/ml/feature/CountVectorizerModel.html">CountVectorizerModel Java文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">java.util.Arrays</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">java.util.List</span><span class="o">;</span>

<span class="kn">import</span> <span class="nn">org.apache.spark.ml.feature.CountVectorizer</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.ml.feature.CountVectorizerModel</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.Dataset</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.Row</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.RowFactory</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.SparkSession</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.*</span><span class="o">;</span>

<span class="c1">// Input data: Each row is a bag of words from a sentence or document.</span>
<span class="n">List</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">data</span> <span class="o">=</span> <span class="n">Arrays</span><span class="o">.</span><span class="na">asList</span><span class="o">(</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="n">Arrays</span><span class="o">.</span><span class="na">asList</span><span class="o">(</span><span class="s">&quot;a&quot;</span><span class="o">,</span> <span class="s">&quot;b&quot;</span><span class="o">,</span> <span class="s">&quot;c&quot;</span><span class="o">)),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="n">Arrays</span><span class="o">.</span><span class="na">asList</span><span class="o">(</span><span class="s">&quot;a&quot;</span><span class="o">,</span> <span class="s">&quot;b&quot;</span><span class="o">,</span> <span class="s">&quot;b&quot;</span><span class="o">,</span> <span class="s">&quot;c&quot;</span><span class="o">,</span> <span class="s">&quot;a&quot;</span><span class="o">))</span>
<span class="o">);</span>
<span class="n">StructType</span> <span class="n">schema</span> <span class="o">=</span> <span class="k">new</span> <span class="n">StructType</span><span class="o">(</span><span class="k">new</span> <span class="n">StructField</span> <span class="o">[]</span> <span class="o">{</span>
  <span class="k">new</span> <span class="n">StructField</span><span class="o">(</span><span class="s">&quot;text&quot;</span><span class="o">,</span> <span class="k">new</span> <span class="n">ArrayType</span><span class="o">(</span><span class="n">DataTypes</span><span class="o">.</span><span class="na">StringType</span><span class="o">,</span> <span class="kc">true</span><span class="o">),</span> <span class="kc">false</span><span class="o">,</span> <span class="n">Metadata</span><span class="o">.</span><span class="na">empty</span><span class="o">())</span>
<span class="o">});</span>
<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="na">createDataFrame</span><span class="o">(</span><span class="n">data</span><span class="o">,</span> <span class="n">schema</span><span class="o">);</span>

<span class="c1">// fit a CountVectorizerModel from the corpus</span>
<span class="n">CountVectorizerModel</span> <span class="n">cvModel</span> <span class="o">=</span> <span class="k">new</span> <span class="n">CountVectorizer</span><span class="o">()</span>
  <span class="o">.</span><span class="na">setInputCol</span><span class="o">(</span><span class="s">&quot;text&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">setOutputCol</span><span class="o">(</span><span class="s">&quot;feature&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">setVocabSize</span><span class="o">(</span><span class="mi">3</span><span class="o">)</span>
  <span class="o">.</span><span class="na">setMinDF</span><span class="o">(</span><span class="mi">2</span><span class="o">)</span>
  <span class="o">.</span><span class="na">fit</span><span class="o">(</span><span class="n">df</span><span class="o">);</span>

<span class="c1">// alternatively, define CountVectorizerModel with a-priori vocabulary</span>
<span class="n">CountVectorizerModel</span> <span class="n">cvm</span> <span class="o">=</span> <span class="k">new</span> <span class="n">CountVectorizerModel</span><span class="o">(</span><span class="k">new</span> <span class="n">String</span><span class="o">[]{</span><span class="s">&quot;a&quot;</span><span class="o">,</span> <span class="s">&quot;b&quot;</span><span class="o">,</span> <span class="s">&quot;c&quot;</span><span class="o">})</span>
  <span class="o">.</span><span class="na">setInputCol</span><span class="o">(</span><span class="s">&quot;text&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">setOutputCol</span><span class="o">(</span><span class="s">&quot;feature&quot;</span><span class="o">);</span>

<span class="n">cvModel</span><span class="o">.</span><span class="na">transform</span><span class="o">(</span><span class="n">df</span><span class="o">).</span><span class="na">show</span><span class="o">(</span><span class="kc">false</span><span class="o">);</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / java / org / apache / spark / examples / ml / JavaCountVectorizerExample.java”中找到完整的示例代码。</small></div>
  </div>

<div data-lang="python">

    <p>有关该API的更多详细信息，请参考<a href="api/python/pyspark.ml.html#pyspark.ml.feature.CountVectorizer">CountVectorizer Python文档</a>和<a href="api/python/pyspark.ml.html#pyspark.ml.feature.CountVectorizerModel">CountVectorizerModel Python文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pyspark.ml.feature</span> <span class="kn">import</span> <span class="n">CountVectorizer</span>

<span class="c1"># Input data: Each row is a bag of words with a ID.</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">([</span>
    <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;a b c&quot;</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="p">)),</span>
    <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="s2">&quot;a b b c a&quot;</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="p">))</span>
<span class="p">],</span> <span class="p">[</span><span class="s2">&quot;id&quot;</span><span class="p">,</span> <span class="s2">&quot;words&quot;</span><span class="p">])</span>

<span class="c1"># fit a CountVectorizerModel from the corpus.</span>
<span class="n">cv</span> <span class="o">=</span> <span class="n">CountVectorizer</span><span class="p">(</span><span class="n">inputCol</span><span class="o">=</span><span class="s2">&quot;words&quot;</span><span class="p">,</span> <span class="n">outputCol</span><span class="o">=</span><span class="s2">&quot;features&quot;</span><span class="p">,</span> <span class="n">vocabSize</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">minDF</span><span class="o">=</span><span class="mf">2.0</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">cv</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
<span class="n">result</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / python / ml / count_vectorizer_example.py”中找到完整的示例代码。</small></div>
  </div>
</div>

<h2 id="featurehasher">FeatureHasher</h2>

<p>特征哈希将一组分类或数字特征投影到指定维的特征向量中（通常比原始特征空间的特征向量小得多）。这是通过使用<a href="https://en.wikipedia.org/wiki/Feature_hashing">哈希技巧</a>将特征映射到特征向量中的索引来完成的。</p>

<p>的<code>FeatureHasher</code>变压器在多列上运行。每列都可以包含数字或分类特征。列数据类型的行为和处理如下：</p>

<ul>
  <li>数字列：对于数字特征，列名的哈希值用于将特征值映射到特征向量中的索引。默认情况下，数字功能不被视为分类功能（即使它们是整数）。要将它们视为分类，请使用<code>categoricalCols</code>参数。</li>
  <li>字符串列：对于分类特征，字符串“ column_name = value”的哈希值用于映射到矢量索引，指示符值为<code>1.0</code> 。因此，分类特征是“一次性”编码的（类似于将<a href="ml-features.html#onehotencoder">OneHotEncoder</a>与<code>dropLast=false</code> ）。</li>
  <li>布尔列：布尔值与字符串列的处理方式相同。也就是说，布尔特征表示为“ column_name = true”或“ column_name = false”，其指标值为<code>1.0</code> 。</li>
</ul>

<p>空（缺失）值将被忽略（在所得特征向量中隐式为零）。</p>

<p>这里使用的哈希函数也是<a href="ml-features.html#tf-idf">HashingTF中</a>使用的<a href="https://en.wikipedia.org/wiki/MurmurHash">MurmurHash 3</a> 。由于使用散列值的简单模来确定矢量索引，因此建议使用2的幂作为numFeatures参数；否则，建议使用2的幂。否则，这些特征将不会均匀地映射到矢量索引。</p>

<p><strong>例子</strong></p>

<p>假设我们有一个带有4个输入列的DataFrame <code>real</code> ， <code>bool</code> ， <code>stringNum</code>和<code>string</code> 。这些不同的数据类型作为输入将说明生成一列特征向量的变换的行为。</p>

<pre><code>real| bool|stringNum|string
----|-----|---------|------
 2.2| true|        1|   foo
 3.3|false|        2|   bar
 4.4|false|        3|   baz
 5.5|false|        4|   foo
</code></pre>

<p>然后输出<code>FeatureHasher.transform</code>在此DataFrame上是：</p>

<pre><code>real|bool |stringNum|string|features
----|-----|---------|------|-------------------------------------------------------
2.2 |true |1        |foo   |(262144,[51871, 63643,174475,253195],[1.0,1.0,2.2,1.0])
3.3 |false|2        |bar   |(262144,[6031,  80619,140467,174475],[1.0,1.0,1.0,3.3])
4.4 |false|3        |baz   |(262144,[24279,140467,174475,196810],[1.0,1.0,4.4,1.0])
5.5 |false|4        |foo   |(262144,[63643,140467,168512,174475],[1.0,1.0,1.0,5.5])
</code></pre>

<p>然后可以将所得的特征向量传递给学习算法。</p>

<div class="codetabs">
<div data-lang="scala">

    <p>有关API的更多详细信息，请参阅<a href="api/scala/index.html#org.apache.spark.ml.feature.FeatureHasher">FeatureHasher Scala文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">org.apache.spark.ml.feature.FeatureHasher</span>

<span class="k">val</span> <span class="n">dataset</span> <span class="k">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="o">(</span><span class="nc">Seq</span><span class="o">(</span>
  <span class="o">(</span><span class="mf">2.2</span><span class="o">,</span> <span class="kc">true</span><span class="o">,</span> <span class="s">&quot;1&quot;</span><span class="o">,</span> <span class="s">&quot;foo&quot;</span><span class="o">),</span>
  <span class="o">(</span><span class="mf">3.3</span><span class="o">,</span> <span class="kc">false</span><span class="o">,</span> <span class="s">&quot;2&quot;</span><span class="o">,</span> <span class="s">&quot;bar&quot;</span><span class="o">),</span>
  <span class="o">(</span><span class="mf">4.4</span><span class="o">,</span> <span class="kc">false</span><span class="o">,</span> <span class="s">&quot;3&quot;</span><span class="o">,</span> <span class="s">&quot;baz&quot;</span><span class="o">),</span>
  <span class="o">(</span><span class="mf">5.5</span><span class="o">,</span> <span class="kc">false</span><span class="o">,</span> <span class="s">&quot;4&quot;</span><span class="o">,</span> <span class="s">&quot;foo&quot;</span><span class="o">)</span>
<span class="o">)).</span><span class="n">toDF</span><span class="o">(</span><span class="s">&quot;real&quot;</span><span class="o">,</span> <span class="s">&quot;bool&quot;</span><span class="o">,</span> <span class="s">&quot;stringNum&quot;</span><span class="o">,</span> <span class="s">&quot;string&quot;</span><span class="o">)</span>

<span class="k">val</span> <span class="n">hasher</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">FeatureHasher</span><span class="o">()</span>
  <span class="o">.</span><span class="n">setInputCols</span><span class="o">(</span><span class="s">&quot;real&quot;</span><span class="o">,</span> <span class="s">&quot;bool&quot;</span><span class="o">,</span> <span class="s">&quot;stringNum&quot;</span><span class="o">,</span> <span class="s">&quot;string&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">setOutputCol</span><span class="o">(</span><span class="s">&quot;features&quot;</span><span class="o">)</span>

<span class="k">val</span> <span class="n">featurized</span> <span class="k">=</span> <span class="n">hasher</span><span class="o">.</span><span class="n">transform</span><span class="o">(</span><span class="n">dataset</span><span class="o">)</span>
<span class="n">featurized</span><span class="o">.</span><span class="n">show</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / scala / org / apache / spark / examples / ml / FeatureHasherExample.scala”中找到完整的示例代码。</small></div>
  </div>

<div data-lang="java">

    <p>有关API的更多详细信息，请参阅<a href="api/java/org/apache/spark/ml/feature/FeatureHasher.html">FeatureHasher Java文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">java.util.Arrays</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">java.util.List</span><span class="o">;</span>

<span class="kn">import</span> <span class="nn">org.apache.spark.ml.feature.FeatureHasher</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.Row</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.RowFactory</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.DataTypes</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.Metadata</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.StructField</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.StructType</span><span class="o">;</span>

<span class="n">List</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">data</span> <span class="o">=</span> <span class="n">Arrays</span><span class="o">.</span><span class="na">asList</span><span class="o">(</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mf">2.2</span><span class="o">,</span> <span class="kc">true</span><span class="o">,</span> <span class="s">&quot;1&quot;</span><span class="o">,</span> <span class="s">&quot;foo&quot;</span><span class="o">),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mf">3.3</span><span class="o">,</span> <span class="kc">false</span><span class="o">,</span> <span class="s">&quot;2&quot;</span><span class="o">,</span> <span class="s">&quot;bar&quot;</span><span class="o">),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mf">4.4</span><span class="o">,</span> <span class="kc">false</span><span class="o">,</span> <span class="s">&quot;3&quot;</span><span class="o">,</span> <span class="s">&quot;baz&quot;</span><span class="o">),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mf">5.5</span><span class="o">,</span> <span class="kc">false</span><span class="o">,</span> <span class="s">&quot;4&quot;</span><span class="o">,</span> <span class="s">&quot;foo&quot;</span><span class="o">)</span>
<span class="o">);</span>
<span class="n">StructType</span> <span class="n">schema</span> <span class="o">=</span> <span class="k">new</span> <span class="n">StructType</span><span class="o">(</span><span class="k">new</span> <span class="n">StructField</span><span class="o">[]{</span>
  <span class="k">new</span> <span class="n">StructField</span><span class="o">(</span><span class="s">&quot;real&quot;</span><span class="o">,</span> <span class="n">DataTypes</span><span class="o">.</span><span class="na">DoubleType</span><span class="o">,</span> <span class="kc">false</span><span class="o">,</span> <span class="n">Metadata</span><span class="o">.</span><span class="na">empty</span><span class="o">()),</span>
  <span class="k">new</span> <span class="n">StructField</span><span class="o">(</span><span class="s">&quot;bool&quot;</span><span class="o">,</span> <span class="n">DataTypes</span><span class="o">.</span><span class="na">BooleanType</span><span class="o">,</span> <span class="kc">false</span><span class="o">,</span> <span class="n">Metadata</span><span class="o">.</span><span class="na">empty</span><span class="o">()),</span>
  <span class="k">new</span> <span class="n">StructField</span><span class="o">(</span><span class="s">&quot;stringNum&quot;</span><span class="o">,</span> <span class="n">DataTypes</span><span class="o">.</span><span class="na">StringType</span><span class="o">,</span> <span class="kc">false</span><span class="o">,</span> <span class="n">Metadata</span><span class="o">.</span><span class="na">empty</span><span class="o">()),</span>
  <span class="k">new</span> <span class="n">StructField</span><span class="o">(</span><span class="s">&quot;string&quot;</span><span class="o">,</span> <span class="n">DataTypes</span><span class="o">.</span><span class="na">StringType</span><span class="o">,</span> <span class="kc">false</span><span class="o">,</span> <span class="n">Metadata</span><span class="o">.</span><span class="na">empty</span><span class="o">())</span>
<span class="o">});</span>
<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">dataset</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="na">createDataFrame</span><span class="o">(</span><span class="n">data</span><span class="o">,</span> <span class="n">schema</span><span class="o">);</span>

<span class="n">FeatureHasher</span> <span class="n">hasher</span> <span class="o">=</span> <span class="k">new</span> <span class="n">FeatureHasher</span><span class="o">()</span>
  <span class="o">.</span><span class="na">setInputCols</span><span class="o">(</span><span class="k">new</span> <span class="n">String</span><span class="o">[]{</span><span class="s">&quot;real&quot;</span><span class="o">,</span> <span class="s">&quot;bool&quot;</span><span class="o">,</span> <span class="s">&quot;stringNum&quot;</span><span class="o">,</span> <span class="s">&quot;string&quot;</span><span class="o">})</span>
  <span class="o">.</span><span class="na">setOutputCol</span><span class="o">(</span><span class="s">&quot;features&quot;</span><span class="o">);</span>

<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">featurized</span> <span class="o">=</span> <span class="n">hasher</span><span class="o">.</span><span class="na">transform</span><span class="o">(</span><span class="n">dataset</span><span class="o">);</span>

<span class="n">featurized</span><span class="o">.</span><span class="na">show</span><span class="o">(</span><span class="kc">false</span><span class="o">);</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / java / org / apache / spark / examples / ml / JavaFeatureHasherExample.java”中找到完整的示例代码。</small></div>
  </div>

<div data-lang="python">

    <p>有关API的更多详细信息，请参阅<a href="api/python/pyspark.ml.html#pyspark.ml.feature.FeatureHasher">FeatureHasher Python文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pyspark.ml.feature</span> <span class="kn">import</span> <span class="n">FeatureHasher</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">([</span>
    <span class="p">(</span><span class="mf">2.2</span><span class="p">,</span> <span class="bp">True</span><span class="p">,</span> <span class="s2">&quot;1&quot;</span><span class="p">,</span> <span class="s2">&quot;foo&quot;</span><span class="p">),</span>
    <span class="p">(</span><span class="mf">3.3</span><span class="p">,</span> <span class="bp">False</span><span class="p">,</span> <span class="s2">&quot;2&quot;</span><span class="p">,</span> <span class="s2">&quot;bar&quot;</span><span class="p">),</span>
    <span class="p">(</span><span class="mf">4.4</span><span class="p">,</span> <span class="bp">False</span><span class="p">,</span> <span class="s2">&quot;3&quot;</span><span class="p">,</span> <span class="s2">&quot;baz&quot;</span><span class="p">),</span>
    <span class="p">(</span><span class="mf">5.5</span><span class="p">,</span> <span class="bp">False</span><span class="p">,</span> <span class="s2">&quot;4&quot;</span><span class="p">,</span> <span class="s2">&quot;foo&quot;</span><span class="p">)</span>
<span class="p">],</span> <span class="p">[</span><span class="s2">&quot;real&quot;</span><span class="p">,</span> <span class="s2">&quot;bool&quot;</span><span class="p">,</span> <span class="s2">&quot;stringNum&quot;</span><span class="p">,</span> <span class="s2">&quot;string&quot;</span><span class="p">])</span>

<span class="n">hasher</span> <span class="o">=</span> <span class="n">FeatureHasher</span><span class="p">(</span><span class="n">inputCols</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;real&quot;</span><span class="p">,</span> <span class="s2">&quot;bool&quot;</span><span class="p">,</span> <span class="s2">&quot;stringNum&quot;</span><span class="p">,</span> <span class="s2">&quot;string&quot;</span><span class="p">],</span>
                       <span class="n">outputCol</span><span class="o">=</span><span class="s2">&quot;features&quot;</span><span class="p">)</span>

<span class="n">featurized</span> <span class="o">=</span> <span class="n">hasher</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
<span class="n">featurized</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / python / ml / feature_hasher_example.py”中找到完整的示例代码。</small></div>
  </div>
</div>

<h1 id="feature-transformers">功能变压器</h1>

<h2 id="tokenizer">分词器</h2>

<p><a href="http://en.wikipedia.org/wiki/Lexical_analysis#Tokenization">标记化</a>是获取文本（例如句子）并将其分解为单个术语（通常是单词）的过程。一个简单的<a href="api/scala/index.html#org.apache.spark.ml.feature.Tokenizer">Tokenizer</a>类提供了此功能。下面的示例显示了如何将句子分成单词序列。</p>

<p><a href="api/scala/index.html#org.apache.spark.ml.feature.RegexTokenizer">RegexTokenizer</a>允许基于正则表达式（regex）匹配进行更高级的标记化。默认情况下，参数“模式”（正则表达式，默认为： <code>"\\s+"</code> ）用作分隔输入文本的定界符。或者，用户可以将参数“ gap”设置为false，以表示正则表达式“ pattern”表示“令牌”，而不是拆分间隙，并找到所有匹配的出现作为标记化结果。</p>

<p><strong>例子</strong></p>

<div class="codetabs">
<div data-lang="scala">

    <p>有关API的更多详细信息，请参考<a href="api/scala/index.html#org.apache.spark.ml.feature.Tokenizer">Tokenizer Scala文档</a>和<a href="api/scala/index.html#org.apache.spark.ml.feature.RegexTokenizer">RegexTokenizer Scala文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">org.apache.spark.ml.feature.</span><span class="o">{</span><span class="nc">RegexTokenizer</span><span class="o">,</span> <span class="nc">Tokenizer</span><span class="o">}</span>
<span class="k">import</span> <span class="nn">org.apache.spark.sql.SparkSession</span>
<span class="k">import</span> <span class="nn">org.apache.spark.sql.functions._</span>

<span class="k">val</span> <span class="n">sentenceDataFrame</span> <span class="k">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="o">(</span><span class="nc">Seq</span><span class="o">(</span>
  <span class="o">(</span><span class="mi">0</span><span class="o">,</span> <span class="s">&quot;Hi I heard about Spark&quot;</span><span class="o">),</span>
  <span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="s">&quot;I wish Java could use case classes&quot;</span><span class="o">),</span>
  <span class="o">(</span><span class="mi">2</span><span class="o">,</span> <span class="s">&quot;Logistic,regression,models,are,neat&quot;</span><span class="o">)</span>
<span class="o">)).</span><span class="n">toDF</span><span class="o">(</span><span class="s">&quot;id&quot;</span><span class="o">,</span> <span class="s">&quot;sentence&quot;</span><span class="o">)</span>

<span class="k">val</span> <span class="n">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">().</span><span class="n">setInputCol</span><span class="o">(</span><span class="s">&quot;sentence&quot;</span><span class="o">).</span><span class="n">setOutputCol</span><span class="o">(</span><span class="s">&quot;words&quot;</span><span class="o">)</span>
<span class="k">val</span> <span class="n">regexTokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">RegexTokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="n">setInputCol</span><span class="o">(</span><span class="s">&quot;sentence&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">setOutputCol</span><span class="o">(</span><span class="s">&quot;words&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">setPattern</span><span class="o">(</span><span class="s">&quot;\\W&quot;</span><span class="o">)</span> <span class="c1">// alternatively .setPattern(&quot;\\w+&quot;).setGaps(false)</span>

<span class="k">val</span> <span class="n">countTokens</span> <span class="k">=</span> <span class="n">udf</span> <span class="o">{</span> <span class="o">(</span><span class="n">words</span><span class="k">:</span> <span class="kt">Seq</span><span class="o">[</span><span class="kt">String</span><span class="o">])</span> <span class="k">=&gt;</span> <span class="n">words</span><span class="o">.</span><span class="n">length</span> <span class="o">}</span>

<span class="k">val</span> <span class="n">tokenized</span> <span class="k">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">transform</span><span class="o">(</span><span class="n">sentenceDataFrame</span><span class="o">)</span>
<span class="n">tokenized</span><span class="o">.</span><span class="n">select</span><span class="o">(</span><span class="s">&quot;sentence&quot;</span><span class="o">,</span> <span class="s">&quot;words&quot;</span><span class="o">)</span>
    <span class="o">.</span><span class="n">withColumn</span><span class="o">(</span><span class="s">&quot;tokens&quot;</span><span class="o">,</span> <span class="n">countTokens</span><span class="o">(</span><span class="n">col</span><span class="o">(</span><span class="s">&quot;words&quot;</span><span class="o">))).</span><span class="n">show</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>

<span class="k">val</span> <span class="n">regexTokenized</span> <span class="k">=</span> <span class="n">regexTokenizer</span><span class="o">.</span><span class="n">transform</span><span class="o">(</span><span class="n">sentenceDataFrame</span><span class="o">)</span>
<span class="n">regexTokenized</span><span class="o">.</span><span class="n">select</span><span class="o">(</span><span class="s">&quot;sentence&quot;</span><span class="o">,</span> <span class="s">&quot;words&quot;</span><span class="o">)</span>
    <span class="o">.</span><span class="n">withColumn</span><span class="o">(</span><span class="s">&quot;tokens&quot;</span><span class="o">,</span> <span class="n">countTokens</span><span class="o">(</span><span class="n">col</span><span class="o">(</span><span class="s">&quot;words&quot;</span><span class="o">))).</span><span class="n">show</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / scala / org / apache / spark / examples / ml / TokenizerExample.scala”中找到完整的示例代码。</small></div>
  </div>

<div data-lang="java">

    <p>有关API的更多详细信息，请参考<a href="api/java/org/apache/spark/ml/feature/Tokenizer.html">Tokenizer Java文档</a>和<a href="api/java/org/apache/spark/ml/feature/RegexTokenizer.html">RegexTokenizer Java文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">java.util.Arrays</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">java.util.List</span><span class="o">;</span>

<span class="kn">import</span> <span class="nn">scala.collection.mutable.WrappedArray</span><span class="o">;</span>

<span class="kn">import</span> <span class="nn">org.apache.spark.ml.feature.RegexTokenizer</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.ml.feature.Tokenizer</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.Dataset</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.Row</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.RowFactory</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.DataTypes</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.Metadata</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.StructField</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.StructType</span><span class="o">;</span>

<span class="c1">// col(&quot;...&quot;) is preferable to df.col(&quot;...&quot;)</span>
<span class="kn">import static</span> <span class="nn">org.apache.spark.sql.functions.callUDF</span><span class="o">;</span>
<span class="kn">import static</span> <span class="nn">org.apache.spark.sql.functions.col</span><span class="o">;</span>

<span class="n">List</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">data</span> <span class="o">=</span> <span class="n">Arrays</span><span class="o">.</span><span class="na">asList</span><span class="o">(</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">0</span><span class="o">,</span> <span class="s">&quot;Hi I heard about Spark&quot;</span><span class="o">),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="s">&quot;I wish Java could use case classes&quot;</span><span class="o">),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">2</span><span class="o">,</span> <span class="s">&quot;Logistic,regression,models,are,neat&quot;</span><span class="o">)</span>
<span class="o">);</span>

<span class="n">StructType</span> <span class="n">schema</span> <span class="o">=</span> <span class="k">new</span> <span class="n">StructType</span><span class="o">(</span><span class="k">new</span> <span class="n">StructField</span><span class="o">[]{</span>
  <span class="k">new</span> <span class="n">StructField</span><span class="o">(</span><span class="s">&quot;id&quot;</span><span class="o">,</span> <span class="n">DataTypes</span><span class="o">.</span><span class="na">IntegerType</span><span class="o">,</span> <span class="kc">false</span><span class="o">,</span> <span class="n">Metadata</span><span class="o">.</span><span class="na">empty</span><span class="o">()),</span>
  <span class="k">new</span> <span class="n">StructField</span><span class="o">(</span><span class="s">&quot;sentence&quot;</span><span class="o">,</span> <span class="n">DataTypes</span><span class="o">.</span><span class="na">StringType</span><span class="o">,</span> <span class="kc">false</span><span class="o">,</span> <span class="n">Metadata</span><span class="o">.</span><span class="na">empty</span><span class="o">())</span>
<span class="o">});</span>

<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">sentenceDataFrame</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="na">createDataFrame</span><span class="o">(</span><span class="n">data</span><span class="o">,</span> <span class="n">schema</span><span class="o">);</span>

<span class="n">Tokenizer</span> <span class="n">tokenizer</span> <span class="o">=</span> <span class="k">new</span> <span class="n">Tokenizer</span><span class="o">().</span><span class="na">setInputCol</span><span class="o">(</span><span class="s">&quot;sentence&quot;</span><span class="o">).</span><span class="na">setOutputCol</span><span class="o">(</span><span class="s">&quot;words&quot;</span><span class="o">);</span>

<span class="n">RegexTokenizer</span> <span class="n">regexTokenizer</span> <span class="o">=</span> <span class="k">new</span> <span class="n">RegexTokenizer</span><span class="o">()</span>
    <span class="o">.</span><span class="na">setInputCol</span><span class="o">(</span><span class="s">&quot;sentence&quot;</span><span class="o">)</span>
    <span class="o">.</span><span class="na">setOutputCol</span><span class="o">(</span><span class="s">&quot;words&quot;</span><span class="o">)</span>
    <span class="o">.</span><span class="na">setPattern</span><span class="o">(</span><span class="s">&quot;\\W&quot;</span><span class="o">);</span>  <span class="c1">// alternatively .setPattern(&quot;\\w+&quot;).setGaps(false);</span>

<span class="n">spark</span><span class="o">.</span><span class="na">udf</span><span class="o">().</span><span class="na">register</span><span class="o">(</span>
  <span class="s">&quot;countTokens&quot;</span><span class="o">,</span> <span class="o">(</span><span class="n">WrappedArray</span><span class="o">&lt;?&gt;</span> <span class="n">words</span><span class="o">)</span> <span class="o">-&gt;</span> <span class="n">words</span><span class="o">.</span><span class="na">size</span><span class="o">(),</span> <span class="n">DataTypes</span><span class="o">.</span><span class="na">IntegerType</span><span class="o">);</span>

<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">tokenized</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="na">transform</span><span class="o">(</span><span class="n">sentenceDataFrame</span><span class="o">);</span>
<span class="n">tokenized</span><span class="o">.</span><span class="na">select</span><span class="o">(</span><span class="s">&quot;sentence&quot;</span><span class="o">,</span> <span class="s">&quot;words&quot;</span><span class="o">)</span>
    <span class="o">.</span><span class="na">withColumn</span><span class="o">(</span><span class="s">&quot;tokens&quot;</span><span class="o">,</span> <span class="n">callUDF</span><span class="o">(</span><span class="s">&quot;countTokens&quot;</span><span class="o">,</span> <span class="n">col</span><span class="o">(</span><span class="s">&quot;words&quot;</span><span class="o">)))</span>
    <span class="o">.</span><span class="na">show</span><span class="o">(</span><span class="kc">false</span><span class="o">);</span>

<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">regexTokenized</span> <span class="o">=</span> <span class="n">regexTokenizer</span><span class="o">.</span><span class="na">transform</span><span class="o">(</span><span class="n">sentenceDataFrame</span><span class="o">);</span>
<span class="n">regexTokenized</span><span class="o">.</span><span class="na">select</span><span class="o">(</span><span class="s">&quot;sentence&quot;</span><span class="o">,</span> <span class="s">&quot;words&quot;</span><span class="o">)</span>
    <span class="o">.</span><span class="na">withColumn</span><span class="o">(</span><span class="s">&quot;tokens&quot;</span><span class="o">,</span> <span class="n">callUDF</span><span class="o">(</span><span class="s">&quot;countTokens&quot;</span><span class="o">,</span> <span class="n">col</span><span class="o">(</span><span class="s">&quot;words&quot;</span><span class="o">)))</span>
    <span class="o">.</span><span class="na">show</span><span class="o">(</span><span class="kc">false</span><span class="o">);</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / java / org / apache / spark / examples / ml / JavaTokenizerExample.java”中找到完整的示例代码。</small></div>
  </div>

<div data-lang="python">

    <p>有关API的更多详细信息，请参考<a href="api/python/pyspark.ml.html#pyspark.ml.feature.Tokenizer">Tokenizer Python文档</a>和<a href="api/python/pyspark.ml.html#pyspark.ml.feature.RegexTokenizer">RegexTokenizer Python文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pyspark.ml.feature</span> <span class="kn">import</span> <span class="n">Tokenizer</span><span class="p">,</span> <span class="n">RegexTokenizer</span>
<span class="kn">from</span> <span class="nn">pyspark.sql.functions</span> <span class="kn">import</span> <span class="n">col</span><span class="p">,</span> <span class="n">udf</span>
<span class="kn">from</span> <span class="nn">pyspark.sql.types</span> <span class="kn">import</span> <span class="n">IntegerType</span>

<span class="n">sentenceDataFrame</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">([</span>
    <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;Hi I heard about Spark&quot;</span><span class="p">),</span>
    <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="s2">&quot;I wish Java could use case classes&quot;</span><span class="p">),</span>
    <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="s2">&quot;Logistic,regression,models,are,neat&quot;</span><span class="p">)</span>
<span class="p">],</span> <span class="p">[</span><span class="s2">&quot;id&quot;</span><span class="p">,</span> <span class="s2">&quot;sentence&quot;</span><span class="p">])</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">(</span><span class="n">inputCol</span><span class="o">=</span><span class="s2">&quot;sentence&quot;</span><span class="p">,</span> <span class="n">outputCol</span><span class="o">=</span><span class="s2">&quot;words&quot;</span><span class="p">)</span>

<span class="n">regexTokenizer</span> <span class="o">=</span> <span class="n">RegexTokenizer</span><span class="p">(</span><span class="n">inputCol</span><span class="o">=</span><span class="s2">&quot;sentence&quot;</span><span class="p">,</span> <span class="n">outputCol</span><span class="o">=</span><span class="s2">&quot;words&quot;</span><span class="p">,</span> <span class="n">pattern</span><span class="o">=</span><span class="s2">&quot;</span><span class="se">\\</span><span class="s2">W&quot;</span><span class="p">)</span>
<span class="c1"># alternatively, pattern=&quot;\\w+&quot;, gaps(False)</span>

<span class="n">countTokens</span> <span class="o">=</span> <span class="n">udf</span><span class="p">(</span><span class="k">lambda</span> <span class="n">words</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">words</span><span class="p">),</span> <span class="n">IntegerType</span><span class="p">())</span>

<span class="n">tokenized</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">sentenceDataFrame</span><span class="p">)</span>
<span class="n">tokenized</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s2">&quot;sentence&quot;</span><span class="p">,</span> <span class="s2">&quot;words&quot;</span><span class="p">)</span>\
    <span class="o">.</span><span class="n">withColumn</span><span class="p">(</span><span class="s2">&quot;tokens&quot;</span><span class="p">,</span> <span class="n">countTokens</span><span class="p">(</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;words&quot;</span><span class="p">)))</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

<span class="n">regexTokenized</span> <span class="o">=</span> <span class="n">regexTokenizer</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">sentenceDataFrame</span><span class="p">)</span>
<span class="n">regexTokenized</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s2">&quot;sentence&quot;</span><span class="p">,</span> <span class="s2">&quot;words&quot;</span><span class="p">)</span> \
    <span class="o">.</span><span class="n">withColumn</span><span class="p">(</span><span class="s2">&quot;tokens&quot;</span><span class="p">,</span> <span class="n">countTokens</span><span class="p">(</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;words&quot;</span><span class="p">)))</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / python / ml / tokenizer_example.py”中找到完整的示例代码。</small></div>
  </div>
</div>

<h2 id="stopwordsremover">StopWordsRemover</h2>
<p><a href="https://en.wikipedia.org/wiki/Stop_words">停用词</a>是应从输入中排除的词，通常是因为这些词频繁出现且含义不大。</p>

<p><code>StopWordsRemover</code>将字符串序列（例如<a href="ml-features.html#tokenizer">Tokenizer</a>的输出）作为输入，并从输入序列中删除所有停用词。停用词列表由<code>stopWords</code>参数。某些语言的默认停用词可以通过致电访问<code>StopWordsRemover.loadDefaultStopWords(language)</code> ，其可用选项为“丹麦语”，“荷兰语”，“英语”，“芬兰语”，“法语”，“德语”，“匈牙利语”，“意大利语”，“挪威语”，“葡萄牙语”，“俄语”， “西班牙语”，“瑞典语”和“土耳其语”。布尔参数<code>caseSensitive</code>指示匹配项是否应区分大小写（默认为false）。</p>

<p><strong>例子</strong></p>

<p>假设我们有以下带有列的DataFrame <code>id</code>和<code>raw</code> ：</p>

<pre><code> id | raw
----|----------
 0  | [I, saw, the, red, balloon]
 1  | [Mary, had, a, little, lamb]
</code></pre>

<p>正在申请<code>StopWordsRemover</code>与<code>raw</code>作为输入列和<code>filtered</code>作为输出列，我们应该获得以下内容：</p>

<pre><code> id | raw                         | filtered
----|-----------------------------|--------------------
 0  | [I, saw, the, red, balloon]  |  [saw, red, balloon]
 1  | [Mary, had, a, little, lamb]|[Mary, little, lamb]
</code></pre>

<p>在<code>filtered</code> ，停用词“ I”，“ the”，“ had”和“ a”已被过滤掉。</p>

<div class="codetabs">

<div data-lang="scala">

    <p>有关API的更多详细信息，请参阅<a href="api/scala/index.html#org.apache.spark.ml.feature.StopWordsRemover">StopWordsRemover Scala文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">org.apache.spark.ml.feature.StopWordsRemover</span>

<span class="k">val</span> <span class="n">remover</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">StopWordsRemover</span><span class="o">()</span>
  <span class="o">.</span><span class="n">setInputCol</span><span class="o">(</span><span class="s">&quot;raw&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">setOutputCol</span><span class="o">(</span><span class="s">&quot;filtered&quot;</span><span class="o">)</span>

<span class="k">val</span> <span class="n">dataSet</span> <span class="k">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="o">(</span><span class="nc">Seq</span><span class="o">(</span>
  <span class="o">(</span><span class="mi">0</span><span class="o">,</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">&quot;I&quot;</span><span class="o">,</span> <span class="s">&quot;saw&quot;</span><span class="o">,</span> <span class="s">&quot;the&quot;</span><span class="o">,</span> <span class="s">&quot;red&quot;</span><span class="o">,</span> <span class="s">&quot;balloon&quot;</span><span class="o">)),</span>
  <span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">&quot;Mary&quot;</span><span class="o">,</span> <span class="s">&quot;had&quot;</span><span class="o">,</span> <span class="s">&quot;a&quot;</span><span class="o">,</span> <span class="s">&quot;little&quot;</span><span class="o">,</span> <span class="s">&quot;lamb&quot;</span><span class="o">))</span>
<span class="o">)).</span><span class="n">toDF</span><span class="o">(</span><span class="s">&quot;id&quot;</span><span class="o">,</span> <span class="s">&quot;raw&quot;</span><span class="o">)</span>

<span class="n">remover</span><span class="o">.</span><span class="n">transform</span><span class="o">(</span><span class="n">dataSet</span><span class="o">).</span><span class="n">show</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / scala / org / apache / spark / examples / ml / StopWordsRemoverExample.scala”中找到完整的示例代码。</small></div>
  </div>

<div data-lang="java">

    <p>有关API的更多详细信息，请参考<a href="api/java/org/apache/spark/ml/feature/StopWordsRemover.html">StopWordsRemover Java文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">java.util.Arrays</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">java.util.List</span><span class="o">;</span>

<span class="kn">import</span> <span class="nn">org.apache.spark.ml.feature.StopWordsRemover</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.Dataset</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.Row</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.RowFactory</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.DataTypes</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.Metadata</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.StructField</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.StructType</span><span class="o">;</span>

<span class="n">StopWordsRemover</span> <span class="n">remover</span> <span class="o">=</span> <span class="k">new</span> <span class="n">StopWordsRemover</span><span class="o">()</span>
  <span class="o">.</span><span class="na">setInputCol</span><span class="o">(</span><span class="s">&quot;raw&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">setOutputCol</span><span class="o">(</span><span class="s">&quot;filtered&quot;</span><span class="o">);</span>

<span class="n">List</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">data</span> <span class="o">=</span> <span class="n">Arrays</span><span class="o">.</span><span class="na">asList</span><span class="o">(</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="n">Arrays</span><span class="o">.</span><span class="na">asList</span><span class="o">(</span><span class="s">&quot;I&quot;</span><span class="o">,</span> <span class="s">&quot;saw&quot;</span><span class="o">,</span> <span class="s">&quot;the&quot;</span><span class="o">,</span> <span class="s">&quot;red&quot;</span><span class="o">,</span> <span class="s">&quot;balloon&quot;</span><span class="o">)),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="n">Arrays</span><span class="o">.</span><span class="na">asList</span><span class="o">(</span><span class="s">&quot;Mary&quot;</span><span class="o">,</span> <span class="s">&quot;had&quot;</span><span class="o">,</span> <span class="s">&quot;a&quot;</span><span class="o">,</span> <span class="s">&quot;little&quot;</span><span class="o">,</span> <span class="s">&quot;lamb&quot;</span><span class="o">))</span>
<span class="o">);</span>

<span class="n">StructType</span> <span class="n">schema</span> <span class="o">=</span> <span class="k">new</span> <span class="n">StructType</span><span class="o">(</span><span class="k">new</span> <span class="n">StructField</span><span class="o">[]{</span>
  <span class="k">new</span> <span class="n">StructField</span><span class="o">(</span>
    <span class="s">&quot;raw&quot;</span><span class="o">,</span> <span class="n">DataTypes</span><span class="o">.</span><span class="na">createArrayType</span><span class="o">(</span><span class="n">DataTypes</span><span class="o">.</span><span class="na">StringType</span><span class="o">),</span> <span class="kc">false</span><span class="o">,</span> <span class="n">Metadata</span><span class="o">.</span><span class="na">empty</span><span class="o">())</span>
<span class="o">});</span>

<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">dataset</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="na">createDataFrame</span><span class="o">(</span><span class="n">data</span><span class="o">,</span> <span class="n">schema</span><span class="o">);</span>
<span class="n">remover</span><span class="o">.</span><span class="na">transform</span><span class="o">(</span><span class="n">dataset</span><span class="o">).</span><span class="na">show</span><span class="o">(</span><span class="kc">false</span><span class="o">);</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / java / org / apache / spark / examples / ml / JavaStopWordsRemoverExample.java”中找到完整的示例代码。</small></div>
  </div>

<div data-lang="python">

    <p>有关API的更多详细信息，请参阅<a href="api/python/pyspark.ml.html#pyspark.ml.feature.StopWordsRemover">StopWordsRemover Python文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pyspark.ml.feature</span> <span class="kn">import</span> <span class="n">StopWordsRemover</span>

<span class="n">sentenceData</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">([</span>
    <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;I&quot;</span><span class="p">,</span> <span class="s2">&quot;saw&quot;</span><span class="p">,</span> <span class="s2">&quot;the&quot;</span><span class="p">,</span> <span class="s2">&quot;red&quot;</span><span class="p">,</span> <span class="s2">&quot;balloon&quot;</span><span class="p">]),</span>
    <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;Mary&quot;</span><span class="p">,</span> <span class="s2">&quot;had&quot;</span><span class="p">,</span> <span class="s2">&quot;a&quot;</span><span class="p">,</span> <span class="s2">&quot;little&quot;</span><span class="p">,</span> <span class="s2">&quot;lamb&quot;</span><span class="p">])</span>
<span class="p">],</span> <span class="p">[</span><span class="s2">&quot;id&quot;</span><span class="p">,</span> <span class="s2">&quot;raw&quot;</span><span class="p">])</span>

<span class="n">remover</span> <span class="o">=</span> <span class="n">StopWordsRemover</span><span class="p">(</span><span class="n">inputCol</span><span class="o">=</span><span class="s2">&quot;raw&quot;</span><span class="p">,</span> <span class="n">outputCol</span><span class="o">=</span><span class="s2">&quot;filtered&quot;</span><span class="p">)</span>
<span class="n">remover</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">sentenceData</span><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / python / ml / stopwords_remover_example.py”中找到完整的示例代码。</small></div>
  </div>
</div>

<h2 id="n-gram">$ n $克</h2>

<p><a href="https://en.wikipedia.org/wiki/N-gram">n-gram</a>是某个整数$ n $的$ n $令牌（通常是单词）的序列。的<code>NGram</code>类可用于将输入要素转换为$ n $ -grams。</p>

<p><code>NGram</code>将字符串序列作为输入（例如<a href="ml-features.html#tokenizer">Tokenizer</a>的输出）。参数<code>n</code>用于确定每个$ n $ -gram中的项数。输出将由一系列$ n $ -gram组成，其中每个$ n $ -gram由一个以空格分隔的$ n $个连续单词的字符串表示。如果输入序列包含少于<code>n</code>字符串，不产生任何输出。</p>

<p><strong>例子</strong></p>

<div class="codetabs">

<div data-lang="scala">

    <p>有关该API的更多详细信息，请参考<a href="api/scala/index.html#org.apache.spark.ml.feature.NGram">NGram Scala文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">org.apache.spark.ml.feature.NGram</span>

<span class="k">val</span> <span class="n">wordDataFrame</span> <span class="k">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="o">(</span><span class="nc">Seq</span><span class="o">(</span>
  <span class="o">(</span><span class="mi">0</span><span class="o">,</span> <span class="nc">Array</span><span class="o">(</span><span class="s">&quot;Hi&quot;</span><span class="o">,</span> <span class="s">&quot;I&quot;</span><span class="o">,</span> <span class="s">&quot;heard&quot;</span><span class="o">,</span> <span class="s">&quot;about&quot;</span><span class="o">,</span> <span class="s">&quot;Spark&quot;</span><span class="o">)),</span>
  <span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="nc">Array</span><span class="o">(</span><span class="s">&quot;I&quot;</span><span class="o">,</span> <span class="s">&quot;wish&quot;</span><span class="o">,</span> <span class="s">&quot;Java&quot;</span><span class="o">,</span> <span class="s">&quot;could&quot;</span><span class="o">,</span> <span class="s">&quot;use&quot;</span><span class="o">,</span> <span class="s">&quot;case&quot;</span><span class="o">,</span> <span class="s">&quot;classes&quot;</span><span class="o">)),</span>
  <span class="o">(</span><span class="mi">2</span><span class="o">,</span> <span class="nc">Array</span><span class="o">(</span><span class="s">&quot;Logistic&quot;</span><span class="o">,</span> <span class="s">&quot;regression&quot;</span><span class="o">,</span> <span class="s">&quot;models&quot;</span><span class="o">,</span> <span class="s">&quot;are&quot;</span><span class="o">,</span> <span class="s">&quot;neat&quot;</span><span class="o">))</span>
<span class="o">)).</span><span class="n">toDF</span><span class="o">(</span><span class="s">&quot;id&quot;</span><span class="o">,</span> <span class="s">&quot;words&quot;</span><span class="o">)</span>

<span class="k">val</span> <span class="n">ngram</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NGram</span><span class="o">().</span><span class="n">setN</span><span class="o">(</span><span class="mi">2</span><span class="o">).</span><span class="n">setInputCol</span><span class="o">(</span><span class="s">&quot;words&quot;</span><span class="o">).</span><span class="n">setOutputCol</span><span class="o">(</span><span class="s">&quot;ngrams&quot;</span><span class="o">)</span>

<span class="k">val</span> <span class="n">ngramDataFrame</span> <span class="k">=</span> <span class="n">ngram</span><span class="o">.</span><span class="n">transform</span><span class="o">(</span><span class="n">wordDataFrame</span><span class="o">)</span>
<span class="n">ngramDataFrame</span><span class="o">.</span><span class="n">select</span><span class="o">(</span><span class="s">&quot;ngrams&quot;</span><span class="o">).</span><span class="n">show</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / scala / org / apache / spark / examples / ml / NGramExample.scala”中找到完整的示例代码。</small></div>
  </div>

<div data-lang="java">

    <p>有关该API的更多详细信息，请参考<a href="api/java/org/apache/spark/ml/feature/NGram.html">NGram Java文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">java.util.Arrays</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">java.util.List</span><span class="o">;</span>

<span class="kn">import</span> <span class="nn">org.apache.spark.ml.feature.NGram</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.Row</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.RowFactory</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.DataTypes</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.Metadata</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.StructField</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.StructType</span><span class="o">;</span>

<span class="n">List</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">data</span> <span class="o">=</span> <span class="n">Arrays</span><span class="o">.</span><span class="na">asList</span><span class="o">(</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">0</span><span class="o">,</span> <span class="n">Arrays</span><span class="o">.</span><span class="na">asList</span><span class="o">(</span><span class="s">&quot;Hi&quot;</span><span class="o">,</span> <span class="s">&quot;I&quot;</span><span class="o">,</span> <span class="s">&quot;heard&quot;</span><span class="o">,</span> <span class="s">&quot;about&quot;</span><span class="o">,</span> <span class="s">&quot;Spark&quot;</span><span class="o">)),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="n">Arrays</span><span class="o">.</span><span class="na">asList</span><span class="o">(</span><span class="s">&quot;I&quot;</span><span class="o">,</span> <span class="s">&quot;wish&quot;</span><span class="o">,</span> <span class="s">&quot;Java&quot;</span><span class="o">,</span> <span class="s">&quot;could&quot;</span><span class="o">,</span> <span class="s">&quot;use&quot;</span><span class="o">,</span> <span class="s">&quot;case&quot;</span><span class="o">,</span> <span class="s">&quot;classes&quot;</span><span class="o">)),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">2</span><span class="o">,</span> <span class="n">Arrays</span><span class="o">.</span><span class="na">asList</span><span class="o">(</span><span class="s">&quot;Logistic&quot;</span><span class="o">,</span> <span class="s">&quot;regression&quot;</span><span class="o">,</span> <span class="s">&quot;models&quot;</span><span class="o">,</span> <span class="s">&quot;are&quot;</span><span class="o">,</span> <span class="s">&quot;neat&quot;</span><span class="o">))</span>
<span class="o">);</span>

<span class="n">StructType</span> <span class="n">schema</span> <span class="o">=</span> <span class="k">new</span> <span class="n">StructType</span><span class="o">(</span><span class="k">new</span> <span class="n">StructField</span><span class="o">[]{</span>
  <span class="k">new</span> <span class="n">StructField</span><span class="o">(</span><span class="s">&quot;id&quot;</span><span class="o">,</span> <span class="n">DataTypes</span><span class="o">.</span><span class="na">IntegerType</span><span class="o">,</span> <span class="kc">false</span><span class="o">,</span> <span class="n">Metadata</span><span class="o">.</span><span class="na">empty</span><span class="o">()),</span>
  <span class="k">new</span> <span class="n">StructField</span><span class="o">(</span>
    <span class="s">&quot;words&quot;</span><span class="o">,</span> <span class="n">DataTypes</span><span class="o">.</span><span class="na">createArrayType</span><span class="o">(</span><span class="n">DataTypes</span><span class="o">.</span><span class="na">StringType</span><span class="o">),</span> <span class="kc">false</span><span class="o">,</span> <span class="n">Metadata</span><span class="o">.</span><span class="na">empty</span><span class="o">())</span>
<span class="o">});</span>

<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">wordDataFrame</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="na">createDataFrame</span><span class="o">(</span><span class="n">data</span><span class="o">,</span> <span class="n">schema</span><span class="o">);</span>

<span class="n">NGram</span> <span class="n">ngramTransformer</span> <span class="o">=</span> <span class="k">new</span> <span class="n">NGram</span><span class="o">().</span><span class="na">setN</span><span class="o">(</span><span class="mi">2</span><span class="o">).</span><span class="na">setInputCol</span><span class="o">(</span><span class="s">&quot;words&quot;</span><span class="o">).</span><span class="na">setOutputCol</span><span class="o">(</span><span class="s">&quot;ngrams&quot;</span><span class="o">);</span>

<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">ngramDataFrame</span> <span class="o">=</span> <span class="n">ngramTransformer</span><span class="o">.</span><span class="na">transform</span><span class="o">(</span><span class="n">wordDataFrame</span><span class="o">);</span>
<span class="n">ngramDataFrame</span><span class="o">.</span><span class="na">select</span><span class="o">(</span><span class="s">&quot;ngrams&quot;</span><span class="o">).</span><span class="na">show</span><span class="o">(</span><span class="kc">false</span><span class="o">);</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / java / org / apache / spark / examples / ml / JavaNGramExample.java”中找到完整的示例代码。</small></div>
  </div>

<div data-lang="python">

    <p>有关该API的更多详细信息，请参考<a href="api/python/pyspark.ml.html#pyspark.ml.feature.NGram">NGram Python文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pyspark.ml.feature</span> <span class="kn">import</span> <span class="n">NGram</span>

<span class="n">wordDataFrame</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">([</span>
    <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;Hi&quot;</span><span class="p">,</span> <span class="s2">&quot;I&quot;</span><span class="p">,</span> <span class="s2">&quot;heard&quot;</span><span class="p">,</span> <span class="s2">&quot;about&quot;</span><span class="p">,</span> <span class="s2">&quot;Spark&quot;</span><span class="p">]),</span>
    <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;I&quot;</span><span class="p">,</span> <span class="s2">&quot;wish&quot;</span><span class="p">,</span> <span class="s2">&quot;Java&quot;</span><span class="p">,</span> <span class="s2">&quot;could&quot;</span><span class="p">,</span> <span class="s2">&quot;use&quot;</span><span class="p">,</span> <span class="s2">&quot;case&quot;</span><span class="p">,</span> <span class="s2">&quot;classes&quot;</span><span class="p">]),</span>
    <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;Logistic&quot;</span><span class="p">,</span> <span class="s2">&quot;regression&quot;</span><span class="p">,</span> <span class="s2">&quot;models&quot;</span><span class="p">,</span> <span class="s2">&quot;are&quot;</span><span class="p">,</span> <span class="s2">&quot;neat&quot;</span><span class="p">])</span>
<span class="p">],</span> <span class="p">[</span><span class="s2">&quot;id&quot;</span><span class="p">,</span> <span class="s2">&quot;words&quot;</span><span class="p">])</span>

<span class="n">ngram</span> <span class="o">=</span> <span class="n">NGram</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">inputCol</span><span class="o">=</span><span class="s2">&quot;words&quot;</span><span class="p">,</span> <span class="n">outputCol</span><span class="o">=</span><span class="s2">&quot;ngrams&quot;</span><span class="p">)</span>

<span class="n">ngramDataFrame</span> <span class="o">=</span> <span class="n">ngram</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">wordDataFrame</span><span class="p">)</span>
<span class="n">ngramDataFrame</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s2">&quot;ngrams&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / python / ml / n_gram_example.py”中找到完整的示例代码。</small></div>
  </div>
</div>

<h2 id="binarizer">二值化器</h2>

<p>二进制化是将数字特征阈值化为二进制（0/1）特征的过程。</p>

<p><code>Binarizer</code>采用通用参数<code>inputCol</code>和<code>outputCol</code> ，以及<code>threshold</code>用于二值化。大于阈值的特征值将二值化为1.0；等于或小于阈值的值二值化为0.0。Vector和Double类型都支持<code>inputCol</code> 。</p>

<p><strong>例子</strong></p>

<div class="codetabs">
<div data-lang="scala">

    <p>有关API的更多详细信息，请参考<a href="api/scala/index.html#org.apache.spark.ml.feature.Binarizer">Binarizer Scala文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">org.apache.spark.ml.feature.Binarizer</span>

<span class="k">val</span> <span class="n">data</span> <span class="k">=</span> <span class="nc">Array</span><span class="o">((</span><span class="mi">0</span><span class="o">,</span> <span class="mf">0.1</span><span class="o">),</span> <span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="mf">0.8</span><span class="o">),</span> <span class="o">(</span><span class="mi">2</span><span class="o">,</span> <span class="mf">0.2</span><span class="o">))</span>
<span class="k">val</span> <span class="n">dataFrame</span> <span class="k">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="n">toDF</span><span class="o">(</span><span class="s">&quot;id&quot;</span><span class="o">,</span> <span class="s">&quot;feature&quot;</span><span class="o">)</span>

<span class="k">val</span> <span class="n">binarizer</span><span class="k">:</span> <span class="kt">Binarizer</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">Binarizer</span><span class="o">()</span>
  <span class="o">.</span><span class="n">setInputCol</span><span class="o">(</span><span class="s">&quot;feature&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">setOutputCol</span><span class="o">(</span><span class="s">&quot;binarized_feature&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">setThreshold</span><span class="o">(</span><span class="mf">0.5</span><span class="o">)</span>

<span class="k">val</span> <span class="n">binarizedDataFrame</span> <span class="k">=</span> <span class="n">binarizer</span><span class="o">.</span><span class="n">transform</span><span class="o">(</span><span class="n">dataFrame</span><span class="o">)</span>

<span class="n">println</span><span class="o">(</span><span class="s">s&quot;Binarizer output with Threshold = </span><span class="si">${</span><span class="n">binarizer</span><span class="o">.</span><span class="n">getThreshold</span><span class="si">}</span><span class="s">&quot;</span><span class="o">)</span>
<span class="n">binarizedDataFrame</span><span class="o">.</span><span class="n">show</span><span class="o">()</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / scala / org / apache / spark / examples / ml / BinarizerExample.scala”中找到完整的示例代码。</small></div>
  </div>

<div data-lang="java">

    <p>有关API的更多详细信息，请参考<a href="api/java/org/apache/spark/ml/feature/Binarizer.html">Binarizer Java文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">java.util.Arrays</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">java.util.List</span><span class="o">;</span>

<span class="kn">import</span> <span class="nn">org.apache.spark.ml.feature.Binarizer</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.Row</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.RowFactory</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.DataTypes</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.Metadata</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.StructField</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.StructType</span><span class="o">;</span>

<span class="n">List</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">data</span> <span class="o">=</span> <span class="n">Arrays</span><span class="o">.</span><span class="na">asList</span><span class="o">(</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">0</span><span class="o">,</span> <span class="mf">0.1</span><span class="o">),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="mf">0.8</span><span class="o">),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">2</span><span class="o">,</span> <span class="mf">0.2</span><span class="o">)</span>
<span class="o">);</span>
<span class="n">StructType</span> <span class="n">schema</span> <span class="o">=</span> <span class="k">new</span> <span class="n">StructType</span><span class="o">(</span><span class="k">new</span> <span class="n">StructField</span><span class="o">[]{</span>
  <span class="k">new</span> <span class="n">StructField</span><span class="o">(</span><span class="s">&quot;id&quot;</span><span class="o">,</span> <span class="n">DataTypes</span><span class="o">.</span><span class="na">IntegerType</span><span class="o">,</span> <span class="kc">false</span><span class="o">,</span> <span class="n">Metadata</span><span class="o">.</span><span class="na">empty</span><span class="o">()),</span>
  <span class="k">new</span> <span class="n">StructField</span><span class="o">(</span><span class="s">&quot;feature&quot;</span><span class="o">,</span> <span class="n">DataTypes</span><span class="o">.</span><span class="na">DoubleType</span><span class="o">,</span> <span class="kc">false</span><span class="o">,</span> <span class="n">Metadata</span><span class="o">.</span><span class="na">empty</span><span class="o">())</span>
<span class="o">});</span>
<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">continuousDataFrame</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="na">createDataFrame</span><span class="o">(</span><span class="n">data</span><span class="o">,</span> <span class="n">schema</span><span class="o">);</span>

<span class="n">Binarizer</span> <span class="n">binarizer</span> <span class="o">=</span> <span class="k">new</span> <span class="n">Binarizer</span><span class="o">()</span>
  <span class="o">.</span><span class="na">setInputCol</span><span class="o">(</span><span class="s">&quot;feature&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">setOutputCol</span><span class="o">(</span><span class="s">&quot;binarized_feature&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">setThreshold</span><span class="o">(</span><span class="mf">0.5</span><span class="o">);</span>

<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">binarizedDataFrame</span> <span class="o">=</span> <span class="n">binarizer</span><span class="o">.</span><span class="na">transform</span><span class="o">(</span><span class="n">continuousDataFrame</span><span class="o">);</span>

<span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">&quot;Binarizer output with Threshold = &quot;</span> <span class="o">+</span> <span class="n">binarizer</span><span class="o">.</span><span class="na">getThreshold</span><span class="o">());</span>
<span class="n">binarizedDataFrame</span><span class="o">.</span><span class="na">show</span><span class="o">();</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / java / org / apache / spark / examples / ml / JavaBinarizerExample.java”中找到完整的示例代码。</small></div>
  </div>

<div data-lang="python">

    <p>有关API的更多详细信息，请参考<a href="api/python/pyspark.ml.html#pyspark.ml.feature.Binarizer">Binarizer Python文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pyspark.ml.feature</span> <span class="kn">import</span> <span class="n">Binarizer</span>

<span class="n">continuousDataFrame</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">([</span>
    <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">),</span>
    <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">),</span>
    <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">)</span>
<span class="p">],</span> <span class="p">[</span><span class="s2">&quot;id&quot;</span><span class="p">,</span> <span class="s2">&quot;feature&quot;</span><span class="p">])</span>

<span class="n">binarizer</span> <span class="o">=</span> <span class="n">Binarizer</span><span class="p">(</span><span class="n">threshold</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">inputCol</span><span class="o">=</span><span class="s2">&quot;feature&quot;</span><span class="p">,</span> <span class="n">outputCol</span><span class="o">=</span><span class="s2">&quot;binarized_feature&quot;</span><span class="p">)</span>

<span class="n">binarizedDataFrame</span> <span class="o">=</span> <span class="n">binarizer</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">continuousDataFrame</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s2">&quot;Binarizer output with Threshold = </span><span class="si">%f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">binarizer</span><span class="o">.</span><span class="n">getThreshold</span><span class="p">())</span>
<span class="n">binarizedDataFrame</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / python / ml / binarizer_example.py”中找到完整的示例代码。</small></div>
  </div>
</div>

<h2 id="pca">PCA</h2>

<p><a href="http://en.wikipedia.org/wiki/Principal_component_analysis">PCA</a>是一种统计过程，它使用正交变换将一组可能相关的变量的观测值转换为一组线性不相关的变量值（称为主成分）。<a href="api/scala/index.html#org.apache.spark.ml.feature.PCA">PCA</a>类训练模型以使用PCA将向量投影到低维空间。下面的示例显示了如何将5维特征向量投影到3维主成分中。</p>

<p><strong>例子</strong></p>

<div class="codetabs">
<div data-lang="scala">

    <p>有关API的更多详细信息，请参考<a href="api/scala/index.html#org.apache.spark.ml.feature.PCA">PCA Scala文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">org.apache.spark.ml.feature.PCA</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.linalg.Vectors</span>

<span class="k">val</span> <span class="n">data</span> <span class="k">=</span> <span class="nc">Array</span><span class="o">(</span>
  <span class="nc">Vectors</span><span class="o">.</span><span class="n">sparse</span><span class="o">(</span><span class="mi">5</span><span class="o">,</span> <span class="nc">Seq</span><span class="o">((</span><span class="mi">1</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">),</span> <span class="o">(</span><span class="mi">3</span><span class="o">,</span> <span class="mf">7.0</span><span class="o">))),</span>
  <span class="nc">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="o">(</span><span class="mf">2.0</span><span class="o">,</span> <span class="mf">0.0</span><span class="o">,</span> <span class="mf">3.0</span><span class="o">,</span> <span class="mf">4.0</span><span class="o">,</span> <span class="mf">5.0</span><span class="o">),</span>
  <span class="nc">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="o">(</span><span class="mf">4.0</span><span class="o">,</span> <span class="mf">0.0</span><span class="o">,</span> <span class="mf">0.0</span><span class="o">,</span> <span class="mf">6.0</span><span class="o">,</span> <span class="mf">7.0</span><span class="o">)</span>
<span class="o">)</span>
<span class="k">val</span> <span class="n">df</span> <span class="k">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="o">(</span><span class="n">data</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="nc">Tuple1</span><span class="o">.</span><span class="n">apply</span><span class="o">)).</span><span class="n">toDF</span><span class="o">(</span><span class="s">&quot;features&quot;</span><span class="o">)</span>

<span class="k">val</span> <span class="n">pca</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">PCA</span><span class="o">()</span>
  <span class="o">.</span><span class="n">setInputCol</span><span class="o">(</span><span class="s">&quot;features&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">setOutputCol</span><span class="o">(</span><span class="s">&quot;pcaFeatures&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">setK</span><span class="o">(</span><span class="mi">3</span><span class="o">)</span>
  <span class="o">.</span><span class="n">fit</span><span class="o">(</span><span class="n">df</span><span class="o">)</span>

<span class="k">val</span> <span class="n">result</span> <span class="k">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">transform</span><span class="o">(</span><span class="n">df</span><span class="o">).</span><span class="n">select</span><span class="o">(</span><span class="s">&quot;pcaFeatures&quot;</span><span class="o">)</span>
<span class="n">result</span><span class="o">.</span><span class="n">show</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / scala / org / apache / spark / examples / ml / PCAExample.scala”中找到完整的示例代码。</small></div>
  </div>

<div data-lang="java">

    <p>有关API的更多详细信息，请参考<a href="api/java/org/apache/spark/ml/feature/PCA.html">PCA Java文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">java.util.Arrays</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">java.util.List</span><span class="o">;</span>

<span class="kn">import</span> <span class="nn">org.apache.spark.ml.feature.PCA</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.ml.feature.PCAModel</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.ml.linalg.VectorUDT</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.ml.linalg.Vectors</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.Dataset</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.Row</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.RowFactory</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.Metadata</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.StructField</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.StructType</span><span class="o">;</span>

<span class="n">List</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">data</span> <span class="o">=</span> <span class="n">Arrays</span><span class="o">.</span><span class="na">asList</span><span class="o">(</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="n">Vectors</span><span class="o">.</span><span class="na">sparse</span><span class="o">(</span><span class="mi">5</span><span class="o">,</span> <span class="k">new</span> <span class="kt">int</span><span class="o">[]{</span><span class="mi">1</span><span class="o">,</span> <span class="mi">3</span><span class="o">},</span> <span class="k">new</span> <span class="kt">double</span><span class="o">[]{</span><span class="mf">1.0</span><span class="o">,</span> <span class="mf">7.0</span><span class="o">})),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="n">Vectors</span><span class="o">.</span><span class="na">dense</span><span class="o">(</span><span class="mf">2.0</span><span class="o">,</span> <span class="mf">0.0</span><span class="o">,</span> <span class="mf">3.0</span><span class="o">,</span> <span class="mf">4.0</span><span class="o">,</span> <span class="mf">5.0</span><span class="o">)),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="n">Vectors</span><span class="o">.</span><span class="na">dense</span><span class="o">(</span><span class="mf">4.0</span><span class="o">,</span> <span class="mf">0.0</span><span class="o">,</span> <span class="mf">0.0</span><span class="o">,</span> <span class="mf">6.0</span><span class="o">,</span> <span class="mf">7.0</span><span class="o">))</span>
<span class="o">);</span>

<span class="n">StructType</span> <span class="n">schema</span> <span class="o">=</span> <span class="k">new</span> <span class="n">StructType</span><span class="o">(</span><span class="k">new</span> <span class="n">StructField</span><span class="o">[]{</span>
  <span class="k">new</span> <span class="n">StructField</span><span class="o">(</span><span class="s">&quot;features&quot;</span><span class="o">,</span> <span class="k">new</span> <span class="n">VectorUDT</span><span class="o">(),</span> <span class="kc">false</span><span class="o">,</span> <span class="n">Metadata</span><span class="o">.</span><span class="na">empty</span><span class="o">()),</span>
<span class="o">});</span>

<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="na">createDataFrame</span><span class="o">(</span><span class="n">data</span><span class="o">,</span> <span class="n">schema</span><span class="o">);</span>

<span class="n">PCAModel</span> <span class="n">pca</span> <span class="o">=</span> <span class="k">new</span> <span class="n">PCA</span><span class="o">()</span>
  <span class="o">.</span><span class="na">setInputCol</span><span class="o">(</span><span class="s">&quot;features&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">setOutputCol</span><span class="o">(</span><span class="s">&quot;pcaFeatures&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">setK</span><span class="o">(</span><span class="mi">3</span><span class="o">)</span>
  <span class="o">.</span><span class="na">fit</span><span class="o">(</span><span class="n">df</span><span class="o">);</span>

<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">result</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="na">transform</span><span class="o">(</span><span class="n">df</span><span class="o">).</span><span class="na">select</span><span class="o">(</span><span class="s">&quot;pcaFeatures&quot;</span><span class="o">);</span>
<span class="n">result</span><span class="o">.</span><span class="na">show</span><span class="o">(</span><span class="kc">false</span><span class="o">);</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / java / org / apache / spark / examples / ml / JavaPCAExample.java”中找到完整的示例代码。</small></div>
  </div>

<div data-lang="python">

    <p>有关API的更多详细信息，请参考<a href="api/python/pyspark.ml.html#pyspark.ml.feature.PCA">PCA Python文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pyspark.ml.feature</span> <span class="kn">import</span> <span class="n">PCA</span>
<span class="kn">from</span> <span class="nn">pyspark.ml.linalg</span> <span class="kn">import</span> <span class="n">Vectors</span>

<span class="n">data</span> <span class="o">=</span> <span class="p">[(</span><span class="n">Vectors</span><span class="o">.</span><span class="n">sparse</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="p">[(</span><span class="mi">1</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">),</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mf">7.0</span><span class="p">)]),),</span>
        <span class="p">(</span><span class="n">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="p">([</span><span class="mf">2.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">,</span> <span class="mf">4.0</span><span class="p">,</span> <span class="mf">5.0</span><span class="p">]),),</span>
        <span class="p">(</span><span class="n">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="p">([</span><span class="mf">4.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">6.0</span><span class="p">,</span> <span class="mf">7.0</span><span class="p">]),)]</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;features&quot;</span><span class="p">])</span>

<span class="n">pca</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">k</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">inputCol</span><span class="o">=</span><span class="s2">&quot;features&quot;</span><span class="p">,</span> <span class="n">outputCol</span><span class="o">=</span><span class="s2">&quot;pcaFeatures&quot;</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">df</span><span class="p">)</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s2">&quot;pcaFeatures&quot;</span><span class="p">)</span>
<span class="n">result</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / python / ml / pca_example.py”中找到完整的示例代码。</small></div>
  </div>
</div>

<h2 id="polynomialexpansion">多项式展开</h2>

<p><a href="http://en.wikipedia.org/wiki/Polynomial_expansion">多项式扩展</a>是将要素扩展到多项式空间的过程，该空间由原始尺寸的n次组合构成。<a href="api/scala/index.html#org.apache.spark.ml.feature.PolynomialExpansion">PolynomialExpansion</a>类提供此功能。下面的示例显示如何将特征扩展到3度多项式空间。</p>

<p><strong>例子</strong></p>

<div class="codetabs">
<div data-lang="scala">

    <p>有关API的更多详细信息，请参阅<a href="api/scala/index.html#org.apache.spark.ml.feature.PolynomialExpansion">PolynomialExpansion Scala文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">org.apache.spark.ml.feature.PolynomialExpansion</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.linalg.Vectors</span>

<span class="k">val</span> <span class="n">data</span> <span class="k">=</span> <span class="nc">Array</span><span class="o">(</span>
  <span class="nc">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="o">(</span><span class="mf">2.0</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">),</span>
  <span class="nc">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="o">(</span><span class="mf">0.0</span><span class="o">,</span> <span class="mf">0.0</span><span class="o">),</span>
  <span class="nc">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="o">(</span><span class="mf">3.0</span><span class="o">,</span> <span class="o">-</span><span class="mf">1.0</span><span class="o">)</span>
<span class="o">)</span>
<span class="k">val</span> <span class="n">df</span> <span class="k">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="o">(</span><span class="n">data</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="nc">Tuple1</span><span class="o">.</span><span class="n">apply</span><span class="o">)).</span><span class="n">toDF</span><span class="o">(</span><span class="s">&quot;features&quot;</span><span class="o">)</span>

<span class="k">val</span> <span class="n">polyExpansion</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">PolynomialExpansion</span><span class="o">()</span>
  <span class="o">.</span><span class="n">setInputCol</span><span class="o">(</span><span class="s">&quot;features&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">setOutputCol</span><span class="o">(</span><span class="s">&quot;polyFeatures&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">setDegree</span><span class="o">(</span><span class="mi">3</span><span class="o">)</span>

<span class="k">val</span> <span class="n">polyDF</span> <span class="k">=</span> <span class="n">polyExpansion</span><span class="o">.</span><span class="n">transform</span><span class="o">(</span><span class="n">df</span><span class="o">)</span>
<span class="n">polyDF</span><span class="o">.</span><span class="n">show</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / scala / org / apache / spark / examples / ml / PolynomialExpansionExample.scala”中找到完整的示例代码。</small></div>
  </div>

<div data-lang="java">

    <p>有关API的更多详细信息，请参阅<a href="api/java/org/apache/spark/ml/feature/PolynomialExpansion.html">PolynomialExpansion Java文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">java.util.Arrays</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">java.util.List</span><span class="o">;</span>

<span class="kn">import</span> <span class="nn">org.apache.spark.ml.feature.PolynomialExpansion</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.ml.linalg.VectorUDT</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.ml.linalg.Vectors</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.Dataset</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.Row</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.RowFactory</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.Metadata</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.StructField</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.StructType</span><span class="o">;</span>

<span class="n">PolynomialExpansion</span> <span class="n">polyExpansion</span> <span class="o">=</span> <span class="k">new</span> <span class="n">PolynomialExpansion</span><span class="o">()</span>
  <span class="o">.</span><span class="na">setInputCol</span><span class="o">(</span><span class="s">&quot;features&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">setOutputCol</span><span class="o">(</span><span class="s">&quot;polyFeatures&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">setDegree</span><span class="o">(</span><span class="mi">3</span><span class="o">);</span>

<span class="n">List</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">data</span> <span class="o">=</span> <span class="n">Arrays</span><span class="o">.</span><span class="na">asList</span><span class="o">(</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="n">Vectors</span><span class="o">.</span><span class="na">dense</span><span class="o">(</span><span class="mf">2.0</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">)),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="n">Vectors</span><span class="o">.</span><span class="na">dense</span><span class="o">(</span><span class="mf">0.0</span><span class="o">,</span> <span class="mf">0.0</span><span class="o">)),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="n">Vectors</span><span class="o">.</span><span class="na">dense</span><span class="o">(</span><span class="mf">3.0</span><span class="o">,</span> <span class="o">-</span><span class="mf">1.0</span><span class="o">))</span>
<span class="o">);</span>
<span class="n">StructType</span> <span class="n">schema</span> <span class="o">=</span> <span class="k">new</span> <span class="n">StructType</span><span class="o">(</span><span class="k">new</span> <span class="n">StructField</span><span class="o">[]{</span>
  <span class="k">new</span> <span class="n">StructField</span><span class="o">(</span><span class="s">&quot;features&quot;</span><span class="o">,</span> <span class="k">new</span> <span class="n">VectorUDT</span><span class="o">(),</span> <span class="kc">false</span><span class="o">,</span> <span class="n">Metadata</span><span class="o">.</span><span class="na">empty</span><span class="o">()),</span>
<span class="o">});</span>
<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="na">createDataFrame</span><span class="o">(</span><span class="n">data</span><span class="o">,</span> <span class="n">schema</span><span class="o">);</span>

<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">polyDF</span> <span class="o">=</span> <span class="n">polyExpansion</span><span class="o">.</span><span class="na">transform</span><span class="o">(</span><span class="n">df</span><span class="o">);</span>
<span class="n">polyDF</span><span class="o">.</span><span class="na">show</span><span class="o">(</span><span class="kc">false</span><span class="o">);</span>
</pre></div>
    <div><small>在代码仓库中的“ examples / src / main / java / org / apache / spark / examples / ml / JavaPolynomialExpansionExample.java”中找到完整的示例代码。</small></div>
  </div>

<div data-lang="python">

    <p>有关API的更多详细信息，请参阅<a href="api/python/pyspark.ml.html#pyspark.ml.feature.PolynomialExpansion">PolynomialExpansion Python文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pyspark.ml.feature</span> <span class="kn">import</span> <span class="n">PolynomialExpansion</span>
<span class="kn">from</span> <span class="nn">pyspark.ml.linalg</span> <span class="kn">import</span> <span class="n">Vectors</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">([</span>
    <span class="p">(</span><span class="n">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="p">([</span><span class="mf">2.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">]),),</span>
    <span class="p">(</span><span class="n">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">]),),</span>
    <span class="p">(</span><span class="n">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="p">([</span><span class="mf">3.0</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.0</span><span class="p">]),)</span>
<span class="p">],</span> <span class="p">[</span><span class="s2">&quot;features&quot;</span><span class="p">])</span>

<span class="n">polyExpansion</span> <span class="o">=</span> <span class="n">PolynomialExpansion</span><span class="p">(</span><span class="n">degree</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">inputCol</span><span class="o">=</span><span class="s2">&quot;features&quot;</span><span class="p">,</span> <span class="n">outputCol</span><span class="o">=</span><span class="s2">&quot;polyFeatures&quot;</span><span class="p">)</span>
<span class="n">polyDF</span> <span class="o">=</span> <span class="n">polyExpansion</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>

<span class="n">polyDF</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / python / ml / polynomial_expansion_example.py”中找到完整的示例代码。</small></div>
  </div>
</div>

<h2 id="discrete-cosine-transform-dct">离散余弦变换（DCT）</h2>

<p><a href="https://en.wikipedia.org/wiki/Discrete_cosine_transform">离散余弦变换</a>将时域中的一个长度$ N $实值序列转换为频域中的另一个长度$ N $实值序列。<a href="api/scala/index.html#org.apache.spark.ml.feature.DCT">DCT</a>类提供此功能，实现<a href="https://en.wikipedia.org/wiki/Discrete_cosine_transform#DCT-II">DCT-II</a>并将结果缩放$ 1 / \ sqrt {2} $，以使变换的表示矩阵为matrix。不对转换后的序列应用任何移位（例如，转换后的序列中的第$ 0 $个元素是第$ 0 $个DCT系数，而<em>不是</em>第$ N / 2 $个）。</p>

<p><strong>例子</strong></p>

<div class="codetabs">
<div data-lang="scala">

    <p>有关API的更多详细信息，请参阅<a href="api/scala/index.html#org.apache.spark.ml.feature.DCT">DCT Scala文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">org.apache.spark.ml.feature.DCT</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.linalg.Vectors</span>

<span class="k">val</span> <span class="n">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span>
  <span class="nc">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="o">(</span><span class="mf">0.0</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">,</span> <span class="o">-</span><span class="mf">2.0</span><span class="o">,</span> <span class="mf">3.0</span><span class="o">),</span>
  <span class="nc">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="o">(-</span><span class="mf">1.0</span><span class="o">,</span> <span class="mf">2.0</span><span class="o">,</span> <span class="mf">4.0</span><span class="o">,</span> <span class="o">-</span><span class="mf">7.0</span><span class="o">),</span>
  <span class="nc">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="o">(</span><span class="mf">14.0</span><span class="o">,</span> <span class="o">-</span><span class="mf">2.0</span><span class="o">,</span> <span class="o">-</span><span class="mf">5.0</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">))</span>

<span class="k">val</span> <span class="n">df</span> <span class="k">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="o">(</span><span class="n">data</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="nc">Tuple1</span><span class="o">.</span><span class="n">apply</span><span class="o">)).</span><span class="n">toDF</span><span class="o">(</span><span class="s">&quot;features&quot;</span><span class="o">)</span>

<span class="k">val</span> <span class="n">dct</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DCT</span><span class="o">()</span>
  <span class="o">.</span><span class="n">setInputCol</span><span class="o">(</span><span class="s">&quot;features&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">setOutputCol</span><span class="o">(</span><span class="s">&quot;featuresDCT&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">setInverse</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>

<span class="k">val</span> <span class="n">dctDf</span> <span class="k">=</span> <span class="n">dct</span><span class="o">.</span><span class="n">transform</span><span class="o">(</span><span class="n">df</span><span class="o">)</span>
<span class="n">dctDf</span><span class="o">.</span><span class="n">select</span><span class="o">(</span><span class="s">&quot;featuresDCT&quot;</span><span class="o">).</span><span class="n">show</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / scala / org / apache / spark / examples / ml / DCTExample.scala”中找到完整的示例代码。</small></div>
  </div>

<div data-lang="java">

    <p>有关API的更多详细信息，请参阅<a href="api/java/org/apache/spark/ml/feature/DCT.html">DCT Java文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">java.util.Arrays</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">java.util.List</span><span class="o">;</span>

<span class="kn">import</span> <span class="nn">org.apache.spark.ml.feature.DCT</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.ml.linalg.VectorUDT</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.ml.linalg.Vectors</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.Row</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.RowFactory</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.Metadata</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.StructField</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.StructType</span><span class="o">;</span>

<span class="n">List</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">data</span> <span class="o">=</span> <span class="n">Arrays</span><span class="o">.</span><span class="na">asList</span><span class="o">(</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="n">Vectors</span><span class="o">.</span><span class="na">dense</span><span class="o">(</span><span class="mf">0.0</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">,</span> <span class="o">-</span><span class="mf">2.0</span><span class="o">,</span> <span class="mf">3.0</span><span class="o">)),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="n">Vectors</span><span class="o">.</span><span class="na">dense</span><span class="o">(-</span><span class="mf">1.0</span><span class="o">,</span> <span class="mf">2.0</span><span class="o">,</span> <span class="mf">4.0</span><span class="o">,</span> <span class="o">-</span><span class="mf">7.0</span><span class="o">)),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="n">Vectors</span><span class="o">.</span><span class="na">dense</span><span class="o">(</span><span class="mf">14.0</span><span class="o">,</span> <span class="o">-</span><span class="mf">2.0</span><span class="o">,</span> <span class="o">-</span><span class="mf">5.0</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">))</span>
<span class="o">);</span>
<span class="n">StructType</span> <span class="n">schema</span> <span class="o">=</span> <span class="k">new</span> <span class="n">StructType</span><span class="o">(</span><span class="k">new</span> <span class="n">StructField</span><span class="o">[]{</span>
  <span class="k">new</span> <span class="n">StructField</span><span class="o">(</span><span class="s">&quot;features&quot;</span><span class="o">,</span> <span class="k">new</span> <span class="n">VectorUDT</span><span class="o">(),</span> <span class="kc">false</span><span class="o">,</span> <span class="n">Metadata</span><span class="o">.</span><span class="na">empty</span><span class="o">()),</span>
<span class="o">});</span>
<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="na">createDataFrame</span><span class="o">(</span><span class="n">data</span><span class="o">,</span> <span class="n">schema</span><span class="o">);</span>

<span class="n">DCT</span> <span class="n">dct</span> <span class="o">=</span> <span class="k">new</span> <span class="n">DCT</span><span class="o">()</span>
  <span class="o">.</span><span class="na">setInputCol</span><span class="o">(</span><span class="s">&quot;features&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">setOutputCol</span><span class="o">(</span><span class="s">&quot;featuresDCT&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">setInverse</span><span class="o">(</span><span class="kc">false</span><span class="o">);</span>

<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">dctDf</span> <span class="o">=</span> <span class="n">dct</span><span class="o">.</span><span class="na">transform</span><span class="o">(</span><span class="n">df</span><span class="o">);</span>

<span class="n">dctDf</span><span class="o">.</span><span class="na">select</span><span class="o">(</span><span class="s">&quot;featuresDCT&quot;</span><span class="o">).</span><span class="na">show</span><span class="o">(</span><span class="kc">false</span><span class="o">);</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / java / org / apache / spark / examples / ml / JavaDCTExample.java”中找到完整的示例代码。</small></div>
  </div>

<div data-lang="python">

    <p>有关API的更多详细信息，请参阅<a href="api/python/pyspark.ml.html#pyspark.ml.feature.DCT">DCT Python文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pyspark.ml.feature</span> <span class="kn">import</span> <span class="n">DCT</span>
<span class="kn">from</span> <span class="nn">pyspark.ml.linalg</span> <span class="kn">import</span> <span class="n">Vectors</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">([</span>
    <span class="p">(</span><span class="n">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">]),),</span>
    <span class="p">(</span><span class="n">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="p">([</span><span class="o">-</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mf">4.0</span><span class="p">,</span> <span class="o">-</span><span class="mf">7.0</span><span class="p">]),),</span>
    <span class="p">(</span><span class="n">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="p">([</span><span class="mf">14.0</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.0</span><span class="p">,</span> <span class="o">-</span><span class="mf">5.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">]),)],</span> <span class="p">[</span><span class="s2">&quot;features&quot;</span><span class="p">])</span>

<span class="n">dct</span> <span class="o">=</span> <span class="n">DCT</span><span class="p">(</span><span class="n">inverse</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">inputCol</span><span class="o">=</span><span class="s2">&quot;features&quot;</span><span class="p">,</span> <span class="n">outputCol</span><span class="o">=</span><span class="s2">&quot;featuresDCT&quot;</span><span class="p">)</span>

<span class="n">dctDf</span> <span class="o">=</span> <span class="n">dct</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>

<span class="n">dctDf</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s2">&quot;featuresDCT&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / python / ml / dct_example.py”中找到完整的示例代码。</small></div>
  </div>
</div>

<h2 id="stringindexer">字符串索引器</h2>

<p><code>StringIndexer</code>将标签的字符串列编码为标签索引的列。
<code>StringIndexer</code>可以编码多个列。索引在<code>[0, numLabels)</code> ，并支持四个排序选项：“ frequencyDesc”：按标签频率的降序（最频繁的标签分配为0），“ frequencyAsc”：按标签频率的升序（最不频繁的标签分配为0），“ alphabetDesc”：按字母顺序的降序，和“ alphabetAsc”：升序（默认=“ frequencyDesc”）。注意，在“ frequencyDesc” /“ frequencyAsc”下，如果频率相等，则进一步按字母对字符串进行排序。</p>

<p>如果用户选择保留，则看不见的标签将放置在索引numLabels处。如果输入列为数字，则将其强制转换为字符串并为字符串值编制索引。当下游管道组件如<code>Estimator</code>要么<code>Transformer</code>要使用此字符串索引标签，必须将组件的输入列设置为此字符串索引列名称。在许多情况下，您可以使用<code>setInputCol</code> 。</p>

<p><strong>例子</strong></p>

<p>假设我们有以下带有列的DataFrame <code>id</code>和<code>category</code> ：</p>

<pre><code> id | category
----|----------
 0  | a
 1  | b
 2  | c
 3  | a
 4  | a
 5  | c
</code></pre>

<p><code>category</code>是带有三个标签的字符串列：“ a”，“ b”和“ c”。正在申请<code>StringIndexer</code>与<code>category</code>作为输入列和<code>categoryIndex</code>作为输出列，我们应该获得以下内容：</p>

<pre><code> id | category | categoryIndex
----|----------|---------------
 0  | a        | 0.0
 1  | b        | 2.0
 2  | c        | 1.0
 3  | a        | 0.0
 4  | a        | 0.0
 5  | c        | 1.0
</code></pre>

<p>“ a”获取索引<code>0</code>因为它是最常见的，后跟带有索引的“ c” <code>1</code>和带有索引的“ b” <code>2</code> 。</p>

<p>此外，关于如何<code>StringIndexer</code>如果适合，将处理看不见的标签<code>StringIndexer</code>在一个数据集上，然后使用它来转换另一个数据集：</p>

<ul>
  <li>引发异常（默认）</li>
  <li>完全跳过包含看不见标签的行</li>
  <li>将看不见的标签放在索引numLabels的特殊附加存储桶中</li>
</ul>

<p><strong>例子</strong></p>

<p>让我们回到前面的示例，但是这次重用我们先前定义的<code>StringIndexer</code>在以下数据集上：</p>

<pre><code> id | category
----|----------
 0  | a
 1  | b
 2  | c
 3  | d
 4  | e
</code></pre>

<p>如果您尚未设定<code>StringIndexer</code>处理看不见的标签或将其设置为“错误”，将引发异常。但是，如果您打电话给<code>setHandleInvalid("skip")</code> ，将生成以下数据集：</p>

<pre><code> id | category | categoryIndex
----|----------|---------------
 0  | a        | 0.0
 1  | b        | 2.0
 2  | c        | 1.0
</code></pre>

<p>请注意，没有出现包含“ d”或“ e”的行。</p>

<p>如果你打电话<code>setHandleInvalid("keep")</code> ，将生成以下数据集：</p>

<pre><code> id | category | categoryIndex
----|----------|---------------
 0  | a        | 0.0
 1  | b        | 2.0
 2  | c        | 1.0
 3  | d        | 3.0
 4  | e        | 3.0
</code></pre>

<p>请注意，包含“ d”或“ e”的行已映射到索引“ 3.0”</p>

<div class="codetabs">

<div data-lang="scala">

    <p>有关API的更多详细信息，请参阅<a href="api/scala/index.html#org.apache.spark.ml.feature.StringIndexer">StringIndexer Scala文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">org.apache.spark.ml.feature.StringIndexer</span>

<span class="k">val</span> <span class="n">df</span> <span class="k">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="o">(</span>
  <span class="nc">Seq</span><span class="o">((</span><span class="mi">0</span><span class="o">,</span> <span class="s">&quot;a&quot;</span><span class="o">),</span> <span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="s">&quot;b&quot;</span><span class="o">),</span> <span class="o">(</span><span class="mi">2</span><span class="o">,</span> <span class="s">&quot;c&quot;</span><span class="o">),</span> <span class="o">(</span><span class="mi">3</span><span class="o">,</span> <span class="s">&quot;a&quot;</span><span class="o">),</span> <span class="o">(</span><span class="mi">4</span><span class="o">,</span> <span class="s">&quot;a&quot;</span><span class="o">),</span> <span class="o">(</span><span class="mi">5</span><span class="o">,</span> <span class="s">&quot;c&quot;</span><span class="o">))</span>
<span class="o">).</span><span class="n">toDF</span><span class="o">(</span><span class="s">&quot;id&quot;</span><span class="o">,</span> <span class="s">&quot;category&quot;</span><span class="o">)</span>

<span class="k">val</span> <span class="n">indexer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">StringIndexer</span><span class="o">()</span>
  <span class="o">.</span><span class="n">setInputCol</span><span class="o">(</span><span class="s">&quot;category&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">setOutputCol</span><span class="o">(</span><span class="s">&quot;categoryIndex&quot;</span><span class="o">)</span>

<span class="k">val</span> <span class="n">indexed</span> <span class="k">=</span> <span class="n">indexer</span><span class="o">.</span><span class="n">fit</span><span class="o">(</span><span class="n">df</span><span class="o">).</span><span class="n">transform</span><span class="o">(</span><span class="n">df</span><span class="o">)</span>
<span class="n">indexed</span><span class="o">.</span><span class="n">show</span><span class="o">()</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / scala / org / apache / spark / examples / ml / StringIndexerExample.scala”中找到完整的示例代码。</small></div>
  </div>

<div data-lang="java">

    <p>有关API的更多详细信息，请参考<a href="api/java/org/apache/spark/ml/feature/StringIndexer.html">StringIndexer Java文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">java.util.Arrays</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">java.util.List</span><span class="o">;</span>

<span class="kn">import</span> <span class="nn">org.apache.spark.ml.feature.StringIndexer</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.Dataset</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.Row</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.RowFactory</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.StructField</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.StructType</span><span class="o">;</span>

<span class="kn">import static</span> <span class="nn">org.apache.spark.sql.types.DataTypes.*</span><span class="o">;</span>

<span class="n">List</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">data</span> <span class="o">=</span> <span class="n">Arrays</span><span class="o">.</span><span class="na">asList</span><span class="o">(</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">0</span><span class="o">,</span> <span class="s">&quot;a&quot;</span><span class="o">),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="s">&quot;b&quot;</span><span class="o">),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">2</span><span class="o">,</span> <span class="s">&quot;c&quot;</span><span class="o">),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">3</span><span class="o">,</span> <span class="s">&quot;a&quot;</span><span class="o">),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">4</span><span class="o">,</span> <span class="s">&quot;a&quot;</span><span class="o">),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">5</span><span class="o">,</span> <span class="s">&quot;c&quot;</span><span class="o">)</span>
<span class="o">);</span>
<span class="n">StructType</span> <span class="n">schema</span> <span class="o">=</span> <span class="k">new</span> <span class="n">StructType</span><span class="o">(</span><span class="k">new</span> <span class="n">StructField</span><span class="o">[]{</span>
  <span class="n">createStructField</span><span class="o">(</span><span class="s">&quot;id&quot;</span><span class="o">,</span> <span class="n">IntegerType</span><span class="o">,</span> <span class="kc">false</span><span class="o">),</span>
  <span class="n">createStructField</span><span class="o">(</span><span class="s">&quot;category&quot;</span><span class="o">,</span> <span class="n">StringType</span><span class="o">,</span> <span class="kc">false</span><span class="o">)</span>
<span class="o">});</span>
<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="na">createDataFrame</span><span class="o">(</span><span class="n">data</span><span class="o">,</span> <span class="n">schema</span><span class="o">);</span>

<span class="n">StringIndexer</span> <span class="n">indexer</span> <span class="o">=</span> <span class="k">new</span> <span class="n">StringIndexer</span><span class="o">()</span>
  <span class="o">.</span><span class="na">setInputCol</span><span class="o">(</span><span class="s">&quot;category&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">setOutputCol</span><span class="o">(</span><span class="s">&quot;categoryIndex&quot;</span><span class="o">);</span>

<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">indexed</span> <span class="o">=</span> <span class="n">indexer</span><span class="o">.</span><span class="na">fit</span><span class="o">(</span><span class="n">df</span><span class="o">).</span><span class="na">transform</span><span class="o">(</span><span class="n">df</span><span class="o">);</span>
<span class="n">indexed</span><span class="o">.</span><span class="na">show</span><span class="o">();</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / java / org / apache / spark / examples / ml / JavaStringIndexerExample.java”中找到完整的示例代码。</small></div>
  </div>

<div data-lang="python">

    <p>有关API的更多详细信息，请参考<a href="api/python/pyspark.ml.html#pyspark.ml.feature.StringIndexer">StringIndexer Python文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pyspark.ml.feature</span> <span class="kn">import</span> <span class="n">StringIndexer</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">(</span>
    <span class="p">[(</span><span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;a&quot;</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="s2">&quot;c&quot;</span><span class="p">),</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="s2">&quot;a&quot;</span><span class="p">),</span> <span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="s2">&quot;a&quot;</span><span class="p">),</span> <span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="s2">&quot;c&quot;</span><span class="p">)],</span>
    <span class="p">[</span><span class="s2">&quot;id&quot;</span><span class="p">,</span> <span class="s2">&quot;category&quot;</span><span class="p">])</span>

<span class="n">indexer</span> <span class="o">=</span> <span class="n">StringIndexer</span><span class="p">(</span><span class="n">inputCol</span><span class="o">=</span><span class="s2">&quot;category&quot;</span><span class="p">,</span> <span class="n">outputCol</span><span class="o">=</span><span class="s2">&quot;categoryIndex&quot;</span><span class="p">)</span>
<span class="n">indexed</span> <span class="o">=</span> <span class="n">indexer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">df</span><span class="p">)</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
<span class="n">indexed</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / python / ml / string_indexer_example.py”中找到完整的示例代码。</small></div>
  </div>
</div>

<h2 id="indextostring">IndexToString</h2>

<p>对称地<code>StringIndexer</code> ， <code>IndexToString</code>将一列标签索引映射回包含原始标签为字符串的列。一个常见的用例是使用<code>StringIndexer</code> ，使用这些索引训练模型，并使用<code>IndexToString</code> 。但是，您可以自由提供自己的标签。</p>

<p><strong>例子</strong></p>

<p>建立在<code>StringIndexer</code>例如，假设我们有以下带有列的DataFrame <code>id</code>和<code>categoryIndex</code> ：</p>

<pre><code> id | categoryIndex
----|---------------
 0  | 0.0
 1  | 2.0
 2  | 1.0
 3  | 0.0
 4  | 0.0
 5  | 1.0
</code></pre>

<p>正在申请<code>IndexToString</code>与<code>categoryIndex</code>作为输入列， <code>originalCategory</code>作为输出列，我们能够检索我们的原始标签（将从列的元数据中推断出它们）：</p>

<pre><code> id | categoryIndex | originalCategory
----|---------------|-----------------
 0  | 0.0           | a
 1  | 2.0           | b
 2  | 1.0           | c
 3  | 0.0           | a
 4  | 0.0           | a
 5  | 1.0           | c
</code></pre>

<div class="codetabs">
<div data-lang="scala">

    <p>有关API的更多详细信息，请参考<a href="api/scala/index.html#org.apache.spark.ml.feature.IndexToString">IndexToString Scala文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">org.apache.spark.ml.attribute.Attribute</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.feature.</span><span class="o">{</span><span class="nc">IndexToString</span><span class="o">,</span> <span class="nc">StringIndexer</span><span class="o">}</span>

<span class="k">val</span> <span class="n">df</span> <span class="k">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="o">(</span><span class="nc">Seq</span><span class="o">(</span>
  <span class="o">(</span><span class="mi">0</span><span class="o">,</span> <span class="s">&quot;a&quot;</span><span class="o">),</span>
  <span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="s">&quot;b&quot;</span><span class="o">),</span>
  <span class="o">(</span><span class="mi">2</span><span class="o">,</span> <span class="s">&quot;c&quot;</span><span class="o">),</span>
  <span class="o">(</span><span class="mi">3</span><span class="o">,</span> <span class="s">&quot;a&quot;</span><span class="o">),</span>
  <span class="o">(</span><span class="mi">4</span><span class="o">,</span> <span class="s">&quot;a&quot;</span><span class="o">),</span>
  <span class="o">(</span><span class="mi">5</span><span class="o">,</span> <span class="s">&quot;c&quot;</span><span class="o">)</span>
<span class="o">)).</span><span class="n">toDF</span><span class="o">(</span><span class="s">&quot;id&quot;</span><span class="o">,</span> <span class="s">&quot;category&quot;</span><span class="o">)</span>

<span class="k">val</span> <span class="n">indexer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">StringIndexer</span><span class="o">()</span>
  <span class="o">.</span><span class="n">setInputCol</span><span class="o">(</span><span class="s">&quot;category&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">setOutputCol</span><span class="o">(</span><span class="s">&quot;categoryIndex&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">fit</span><span class="o">(</span><span class="n">df</span><span class="o">)</span>
<span class="k">val</span> <span class="n">indexed</span> <span class="k">=</span> <span class="n">indexer</span><span class="o">.</span><span class="n">transform</span><span class="o">(</span><span class="n">df</span><span class="o">)</span>

<span class="n">println</span><span class="o">(</span><span class="s">s&quot;Transformed string column &#39;</span><span class="si">${</span><span class="n">indexer</span><span class="o">.</span><span class="n">getInputCol</span><span class="si">}</span><span class="s">&#39; &quot;</span> <span class="o">+</span>
    <span class="s">s&quot;to indexed column &#39;</span><span class="si">${</span><span class="n">indexer</span><span class="o">.</span><span class="n">getOutputCol</span><span class="si">}</span><span class="s">&#39;&quot;</span><span class="o">)</span>
<span class="n">indexed</span><span class="o">.</span><span class="n">show</span><span class="o">()</span>

<span class="k">val</span> <span class="n">inputColSchema</span> <span class="k">=</span> <span class="n">indexed</span><span class="o">.</span><span class="n">schema</span><span class="o">(</span><span class="n">indexer</span><span class="o">.</span><span class="n">getOutputCol</span><span class="o">)</span>
<span class="n">println</span><span class="o">(</span><span class="s">s&quot;StringIndexer will store labels in output column metadata: &quot;</span> <span class="o">+</span>
    <span class="s">s&quot;</span><span class="si">${</span><span class="nc">Attribute</span><span class="o">.</span><span class="n">fromStructField</span><span class="o">(</span><span class="n">inputColSchema</span><span class="o">).</span><span class="n">toString</span><span class="si">}</span><span class="s">\n&quot;</span><span class="o">)</span>

<span class="k">val</span> <span class="n">converter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">IndexToString</span><span class="o">()</span>
  <span class="o">.</span><span class="n">setInputCol</span><span class="o">(</span><span class="s">&quot;categoryIndex&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">setOutputCol</span><span class="o">(</span><span class="s">&quot;originalCategory&quot;</span><span class="o">)</span>

<span class="k">val</span> <span class="n">converted</span> <span class="k">=</span> <span class="n">converter</span><span class="o">.</span><span class="n">transform</span><span class="o">(</span><span class="n">indexed</span><span class="o">)</span>

<span class="n">println</span><span class="o">(</span><span class="s">s&quot;Transformed indexed column &#39;</span><span class="si">${</span><span class="n">converter</span><span class="o">.</span><span class="n">getInputCol</span><span class="si">}</span><span class="s">&#39; back to original string &quot;</span> <span class="o">+</span>
    <span class="s">s&quot;column &#39;</span><span class="si">${</span><span class="n">converter</span><span class="o">.</span><span class="n">getOutputCol</span><span class="si">}</span><span class="s">&#39; using labels in metadata&quot;</span><span class="o">)</span>
<span class="n">converted</span><span class="o">.</span><span class="n">select</span><span class="o">(</span><span class="s">&quot;id&quot;</span><span class="o">,</span> <span class="s">&quot;categoryIndex&quot;</span><span class="o">,</span> <span class="s">&quot;originalCategory&quot;</span><span class="o">).</span><span class="n">show</span><span class="o">()</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / scala / org / apache / spark / examples / ml / IndexToStringExample.scala”中找到完整的示例代码。</small></div>

  </div>

<div data-lang="java">

    <p>有关API的更多详细信息，请参考<a href="api/java/org/apache/spark/ml/feature/IndexToString.html">IndexToString Java文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">java.util.Arrays</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">java.util.List</span><span class="o">;</span>

<span class="kn">import</span> <span class="nn">org.apache.spark.ml.attribute.Attribute</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.ml.feature.IndexToString</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.ml.feature.StringIndexer</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.ml.feature.StringIndexerModel</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.Row</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.RowFactory</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.DataTypes</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.Metadata</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.StructField</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.StructType</span><span class="o">;</span>

<span class="n">List</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">data</span> <span class="o">=</span> <span class="n">Arrays</span><span class="o">.</span><span class="na">asList</span><span class="o">(</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">0</span><span class="o">,</span> <span class="s">&quot;a&quot;</span><span class="o">),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="s">&quot;b&quot;</span><span class="o">),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">2</span><span class="o">,</span> <span class="s">&quot;c&quot;</span><span class="o">),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">3</span><span class="o">,</span> <span class="s">&quot;a&quot;</span><span class="o">),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">4</span><span class="o">,</span> <span class="s">&quot;a&quot;</span><span class="o">),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">5</span><span class="o">,</span> <span class="s">&quot;c&quot;</span><span class="o">)</span>
<span class="o">);</span>
<span class="n">StructType</span> <span class="n">schema</span> <span class="o">=</span> <span class="k">new</span> <span class="n">StructType</span><span class="o">(</span><span class="k">new</span> <span class="n">StructField</span><span class="o">[]{</span>
  <span class="k">new</span> <span class="n">StructField</span><span class="o">(</span><span class="s">&quot;id&quot;</span><span class="o">,</span> <span class="n">DataTypes</span><span class="o">.</span><span class="na">IntegerType</span><span class="o">,</span> <span class="kc">false</span><span class="o">,</span> <span class="n">Metadata</span><span class="o">.</span><span class="na">empty</span><span class="o">()),</span>
  <span class="k">new</span> <span class="n">StructField</span><span class="o">(</span><span class="s">&quot;category&quot;</span><span class="o">,</span> <span class="n">DataTypes</span><span class="o">.</span><span class="na">StringType</span><span class="o">,</span> <span class="kc">false</span><span class="o">,</span> <span class="n">Metadata</span><span class="o">.</span><span class="na">empty</span><span class="o">())</span>
<span class="o">});</span>
<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="na">createDataFrame</span><span class="o">(</span><span class="n">data</span><span class="o">,</span> <span class="n">schema</span><span class="o">);</span>

<span class="n">StringIndexerModel</span> <span class="n">indexer</span> <span class="o">=</span> <span class="k">new</span> <span class="n">StringIndexer</span><span class="o">()</span>
  <span class="o">.</span><span class="na">setInputCol</span><span class="o">(</span><span class="s">&quot;category&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">setOutputCol</span><span class="o">(</span><span class="s">&quot;categoryIndex&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">fit</span><span class="o">(</span><span class="n">df</span><span class="o">);</span>
<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">indexed</span> <span class="o">=</span> <span class="n">indexer</span><span class="o">.</span><span class="na">transform</span><span class="o">(</span><span class="n">df</span><span class="o">);</span>

<span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">&quot;Transformed string column &#39;&quot;</span> <span class="o">+</span> <span class="n">indexer</span><span class="o">.</span><span class="na">getInputCol</span><span class="o">()</span> <span class="o">+</span> <span class="s">&quot;&#39; &quot;</span> <span class="o">+</span>
    <span class="s">&quot;to indexed column &#39;&quot;</span> <span class="o">+</span> <span class="n">indexer</span><span class="o">.</span><span class="na">getOutputCol</span><span class="o">()</span> <span class="o">+</span> <span class="s">&quot;&#39;&quot;</span><span class="o">);</span>
<span class="n">indexed</span><span class="o">.</span><span class="na">show</span><span class="o">();</span>

<span class="n">StructField</span> <span class="n">inputColSchema</span> <span class="o">=</span> <span class="n">indexed</span><span class="o">.</span><span class="na">schema</span><span class="o">().</span><span class="na">apply</span><span class="o">(</span><span class="n">indexer</span><span class="o">.</span><span class="na">getOutputCol</span><span class="o">());</span>
<span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">&quot;StringIndexer will store labels in output column metadata: &quot;</span> <span class="o">+</span>
    <span class="n">Attribute</span><span class="o">.</span><span class="na">fromStructField</span><span class="o">(</span><span class="n">inputColSchema</span><span class="o">).</span><span class="na">toString</span><span class="o">()</span> <span class="o">+</span> <span class="s">&quot;\n&quot;</span><span class="o">);</span>

<span class="n">IndexToString</span> <span class="n">converter</span> <span class="o">=</span> <span class="k">new</span> <span class="n">IndexToString</span><span class="o">()</span>
  <span class="o">.</span><span class="na">setInputCol</span><span class="o">(</span><span class="s">&quot;categoryIndex&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">setOutputCol</span><span class="o">(</span><span class="s">&quot;originalCategory&quot;</span><span class="o">);</span>
<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">converted</span> <span class="o">=</span> <span class="n">converter</span><span class="o">.</span><span class="na">transform</span><span class="o">(</span><span class="n">indexed</span><span class="o">);</span>

<span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">&quot;Transformed indexed column &#39;&quot;</span> <span class="o">+</span> <span class="n">converter</span><span class="o">.</span><span class="na">getInputCol</span><span class="o">()</span> <span class="o">+</span> <span class="s">&quot;&#39; back to &quot;</span> <span class="o">+</span>
    <span class="s">&quot;original string column &#39;&quot;</span> <span class="o">+</span> <span class="n">converter</span><span class="o">.</span><span class="na">getOutputCol</span><span class="o">()</span> <span class="o">+</span> <span class="s">&quot;&#39; using labels in metadata&quot;</span><span class="o">);</span>
<span class="n">converted</span><span class="o">.</span><span class="na">select</span><span class="o">(</span><span class="s">&quot;id&quot;</span><span class="o">,</span> <span class="s">&quot;categoryIndex&quot;</span><span class="o">,</span> <span class="s">&quot;originalCategory&quot;</span><span class="o">).</span><span class="na">show</span><span class="o">();</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / java / org / apache / spark / examples / ml / JavaIndexToStringExample.java”中找到完整的示例代码。</small></div>

  </div>

<div data-lang="python">

    <p>有关API的更多详细信息，请参考<a href="api/python/pyspark.ml.html#pyspark.ml.feature.IndexToString">IndexToString Python文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pyspark.ml.feature</span> <span class="kn">import</span> <span class="n">IndexToString</span><span class="p">,</span> <span class="n">StringIndexer</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">(</span>
    <span class="p">[(</span><span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;a&quot;</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="s2">&quot;c&quot;</span><span class="p">),</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="s2">&quot;a&quot;</span><span class="p">),</span> <span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="s2">&quot;a&quot;</span><span class="p">),</span> <span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="s2">&quot;c&quot;</span><span class="p">)],</span>
    <span class="p">[</span><span class="s2">&quot;id&quot;</span><span class="p">,</span> <span class="s2">&quot;category&quot;</span><span class="p">])</span>

<span class="n">indexer</span> <span class="o">=</span> <span class="n">StringIndexer</span><span class="p">(</span><span class="n">inputCol</span><span class="o">=</span><span class="s2">&quot;category&quot;</span><span class="p">,</span> <span class="n">outputCol</span><span class="o">=</span><span class="s2">&quot;categoryIndex&quot;</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">indexer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
<span class="n">indexed</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s2">&quot;Transformed string column &#39;</span><span class="si">%s</span><span class="s2">&#39; to indexed column &#39;</span><span class="si">%s</span><span class="s2">&#39;&quot;</span>
      <span class="o">%</span> <span class="p">(</span><span class="n">indexer</span><span class="o">.</span><span class="n">getInputCol</span><span class="p">(),</span> <span class="n">indexer</span><span class="o">.</span><span class="n">getOutputCol</span><span class="p">()))</span>
<span class="n">indexed</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="k">print</span><span class="p">(</span><span class="s2">&quot;StringIndexer will store labels in output column metadata</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="n">converter</span> <span class="o">=</span> <span class="n">IndexToString</span><span class="p">(</span><span class="n">inputCol</span><span class="o">=</span><span class="s2">&quot;categoryIndex&quot;</span><span class="p">,</span> <span class="n">outputCol</span><span class="o">=</span><span class="s2">&quot;originalCategory&quot;</span><span class="p">)</span>
<span class="n">converted</span> <span class="o">=</span> <span class="n">converter</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">indexed</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s2">&quot;Transformed indexed column &#39;</span><span class="si">%s</span><span class="s2">&#39; back to original string column &#39;</span><span class="si">%s</span><span class="s2">&#39; using &quot;</span>
      <span class="s2">&quot;labels in metadata&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">converter</span><span class="o">.</span><span class="n">getInputCol</span><span class="p">(),</span> <span class="n">converter</span><span class="o">.</span><span class="n">getOutputCol</span><span class="p">()))</span>
<span class="n">converted</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s2">&quot;id&quot;</span><span class="p">,</span> <span class="s2">&quot;categoryIndex&quot;</span><span class="p">,</span> <span class="s2">&quot;originalCategory&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / python / ml / index_to_string_example.py”中找到完整的示例代码。</small></div>

  </div>
</div>

<h2 id="onehotencoder">OneHotEncoder</h2>

<p><a href="http://en.wikipedia.org/wiki/One-hot">一键热编码</a>将表示为标签索引的分类特征映射到二进制向量，该向量最多具有一个单一的单值，该单值表示所有特征值集合中特定特征值的存在。此编码允许期望连续特征（例如逻辑回归）的算法使用分类特征。对于字符串类型的输入数据，通常首先使用<a href="ml-features.html#stringindexer">StringIndexer</a>对分类特征进行编码。</p>

<p><code>OneHotEncoder</code>可以转换多列，为每个输入列返回一个热编码的输出矢量列。通常使用<a href="ml-features.html#vectorassembler">VectorAssembler</a>将这些向量合并为单个特征向量。</p>

<p><code>OneHotEncoder</code>支持<code>handleInvalid</code>参数，用于选择在转换数据期间如何处理无效输入。可用的选项包括“保持”（将任何无效输入分配给额外的类别索引）和“错误”（引发错误）。</p>

<p><strong>例子</strong></p>

<div class="codetabs">
<div data-lang="scala">

    <p>有关API的更多详细信息，请参考<a href="api/scala/index.html#org.apache.spark.ml.feature.OneHotEncoder">OneHotEncoder Scala文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">org.apache.spark.ml.feature.OneHotEncoder</span>

<span class="k">val</span> <span class="n">df</span> <span class="k">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="o">(</span><span class="nc">Seq</span><span class="o">(</span>
  <span class="o">(</span><span class="mf">0.0</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">),</span>
  <span class="o">(</span><span class="mf">1.0</span><span class="o">,</span> <span class="mf">0.0</span><span class="o">),</span>
  <span class="o">(</span><span class="mf">2.0</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">),</span>
  <span class="o">(</span><span class="mf">0.0</span><span class="o">,</span> <span class="mf">2.0</span><span class="o">),</span>
  <span class="o">(</span><span class="mf">0.0</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">),</span>
  <span class="o">(</span><span class="mf">2.0</span><span class="o">,</span> <span class="mf">0.0</span><span class="o">)</span>
<span class="o">)).</span><span class="n">toDF</span><span class="o">(</span><span class="s">&quot;categoryIndex1&quot;</span><span class="o">,</span> <span class="s">&quot;categoryIndex2&quot;</span><span class="o">)</span>

<span class="k">val</span> <span class="n">encoder</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">OneHotEncoder</span><span class="o">()</span>
  <span class="o">.</span><span class="n">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">&quot;categoryIndex1&quot;</span><span class="o">,</span> <span class="s">&quot;categoryIndex2&quot;</span><span class="o">))</span>
  <span class="o">.</span><span class="n">setOutputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">&quot;categoryVec1&quot;</span><span class="o">,</span> <span class="s">&quot;categoryVec2&quot;</span><span class="o">))</span>
<span class="k">val</span> <span class="n">model</span> <span class="k">=</span> <span class="n">encoder</span><span class="o">.</span><span class="n">fit</span><span class="o">(</span><span class="n">df</span><span class="o">)</span>

<span class="k">val</span> <span class="n">encoded</span> <span class="k">=</span> <span class="n">model</span><span class="o">.</span><span class="n">transform</span><span class="o">(</span><span class="n">df</span><span class="o">)</span>
<span class="n">encoded</span><span class="o">.</span><span class="n">show</span><span class="o">()</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / scala / org / apache / spark / examples / ml / OneHotEncoderExample.scala”中找到完整的示例代码。</small></div>
  </div>

<div data-lang="java">

    <p>有关API的更多详细信息，请参考<a href="api/java/org/apache/spark/ml/feature/OneHotEncoder.html">OneHotEncoder Java文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">java.util.Arrays</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">java.util.List</span><span class="o">;</span>

<span class="kn">import</span> <span class="nn">org.apache.spark.ml.feature.OneHotEncoder</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.ml.feature.OneHotEncoderModel</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.Dataset</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.Row</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.RowFactory</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.DataTypes</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.Metadata</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.StructField</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.StructType</span><span class="o">;</span>

<span class="n">List</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">data</span> <span class="o">=</span> <span class="n">Arrays</span><span class="o">.</span><span class="na">asList</span><span class="o">(</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mf">0.0</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mf">1.0</span><span class="o">,</span> <span class="mf">0.0</span><span class="o">),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mf">2.0</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mf">0.0</span><span class="o">,</span> <span class="mf">2.0</span><span class="o">),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mf">0.0</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mf">2.0</span><span class="o">,</span> <span class="mf">0.0</span><span class="o">)</span>
<span class="o">);</span>

<span class="n">StructType</span> <span class="n">schema</span> <span class="o">=</span> <span class="k">new</span> <span class="n">StructType</span><span class="o">(</span><span class="k">new</span> <span class="n">StructField</span><span class="o">[]{</span>
  <span class="k">new</span> <span class="n">StructField</span><span class="o">(</span><span class="s">&quot;categoryIndex1&quot;</span><span class="o">,</span> <span class="n">DataTypes</span><span class="o">.</span><span class="na">DoubleType</span><span class="o">,</span> <span class="kc">false</span><span class="o">,</span> <span class="n">Metadata</span><span class="o">.</span><span class="na">empty</span><span class="o">()),</span>
  <span class="k">new</span> <span class="n">StructField</span><span class="o">(</span><span class="s">&quot;categoryIndex2&quot;</span><span class="o">,</span> <span class="n">DataTypes</span><span class="o">.</span><span class="na">DoubleType</span><span class="o">,</span> <span class="kc">false</span><span class="o">,</span> <span class="n">Metadata</span><span class="o">.</span><span class="na">empty</span><span class="o">())</span>
<span class="o">});</span>

<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="na">createDataFrame</span><span class="o">(</span><span class="n">data</span><span class="o">,</span> <span class="n">schema</span><span class="o">);</span>

<span class="n">OneHotEncoder</span> <span class="n">encoder</span> <span class="o">=</span> <span class="k">new</span> <span class="n">OneHotEncoder</span><span class="o">()</span>
  <span class="o">.</span><span class="na">setInputCols</span><span class="o">(</span><span class="k">new</span> <span class="n">String</span><span class="o">[]</span> <span class="o">{</span><span class="s">&quot;categoryIndex1&quot;</span><span class="o">,</span> <span class="s">&quot;categoryIndex2&quot;</span><span class="o">})</span>
  <span class="o">.</span><span class="na">setOutputCols</span><span class="o">(</span><span class="k">new</span> <span class="n">String</span><span class="o">[]</span> <span class="o">{</span><span class="s">&quot;categoryVec1&quot;</span><span class="o">,</span> <span class="s">&quot;categoryVec2&quot;</span><span class="o">});</span>

<span class="n">OneHotEncoderModel</span> <span class="n">model</span> <span class="o">=</span> <span class="n">encoder</span><span class="o">.</span><span class="na">fit</span><span class="o">(</span><span class="n">df</span><span class="o">);</span>
<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">encoded</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="na">transform</span><span class="o">(</span><span class="n">df</span><span class="o">);</span>
<span class="n">encoded</span><span class="o">.</span><span class="na">show</span><span class="o">();</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / java / org / apache / spark / examples / ml / JavaOneHotEncoderExample.java”中找到完整的示例代码。</small></div>
  </div>

<div data-lang="python">

    <p>有关API的更多详细信息，请参考<a href="api/python/pyspark.ml.html#pyspark.ml.feature.OneHotEncoder">OneHotEncoder Python文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pyspark.ml.feature</span> <span class="kn">import</span> <span class="n">OneHotEncoder</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">([</span>
    <span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">),</span>
    <span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">),</span>
    <span class="p">(</span><span class="mf">2.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">),</span>
    <span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">),</span>
    <span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">),</span>
    <span class="p">(</span><span class="mf">2.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">)</span>
<span class="p">],</span> <span class="p">[</span><span class="s2">&quot;categoryIndex1&quot;</span><span class="p">,</span> <span class="s2">&quot;categoryIndex2&quot;</span><span class="p">])</span>

<span class="n">encoder</span> <span class="o">=</span> <span class="n">OneHotEncoder</span><span class="p">(</span><span class="n">inputCols</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;categoryIndex1&quot;</span><span class="p">,</span> <span class="s2">&quot;categoryIndex2&quot;</span><span class="p">],</span>
                        <span class="n">outputCols</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;categoryVec1&quot;</span><span class="p">,</span> <span class="s2">&quot;categoryVec2&quot;</span><span class="p">])</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">encoder</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
<span class="n">encoded</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
<span class="n">encoded</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / python / ml / onehot_encoder_example.py”中找到完整的示例代码。</small></div>
  </div>
</div>

<h2 id="vectorindexer">VectorIndexer</h2>

<p><code>VectorIndexer</code>帮助索引以下数据集中的分类特征<code>Vector</code> s。它既可以自动确定哪些特征是分类的，又可以将原始值转换为分类索引。具体来说，它执行以下操作：</p>

<ol>
  <li>取得类型为<a href="api/scala/index.html#org.apache.spark.ml.linalg.Vector">Vector</a>的输入列和一个参数<code>maxCategories</code> 。</li>
  <li>根据不同值的数量确定哪些要素应归类，其中最多包含哪些要素<code>maxCategories</code>被宣布为绝对。</li>
  <li>为每个分类特征计算从0开始的分类索引。</li>
  <li>为分类特征建立索引，并将原始特征值转换为索引。</li>
</ol>

<p>索引分类特征允许诸如决策树和树组合之类的算法适当地处理分类特征，从而提高性能。</p>

<p><strong>例子</strong></p>

<p>在下面的示例中，我们读取了标记点的数据集，然后使用<code>VectorIndexer</code>决定应将哪些功能视为分类。我们将分类特征值转换为其索引。然后，可以将转换后的数据传递给算法，例如<code>DecisionTreeRegressor</code>处理分类特征。</p>

<div class="codetabs">
<div data-lang="scala">

    <p>有关API的更多详细信息，请参考<a href="api/scala/index.html#org.apache.spark.ml.feature.VectorIndexer">VectorIndexer Scala文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">org.apache.spark.ml.feature.VectorIndexer</span>

<span class="k">val</span> <span class="n">data</span> <span class="k">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">format</span><span class="o">(</span><span class="s">&quot;libsvm&quot;</span><span class="o">).</span><span class="n">load</span><span class="o">(</span><span class="s">&quot;data/mllib/sample_libsvm_data.txt&quot;</span><span class="o">)</span>

<span class="k">val</span> <span class="n">indexer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">VectorIndexer</span><span class="o">()</span>
  <span class="o">.</span><span class="n">setInputCol</span><span class="o">(</span><span class="s">&quot;features&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">setOutputCol</span><span class="o">(</span><span class="s">&quot;indexed&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">setMaxCategories</span><span class="o">(</span><span class="mi">10</span><span class="o">)</span>

<span class="k">val</span> <span class="n">indexerModel</span> <span class="k">=</span> <span class="n">indexer</span><span class="o">.</span><span class="n">fit</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="k">val</span> <span class="n">categoricalFeatures</span><span class="k">:</span> <span class="kt">Set</span><span class="o">[</span><span class="kt">Int</span><span class="o">]</span> <span class="k">=</span> <span class="n">indexerModel</span><span class="o">.</span><span class="n">categoryMaps</span><span class="o">.</span><span class="n">keys</span><span class="o">.</span><span class="n">toSet</span>
<span class="n">println</span><span class="o">(</span><span class="s">s&quot;Chose </span><span class="si">${</span><span class="n">categoricalFeatures</span><span class="o">.</span><span class="n">size</span><span class="si">}</span><span class="s"> &quot;</span> <span class="o">+</span>
  <span class="s">s&quot;categorical features: </span><span class="si">${</span><span class="n">categoricalFeatures</span><span class="o">.</span><span class="n">mkString</span><span class="o">(</span><span class="s">&quot;, &quot;</span><span class="o">)</span><span class="si">}</span><span class="s">&quot;</span><span class="o">)</span>

<span class="c1">// Create new column &quot;indexed&quot; with categorical values transformed to indices</span>
<span class="k">val</span> <span class="n">indexedData</span> <span class="k">=</span> <span class="n">indexerModel</span><span class="o">.</span><span class="n">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>
<span class="n">indexedData</span><span class="o">.</span><span class="n">show</span><span class="o">()</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / scala / org / apache / spark / examples / ml / VectorIndexerExample.scala”中找到完整的示例代码。</small></div>
  </div>

<div data-lang="java">

    <p>有关API的更多详细信息，请参考<a href="api/java/org/apache/spark/ml/feature/VectorIndexer.html">VectorIndexer Java文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">java.util.Map</span><span class="o">;</span>

<span class="kn">import</span> <span class="nn">org.apache.spark.ml.feature.VectorIndexer</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.ml.feature.VectorIndexerModel</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.Dataset</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.Row</span><span class="o">;</span>

<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="na">read</span><span class="o">().</span><span class="na">format</span><span class="o">(</span><span class="s">&quot;libsvm&quot;</span><span class="o">).</span><span class="na">load</span><span class="o">(</span><span class="s">&quot;data/mllib/sample_libsvm_data.txt&quot;</span><span class="o">);</span>

<span class="n">VectorIndexer</span> <span class="n">indexer</span> <span class="o">=</span> <span class="k">new</span> <span class="n">VectorIndexer</span><span class="o">()</span>
  <span class="o">.</span><span class="na">setInputCol</span><span class="o">(</span><span class="s">&quot;features&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">setOutputCol</span><span class="o">(</span><span class="s">&quot;indexed&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">setMaxCategories</span><span class="o">(</span><span class="mi">10</span><span class="o">);</span>
<span class="n">VectorIndexerModel</span> <span class="n">indexerModel</span> <span class="o">=</span> <span class="n">indexer</span><span class="o">.</span><span class="na">fit</span><span class="o">(</span><span class="n">data</span><span class="o">);</span>

<span class="n">Map</span><span class="o">&lt;</span><span class="n">Integer</span><span class="o">,</span> <span class="n">Map</span><span class="o">&lt;</span><span class="n">Double</span><span class="o">,</span> <span class="n">Integer</span><span class="o">&gt;&gt;</span> <span class="n">categoryMaps</span> <span class="o">=</span> <span class="n">indexerModel</span><span class="o">.</span><span class="na">javaCategoryMaps</span><span class="o">();</span>
<span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">print</span><span class="o">(</span><span class="s">&quot;Chose &quot;</span> <span class="o">+</span> <span class="n">categoryMaps</span><span class="o">.</span><span class="na">size</span><span class="o">()</span> <span class="o">+</span> <span class="s">&quot; categorical features:&quot;</span><span class="o">);</span>

<span class="k">for</span> <span class="o">(</span><span class="n">Integer</span> <span class="n">feature</span> <span class="o">:</span> <span class="n">categoryMaps</span><span class="o">.</span><span class="na">keySet</span><span class="o">())</span> <span class="o">{</span>
  <span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">print</span><span class="o">(</span><span class="s">&quot; &quot;</span> <span class="o">+</span> <span class="n">feature</span><span class="o">);</span>
<span class="o">}</span>
<span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">();</span>

<span class="c1">// Create new column &quot;indexed&quot; with categorical values transformed to indices</span>
<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">indexedData</span> <span class="o">=</span> <span class="n">indexerModel</span><span class="o">.</span><span class="na">transform</span><span class="o">(</span><span class="n">data</span><span class="o">);</span>
<span class="n">indexedData</span><span class="o">.</span><span class="na">show</span><span class="o">();</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / java / org / apache / spark / examples / ml / JavaVectorIndexerExample.java”中找到完整的示例代码。</small></div>
  </div>

<div data-lang="python">

    <p>有关API的更多详细信息，请参考<a href="api/python/pyspark.ml.html#pyspark.ml.feature.VectorIndexer">VectorIndexer Python文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pyspark.ml.feature</span> <span class="kn">import</span> <span class="n">VectorIndexer</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot;libsvm&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;data/mllib/sample_libsvm_data.txt&quot;</span><span class="p">)</span>

<span class="n">indexer</span> <span class="o">=</span> <span class="n">VectorIndexer</span><span class="p">(</span><span class="n">inputCol</span><span class="o">=</span><span class="s2">&quot;features&quot;</span><span class="p">,</span> <span class="n">outputCol</span><span class="o">=</span><span class="s2">&quot;indexed&quot;</span><span class="p">,</span> <span class="n">maxCategories</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">indexerModel</span> <span class="o">=</span> <span class="n">indexer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">categoricalFeatures</span> <span class="o">=</span> <span class="n">indexerModel</span><span class="o">.</span><span class="n">categoryMaps</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&quot;Chose </span><span class="si">%d</span><span class="s2"> categorical features: </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span>
      <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">categoricalFeatures</span><span class="p">),</span> <span class="s2">&quot;, &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">k</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">categoricalFeatures</span><span class="o">.</span><span class="n">keys</span><span class="p">())))</span>

<span class="c1"># Create new column &quot;indexed&quot; with categorical values transformed to indices</span>
<span class="n">indexedData</span> <span class="o">=</span> <span class="n">indexerModel</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">indexedData</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / python / ml / vector_indexer_example.py”中找到完整的示例代码。</small></div>
  </div>
</div>

<h2 id="interaction">相互作用</h2>

<p><code>Interaction</code>是一个<code>Transformer</code>它采用向量列或双值列，并生成一个向量列，其中包含来自每个输入列的一个值的所有组合的乘积。</p>

<p>例如，如果您有2个向量类型的列，每个向量类型的列都有3个维作为输入列，那么您将获得9维向量作为输出列。</p>

<p><strong>例子</strong></p>

<p>假设我们具有以下DataFrame，其中的列为“ id1”，“ vec1”和“ vec2”：</p>

<pre><code>  id1|vec1          |vec2          
  ---|--------------|--------------
  1  |[1.0,2.0,3.0] |[8.0,4.0,5.0] 
  2  |[4.0,3.0,8.0] |[7.0,9.0,8.0] 
  3  |[6.0,1.0,9.0] |[2.0,3.0,6.0] 
  4  |[10.0,8.0,6.0]|[9.0,4.0,5.0] 
  5  |[9.0,2.0,7.0] |[10.0,7.0,3.0]
  6  |[1.0,1.0,4.0] |[2.0,8.0,4.0]     
</code></pre>

<p>正在申请<code>Interaction</code>与那些输入列，然后<code>interactedCol</code>由于输出列包含：</p>

<pre><code>  id1|vec1          |vec2          |interactedCol                                         
  ---|--------------|--------------|------------------------------------------------------
  1  |[1.0,2.0,3.0] |[8.0,4.0,5.0] |[8.0,4.0,5.0,16.0,8.0,10.0,24.0,12.0,15.0]            
  2  |[4.0,3.0,8.0] |[7.0,9.0,8.0] |[56.0,72.0,64.0,42.0,54.0,48.0,112.0,144.0,128.0]     
  3  |[6.0,1.0,9.0] |[2.0,3.0,6.0] |[36.0,54.0,108.0,6.0,9.0,18.0,54.0,81.0,162.0]        
  4  |[10.0,8.0,6.0]|[9.0,4.0,5.0] |[360.0,160.0,200.0,288.0,128.0,160.0,216.0,96.0,120.0]
  5  |[9.0,2.0,7.0] |[10.0,7.0,3.0]|[450.0,315.0,135.0,100.0,70.0,30.0,350.0,245.0,105.0] 
  6  |[1.0,1.0,4.0] |[2.0,8.0,4.0] |[12.0,48.0,24.0,12.0,48.0,24.0,48.0,192.0,96.0]       
</code></pre>

<div class="codetabs">
<div data-lang="scala">

    <p>有关API的更多详细信息，请参考<a href="api/scala/index.html#org.apache.spark.ml.feature.Interaction">Interaction Scala文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">org.apache.spark.ml.feature.Interaction</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.feature.VectorAssembler</span>

<span class="k">val</span> <span class="n">df</span> <span class="k">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="o">(</span><span class="nc">Seq</span><span class="o">(</span>
  <span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="mi">1</span><span class="o">,</span> <span class="mi">2</span><span class="o">,</span> <span class="mi">3</span><span class="o">,</span> <span class="mi">8</span><span class="o">,</span> <span class="mi">4</span><span class="o">,</span> <span class="mi">5</span><span class="o">),</span>
  <span class="o">(</span><span class="mi">2</span><span class="o">,</span> <span class="mi">4</span><span class="o">,</span> <span class="mi">3</span><span class="o">,</span> <span class="mi">8</span><span class="o">,</span> <span class="mi">7</span><span class="o">,</span> <span class="mi">9</span><span class="o">,</span> <span class="mi">8</span><span class="o">),</span>
  <span class="o">(</span><span class="mi">3</span><span class="o">,</span> <span class="mi">6</span><span class="o">,</span> <span class="mi">1</span><span class="o">,</span> <span class="mi">9</span><span class="o">,</span> <span class="mi">2</span><span class="o">,</span> <span class="mi">3</span><span class="o">,</span> <span class="mi">6</span><span class="o">),</span>
  <span class="o">(</span><span class="mi">4</span><span class="o">,</span> <span class="mi">10</span><span class="o">,</span> <span class="mi">8</span><span class="o">,</span> <span class="mi">6</span><span class="o">,</span> <span class="mi">9</span><span class="o">,</span> <span class="mi">4</span><span class="o">,</span> <span class="mi">5</span><span class="o">),</span>
  <span class="o">(</span><span class="mi">5</span><span class="o">,</span> <span class="mi">9</span><span class="o">,</span> <span class="mi">2</span><span class="o">,</span> <span class="mi">7</span><span class="o">,</span> <span class="mi">10</span><span class="o">,</span> <span class="mi">7</span><span class="o">,</span> <span class="mi">3</span><span class="o">),</span>
  <span class="o">(</span><span class="mi">6</span><span class="o">,</span> <span class="mi">1</span><span class="o">,</span> <span class="mi">1</span><span class="o">,</span> <span class="mi">4</span><span class="o">,</span> <span class="mi">2</span><span class="o">,</span> <span class="mi">8</span><span class="o">,</span> <span class="mi">4</span><span class="o">)</span>
<span class="o">)).</span><span class="n">toDF</span><span class="o">(</span><span class="s">&quot;id1&quot;</span><span class="o">,</span> <span class="s">&quot;id2&quot;</span><span class="o">,</span> <span class="s">&quot;id3&quot;</span><span class="o">,</span> <span class="s">&quot;id4&quot;</span><span class="o">,</span> <span class="s">&quot;id5&quot;</span><span class="o">,</span> <span class="s">&quot;id6&quot;</span><span class="o">,</span> <span class="s">&quot;id7&quot;</span><span class="o">)</span>

<span class="k">val</span> <span class="n">assembler1</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">VectorAssembler</span><span class="o">().</span>
  <span class="n">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">&quot;id2&quot;</span><span class="o">,</span> <span class="s">&quot;id3&quot;</span><span class="o">,</span> <span class="s">&quot;id4&quot;</span><span class="o">)).</span>
  <span class="n">setOutputCol</span><span class="o">(</span><span class="s">&quot;vec1&quot;</span><span class="o">)</span>

<span class="k">val</span> <span class="n">assembled1</span> <span class="k">=</span> <span class="n">assembler1</span><span class="o">.</span><span class="n">transform</span><span class="o">(</span><span class="n">df</span><span class="o">)</span>

<span class="k">val</span> <span class="n">assembler2</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">VectorAssembler</span><span class="o">().</span>
  <span class="n">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">&quot;id5&quot;</span><span class="o">,</span> <span class="s">&quot;id6&quot;</span><span class="o">,</span> <span class="s">&quot;id7&quot;</span><span class="o">)).</span>
  <span class="n">setOutputCol</span><span class="o">(</span><span class="s">&quot;vec2&quot;</span><span class="o">)</span>

<span class="k">val</span> <span class="n">assembled2</span> <span class="k">=</span> <span class="n">assembler2</span><span class="o">.</span><span class="n">transform</span><span class="o">(</span><span class="n">assembled1</span><span class="o">).</span><span class="n">select</span><span class="o">(</span><span class="s">&quot;id1&quot;</span><span class="o">,</span> <span class="s">&quot;vec1&quot;</span><span class="o">,</span> <span class="s">&quot;vec2&quot;</span><span class="o">)</span>

<span class="k">val</span> <span class="n">interaction</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Interaction</span><span class="o">()</span>
  <span class="o">.</span><span class="n">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">&quot;id1&quot;</span><span class="o">,</span> <span class="s">&quot;vec1&quot;</span><span class="o">,</span> <span class="s">&quot;vec2&quot;</span><span class="o">))</span>
  <span class="o">.</span><span class="n">setOutputCol</span><span class="o">(</span><span class="s">&quot;interactedCol&quot;</span><span class="o">)</span>

<span class="k">val</span> <span class="n">interacted</span> <span class="k">=</span> <span class="n">interaction</span><span class="o">.</span><span class="n">transform</span><span class="o">(</span><span class="n">assembled2</span><span class="o">)</span>

<span class="n">interacted</span><span class="o">.</span><span class="n">show</span><span class="o">(</span><span class="n">truncate</span> <span class="k">=</span> <span class="kc">false</span><span class="o">)</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / scala / org / apache / spark / examples / ml / InteractionExample.scala”中找到完整的示例代码。</small></div>
  </div>

<div data-lang="java">

    <p>有关API的更多详细信息，请参阅<a href="api/java/org/apache/spark/ml/feature/Interaction.html">Interaction Java文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="n">List</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">data</span> <span class="o">=</span> <span class="n">Arrays</span><span class="o">.</span><span class="na">asList</span><span class="o">(</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="mi">1</span><span class="o">,</span> <span class="mi">2</span><span class="o">,</span> <span class="mi">3</span><span class="o">,</span> <span class="mi">8</span><span class="o">,</span> <span class="mi">4</span><span class="o">,</span> <span class="mi">5</span><span class="o">),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">2</span><span class="o">,</span> <span class="mi">4</span><span class="o">,</span> <span class="mi">3</span><span class="o">,</span> <span class="mi">8</span><span class="o">,</span> <span class="mi">7</span><span class="o">,</span> <span class="mi">9</span><span class="o">,</span> <span class="mi">8</span><span class="o">),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">3</span><span class="o">,</span> <span class="mi">6</span><span class="o">,</span> <span class="mi">1</span><span class="o">,</span> <span class="mi">9</span><span class="o">,</span> <span class="mi">2</span><span class="o">,</span> <span class="mi">3</span><span class="o">,</span> <span class="mi">6</span><span class="o">),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">4</span><span class="o">,</span> <span class="mi">10</span><span class="o">,</span> <span class="mi">8</span><span class="o">,</span> <span class="mi">6</span><span class="o">,</span> <span class="mi">9</span><span class="o">,</span> <span class="mi">4</span><span class="o">,</span> <span class="mi">5</span><span class="o">),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">5</span><span class="o">,</span> <span class="mi">9</span><span class="o">,</span> <span class="mi">2</span><span class="o">,</span> <span class="mi">7</span><span class="o">,</span> <span class="mi">10</span><span class="o">,</span> <span class="mi">7</span><span class="o">,</span> <span class="mi">3</span><span class="o">),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">6</span><span class="o">,</span> <span class="mi">1</span><span class="o">,</span> <span class="mi">1</span><span class="o">,</span> <span class="mi">4</span><span class="o">,</span> <span class="mi">2</span><span class="o">,</span> <span class="mi">8</span><span class="o">,</span> <span class="mi">4</span><span class="o">)</span>
<span class="o">);</span>

<span class="n">StructType</span> <span class="n">schema</span> <span class="o">=</span> <span class="k">new</span> <span class="n">StructType</span><span class="o">(</span><span class="k">new</span> <span class="n">StructField</span><span class="o">[]{</span>
  <span class="k">new</span> <span class="n">StructField</span><span class="o">(</span><span class="s">&quot;id1&quot;</span><span class="o">,</span> <span class="n">DataTypes</span><span class="o">.</span><span class="na">IntegerType</span><span class="o">,</span> <span class="kc">false</span><span class="o">,</span> <span class="n">Metadata</span><span class="o">.</span><span class="na">empty</span><span class="o">()),</span>
  <span class="k">new</span> <span class="n">StructField</span><span class="o">(</span><span class="s">&quot;id2&quot;</span><span class="o">,</span> <span class="n">DataTypes</span><span class="o">.</span><span class="na">IntegerType</span><span class="o">,</span> <span class="kc">false</span><span class="o">,</span> <span class="n">Metadata</span><span class="o">.</span><span class="na">empty</span><span class="o">()),</span>
  <span class="k">new</span> <span class="n">StructField</span><span class="o">(</span><span class="s">&quot;id3&quot;</span><span class="o">,</span> <span class="n">DataTypes</span><span class="o">.</span><span class="na">IntegerType</span><span class="o">,</span> <span class="kc">false</span><span class="o">,</span> <span class="n">Metadata</span><span class="o">.</span><span class="na">empty</span><span class="o">()),</span>
  <span class="k">new</span> <span class="n">StructField</span><span class="o">(</span><span class="s">&quot;id4&quot;</span><span class="o">,</span> <span class="n">DataTypes</span><span class="o">.</span><span class="na">IntegerType</span><span class="o">,</span> <span class="kc">false</span><span class="o">,</span> <span class="n">Metadata</span><span class="o">.</span><span class="na">empty</span><span class="o">()),</span>
  <span class="k">new</span> <span class="n">StructField</span><span class="o">(</span><span class="s">&quot;id5&quot;</span><span class="o">,</span> <span class="n">DataTypes</span><span class="o">.</span><span class="na">IntegerType</span><span class="o">,</span> <span class="kc">false</span><span class="o">,</span> <span class="n">Metadata</span><span class="o">.</span><span class="na">empty</span><span class="o">()),</span>
  <span class="k">new</span> <span class="n">StructField</span><span class="o">(</span><span class="s">&quot;id6&quot;</span><span class="o">,</span> <span class="n">DataTypes</span><span class="o">.</span><span class="na">IntegerType</span><span class="o">,</span> <span class="kc">false</span><span class="o">,</span> <span class="n">Metadata</span><span class="o">.</span><span class="na">empty</span><span class="o">()),</span>
  <span class="k">new</span> <span class="n">StructField</span><span class="o">(</span><span class="s">&quot;id7&quot;</span><span class="o">,</span> <span class="n">DataTypes</span><span class="o">.</span><span class="na">IntegerType</span><span class="o">,</span> <span class="kc">false</span><span class="o">,</span> <span class="n">Metadata</span><span class="o">.</span><span class="na">empty</span><span class="o">())</span>
<span class="o">});</span>

<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="na">createDataFrame</span><span class="o">(</span><span class="n">data</span><span class="o">,</span> <span class="n">schema</span><span class="o">);</span>

<span class="n">VectorAssembler</span> <span class="n">assembler1</span> <span class="o">=</span> <span class="k">new</span> <span class="n">VectorAssembler</span><span class="o">()</span>
        <span class="o">.</span><span class="na">setInputCols</span><span class="o">(</span><span class="k">new</span> <span class="n">String</span><span class="o">[]{</span><span class="s">&quot;id2&quot;</span><span class="o">,</span> <span class="s">&quot;id3&quot;</span><span class="o">,</span> <span class="s">&quot;id4&quot;</span><span class="o">})</span>
        <span class="o">.</span><span class="na">setOutputCol</span><span class="o">(</span><span class="s">&quot;vec1&quot;</span><span class="o">);</span>

<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">assembled1</span> <span class="o">=</span> <span class="n">assembler1</span><span class="o">.</span><span class="na">transform</span><span class="o">(</span><span class="n">df</span><span class="o">);</span>

<span class="n">VectorAssembler</span> <span class="n">assembler2</span> <span class="o">=</span> <span class="k">new</span> <span class="n">VectorAssembler</span><span class="o">()</span>
        <span class="o">.</span><span class="na">setInputCols</span><span class="o">(</span><span class="k">new</span> <span class="n">String</span><span class="o">[]{</span><span class="s">&quot;id5&quot;</span><span class="o">,</span> <span class="s">&quot;id6&quot;</span><span class="o">,</span> <span class="s">&quot;id7&quot;</span><span class="o">})</span>
        <span class="o">.</span><span class="na">setOutputCol</span><span class="o">(</span><span class="s">&quot;vec2&quot;</span><span class="o">);</span>

<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">assembled2</span> <span class="o">=</span> <span class="n">assembler2</span><span class="o">.</span><span class="na">transform</span><span class="o">(</span><span class="n">assembled1</span><span class="o">).</span><span class="na">select</span><span class="o">(</span><span class="s">&quot;id1&quot;</span><span class="o">,</span> <span class="s">&quot;vec1&quot;</span><span class="o">,</span> <span class="s">&quot;vec2&quot;</span><span class="o">);</span>

<span class="n">Interaction</span> <span class="n">interaction</span> <span class="o">=</span> <span class="k">new</span> <span class="n">Interaction</span><span class="o">()</span>
        <span class="o">.</span><span class="na">setInputCols</span><span class="o">(</span><span class="k">new</span> <span class="n">String</span><span class="o">[]{</span><span class="s">&quot;id1&quot;</span><span class="o">,</span><span class="s">&quot;vec1&quot;</span><span class="o">,</span><span class="s">&quot;vec2&quot;</span><span class="o">})</span>
        <span class="o">.</span><span class="na">setOutputCol</span><span class="o">(</span><span class="s">&quot;interactedCol&quot;</span><span class="o">);</span>

<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">interacted</span> <span class="o">=</span> <span class="n">interaction</span><span class="o">.</span><span class="na">transform</span><span class="o">(</span><span class="n">assembled2</span><span class="o">);</span>

<span class="n">interacted</span><span class="o">.</span><span class="na">show</span><span class="o">(</span><span class="kc">false</span><span class="o">);</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / java / org / apache / spark / examples / ml / JavaInteractionExample.java”中找到完整的示例代码。</small></div>
  </div>

<div data-lang="python">

    <p>有关API的更多详细信息，请参阅<a href="api/python/pyspark.ml.html#pyspark.ml.feature.Interaction">Interaction Python文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pyspark.ml.feature</span> <span class="kn">import</span> <span class="n">Interaction</span><span class="p">,</span> <span class="n">VectorAssembler</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">(</span>
    <span class="p">[(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span>
     <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">8</span><span class="p">),</span>
     <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">6</span><span class="p">),</span>
     <span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span>
     <span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span>
     <span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">4</span><span class="p">)],</span>
    <span class="p">[</span><span class="s2">&quot;id1&quot;</span><span class="p">,</span> <span class="s2">&quot;id2&quot;</span><span class="p">,</span> <span class="s2">&quot;id3&quot;</span><span class="p">,</span> <span class="s2">&quot;id4&quot;</span><span class="p">,</span> <span class="s2">&quot;id5&quot;</span><span class="p">,</span> <span class="s2">&quot;id6&quot;</span><span class="p">,</span> <span class="s2">&quot;id7&quot;</span><span class="p">])</span>

<span class="n">assembler1</span> <span class="o">=</span> <span class="n">VectorAssembler</span><span class="p">(</span><span class="n">inputCols</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;id2&quot;</span><span class="p">,</span> <span class="s2">&quot;id3&quot;</span><span class="p">,</span> <span class="s2">&quot;id4&quot;</span><span class="p">],</span> <span class="n">outputCol</span><span class="o">=</span><span class="s2">&quot;vec1&quot;</span><span class="p">)</span>

<span class="n">assembled1</span> <span class="o">=</span> <span class="n">assembler1</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>

<span class="n">assembler2</span> <span class="o">=</span> <span class="n">VectorAssembler</span><span class="p">(</span><span class="n">inputCols</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;id5&quot;</span><span class="p">,</span> <span class="s2">&quot;id6&quot;</span><span class="p">,</span> <span class="s2">&quot;id7&quot;</span><span class="p">],</span> <span class="n">outputCol</span><span class="o">=</span><span class="s2">&quot;vec2&quot;</span><span class="p">)</span>

<span class="n">assembled2</span> <span class="o">=</span> <span class="n">assembler2</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">assembled1</span><span class="p">)</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s2">&quot;id1&quot;</span><span class="p">,</span> <span class="s2">&quot;vec1&quot;</span><span class="p">,</span> <span class="s2">&quot;vec2&quot;</span><span class="p">)</span>

<span class="n">interaction</span> <span class="o">=</span> <span class="n">Interaction</span><span class="p">(</span><span class="n">inputCols</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;id1&quot;</span><span class="p">,</span> <span class="s2">&quot;vec1&quot;</span><span class="p">,</span> <span class="s2">&quot;vec2&quot;</span><span class="p">],</span> <span class="n">outputCol</span><span class="o">=</span><span class="s2">&quot;interactedCol&quot;</span><span class="p">)</span>

<span class="n">interacted</span> <span class="o">=</span> <span class="n">interaction</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">assembled2</span><span class="p">)</span>

<span class="n">interacted</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / python / ml / interaction_example.py”中找到完整的示例代码。</small></div>
  </div>
</div>

<h2 id="normalizer">归一化</h2>

<p><code>Normalizer</code>是一个<code>Transformer</code>转换的数据集<code>Vector</code>行，将每行标准化<code>Vector</code>有单位规范。它需要参数<code>p</code> ，它指定用于归一化的<a href="http://en.wikipedia.org/wiki/Norm_%28mathematics%29#p-norm">p范数</a> 。 （默认情况下，$ p = 2 $。）这种规范化可以帮助您标准化输入数据并改善学习算法的行为。</p>

<p><strong>例子</strong></p>

<p>以下示例演示了如何以libsvm格式加载数据集，然后将每行规范化以具有单位$ L ^ 1 $规范和单位$ L ^ \ infty $规范。</p>

<div class="codetabs">
<div data-lang="scala">

    <p>有关API的更多详细信息，请参阅<a href="api/scala/index.html#org.apache.spark.ml.feature.Normalizer">Normalizer Scala文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">org.apache.spark.ml.feature.Normalizer</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.linalg.Vectors</span>

<span class="k">val</span> <span class="n">dataFrame</span> <span class="k">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="o">(</span><span class="nc">Seq</span><span class="o">(</span>
  <span class="o">(</span><span class="mi">0</span><span class="o">,</span> <span class="nc">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="o">(</span><span class="mf">1.0</span><span class="o">,</span> <span class="mf">0.5</span><span class="o">,</span> <span class="o">-</span><span class="mf">1.0</span><span class="o">)),</span>
  <span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="nc">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="o">(</span><span class="mf">2.0</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">)),</span>
  <span class="o">(</span><span class="mi">2</span><span class="o">,</span> <span class="nc">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="o">(</span><span class="mf">4.0</span><span class="o">,</span> <span class="mf">10.0</span><span class="o">,</span> <span class="mf">2.0</span><span class="o">))</span>
<span class="o">)).</span><span class="n">toDF</span><span class="o">(</span><span class="s">&quot;id&quot;</span><span class="o">,</span> <span class="s">&quot;features&quot;</span><span class="o">)</span>

<span class="c1">// Normalize each Vector using $L^1$ norm.</span>
<span class="k">val</span> <span class="n">normalizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Normalizer</span><span class="o">()</span>
  <span class="o">.</span><span class="n">setInputCol</span><span class="o">(</span><span class="s">&quot;features&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">setOutputCol</span><span class="o">(</span><span class="s">&quot;normFeatures&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">setP</span><span class="o">(</span><span class="mf">1.0</span><span class="o">)</span>

<span class="k">val</span> <span class="n">l1NormData</span> <span class="k">=</span> <span class="n">normalizer</span><span class="o">.</span><span class="n">transform</span><span class="o">(</span><span class="n">dataFrame</span><span class="o">)</span>
<span class="n">println</span><span class="o">(</span><span class="s">&quot;Normalized using L^1 norm&quot;</span><span class="o">)</span>
<span class="n">l1NormData</span><span class="o">.</span><span class="n">show</span><span class="o">()</span>

<span class="c1">// Normalize each Vector using $L^\infty$ norm.</span>
<span class="k">val</span> <span class="n">lInfNormData</span> <span class="k">=</span> <span class="n">normalizer</span><span class="o">.</span><span class="n">transform</span><span class="o">(</span><span class="n">dataFrame</span><span class="o">,</span> <span class="n">normalizer</span><span class="o">.</span><span class="n">p</span> <span class="o">-&gt;</span> <span class="nc">Double</span><span class="o">.</span><span class="nc">PositiveInfinity</span><span class="o">)</span>
<span class="n">println</span><span class="o">(</span><span class="s">&quot;Normalized using L^inf norm&quot;</span><span class="o">)</span>
<span class="n">lInfNormData</span><span class="o">.</span><span class="n">show</span><span class="o">()</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / scala / org / apache / spark / examples / ml / NormalizerExample.scala”中找到完整的示例代码。</small></div>
  </div>

<div data-lang="java">

    <p>有关API的更多详细信息，请参阅<a href="api/java/org/apache/spark/ml/feature/Normalizer.html">Normalizer Java文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">java.util.Arrays</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">java.util.List</span><span class="o">;</span>

<span class="kn">import</span> <span class="nn">org.apache.spark.ml.feature.Normalizer</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.ml.linalg.Vectors</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.ml.linalg.VectorUDT</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.Dataset</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.Row</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.RowFactory</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.DataTypes</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.Metadata</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.StructField</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.StructType</span><span class="o">;</span>

<span class="n">List</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">data</span> <span class="o">=</span> <span class="n">Arrays</span><span class="o">.</span><span class="na">asList</span><span class="o">(</span>
    <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">0</span><span class="o">,</span> <span class="n">Vectors</span><span class="o">.</span><span class="na">dense</span><span class="o">(</span><span class="mf">1.0</span><span class="o">,</span> <span class="mf">0.1</span><span class="o">,</span> <span class="o">-</span><span class="mf">8.0</span><span class="o">)),</span>
    <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="n">Vectors</span><span class="o">.</span><span class="na">dense</span><span class="o">(</span><span class="mf">2.0</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">,</span> <span class="o">-</span><span class="mf">4.0</span><span class="o">)),</span>
    <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">2</span><span class="o">,</span> <span class="n">Vectors</span><span class="o">.</span><span class="na">dense</span><span class="o">(</span><span class="mf">4.0</span><span class="o">,</span> <span class="mf">10.0</span><span class="o">,</span> <span class="mf">8.0</span><span class="o">))</span>
<span class="o">);</span>
<span class="n">StructType</span> <span class="n">schema</span> <span class="o">=</span> <span class="k">new</span> <span class="n">StructType</span><span class="o">(</span><span class="k">new</span> <span class="n">StructField</span><span class="o">[]{</span>
    <span class="k">new</span> <span class="n">StructField</span><span class="o">(</span><span class="s">&quot;id&quot;</span><span class="o">,</span> <span class="n">DataTypes</span><span class="o">.</span><span class="na">IntegerType</span><span class="o">,</span> <span class="kc">false</span><span class="o">,</span> <span class="n">Metadata</span><span class="o">.</span><span class="na">empty</span><span class="o">()),</span>
    <span class="k">new</span> <span class="n">StructField</span><span class="o">(</span><span class="s">&quot;features&quot;</span><span class="o">,</span> <span class="k">new</span> <span class="n">VectorUDT</span><span class="o">(),</span> <span class="kc">false</span><span class="o">,</span> <span class="n">Metadata</span><span class="o">.</span><span class="na">empty</span><span class="o">())</span>
<span class="o">});</span>
<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">dataFrame</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="na">createDataFrame</span><span class="o">(</span><span class="n">data</span><span class="o">,</span> <span class="n">schema</span><span class="o">);</span>

<span class="c1">// Normalize each Vector using $L^1$ norm.</span>
<span class="n">Normalizer</span> <span class="n">normalizer</span> <span class="o">=</span> <span class="k">new</span> <span class="n">Normalizer</span><span class="o">()</span>
  <span class="o">.</span><span class="na">setInputCol</span><span class="o">(</span><span class="s">&quot;features&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">setOutputCol</span><span class="o">(</span><span class="s">&quot;normFeatures&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">setP</span><span class="o">(</span><span class="mf">1.0</span><span class="o">);</span>

<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">l1NormData</span> <span class="o">=</span> <span class="n">normalizer</span><span class="o">.</span><span class="na">transform</span><span class="o">(</span><span class="n">dataFrame</span><span class="o">);</span>
<span class="n">l1NormData</span><span class="o">.</span><span class="na">show</span><span class="o">();</span>

<span class="c1">// Normalize each Vector using $L^\infty$ norm.</span>
<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">lInfNormData</span> <span class="o">=</span>
  <span class="n">normalizer</span><span class="o">.</span><span class="na">transform</span><span class="o">(</span><span class="n">dataFrame</span><span class="o">,</span> <span class="n">normalizer</span><span class="o">.</span><span class="na">p</span><span class="o">().</span><span class="na">w</span><span class="o">(</span><span class="n">Double</span><span class="o">.</span><span class="na">POSITIVE_INFINITY</span><span class="o">));</span>
<span class="n">lInfNormData</span><span class="o">.</span><span class="na">show</span><span class="o">();</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / java / org / apache / spark / examples / ml / JavaNormalizerExample.java”中找到完整的示例代码。</small></div>
  </div>

<div data-lang="python">

    <p>有关API的更多详细信息，请参阅<a href="api/python/pyspark.ml.html#pyspark.ml.feature.Normalizer">Normalizer Python文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pyspark.ml.feature</span> <span class="kn">import</span> <span class="n">Normalizer</span>
<span class="kn">from</span> <span class="nn">pyspark.ml.linalg</span> <span class="kn">import</span> <span class="n">Vectors</span>

<span class="n">dataFrame</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">([</span>
    <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.0</span><span class="p">]),),</span>
    <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="p">([</span><span class="mf">2.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">]),),</span>
    <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="p">([</span><span class="mf">4.0</span><span class="p">,</span> <span class="mf">10.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">]),)</span>
<span class="p">],</span> <span class="p">[</span><span class="s2">&quot;id&quot;</span><span class="p">,</span> <span class="s2">&quot;features&quot;</span><span class="p">])</span>

<span class="c1"># Normalize each Vector using $L^1$ norm.</span>
<span class="n">normalizer</span> <span class="o">=</span> <span class="n">Normalizer</span><span class="p">(</span><span class="n">inputCol</span><span class="o">=</span><span class="s2">&quot;features&quot;</span><span class="p">,</span> <span class="n">outputCol</span><span class="o">=</span><span class="s2">&quot;normFeatures&quot;</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
<span class="n">l1NormData</span> <span class="o">=</span> <span class="n">normalizer</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">dataFrame</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&quot;Normalized using L^1 norm&quot;</span><span class="p">)</span>
<span class="n">l1NormData</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Normalize each Vector using $L^\infty$ norm.</span>
<span class="n">lInfNormData</span> <span class="o">=</span> <span class="n">normalizer</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">dataFrame</span><span class="p">,</span> <span class="p">{</span><span class="n">normalizer</span><span class="o">.</span><span class="n">p</span><span class="p">:</span> <span class="nb">float</span><span class="p">(</span><span class="s2">&quot;inf&quot;</span><span class="p">)})</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&quot;Normalized using L^inf norm&quot;</span><span class="p">)</span>
<span class="n">lInfNormData</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / python / ml / normalizer_example.py”中找到完整的示例代码。</small></div>
  </div>
</div>

<h2 id="standardscaler">标准缩放器</h2>

<p><code>StandardScaler</code>转换的数据集<code>Vector</code>行，将每个特征归一化为具有单位标准偏差和/或零均值。它带有参数：</p>

<ul>
  <li><code>withStd</code> ：默认为True。将数据缩放到单位标准偏差。</li>
  <li><code>withMean</code> ：默认为False。在缩放之前，将数据以均值居中。它将生成密集的输出，因此在应用于稀疏输入时要小心。</li>
</ul>

<p><code>StandardScaler</code>是一个<code>Estimator</code>可以是<code>fit</code>在数据集上产生一个<code>StandardScalerModel</code> ;这相当于计算摘要统计信息。然后，模型可以将<code>Vector</code>数据集中的列具有单位标准偏差和/或零均值特征。</p>

<p>请注意，如果要素的标准偏差为零，它将返回默认值<code>0.0</code>的价值<code>Vector</code>该功能。</p>

<p><strong>例子</strong></p>

<p>以下示例演示了如何以libsvm格式加载数据集，然后将每个功能标准化以具有单位标准差。</p>

<div class="codetabs">
<div data-lang="scala">

    <p>有关API的更多详细信息，请参阅<a href="api/scala/index.html#org.apache.spark.ml.feature.StandardScaler">StandardScaler Scala文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">org.apache.spark.ml.feature.StandardScaler</span>

<span class="k">val</span> <span class="n">dataFrame</span> <span class="k">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">format</span><span class="o">(</span><span class="s">&quot;libsvm&quot;</span><span class="o">).</span><span class="n">load</span><span class="o">(</span><span class="s">&quot;data/mllib/sample_libsvm_data.txt&quot;</span><span class="o">)</span>

<span class="k">val</span> <span class="n">scaler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">StandardScaler</span><span class="o">()</span>
  <span class="o">.</span><span class="n">setInputCol</span><span class="o">(</span><span class="s">&quot;features&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">setOutputCol</span><span class="o">(</span><span class="s">&quot;scaledFeatures&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">setWithStd</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>
  <span class="o">.</span><span class="n">setWithMean</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>

<span class="c1">// Compute summary statistics by fitting the StandardScaler.</span>
<span class="k">val</span> <span class="n">scalerModel</span> <span class="k">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit</span><span class="o">(</span><span class="n">dataFrame</span><span class="o">)</span>

<span class="c1">// Normalize each feature to have unit standard deviation.</span>
<span class="k">val</span> <span class="n">scaledData</span> <span class="k">=</span> <span class="n">scalerModel</span><span class="o">.</span><span class="n">transform</span><span class="o">(</span><span class="n">dataFrame</span><span class="o">)</span>
<span class="n">scaledData</span><span class="o">.</span><span class="n">show</span><span class="o">()</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / scala / org / apache / spark / examples / ml / StandardScalerExample.scala”中找到完整的示例代码。</small></div>
  </div>

<div data-lang="java">

    <p>有关API的更多详细信息，请参阅<a href="api/java/org/apache/spark/ml/feature/StandardScaler.html">StandardScaler Java文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">org.apache.spark.ml.feature.StandardScaler</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.ml.feature.StandardScalerModel</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.Dataset</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.Row</span><span class="o">;</span>

<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">dataFrame</span> <span class="o">=</span>
  <span class="n">spark</span><span class="o">.</span><span class="na">read</span><span class="o">().</span><span class="na">format</span><span class="o">(</span><span class="s">&quot;libsvm&quot;</span><span class="o">).</span><span class="na">load</span><span class="o">(</span><span class="s">&quot;data/mllib/sample_libsvm_data.txt&quot;</span><span class="o">);</span>

<span class="n">StandardScaler</span> <span class="n">scaler</span> <span class="o">=</span> <span class="k">new</span> <span class="n">StandardScaler</span><span class="o">()</span>
  <span class="o">.</span><span class="na">setInputCol</span><span class="o">(</span><span class="s">&quot;features&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">setOutputCol</span><span class="o">(</span><span class="s">&quot;scaledFeatures&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">setWithStd</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>
  <span class="o">.</span><span class="na">setWithMean</span><span class="o">(</span><span class="kc">false</span><span class="o">);</span>

<span class="c1">// Compute summary statistics by fitting the StandardScaler</span>
<span class="n">StandardScalerModel</span> <span class="n">scalerModel</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="na">fit</span><span class="o">(</span><span class="n">dataFrame</span><span class="o">);</span>

<span class="c1">// Normalize each feature to have unit standard deviation.</span>
<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">scaledData</span> <span class="o">=</span> <span class="n">scalerModel</span><span class="o">.</span><span class="na">transform</span><span class="o">(</span><span class="n">dataFrame</span><span class="o">);</span>
<span class="n">scaledData</span><span class="o">.</span><span class="na">show</span><span class="o">();</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / java / org / apache / spark / examples / ml / JavaStandardScalerExample.java”中找到完整的示例代码。</small></div>
  </div>

<div data-lang="python">

    <p>有关API的更多详细信息，请参阅<a href="api/python/pyspark.ml.html#pyspark.ml.feature.StandardScaler">StandardScaler Python文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pyspark.ml.feature</span> <span class="kn">import</span> <span class="n">StandardScaler</span>

<span class="n">dataFrame</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot;libsvm&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;data/mllib/sample_libsvm_data.txt&quot;</span><span class="p">)</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">(</span><span class="n">inputCol</span><span class="o">=</span><span class="s2">&quot;features&quot;</span><span class="p">,</span> <span class="n">outputCol</span><span class="o">=</span><span class="s2">&quot;scaledFeatures&quot;</span><span class="p">,</span>
                        <span class="n">withStd</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">withMean</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

<span class="c1"># Compute summary statistics by fitting the StandardScaler</span>
<span class="n">scalerModel</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">dataFrame</span><span class="p">)</span>

<span class="c1"># Normalize each feature to have unit standard deviation.</span>
<span class="n">scaledData</span> <span class="o">=</span> <span class="n">scalerModel</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">dataFrame</span><span class="p">)</span>
<span class="n">scaledData</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / python / ml / standard_scaler_example.py”中找到完整的示例代码。</small></div>
  </div>
</div>

<h2 id="robustscaler">健壮的洁牙机</h2>

<p><code>RobustScaler</code>转换的数据集<code>Vector</code>行，删除中位数并根据特定的分位数范围（默认情况下为IQR：四分位间距，即第一四分位数和第三四分位数之间的分位数范围）缩放数据。它的行为与<code>StandardScaler</code> ，但是使用中位数和分位数范围代替均值和标准差，这使其对异常值具有鲁棒性。它带有参数：</p>

<ul>
  <li><code>lower</code> ：默认为0.25。降低分位数以计算分位数范围，所有功能均共享。</li>
  <li><code>upper</code> ：默认为0.75。上分位数可计算所有功能共享的分位数范围。</li>
  <li><code>withScaling</code> ：默认为True。将数据缩放到分位数范围。</li>
  <li><code>withCentering</code> ：默认为False。在缩放之前，将数据以中位数居中。它将生成密集的输出，因此在应用于稀疏输入时要小心。</li>
</ul>

<p><code>RobustScaler</code>是一个<code>Estimator</code>可以是<code>fit</code>在数据集上产生一个<code>RobustScalerModel</code> ;这相当于计算分位数统计。然后，模型可以将<code>Vector</code>数据集中的列具有单位分位数范围和/或零中位数特征。</p>

<p>请注意，如果要素的分位数范围为零，它将返回默认值<code>0.0</code>的价值<code>Vector</code>该功能。</p>

<p><strong>例子</strong></p>

<p>以下示例演示了如何以libsvm格式加载数据集，然后将每个功能规范化以具有单位分位数范围。</p>

<div class="codetabs">
<div data-lang="scala">

    <p>有关API的更多详细信息，请参阅<a href="api/scala/index.html#org.apache.spark.ml.feature.RobustScaler">RobustScaler Scala文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">org.apache.spark.ml.feature.RobustScaler</span>

<span class="k">val</span> <span class="n">dataFrame</span> <span class="k">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">format</span><span class="o">(</span><span class="s">&quot;libsvm&quot;</span><span class="o">).</span><span class="n">load</span><span class="o">(</span><span class="s">&quot;data/mllib/sample_libsvm_data.txt&quot;</span><span class="o">)</span>

<span class="k">val</span> <span class="n">scaler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">RobustScaler</span><span class="o">()</span>
  <span class="o">.</span><span class="n">setInputCol</span><span class="o">(</span><span class="s">&quot;features&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">setOutputCol</span><span class="o">(</span><span class="s">&quot;scaledFeatures&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">setWithScaling</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>
  <span class="o">.</span><span class="n">setWithCentering</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
  <span class="o">.</span><span class="n">setLower</span><span class="o">(</span><span class="mf">0.25</span><span class="o">)</span>
  <span class="o">.</span><span class="n">setUpper</span><span class="o">(</span><span class="mf">0.75</span><span class="o">)</span>

<span class="c1">// Compute summary statistics by fitting the RobustScaler.</span>
<span class="k">val</span> <span class="n">scalerModel</span> <span class="k">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit</span><span class="o">(</span><span class="n">dataFrame</span><span class="o">)</span>

<span class="c1">// Transform each feature to have unit quantile range.</span>
<span class="k">val</span> <span class="n">scaledData</span> <span class="k">=</span> <span class="n">scalerModel</span><span class="o">.</span><span class="n">transform</span><span class="o">(</span><span class="n">dataFrame</span><span class="o">)</span>
<span class="n">scaledData</span><span class="o">.</span><span class="n">show</span><span class="o">()</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / scala / org / apache / spark / examples / ml / RobustScalerExample.scala”中找到完整的示例代码。</small></div>
  </div>

<div data-lang="java">

    <p>有关API的更多详细信息，请参阅<a href="api/java/org/apache/spark/ml/feature/RobustScaler.html">RobustScaler Java文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">org.apache.spark.ml.feature.RobustScaler</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.ml.feature.RobustScalerModel</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.Dataset</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.Row</span><span class="o">;</span>

<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">dataFrame</span> <span class="o">=</span>
  <span class="n">spark</span><span class="o">.</span><span class="na">read</span><span class="o">().</span><span class="na">format</span><span class="o">(</span><span class="s">&quot;libsvm&quot;</span><span class="o">).</span><span class="na">load</span><span class="o">(</span><span class="s">&quot;data/mllib/sample_libsvm_data.txt&quot;</span><span class="o">);</span>

<span class="n">RobustScaler</span> <span class="n">scaler</span> <span class="o">=</span> <span class="k">new</span> <span class="n">RobustScaler</span><span class="o">()</span>
  <span class="o">.</span><span class="na">setInputCol</span><span class="o">(</span><span class="s">&quot;features&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">setOutputCol</span><span class="o">(</span><span class="s">&quot;scaledFeatures&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">setWithScaling</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>
  <span class="o">.</span><span class="na">setWithCentering</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
  <span class="o">.</span><span class="na">setLower</span><span class="o">(</span><span class="mf">0.25</span><span class="o">)</span>
  <span class="o">.</span><span class="na">setUpper</span><span class="o">(</span><span class="mf">0.75</span><span class="o">);</span>

<span class="c1">// Compute summary statistics by fitting the RobustScaler</span>
<span class="n">RobustScalerModel</span> <span class="n">scalerModel</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="na">fit</span><span class="o">(</span><span class="n">dataFrame</span><span class="o">);</span>

<span class="c1">// Transform each feature to have unit quantile range.</span>
<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">scaledData</span> <span class="o">=</span> <span class="n">scalerModel</span><span class="o">.</span><span class="na">transform</span><span class="o">(</span><span class="n">dataFrame</span><span class="o">);</span>
<span class="n">scaledData</span><span class="o">.</span><span class="na">show</span><span class="o">();</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / java / org / apache / spark / examples / ml / JavaRobustScalerExample.java”中找到完整的示例代码。</small></div>
  </div>

<div data-lang="python">

    <p>有关API的更多详细信息，请参阅<a href="api/python/pyspark.ml.html#pyspark.ml.feature.RobustScaler">RobustScaler Python文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pyspark.ml.feature</span> <span class="kn">import</span> <span class="n">RobustScaler</span>

<span class="n">dataFrame</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot;libsvm&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;data/mllib/sample_libsvm_data.txt&quot;</span><span class="p">)</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">RobustScaler</span><span class="p">(</span><span class="n">inputCol</span><span class="o">=</span><span class="s2">&quot;features&quot;</span><span class="p">,</span> <span class="n">outputCol</span><span class="o">=</span><span class="s2">&quot;scaledFeatures&quot;</span><span class="p">,</span>
                      <span class="n">withScaling</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">withCentering</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
                      <span class="n">lower</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span> <span class="n">upper</span><span class="o">=</span><span class="mf">0.75</span><span class="p">)</span>

<span class="c1"># Compute summary statistics by fitting the RobustScaler</span>
<span class="n">scalerModel</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">dataFrame</span><span class="p">)</span>

<span class="c1"># Transform each feature to have unit quantile range.</span>
<span class="n">scaledData</span> <span class="o">=</span> <span class="n">scalerModel</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">dataFrame</span><span class="p">)</span>
<span class="n">scaledData</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / python / ml / robust_scaler_example.py”中找到完整的示例代码。</small></div>
  </div>
</div>

<h2 id="minmaxscaler">MinMaxScaler</h2>

<p><code>MinMaxScaler</code>转换的数据集<code>Vector</code>行，将每个要素重新缩放到特定范围（通常为[0，1]）。它带有参数：</p>

<ul>
  <li><code>min</code> ：默认为0.0。转换后的下限，由所有功能共享。</li>
  <li><code>max</code> ：默认为1.0。转换后的上限，由所有功能共享。</li>
</ul>

<p><code>MinMaxScaler</code>计算数据集的摘要统计信息并产生一个<code>MinMaxScalerModel</code> 。然后，模型可以分别变换每个特征，以使其处于给定范围内。</p>

<p>特征E的重新缩放值计算如下： <code>\begin{equation} Rescaled(e_i) = \frac{e_i - E_{min}}{E_{max} - E_{min}} * (max - min) + min \end{equation}</code>对于这种情况<code>$E_{max} == E_{min}$</code> ，<code>$Rescaled(e_i) = 0.5 * (max + min)$</code></p>

<p>请注意，由于零值可能会转换为非零值，因此变压器的输出为<code>DenseVector</code>即使是稀疏输入。</p>

<p><strong>例子</strong></p>

<p>以下示例演示了如何以libsvm格式加载数据集，然后将每个功能重新缩放为[0，1]。</p>

<div class="codetabs">
<div data-lang="scala">

    <p>有关API的更多详细信息，请参考<a href="api/scala/index.html#org.apache.spark.ml.feature.MinMaxScaler">MinMaxScaler Scala文档</a>和<a href="api/scala/index.html#org.apache.spark.ml.feature.MinMaxScalerModel">MinMaxScalerModel Scala文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">org.apache.spark.ml.feature.MinMaxScaler</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.linalg.Vectors</span>

<span class="k">val</span> <span class="n">dataFrame</span> <span class="k">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="o">(</span><span class="nc">Seq</span><span class="o">(</span>
  <span class="o">(</span><span class="mi">0</span><span class="o">,</span> <span class="nc">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="o">(</span><span class="mf">1.0</span><span class="o">,</span> <span class="mf">0.1</span><span class="o">,</span> <span class="o">-</span><span class="mf">1.0</span><span class="o">)),</span>
  <span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="nc">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="o">(</span><span class="mf">2.0</span><span class="o">,</span> <span class="mf">1.1</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">)),</span>
  <span class="o">(</span><span class="mi">2</span><span class="o">,</span> <span class="nc">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="o">(</span><span class="mf">3.0</span><span class="o">,</span> <span class="mf">10.1</span><span class="o">,</span> <span class="mf">3.0</span><span class="o">))</span>
<span class="o">)).</span><span class="n">toDF</span><span class="o">(</span><span class="s">&quot;id&quot;</span><span class="o">,</span> <span class="s">&quot;features&quot;</span><span class="o">)</span>

<span class="k">val</span> <span class="n">scaler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">MinMaxScaler</span><span class="o">()</span>
  <span class="o">.</span><span class="n">setInputCol</span><span class="o">(</span><span class="s">&quot;features&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">setOutputCol</span><span class="o">(</span><span class="s">&quot;scaledFeatures&quot;</span><span class="o">)</span>

<span class="c1">// Compute summary statistics and generate MinMaxScalerModel</span>
<span class="k">val</span> <span class="n">scalerModel</span> <span class="k">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit</span><span class="o">(</span><span class="n">dataFrame</span><span class="o">)</span>

<span class="c1">// rescale each feature to range [min, max].</span>
<span class="k">val</span> <span class="n">scaledData</span> <span class="k">=</span> <span class="n">scalerModel</span><span class="o">.</span><span class="n">transform</span><span class="o">(</span><span class="n">dataFrame</span><span class="o">)</span>
<span class="n">println</span><span class="o">(</span><span class="s">s&quot;Features scaled to range: [</span><span class="si">${</span><span class="n">scaler</span><span class="o">.</span><span class="n">getMin</span><span class="si">}</span><span class="s">, </span><span class="si">${</span><span class="n">scaler</span><span class="o">.</span><span class="n">getMax</span><span class="si">}</span><span class="s">]&quot;</span><span class="o">)</span>
<span class="n">scaledData</span><span class="o">.</span><span class="n">select</span><span class="o">(</span><span class="s">&quot;features&quot;</span><span class="o">,</span> <span class="s">&quot;scaledFeatures&quot;</span><span class="o">).</span><span class="n">show</span><span class="o">()</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / scala / org / apache / spark / examples / ml / MinMaxScalerExample.scala”中找到完整的示例代码。</small></div>
  </div>

<div data-lang="java">

    <p>有关API的更多详细信息，请参考<a href="api/java/org/apache/spark/ml/feature/MinMaxScaler.html">MinMaxScaler Java文档</a>和<a href="api/java/org/apache/spark/ml/feature/MinMaxScalerModel.html">MinMaxScalerModel Java文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">java.util.Arrays</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">java.util.List</span><span class="o">;</span>

<span class="kn">import</span> <span class="nn">org.apache.spark.ml.feature.MinMaxScaler</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.ml.feature.MinMaxScalerModel</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.ml.linalg.Vectors</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.ml.linalg.VectorUDT</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.Dataset</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.Row</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.RowFactory</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.DataTypes</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.Metadata</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.StructField</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.StructType</span><span class="o">;</span>

<span class="n">List</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">data</span> <span class="o">=</span> <span class="n">Arrays</span><span class="o">.</span><span class="na">asList</span><span class="o">(</span>
    <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">0</span><span class="o">,</span> <span class="n">Vectors</span><span class="o">.</span><span class="na">dense</span><span class="o">(</span><span class="mf">1.0</span><span class="o">,</span> <span class="mf">0.1</span><span class="o">,</span> <span class="o">-</span><span class="mf">1.0</span><span class="o">)),</span>
    <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="n">Vectors</span><span class="o">.</span><span class="na">dense</span><span class="o">(</span><span class="mf">2.0</span><span class="o">,</span> <span class="mf">1.1</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">)),</span>
    <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">2</span><span class="o">,</span> <span class="n">Vectors</span><span class="o">.</span><span class="na">dense</span><span class="o">(</span><span class="mf">3.0</span><span class="o">,</span> <span class="mf">10.1</span><span class="o">,</span> <span class="mf">3.0</span><span class="o">))</span>
<span class="o">);</span>
<span class="n">StructType</span> <span class="n">schema</span> <span class="o">=</span> <span class="k">new</span> <span class="n">StructType</span><span class="o">(</span><span class="k">new</span> <span class="n">StructField</span><span class="o">[]{</span>
    <span class="k">new</span> <span class="n">StructField</span><span class="o">(</span><span class="s">&quot;id&quot;</span><span class="o">,</span> <span class="n">DataTypes</span><span class="o">.</span><span class="na">IntegerType</span><span class="o">,</span> <span class="kc">false</span><span class="o">,</span> <span class="n">Metadata</span><span class="o">.</span><span class="na">empty</span><span class="o">()),</span>
    <span class="k">new</span> <span class="n">StructField</span><span class="o">(</span><span class="s">&quot;features&quot;</span><span class="o">,</span> <span class="k">new</span> <span class="n">VectorUDT</span><span class="o">(),</span> <span class="kc">false</span><span class="o">,</span> <span class="n">Metadata</span><span class="o">.</span><span class="na">empty</span><span class="o">())</span>
<span class="o">});</span>
<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">dataFrame</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="na">createDataFrame</span><span class="o">(</span><span class="n">data</span><span class="o">,</span> <span class="n">schema</span><span class="o">);</span>

<span class="n">MinMaxScaler</span> <span class="n">scaler</span> <span class="o">=</span> <span class="k">new</span> <span class="n">MinMaxScaler</span><span class="o">()</span>
  <span class="o">.</span><span class="na">setInputCol</span><span class="o">(</span><span class="s">&quot;features&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">setOutputCol</span><span class="o">(</span><span class="s">&quot;scaledFeatures&quot;</span><span class="o">);</span>

<span class="c1">// Compute summary statistics and generate MinMaxScalerModel</span>
<span class="n">MinMaxScalerModel</span> <span class="n">scalerModel</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="na">fit</span><span class="o">(</span><span class="n">dataFrame</span><span class="o">);</span>

<span class="c1">// rescale each feature to range [min, max].</span>
<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">scaledData</span> <span class="o">=</span> <span class="n">scalerModel</span><span class="o">.</span><span class="na">transform</span><span class="o">(</span><span class="n">dataFrame</span><span class="o">);</span>
<span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">&quot;Features scaled to range: [&quot;</span> <span class="o">+</span> <span class="n">scaler</span><span class="o">.</span><span class="na">getMin</span><span class="o">()</span> <span class="o">+</span> <span class="s">&quot;, &quot;</span>
    <span class="o">+</span> <span class="n">scaler</span><span class="o">.</span><span class="na">getMax</span><span class="o">()</span> <span class="o">+</span> <span class="s">&quot;]&quot;</span><span class="o">);</span>
<span class="n">scaledData</span><span class="o">.</span><span class="na">select</span><span class="o">(</span><span class="s">&quot;features&quot;</span><span class="o">,</span> <span class="s">&quot;scaledFeatures&quot;</span><span class="o">).</span><span class="na">show</span><span class="o">();</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / java / org / apache / spark / examples / ml / JavaMinMaxScalerExample.java”中找到完整的示例代码。</small></div>
  </div>

<div data-lang="python">

    <p>有关API的更多详细信息，请参考<a href="api/python/pyspark.ml.html#pyspark.ml.feature.MinMaxScaler">MinMaxScaler Python文档</a>和<a href="api/python/pyspark.ml.html#pyspark.ml.feature.MinMaxScalerModel">MinMaxScalerModel Python文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pyspark.ml.feature</span> <span class="kn">import</span> <span class="n">MinMaxScaler</span>
<span class="kn">from</span> <span class="nn">pyspark.ml.linalg</span> <span class="kn">import</span> <span class="n">Vectors</span>

<span class="n">dataFrame</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">([</span>
    <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.0</span><span class="p">]),),</span>
    <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="p">([</span><span class="mf">2.0</span><span class="p">,</span> <span class="mf">1.1</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">]),),</span>
    <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="p">([</span><span class="mf">3.0</span><span class="p">,</span> <span class="mf">10.1</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">]),)</span>
<span class="p">],</span> <span class="p">[</span><span class="s2">&quot;id&quot;</span><span class="p">,</span> <span class="s2">&quot;features&quot;</span><span class="p">])</span>

<span class="n">scaler</span> <span class="o">=</span> <span class="n">MinMaxScaler</span><span class="p">(</span><span class="n">inputCol</span><span class="o">=</span><span class="s2">&quot;features&quot;</span><span class="p">,</span> <span class="n">outputCol</span><span class="o">=</span><span class="s2">&quot;scaledFeatures&quot;</span><span class="p">)</span>

<span class="c1"># Compute summary statistics and generate MinMaxScalerModel</span>
<span class="n">scalerModel</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">dataFrame</span><span class="p">)</span>

<span class="c1"># rescale each feature to range [min, max].</span>
<span class="n">scaledData</span> <span class="o">=</span> <span class="n">scalerModel</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">dataFrame</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&quot;Features scaled to range: [</span><span class="si">%f</span><span class="s2">, </span><span class="si">%f</span><span class="s2">]&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">scaler</span><span class="o">.</span><span class="n">getMin</span><span class="p">(),</span> <span class="n">scaler</span><span class="o">.</span><span class="n">getMax</span><span class="p">()))</span>
<span class="n">scaledData</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s2">&quot;features&quot;</span><span class="p">,</span> <span class="s2">&quot;scaledFeatures&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / python / ml / min_max_scaler_example.py”中找到完整的示例代码。</small></div>
  </div>
</div>

<h2 id="maxabsscaler">MaxAbsScaler</h2>

<p><code>MaxAbsScaler</code>转换的数据集<code>Vector</code>行，通过除以每个要素中的最大绝对值，将每个要素重新缩放为[-1，1]范围。它不会移动/居中数据，因此不会破坏任何稀疏性。</p>

<p><code>MaxAbsScaler</code>计算数据集的摘要统计信息并产生一个<code>MaxAbsScalerModel</code> 。然后，模型可以将每个特征分别转换为范围[-1，1]。</p>

<p><strong>例子</strong></p>

<p>下面的示例演示如何以libsvm格式加载数据集，然后将每个功能重新缩放为[-1，1]。</p>

<div class="codetabs">
<div data-lang="scala">

    <p>有关API的更多详细信息，请参考<a href="api/scala/index.html#org.apache.spark.ml.feature.MaxAbsScaler">MaxAbsScaler Scala文档</a>和<a href="api/scala/index.html#org.apache.spark.ml.feature.MaxAbsScalerModel">MaxAbsScalerModel Scala文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">org.apache.spark.ml.feature.MaxAbsScaler</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.linalg.Vectors</span>

<span class="k">val</span> <span class="n">dataFrame</span> <span class="k">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="o">(</span><span class="nc">Seq</span><span class="o">(</span>
  <span class="o">(</span><span class="mi">0</span><span class="o">,</span> <span class="nc">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="o">(</span><span class="mf">1.0</span><span class="o">,</span> <span class="mf">0.1</span><span class="o">,</span> <span class="o">-</span><span class="mf">8.0</span><span class="o">)),</span>
  <span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="nc">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="o">(</span><span class="mf">2.0</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">,</span> <span class="o">-</span><span class="mf">4.0</span><span class="o">)),</span>
  <span class="o">(</span><span class="mi">2</span><span class="o">,</span> <span class="nc">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="o">(</span><span class="mf">4.0</span><span class="o">,</span> <span class="mf">10.0</span><span class="o">,</span> <span class="mf">8.0</span><span class="o">))</span>
<span class="o">)).</span><span class="n">toDF</span><span class="o">(</span><span class="s">&quot;id&quot;</span><span class="o">,</span> <span class="s">&quot;features&quot;</span><span class="o">)</span>

<span class="k">val</span> <span class="n">scaler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">MaxAbsScaler</span><span class="o">()</span>
  <span class="o">.</span><span class="n">setInputCol</span><span class="o">(</span><span class="s">&quot;features&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">setOutputCol</span><span class="o">(</span><span class="s">&quot;scaledFeatures&quot;</span><span class="o">)</span>

<span class="c1">// Compute summary statistics and generate MaxAbsScalerModel</span>
<span class="k">val</span> <span class="n">scalerModel</span> <span class="k">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit</span><span class="o">(</span><span class="n">dataFrame</span><span class="o">)</span>

<span class="c1">// rescale each feature to range [-1, 1]</span>
<span class="k">val</span> <span class="n">scaledData</span> <span class="k">=</span> <span class="n">scalerModel</span><span class="o">.</span><span class="n">transform</span><span class="o">(</span><span class="n">dataFrame</span><span class="o">)</span>
<span class="n">scaledData</span><span class="o">.</span><span class="n">select</span><span class="o">(</span><span class="s">&quot;features&quot;</span><span class="o">,</span> <span class="s">&quot;scaledFeatures&quot;</span><span class="o">).</span><span class="n">show</span><span class="o">()</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / scala / org / apache / spark / examples / ml / MaxAbsScalerExample.scala”中找到完整的示例代码。</small></div>
  </div>

<div data-lang="java">

    <p>有关API的更多详细信息，请参考<a href="api/java/org/apache/spark/ml/feature/MaxAbsScaler.html">MaxAbsScaler Java文档</a>和<a href="api/java/org/apache/spark/ml/feature/MaxAbsScalerModel.html">MaxAbsScalerModel Java文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">java.util.Arrays</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">java.util.List</span><span class="o">;</span>

<span class="kn">import</span> <span class="nn">org.apache.spark.ml.feature.MaxAbsScaler</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.ml.feature.MaxAbsScalerModel</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.ml.linalg.Vectors</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.ml.linalg.VectorUDT</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.Dataset</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.Row</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.RowFactory</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.DataTypes</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.Metadata</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.StructField</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.StructType</span><span class="o">;</span>

<span class="n">List</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">data</span> <span class="o">=</span> <span class="n">Arrays</span><span class="o">.</span><span class="na">asList</span><span class="o">(</span>
    <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">0</span><span class="o">,</span> <span class="n">Vectors</span><span class="o">.</span><span class="na">dense</span><span class="o">(</span><span class="mf">1.0</span><span class="o">,</span> <span class="mf">0.1</span><span class="o">,</span> <span class="o">-</span><span class="mf">8.0</span><span class="o">)),</span>
    <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="n">Vectors</span><span class="o">.</span><span class="na">dense</span><span class="o">(</span><span class="mf">2.0</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">,</span> <span class="o">-</span><span class="mf">4.0</span><span class="o">)),</span>
    <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">2</span><span class="o">,</span> <span class="n">Vectors</span><span class="o">.</span><span class="na">dense</span><span class="o">(</span><span class="mf">4.0</span><span class="o">,</span> <span class="mf">10.0</span><span class="o">,</span> <span class="mf">8.0</span><span class="o">))</span>
<span class="o">);</span>
<span class="n">StructType</span> <span class="n">schema</span> <span class="o">=</span> <span class="k">new</span> <span class="n">StructType</span><span class="o">(</span><span class="k">new</span> <span class="n">StructField</span><span class="o">[]{</span>
    <span class="k">new</span> <span class="n">StructField</span><span class="o">(</span><span class="s">&quot;id&quot;</span><span class="o">,</span> <span class="n">DataTypes</span><span class="o">.</span><span class="na">IntegerType</span><span class="o">,</span> <span class="kc">false</span><span class="o">,</span> <span class="n">Metadata</span><span class="o">.</span><span class="na">empty</span><span class="o">()),</span>
    <span class="k">new</span> <span class="n">StructField</span><span class="o">(</span><span class="s">&quot;features&quot;</span><span class="o">,</span> <span class="k">new</span> <span class="n">VectorUDT</span><span class="o">(),</span> <span class="kc">false</span><span class="o">,</span> <span class="n">Metadata</span><span class="o">.</span><span class="na">empty</span><span class="o">())</span>
<span class="o">});</span>
<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">dataFrame</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="na">createDataFrame</span><span class="o">(</span><span class="n">data</span><span class="o">,</span> <span class="n">schema</span><span class="o">);</span>

<span class="n">MaxAbsScaler</span> <span class="n">scaler</span> <span class="o">=</span> <span class="k">new</span> <span class="n">MaxAbsScaler</span><span class="o">()</span>
  <span class="o">.</span><span class="na">setInputCol</span><span class="o">(</span><span class="s">&quot;features&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">setOutputCol</span><span class="o">(</span><span class="s">&quot;scaledFeatures&quot;</span><span class="o">);</span>

<span class="c1">// Compute summary statistics and generate MaxAbsScalerModel</span>
<span class="n">MaxAbsScalerModel</span> <span class="n">scalerModel</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="na">fit</span><span class="o">(</span><span class="n">dataFrame</span><span class="o">);</span>

<span class="c1">// rescale each feature to range [-1, 1].</span>
<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">scaledData</span> <span class="o">=</span> <span class="n">scalerModel</span><span class="o">.</span><span class="na">transform</span><span class="o">(</span><span class="n">dataFrame</span><span class="o">);</span>
<span class="n">scaledData</span><span class="o">.</span><span class="na">select</span><span class="o">(</span><span class="s">&quot;features&quot;</span><span class="o">,</span> <span class="s">&quot;scaledFeatures&quot;</span><span class="o">).</span><span class="na">show</span><span class="o">();</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / java / org / apache / spark / examples / ml / JavaMaxAbsScalerExample.java”中找到完整的示例代码。</small></div>
  </div>

<div data-lang="python">

    <p>有关API的更多详细信息，请参考<a href="api/python/pyspark.ml.html#pyspark.ml.feature.MaxAbsScaler">MaxAbsScaler Python文档</a>和<a href="api/python/pyspark.ml.html#pyspark.ml.feature.MaxAbsScalerModel">MaxAbsScalerModel Python文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pyspark.ml.feature</span> <span class="kn">import</span> <span class="n">MaxAbsScaler</span>
<span class="kn">from</span> <span class="nn">pyspark.ml.linalg</span> <span class="kn">import</span> <span class="n">Vectors</span>

<span class="n">dataFrame</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">([</span>
    <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="o">-</span><span class="mf">8.0</span><span class="p">]),),</span>
    <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="p">([</span><span class="mf">2.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="o">-</span><span class="mf">4.0</span><span class="p">]),),</span>
    <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="p">([</span><span class="mf">4.0</span><span class="p">,</span> <span class="mf">10.0</span><span class="p">,</span> <span class="mf">8.0</span><span class="p">]),)</span>
<span class="p">],</span> <span class="p">[</span><span class="s2">&quot;id&quot;</span><span class="p">,</span> <span class="s2">&quot;features&quot;</span><span class="p">])</span>

<span class="n">scaler</span> <span class="o">=</span> <span class="n">MaxAbsScaler</span><span class="p">(</span><span class="n">inputCol</span><span class="o">=</span><span class="s2">&quot;features&quot;</span><span class="p">,</span> <span class="n">outputCol</span><span class="o">=</span><span class="s2">&quot;scaledFeatures&quot;</span><span class="p">)</span>

<span class="c1"># Compute summary statistics and generate MaxAbsScalerModel</span>
<span class="n">scalerModel</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">dataFrame</span><span class="p">)</span>

<span class="c1"># rescale each feature to range [-1, 1].</span>
<span class="n">scaledData</span> <span class="o">=</span> <span class="n">scalerModel</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">dataFrame</span><span class="p">)</span>

<span class="n">scaledData</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s2">&quot;features&quot;</span><span class="p">,</span> <span class="s2">&quot;scaledFeatures&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / python / ml / max_abs_scaler_example.py”中找到完整的示例代码。</small></div>
  </div>
</div>

<h2 id="bucketizer">铲斗机</h2>

<p><code>Bucketizer</code>将一列连续要素转换为一列要素存储桶，其中存储桶由用户指定。它带有一个参数：</p>

<ul>
  <li><code>splits</code> ：用于将连续要素映射到存储桶的参数。使用n + 1个拆分，有n个存储桶。拆分x，y定义的存储桶除最后一个存储桶（也包括y）外，其值都在[x，y）范围内。分割数应严格增加。必须明确提供-inf，inf的值以覆盖所有Double值；否则，超出指定分割的值将被视为错误。两个例子<code>splits</code>是<code>Array(Double.NegativeInfinity, 0.0, 1.0, Double.PositiveInfinity)</code>和<code>Array(0.0, 1.0, 2.0)</code> 。</li>
</ul>

<p>请注意，如果您不了解目标列的上限和下限，则应添加<code>Double.NegativeInfinity</code>和<code>Double.PositiveInfinity</code>作为分割的边界，以防止可能超出Bucketizer边界异常。</p>

<p>还请注意，您提供的拆分必须严格按升序排列，即<code>s0 < s1 < s2 < ... < sn</code> 。</p>

<p>可以在<a href="api/scala/index.html#org.apache.spark.ml.feature.Bucketizer">Bucketizer</a>的API文档中找到更多详细信息。</p>

<p><strong>例子</strong></p>

<p>以下示例演示了如何对<code>Double</code>放入另一个索引导向的列。</p>

<div class="codetabs">
<div data-lang="scala">

    <p>有关API的更多详细信息，请参考<a href="api/scala/index.html#org.apache.spark.ml.feature.Bucketizer">Bucketizer Scala文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">org.apache.spark.ml.feature.Bucketizer</span>

<span class="k">val</span> <span class="n">splits</span> <span class="k">=</span> <span class="nc">Array</span><span class="o">(</span><span class="nc">Double</span><span class="o">.</span><span class="nc">NegativeInfinity</span><span class="o">,</span> <span class="o">-</span><span class="mf">0.5</span><span class="o">,</span> <span class="mf">0.0</span><span class="o">,</span> <span class="mf">0.5</span><span class="o">,</span> <span class="nc">Double</span><span class="o">.</span><span class="nc">PositiveInfinity</span><span class="o">)</span>

<span class="k">val</span> <span class="n">data</span> <span class="k">=</span> <span class="nc">Array</span><span class="o">(-</span><span class="mf">999.9</span><span class="o">,</span> <span class="o">-</span><span class="mf">0.5</span><span class="o">,</span> <span class="o">-</span><span class="mf">0.3</span><span class="o">,</span> <span class="mf">0.0</span><span class="o">,</span> <span class="mf">0.2</span><span class="o">,</span> <span class="mf">999.9</span><span class="o">)</span>
<span class="k">val</span> <span class="n">dataFrame</span> <span class="k">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="o">(</span><span class="n">data</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="nc">Tuple1</span><span class="o">.</span><span class="n">apply</span><span class="o">)).</span><span class="n">toDF</span><span class="o">(</span><span class="s">&quot;features&quot;</span><span class="o">)</span>

<span class="k">val</span> <span class="n">bucketizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Bucketizer</span><span class="o">()</span>
  <span class="o">.</span><span class="n">setInputCol</span><span class="o">(</span><span class="s">&quot;features&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">setOutputCol</span><span class="o">(</span><span class="s">&quot;bucketedFeatures&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">setSplits</span><span class="o">(</span><span class="n">splits</span><span class="o">)</span>

<span class="c1">// Transform original data into its bucket index.</span>
<span class="k">val</span> <span class="n">bucketedData</span> <span class="k">=</span> <span class="n">bucketizer</span><span class="o">.</span><span class="n">transform</span><span class="o">(</span><span class="n">dataFrame</span><span class="o">)</span>

<span class="n">println</span><span class="o">(</span><span class="s">s&quot;Bucketizer output with </span><span class="si">${</span><span class="n">bucketizer</span><span class="o">.</span><span class="n">getSplits</span><span class="o">.</span><span class="n">length</span><span class="o">-</span><span class="mi">1</span><span class="si">}</span><span class="s"> buckets&quot;</span><span class="o">)</span>
<span class="n">bucketedData</span><span class="o">.</span><span class="n">show</span><span class="o">()</span>

<span class="k">val</span> <span class="n">splitsArray</span> <span class="k">=</span> <span class="nc">Array</span><span class="o">(</span>
  <span class="nc">Array</span><span class="o">(</span><span class="nc">Double</span><span class="o">.</span><span class="nc">NegativeInfinity</span><span class="o">,</span> <span class="o">-</span><span class="mf">0.5</span><span class="o">,</span> <span class="mf">0.0</span><span class="o">,</span> <span class="mf">0.5</span><span class="o">,</span> <span class="nc">Double</span><span class="o">.</span><span class="nc">PositiveInfinity</span><span class="o">),</span>
  <span class="nc">Array</span><span class="o">(</span><span class="nc">Double</span><span class="o">.</span><span class="nc">NegativeInfinity</span><span class="o">,</span> <span class="o">-</span><span class="mf">0.3</span><span class="o">,</span> <span class="mf">0.0</span><span class="o">,</span> <span class="mf">0.3</span><span class="o">,</span> <span class="nc">Double</span><span class="o">.</span><span class="nc">PositiveInfinity</span><span class="o">))</span>

<span class="k">val</span> <span class="n">data2</span> <span class="k">=</span> <span class="nc">Array</span><span class="o">(</span>
  <span class="o">(-</span><span class="mf">999.9</span><span class="o">,</span> <span class="o">-</span><span class="mf">999.9</span><span class="o">),</span>
  <span class="o">(-</span><span class="mf">0.5</span><span class="o">,</span> <span class="o">-</span><span class="mf">0.2</span><span class="o">),</span>
  <span class="o">(-</span><span class="mf">0.3</span><span class="o">,</span> <span class="o">-</span><span class="mf">0.1</span><span class="o">),</span>
  <span class="o">(</span><span class="mf">0.0</span><span class="o">,</span> <span class="mf">0.0</span><span class="o">),</span>
  <span class="o">(</span><span class="mf">0.2</span><span class="o">,</span> <span class="mf">0.4</span><span class="o">),</span>
  <span class="o">(</span><span class="mf">999.9</span><span class="o">,</span> <span class="mf">999.9</span><span class="o">))</span>
<span class="k">val</span> <span class="n">dataFrame2</span> <span class="k">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="o">(</span><span class="n">data2</span><span class="o">).</span><span class="n">toDF</span><span class="o">(</span><span class="s">&quot;features1&quot;</span><span class="o">,</span> <span class="s">&quot;features2&quot;</span><span class="o">)</span>

<span class="k">val</span> <span class="n">bucketizer2</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Bucketizer</span><span class="o">()</span>
  <span class="o">.</span><span class="n">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">&quot;features1&quot;</span><span class="o">,</span> <span class="s">&quot;features2&quot;</span><span class="o">))</span>
  <span class="o">.</span><span class="n">setOutputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">&quot;bucketedFeatures1&quot;</span><span class="o">,</span> <span class="s">&quot;bucketedFeatures2&quot;</span><span class="o">))</span>
  <span class="o">.</span><span class="n">setSplitsArray</span><span class="o">(</span><span class="n">splitsArray</span><span class="o">)</span>

<span class="c1">// Transform original data into its bucket index.</span>
<span class="k">val</span> <span class="n">bucketedData2</span> <span class="k">=</span> <span class="n">bucketizer2</span><span class="o">.</span><span class="n">transform</span><span class="o">(</span><span class="n">dataFrame2</span><span class="o">)</span>

<span class="n">println</span><span class="o">(</span><span class="s">s&quot;Bucketizer output with [&quot;</span> <span class="o">+</span>
  <span class="s">s&quot;</span><span class="si">${</span><span class="n">bucketizer2</span><span class="o">.</span><span class="n">getSplitsArray</span><span class="o">(</span><span class="mi">0</span><span class="o">).</span><span class="n">length</span><span class="o">-</span><span class="mi">1</span><span class="si">}</span><span class="s">, &quot;</span> <span class="o">+</span>
  <span class="s">s&quot;</span><span class="si">${</span><span class="n">bucketizer2</span><span class="o">.</span><span class="n">getSplitsArray</span><span class="o">(</span><span class="mi">1</span><span class="o">).</span><span class="n">length</span><span class="o">-</span><span class="mi">1</span><span class="si">}</span><span class="s">] buckets for each input column&quot;</span><span class="o">)</span>
<span class="n">bucketedData2</span><span class="o">.</span><span class="n">show</span><span class="o">()</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / scala / org / apache / spark / examples / ml / BucketizerExample.scala”中找到完整的示例代码。</small></div>
  </div>

<div data-lang="java">

    <p>有关API的更多详细信息，请参阅<a href="api/java/org/apache/spark/ml/feature/Bucketizer.html">Bucketizer Java文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">java.util.Arrays</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">java.util.List</span><span class="o">;</span>

<span class="kn">import</span> <span class="nn">org.apache.spark.ml.feature.Bucketizer</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.Dataset</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.Row</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.RowFactory</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.DataTypes</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.Metadata</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.StructField</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.StructType</span><span class="o">;</span>

<span class="kt">double</span><span class="o">[]</span> <span class="n">splits</span> <span class="o">=</span> <span class="o">{</span><span class="n">Double</span><span class="o">.</span><span class="na">NEGATIVE_INFINITY</span><span class="o">,</span> <span class="o">-</span><span class="mf">0.5</span><span class="o">,</span> <span class="mf">0.0</span><span class="o">,</span> <span class="mf">0.5</span><span class="o">,</span> <span class="n">Double</span><span class="o">.</span><span class="na">POSITIVE_INFINITY</span><span class="o">};</span>

<span class="n">List</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">data</span> <span class="o">=</span> <span class="n">Arrays</span><span class="o">.</span><span class="na">asList</span><span class="o">(</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(-</span><span class="mf">999.9</span><span class="o">),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(-</span><span class="mf">0.5</span><span class="o">),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(-</span><span class="mf">0.3</span><span class="o">),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mf">0.0</span><span class="o">),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mf">0.2</span><span class="o">),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mf">999.9</span><span class="o">)</span>
<span class="o">);</span>
<span class="n">StructType</span> <span class="n">schema</span> <span class="o">=</span> <span class="k">new</span> <span class="n">StructType</span><span class="o">(</span><span class="k">new</span> <span class="n">StructField</span><span class="o">[]{</span>
  <span class="k">new</span> <span class="n">StructField</span><span class="o">(</span><span class="s">&quot;features&quot;</span><span class="o">,</span> <span class="n">DataTypes</span><span class="o">.</span><span class="na">DoubleType</span><span class="o">,</span> <span class="kc">false</span><span class="o">,</span> <span class="n">Metadata</span><span class="o">.</span><span class="na">empty</span><span class="o">())</span>
<span class="o">});</span>
<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">dataFrame</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="na">createDataFrame</span><span class="o">(</span><span class="n">data</span><span class="o">,</span> <span class="n">schema</span><span class="o">);</span>

<span class="n">Bucketizer</span> <span class="n">bucketizer</span> <span class="o">=</span> <span class="k">new</span> <span class="n">Bucketizer</span><span class="o">()</span>
  <span class="o">.</span><span class="na">setInputCol</span><span class="o">(</span><span class="s">&quot;features&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">setOutputCol</span><span class="o">(</span><span class="s">&quot;bucketedFeatures&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">setSplits</span><span class="o">(</span><span class="n">splits</span><span class="o">);</span>

<span class="c1">// Transform original data into its bucket index.</span>
<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">bucketedData</span> <span class="o">=</span> <span class="n">bucketizer</span><span class="o">.</span><span class="na">transform</span><span class="o">(</span><span class="n">dataFrame</span><span class="o">);</span>

<span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">&quot;Bucketizer output with &quot;</span> <span class="o">+</span> <span class="o">(</span><span class="n">bucketizer</span><span class="o">.</span><span class="na">getSplits</span><span class="o">().</span><span class="na">length</span><span class="o">-</span><span class="mi">1</span><span class="o">)</span> <span class="o">+</span> <span class="s">&quot; buckets&quot;</span><span class="o">);</span>
<span class="n">bucketedData</span><span class="o">.</span><span class="na">show</span><span class="o">();</span>

<span class="c1">// Bucketize multiple columns at one pass.</span>
<span class="kt">double</span><span class="o">[][]</span> <span class="n">splitsArray</span> <span class="o">=</span> <span class="o">{</span>
  <span class="o">{</span><span class="n">Double</span><span class="o">.</span><span class="na">NEGATIVE_INFINITY</span><span class="o">,</span> <span class="o">-</span><span class="mf">0.5</span><span class="o">,</span> <span class="mf">0.0</span><span class="o">,</span> <span class="mf">0.5</span><span class="o">,</span> <span class="n">Double</span><span class="o">.</span><span class="na">POSITIVE_INFINITY</span><span class="o">},</span>
  <span class="o">{</span><span class="n">Double</span><span class="o">.</span><span class="na">NEGATIVE_INFINITY</span><span class="o">,</span> <span class="o">-</span><span class="mf">0.3</span><span class="o">,</span> <span class="mf">0.0</span><span class="o">,</span> <span class="mf">0.3</span><span class="o">,</span> <span class="n">Double</span><span class="o">.</span><span class="na">POSITIVE_INFINITY</span><span class="o">}</span>
<span class="o">};</span>

<span class="n">List</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">data2</span> <span class="o">=</span> <span class="n">Arrays</span><span class="o">.</span><span class="na">asList</span><span class="o">(</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(-</span><span class="mf">999.9</span><span class="o">,</span> <span class="o">-</span><span class="mf">999.9</span><span class="o">),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(-</span><span class="mf">0.5</span><span class="o">,</span> <span class="o">-</span><span class="mf">0.2</span><span class="o">),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(-</span><span class="mf">0.3</span><span class="o">,</span> <span class="o">-</span><span class="mf">0.1</span><span class="o">),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mf">0.0</span><span class="o">,</span> <span class="mf">0.0</span><span class="o">),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mf">0.2</span><span class="o">,</span> <span class="mf">0.4</span><span class="o">),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mf">999.9</span><span class="o">,</span> <span class="mf">999.9</span><span class="o">)</span>
<span class="o">);</span>
<span class="n">StructType</span> <span class="n">schema2</span> <span class="o">=</span> <span class="k">new</span> <span class="n">StructType</span><span class="o">(</span><span class="k">new</span> <span class="n">StructField</span><span class="o">[]{</span>
  <span class="k">new</span> <span class="n">StructField</span><span class="o">(</span><span class="s">&quot;features1&quot;</span><span class="o">,</span> <span class="n">DataTypes</span><span class="o">.</span><span class="na">DoubleType</span><span class="o">,</span> <span class="kc">false</span><span class="o">,</span> <span class="n">Metadata</span><span class="o">.</span><span class="na">empty</span><span class="o">()),</span>
  <span class="k">new</span> <span class="n">StructField</span><span class="o">(</span><span class="s">&quot;features2&quot;</span><span class="o">,</span> <span class="n">DataTypes</span><span class="o">.</span><span class="na">DoubleType</span><span class="o">,</span> <span class="kc">false</span><span class="o">,</span> <span class="n">Metadata</span><span class="o">.</span><span class="na">empty</span><span class="o">())</span>
<span class="o">});</span>
<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">dataFrame2</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="na">createDataFrame</span><span class="o">(</span><span class="n">data2</span><span class="o">,</span> <span class="n">schema2</span><span class="o">);</span>

<span class="n">Bucketizer</span> <span class="n">bucketizer2</span> <span class="o">=</span> <span class="k">new</span> <span class="n">Bucketizer</span><span class="o">()</span>
  <span class="o">.</span><span class="na">setInputCols</span><span class="o">(</span><span class="k">new</span> <span class="n">String</span><span class="o">[]</span> <span class="o">{</span><span class="s">&quot;features1&quot;</span><span class="o">,</span> <span class="s">&quot;features2&quot;</span><span class="o">})</span>
  <span class="o">.</span><span class="na">setOutputCols</span><span class="o">(</span><span class="k">new</span> <span class="n">String</span><span class="o">[]</span> <span class="o">{</span><span class="s">&quot;bucketedFeatures1&quot;</span><span class="o">,</span> <span class="s">&quot;bucketedFeatures2&quot;</span><span class="o">})</span>
  <span class="o">.</span><span class="na">setSplitsArray</span><span class="o">(</span><span class="n">splitsArray</span><span class="o">);</span>
<span class="c1">// Transform original data into its bucket index.</span>
<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">bucketedData2</span> <span class="o">=</span> <span class="n">bucketizer2</span><span class="o">.</span><span class="na">transform</span><span class="o">(</span><span class="n">dataFrame2</span><span class="o">);</span>

<span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">&quot;Bucketizer output with [&quot;</span> <span class="o">+</span>
  <span class="o">(</span><span class="n">bucketizer2</span><span class="o">.</span><span class="na">getSplitsArray</span><span class="o">()[</span><span class="mi">0</span><span class="o">].</span><span class="na">length</span><span class="o">-</span><span class="mi">1</span><span class="o">)</span> <span class="o">+</span> <span class="s">&quot;, &quot;</span> <span class="o">+</span>
  <span class="o">(</span><span class="n">bucketizer2</span><span class="o">.</span><span class="na">getSplitsArray</span><span class="o">()[</span><span class="mi">1</span><span class="o">].</span><span class="na">length</span><span class="o">-</span><span class="mi">1</span><span class="o">)</span> <span class="o">+</span> <span class="s">&quot;] buckets for each input column&quot;</span><span class="o">);</span>
<span class="n">bucketedData2</span><span class="o">.</span><span class="na">show</span><span class="o">();</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / java / org / apache / spark / examples / ml / JavaBucketizerExample.java”中找到完整的示例代码。</small></div>
  </div>

<div data-lang="python">

    <p>有关API的更多详细信息，请参见<a href="api/python/pyspark.ml.html#pyspark.ml.feature.Bucketizer">Bucketizer Python文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pyspark.ml.feature</span> <span class="kn">import</span> <span class="n">Bucketizer</span>

<span class="n">splits</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="nb">float</span><span class="p">(</span><span class="s2">&quot;inf&quot;</span><span class="p">),</span> <span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="nb">float</span><span class="p">(</span><span class="s2">&quot;inf&quot;</span><span class="p">)]</span>

<span class="n">data</span> <span class="o">=</span> <span class="p">[(</span><span class="o">-</span><span class="mf">999.9</span><span class="p">,),</span> <span class="p">(</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,),</span> <span class="p">(</span><span class="o">-</span><span class="mf">0.3</span><span class="p">,),</span> <span class="p">(</span><span class="mf">0.0</span><span class="p">,),</span> <span class="p">(</span><span class="mf">0.2</span><span class="p">,),</span> <span class="p">(</span><span class="mf">999.9</span><span class="p">,)]</span>
<span class="n">dataFrame</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;features&quot;</span><span class="p">])</span>

<span class="n">bucketizer</span> <span class="o">=</span> <span class="n">Bucketizer</span><span class="p">(</span><span class="n">splits</span><span class="o">=</span><span class="n">splits</span><span class="p">,</span> <span class="n">inputCol</span><span class="o">=</span><span class="s2">&quot;features&quot;</span><span class="p">,</span> <span class="n">outputCol</span><span class="o">=</span><span class="s2">&quot;bucketedFeatures&quot;</span><span class="p">)</span>

<span class="c1"># Transform original data into its bucket index.</span>
<span class="n">bucketedData</span> <span class="o">=</span> <span class="n">bucketizer</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">dataFrame</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s2">&quot;Bucketizer output with </span><span class="si">%d</span><span class="s2"> buckets&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">bucketizer</span><span class="o">.</span><span class="n">getSplits</span><span class="p">())</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
<span class="n">bucketedData</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / python / ml / bucketizer_example.py”中找到完整的示例代码。</small></div>
  </div>
</div>

<h2 id="elementwiseproduct">Elementwise产品</h2>

<p>ElementwiseProduct使用逐元素乘法将每个输入向量乘以提供的“权重”向量。换句话说，它通过标量乘法器缩放数据集的每一列。这表示输入向量之间的<a href="https://en.wikipedia.org/wiki/Hadamard_product_%28matrices%29">Hadamard乘积</a> ， <code>v</code>和转换向量<code>w</code> ，以产生结果向量。</p>

<p><code>\[ \begin{pmatrix} v_1 \\ \vdots \\ v_N \end{pmatrix} \circ \begin{pmatrix} w_1 \\ \vdots \\ w_N \end{pmatrix} = \begin{pmatrix} v_1 w_1 \\ \vdots \\ v_N w_N \end{pmatrix} \]</code></p>

<p><strong>例子</strong></p>

<p>下面的示例演示了如何使用转换向量值转换向量。</p>

<div class="codetabs">
<div data-lang="scala">

    <p>有关API的更多详细信息，请参阅<a href="api/scala/index.html#org.apache.spark.ml.feature.ElementwiseProduct">ElementwiseProduct Scala文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">org.apache.spark.ml.feature.ElementwiseProduct</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.linalg.Vectors</span>

<span class="c1">// Create some vector data; also works for sparse vectors</span>
<span class="k">val</span> <span class="n">dataFrame</span> <span class="k">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="o">(</span><span class="nc">Seq</span><span class="o">(</span>
  <span class="o">(</span><span class="s">&quot;a&quot;</span><span class="o">,</span> <span class="nc">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="o">(</span><span class="mf">1.0</span><span class="o">,</span> <span class="mf">2.0</span><span class="o">,</span> <span class="mf">3.0</span><span class="o">)),</span>
  <span class="o">(</span><span class="s">&quot;b&quot;</span><span class="o">,</span> <span class="nc">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="o">(</span><span class="mf">4.0</span><span class="o">,</span> <span class="mf">5.0</span><span class="o">,</span> <span class="mf">6.0</span><span class="o">)))).</span><span class="n">toDF</span><span class="o">(</span><span class="s">&quot;id&quot;</span><span class="o">,</span> <span class="s">&quot;vector&quot;</span><span class="o">)</span>

<span class="k">val</span> <span class="n">transformingVector</span> <span class="k">=</span> <span class="nc">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="o">(</span><span class="mf">0.0</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">,</span> <span class="mf">2.0</span><span class="o">)</span>
<span class="k">val</span> <span class="n">transformer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">ElementwiseProduct</span><span class="o">()</span>
  <span class="o">.</span><span class="n">setScalingVec</span><span class="o">(</span><span class="n">transformingVector</span><span class="o">)</span>
  <span class="o">.</span><span class="n">setInputCol</span><span class="o">(</span><span class="s">&quot;vector&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">setOutputCol</span><span class="o">(</span><span class="s">&quot;transformedVector&quot;</span><span class="o">)</span>

<span class="c1">// Batch transform the vectors to create new column:</span>
<span class="n">transformer</span><span class="o">.</span><span class="n">transform</span><span class="o">(</span><span class="n">dataFrame</span><span class="o">).</span><span class="n">show</span><span class="o">()</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / scala / org / apache / spark / examples / ml / ElementwiseProductExample.scala”中找到完整的示例代码。</small></div>
  </div>

<div data-lang="java">

    <p>有关API的更多详细信息，请参阅<a href="api/java/org/apache/spark/ml/feature/ElementwiseProduct.html">ElementwiseProduct Java文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">java.util.ArrayList</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">java.util.Arrays</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">java.util.List</span><span class="o">;</span>

<span class="kn">import</span> <span class="nn">org.apache.spark.ml.feature.ElementwiseProduct</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.ml.linalg.Vector</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.ml.linalg.VectorUDT</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.ml.linalg.Vectors</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.Row</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.RowFactory</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.DataTypes</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.StructField</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.StructType</span><span class="o">;</span>

<span class="c1">// Create some vector data; also works for sparse vectors</span>
<span class="n">List</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">data</span> <span class="o">=</span> <span class="n">Arrays</span><span class="o">.</span><span class="na">asList</span><span class="o">(</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="s">&quot;a&quot;</span><span class="o">,</span> <span class="n">Vectors</span><span class="o">.</span><span class="na">dense</span><span class="o">(</span><span class="mf">1.0</span><span class="o">,</span> <span class="mf">2.0</span><span class="o">,</span> <span class="mf">3.0</span><span class="o">)),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="s">&quot;b&quot;</span><span class="o">,</span> <span class="n">Vectors</span><span class="o">.</span><span class="na">dense</span><span class="o">(</span><span class="mf">4.0</span><span class="o">,</span> <span class="mf">5.0</span><span class="o">,</span> <span class="mf">6.0</span><span class="o">))</span>
<span class="o">);</span>

<span class="n">List</span><span class="o">&lt;</span><span class="n">StructField</span><span class="o">&gt;</span> <span class="n">fields</span> <span class="o">=</span> <span class="k">new</span> <span class="n">ArrayList</span><span class="o">&lt;&gt;(</span><span class="mi">2</span><span class="o">);</span>
<span class="n">fields</span><span class="o">.</span><span class="na">add</span><span class="o">(</span><span class="n">DataTypes</span><span class="o">.</span><span class="na">createStructField</span><span class="o">(</span><span class="s">&quot;id&quot;</span><span class="o">,</span> <span class="n">DataTypes</span><span class="o">.</span><span class="na">StringType</span><span class="o">,</span> <span class="kc">false</span><span class="o">));</span>
<span class="n">fields</span><span class="o">.</span><span class="na">add</span><span class="o">(</span><span class="n">DataTypes</span><span class="o">.</span><span class="na">createStructField</span><span class="o">(</span><span class="s">&quot;vector&quot;</span><span class="o">,</span> <span class="k">new</span> <span class="n">VectorUDT</span><span class="o">(),</span> <span class="kc">false</span><span class="o">));</span>

<span class="n">StructType</span> <span class="n">schema</span> <span class="o">=</span> <span class="n">DataTypes</span><span class="o">.</span><span class="na">createStructType</span><span class="o">(</span><span class="n">fields</span><span class="o">);</span>

<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">dataFrame</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="na">createDataFrame</span><span class="o">(</span><span class="n">data</span><span class="o">,</span> <span class="n">schema</span><span class="o">);</span>

<span class="n">Vector</span> <span class="n">transformingVector</span> <span class="o">=</span> <span class="n">Vectors</span><span class="o">.</span><span class="na">dense</span><span class="o">(</span><span class="mf">0.0</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">,</span> <span class="mf">2.0</span><span class="o">);</span>

<span class="n">ElementwiseProduct</span> <span class="n">transformer</span> <span class="o">=</span> <span class="k">new</span> <span class="n">ElementwiseProduct</span><span class="o">()</span>
  <span class="o">.</span><span class="na">setScalingVec</span><span class="o">(</span><span class="n">transformingVector</span><span class="o">)</span>
  <span class="o">.</span><span class="na">setInputCol</span><span class="o">(</span><span class="s">&quot;vector&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">setOutputCol</span><span class="o">(</span><span class="s">&quot;transformedVector&quot;</span><span class="o">);</span>

<span class="c1">// Batch transform the vectors to create new column:</span>
<span class="n">transformer</span><span class="o">.</span><span class="na">transform</span><span class="o">(</span><span class="n">dataFrame</span><span class="o">).</span><span class="na">show</span><span class="o">();</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / java / org / apache / spark / examples / ml / JavaElementwiseProductExample.java”中找到完整的示例代码。</small></div>
  </div>

<div data-lang="python">

    <p>有关API的更多详细信息，请参阅<a href="api/python/pyspark.ml.html#pyspark.ml.feature.ElementwiseProduct">ElementwiseProduct Python文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pyspark.ml.feature</span> <span class="kn">import</span> <span class="n">ElementwiseProduct</span>
<span class="kn">from</span> <span class="nn">pyspark.ml.linalg</span> <span class="kn">import</span> <span class="n">Vectors</span>

<span class="c1"># Create some vector data; also works for sparse vectors</span>
<span class="n">data</span> <span class="o">=</span> <span class="p">[(</span><span class="n">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">]),),</span> <span class="p">(</span><span class="n">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="p">([</span><span class="mf">4.0</span><span class="p">,</span> <span class="mf">5.0</span><span class="p">,</span> <span class="mf">6.0</span><span class="p">]),)]</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;vector&quot;</span><span class="p">])</span>
<span class="n">transformer</span> <span class="o">=</span> <span class="n">ElementwiseProduct</span><span class="p">(</span><span class="n">scalingVec</span><span class="o">=</span><span class="n">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">]),</span>
                                 <span class="n">inputCol</span><span class="o">=</span><span class="s2">&quot;vector&quot;</span><span class="p">,</span> <span class="n">outputCol</span><span class="o">=</span><span class="s2">&quot;transformedVector&quot;</span><span class="p">)</span>
<span class="c1"># Batch transform the vectors to create new column:</span>
<span class="n">transformer</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">df</span><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / python / ml / elementwise_product_example.py”中找到完整的示例代码。</small></div>
  </div>
</div>

<h2 id="sqltransformer">SQLTransformer</h2>

<p><code>SQLTransformer</code>实现由SQL语句定义的转换。目前，我们仅支持SQL语法，例如<code>"SELECT ... FROM __THIS__ ..."</code>哪里<code>"__THIS__"</code>表示输入数据集的基础表。select子句指定要在输出中显示的字段，常量和表达式，并且可以是Spark SQL支持的任何select子句。用户还可以使用Spark SQL内置函数和UDF对这些选定的列进行操作。例如， <code>SQLTransformer</code>支持以下语句：</p>

<ul>
  <li><code>SELECT a, a + b AS a_b FROM __THIS__</code></li>
  <li><code>SELECT a, SQRT(b) AS b_sqrt FROM __THIS__ where a > 5</code></li>
  <li><code>SELECT a, b, SUM(c) AS c_sum FROM __THIS__ GROUP BY a, b</code></li>
</ul>

<p><strong>例子</strong></p>

<p>假设我们有以下带有列的DataFrame <code>id</code> ， <code>v1</code>和<code>v2</code> ：</p>

<pre><code> id |  v1 |  v2
----|-----|-----
 0  | 1.0 | 3.0  
 2  | 2.0 | 5.0
</code></pre>

<p>这是<code>SQLTransformer</code>有陈述<code>"SELECT *, (v1 + v2) AS v3, (v1 * v2) AS v4 FROM __THIS__"</code> ：</p>

<pre><code> id |  v1 |  v2 |  v3 |  v4
----|-----|-----|-----|-----
 0  | 1.0 | 3.0 | 4.0 | 3.0
 2  | 2.0 | 5.0 | 7.0 |10.0
</code></pre>

<div class="codetabs">
<div data-lang="scala">

    <p>有关该API的更多详细信息，请参考<a href="api/scala/index.html#org.apache.spark.ml.feature.SQLTransformer">SQLTransformer Scala文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">org.apache.spark.ml.feature.SQLTransformer</span>

<span class="k">val</span> <span class="n">df</span> <span class="k">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="o">(</span>
  <span class="nc">Seq</span><span class="o">((</span><span class="mi">0</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">,</span> <span class="mf">3.0</span><span class="o">),</span> <span class="o">(</span><span class="mi">2</span><span class="o">,</span> <span class="mf">2.0</span><span class="o">,</span> <span class="mf">5.0</span><span class="o">))).</span><span class="n">toDF</span><span class="o">(</span><span class="s">&quot;id&quot;</span><span class="o">,</span> <span class="s">&quot;v1&quot;</span><span class="o">,</span> <span class="s">&quot;v2&quot;</span><span class="o">)</span>

<span class="k">val</span> <span class="n">sqlTrans</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SQLTransformer</span><span class="o">().</span><span class="n">setStatement</span><span class="o">(</span>
  <span class="s">&quot;SELECT *, (v1 + v2) AS v3, (v1 * v2) AS v4 FROM __THIS__&quot;</span><span class="o">)</span>

<span class="n">sqlTrans</span><span class="o">.</span><span class="n">transform</span><span class="o">(</span><span class="n">df</span><span class="o">).</span><span class="n">show</span><span class="o">()</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / scala / org / apache / spark / examples / ml / SQLTransformerExample.scala”中找到完整的示例代码。</small></div>
  </div>

<div data-lang="java">

    <p>有关该API的更多详细信息，请参考<a href="api/java/org/apache/spark/ml/feature/SQLTransformer.html">SQLTransformer Java文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">java.util.Arrays</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">java.util.List</span><span class="o">;</span>

<span class="kn">import</span> <span class="nn">org.apache.spark.ml.feature.SQLTransformer</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.Dataset</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.Row</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.RowFactory</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.SparkSession</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.*</span><span class="o">;</span>

<span class="n">List</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">data</span> <span class="o">=</span> <span class="n">Arrays</span><span class="o">.</span><span class="na">asList</span><span class="o">(</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">0</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">,</span> <span class="mf">3.0</span><span class="o">),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">2</span><span class="o">,</span> <span class="mf">2.0</span><span class="o">,</span> <span class="mf">5.0</span><span class="o">)</span>
<span class="o">);</span>
<span class="n">StructType</span> <span class="n">schema</span> <span class="o">=</span> <span class="k">new</span> <span class="n">StructType</span><span class="o">(</span><span class="k">new</span> <span class="n">StructField</span> <span class="o">[]</span> <span class="o">{</span>
  <span class="k">new</span> <span class="n">StructField</span><span class="o">(</span><span class="s">&quot;id&quot;</span><span class="o">,</span> <span class="n">DataTypes</span><span class="o">.</span><span class="na">IntegerType</span><span class="o">,</span> <span class="kc">false</span><span class="o">,</span> <span class="n">Metadata</span><span class="o">.</span><span class="na">empty</span><span class="o">()),</span>
  <span class="k">new</span> <span class="n">StructField</span><span class="o">(</span><span class="s">&quot;v1&quot;</span><span class="o">,</span> <span class="n">DataTypes</span><span class="o">.</span><span class="na">DoubleType</span><span class="o">,</span> <span class="kc">false</span><span class="o">,</span> <span class="n">Metadata</span><span class="o">.</span><span class="na">empty</span><span class="o">()),</span>
  <span class="k">new</span> <span class="n">StructField</span><span class="o">(</span><span class="s">&quot;v2&quot;</span><span class="o">,</span> <span class="n">DataTypes</span><span class="o">.</span><span class="na">DoubleType</span><span class="o">,</span> <span class="kc">false</span><span class="o">,</span> <span class="n">Metadata</span><span class="o">.</span><span class="na">empty</span><span class="o">())</span>
<span class="o">});</span>
<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="na">createDataFrame</span><span class="o">(</span><span class="n">data</span><span class="o">,</span> <span class="n">schema</span><span class="o">);</span>

<span class="n">SQLTransformer</span> <span class="n">sqlTrans</span> <span class="o">=</span> <span class="k">new</span> <span class="n">SQLTransformer</span><span class="o">().</span><span class="na">setStatement</span><span class="o">(</span>
  <span class="s">&quot;SELECT *, (v1 + v2) AS v3, (v1 * v2) AS v4 FROM __THIS__&quot;</span><span class="o">);</span>

<span class="n">sqlTrans</span><span class="o">.</span><span class="na">transform</span><span class="o">(</span><span class="n">df</span><span class="o">).</span><span class="na">show</span><span class="o">();</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / java / org / apache / spark / examples / ml / JavaSQLTransformerExample.java”中找到完整的示例代码。</small></div>
  </div>

<div data-lang="python">

    <p>有关API的更多详细信息，请参考<a href="api/python/pyspark.ml.html#pyspark.ml.feature.SQLTransformer">SQLTransformer Python文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pyspark.ml.feature</span> <span class="kn">import</span> <span class="n">SQLTransformer</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">([</span>
    <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">),</span>
    <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mf">5.0</span><span class="p">)</span>
<span class="p">],</span> <span class="p">[</span><span class="s2">&quot;id&quot;</span><span class="p">,</span> <span class="s2">&quot;v1&quot;</span><span class="p">,</span> <span class="s2">&quot;v2&quot;</span><span class="p">])</span>
<span class="n">sqlTrans</span> <span class="o">=</span> <span class="n">SQLTransformer</span><span class="p">(</span>
    <span class="n">statement</span><span class="o">=</span><span class="s2">&quot;SELECT *, (v1 + v2) AS v3, (v1 * v2) AS v4 FROM __THIS__&quot;</span><span class="p">)</span>
<span class="n">sqlTrans</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">df</span><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / python / ml / sql_transformer.py”中找到完整的示例代码。</small></div>
  </div>
</div>

<h2 id="vectorassembler">VectorAssembler</h2>

<p><code>VectorAssembler</code>是将给定的列列表合并为单个向量列的转换器。这对于将原始特征和由不同特征转换器生成的特征组合到单个特征向量中很有用，以便训练诸如逻辑回归和决策树之类的ML模型。
<code>VectorAssembler</code>接受以下输入列类型：所有数字类型，布尔类型和向量类型。在每一行中，输入列的值将按指定顺序连接到向量中。</p>

<p><strong>例子</strong></p>

<p>假设我们有一个带有列的DataFrame <code>id</code> ， <code>hour</code> ， <code>mobile</code> ， <code>userFeatures</code>和<code>clicked</code> ：</p>

<pre><code> id | hour | mobile | userFeatures     | clicked
----|------|--------|------------------|---------
 0  | 18   | 1.0    | [0.0, 10.0, 0.5] | 1.0
</code></pre>

<p><code>userFeatures</code>是包含三个用户功能的向量列。我们要结合<code>hour</code> ， <code>mobile</code>和<code>userFeatures</code>进入一个称为<code>features</code>并用它来预测<code>clicked</code>或不。如果我们设置<code>VectorAssembler</code>的输入列<code>hour</code> ， <code>mobile</code>和<code>userFeatures</code>并将输出列到<code>features</code> ，转换后，我们应该获得以下DataFrame：</p>

<pre><code> id | hour | mobile | userFeatures     | clicked | features
----|------|--------|------------------|---------|-----------------------------
 0  | 18   | 1.0    | [0.0, 10.0, 0.5] | 1.0     | [18.0, 1.0, 0.0, 10.0, 0.5]
</code></pre>

<div class="codetabs">
<div data-lang="scala">

    <p>有关API的更多详细信息，请参考<a href="api/scala/index.html#org.apache.spark.ml.feature.VectorAssembler">VectorAssembler Scala文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">org.apache.spark.ml.feature.VectorAssembler</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.linalg.Vectors</span>

<span class="k">val</span> <span class="n">dataset</span> <span class="k">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="o">(</span>
  <span class="nc">Seq</span><span class="o">((</span><span class="mi">0</span><span class="o">,</span> <span class="mi">18</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">,</span> <span class="nc">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="o">(</span><span class="mf">0.0</span><span class="o">,</span> <span class="mf">10.0</span><span class="o">,</span> <span class="mf">0.5</span><span class="o">),</span> <span class="mf">1.0</span><span class="o">))</span>
<span class="o">).</span><span class="n">toDF</span><span class="o">(</span><span class="s">&quot;id&quot;</span><span class="o">,</span> <span class="s">&quot;hour&quot;</span><span class="o">,</span> <span class="s">&quot;mobile&quot;</span><span class="o">,</span> <span class="s">&quot;userFeatures&quot;</span><span class="o">,</span> <span class="s">&quot;clicked&quot;</span><span class="o">)</span>

<span class="k">val</span> <span class="n">assembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">VectorAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="n">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">&quot;hour&quot;</span><span class="o">,</span> <span class="s">&quot;mobile&quot;</span><span class="o">,</span> <span class="s">&quot;userFeatures&quot;</span><span class="o">))</span>
  <span class="o">.</span><span class="n">setOutputCol</span><span class="o">(</span><span class="s">&quot;features&quot;</span><span class="o">)</span>

<span class="k">val</span> <span class="n">output</span> <span class="k">=</span> <span class="n">assembler</span><span class="o">.</span><span class="n">transform</span><span class="o">(</span><span class="n">dataset</span><span class="o">)</span>
<span class="n">println</span><span class="o">(</span><span class="s">&quot;Assembled columns &#39;hour&#39;, &#39;mobile&#39;, &#39;userFeatures&#39; to vector column &#39;features&#39;&quot;</span><span class="o">)</span>
<span class="n">output</span><span class="o">.</span><span class="n">select</span><span class="o">(</span><span class="s">&quot;features&quot;</span><span class="o">,</span> <span class="s">&quot;clicked&quot;</span><span class="o">).</span><span class="n">show</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / scala / org / apache / spark / examples / ml / VectorAssemblerExample.scala”中找到完整的示例代码。</small></div>
  </div>

<div data-lang="java">

    <p>有关API的更多详细信息，请参考<a href="api/java/org/apache/spark/ml/feature/VectorAssembler.html">VectorAssembler Java文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">java.util.Arrays</span><span class="o">;</span>

<span class="kn">import</span> <span class="nn">org.apache.spark.ml.feature.VectorAssembler</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.ml.linalg.VectorUDT</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.ml.linalg.Vectors</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.Dataset</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.Row</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.RowFactory</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.*</span><span class="o">;</span>
<span class="kn">import static</span> <span class="nn">org.apache.spark.sql.types.DataTypes.*</span><span class="o">;</span>

<span class="n">StructType</span> <span class="n">schema</span> <span class="o">=</span> <span class="n">createStructType</span><span class="o">(</span><span class="k">new</span> <span class="n">StructField</span><span class="o">[]{</span>
  <span class="n">createStructField</span><span class="o">(</span><span class="s">&quot;id&quot;</span><span class="o">,</span> <span class="n">IntegerType</span><span class="o">,</span> <span class="kc">false</span><span class="o">),</span>
  <span class="n">createStructField</span><span class="o">(</span><span class="s">&quot;hour&quot;</span><span class="o">,</span> <span class="n">IntegerType</span><span class="o">,</span> <span class="kc">false</span><span class="o">),</span>
  <span class="n">createStructField</span><span class="o">(</span><span class="s">&quot;mobile&quot;</span><span class="o">,</span> <span class="n">DoubleType</span><span class="o">,</span> <span class="kc">false</span><span class="o">),</span>
  <span class="n">createStructField</span><span class="o">(</span><span class="s">&quot;userFeatures&quot;</span><span class="o">,</span> <span class="k">new</span> <span class="n">VectorUDT</span><span class="o">(),</span> <span class="kc">false</span><span class="o">),</span>
  <span class="n">createStructField</span><span class="o">(</span><span class="s">&quot;clicked&quot;</span><span class="o">,</span> <span class="n">DoubleType</span><span class="o">,</span> <span class="kc">false</span><span class="o">)</span>
<span class="o">});</span>
<span class="n">Row</span> <span class="n">row</span> <span class="o">=</span> <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">0</span><span class="o">,</span> <span class="mi">18</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">,</span> <span class="n">Vectors</span><span class="o">.</span><span class="na">dense</span><span class="o">(</span><span class="mf">0.0</span><span class="o">,</span> <span class="mf">10.0</span><span class="o">,</span> <span class="mf">0.5</span><span class="o">),</span> <span class="mf">1.0</span><span class="o">);</span>
<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">dataset</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="na">createDataFrame</span><span class="o">(</span><span class="n">Arrays</span><span class="o">.</span><span class="na">asList</span><span class="o">(</span><span class="n">row</span><span class="o">),</span> <span class="n">schema</span><span class="o">);</span>

<span class="n">VectorAssembler</span> <span class="n">assembler</span> <span class="o">=</span> <span class="k">new</span> <span class="n">VectorAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="na">setInputCols</span><span class="o">(</span><span class="k">new</span> <span class="n">String</span><span class="o">[]{</span><span class="s">&quot;hour&quot;</span><span class="o">,</span> <span class="s">&quot;mobile&quot;</span><span class="o">,</span> <span class="s">&quot;userFeatures&quot;</span><span class="o">})</span>
  <span class="o">.</span><span class="na">setOutputCol</span><span class="o">(</span><span class="s">&quot;features&quot;</span><span class="o">);</span>

<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">output</span> <span class="o">=</span> <span class="n">assembler</span><span class="o">.</span><span class="na">transform</span><span class="o">(</span><span class="n">dataset</span><span class="o">);</span>
<span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">&quot;Assembled columns &#39;hour&#39;, &#39;mobile&#39;, &#39;userFeatures&#39; to vector column &quot;</span> <span class="o">+</span>
    <span class="s">&quot;&#39;features&#39;&quot;</span><span class="o">);</span>
<span class="n">output</span><span class="o">.</span><span class="na">select</span><span class="o">(</span><span class="s">&quot;features&quot;</span><span class="o">,</span> <span class="s">&quot;clicked&quot;</span><span class="o">).</span><span class="na">show</span><span class="o">(</span><span class="kc">false</span><span class="o">);</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / java / org / apache / spark / examples / ml / JavaVectorAssemblerExample.java”中找到完整的示例代码。</small></div>
  </div>

<div data-lang="python">

    <p>有关API的更多详细信息，请参考<a href="api/python/pyspark.ml.html#pyspark.ml.feature.VectorAssembler">VectorAssembler Python文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pyspark.ml.linalg</span> <span class="kn">import</span> <span class="n">Vectors</span>
<span class="kn">from</span> <span class="nn">pyspark.ml.feature</span> <span class="kn">import</span> <span class="n">VectorAssembler</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">(</span>
    <span class="p">[(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">18</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">10.0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">]),</span> <span class="mf">1.0</span><span class="p">)],</span>
    <span class="p">[</span><span class="s2">&quot;id&quot;</span><span class="p">,</span> <span class="s2">&quot;hour&quot;</span><span class="p">,</span> <span class="s2">&quot;mobile&quot;</span><span class="p">,</span> <span class="s2">&quot;userFeatures&quot;</span><span class="p">,</span> <span class="s2">&quot;clicked&quot;</span><span class="p">])</span>

<span class="n">assembler</span> <span class="o">=</span> <span class="n">VectorAssembler</span><span class="p">(</span>
    <span class="n">inputCols</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;hour&quot;</span><span class="p">,</span> <span class="s2">&quot;mobile&quot;</span><span class="p">,</span> <span class="s2">&quot;userFeatures&quot;</span><span class="p">],</span>
    <span class="n">outputCol</span><span class="o">=</span><span class="s2">&quot;features&quot;</span><span class="p">)</span>

<span class="n">output</span> <span class="o">=</span> <span class="n">assembler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&quot;Assembled columns &#39;hour&#39;, &#39;mobile&#39;, &#39;userFeatures&#39; to vector column &#39;features&#39;&quot;</span><span class="p">)</span>
<span class="n">output</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s2">&quot;features&quot;</span><span class="p">,</span> <span class="s2">&quot;clicked&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / python / ml / vector_assembler_example.py”中找到完整的示例代码。</small></div>
  </div>
</div>

<h2 id="vectorsizehint">VectorSizeHint</h2>

<p>有时明确指定列的向量大小可能很有用<code>VectorType</code> 。例如， <code>VectorAssembler</code>使用其输入列中的大小信息来为其输出列生成大小信息和元数据。尽管在某些情况下，可以通过检查列的内容来获取此信息，但是在流数据帧中，只有在启动流之后，内容才可用。 <code>VectorSizeHint</code>允许用户显式指定列的向量大小，以便<code>VectorAssembler</code>或可能需要知道矢量大小的其他转换器，可以将该列用作输入。</p>

<p>使用<code>VectorSizeHint</code>用户必须设置<code>inputCol</code>和<code>size</code>参数。将此转换器应用于数据框会生成一个新的数据框，其中包含用于更新的元数据<code>inputCol</code>指定向量大小。对结果数据帧的下游操作可以使用元数据获得此大小。</p>

<p><code>VectorSizeHint</code>也可以选择<code>handleInvalid</code>当vector列包含null或错误大小的vector时控制其行为的参数。默认<code>handleInvalid</code>设置为“错误”，表示应引发异常。此参数也可以设置为“跳过”，指示应从结果数据框中过滤出包含无效值的行，或“乐观”，指示不应检查该列的无效值，而应保留所有行。请注意，使用“乐观”可能会导致结果数据框处于不一致状态，这意味着该列的元数据<code>VectorSizeHint</code>应用于与该列的内容不匹配。用户应注意避免这种不一致的状态。</p>

<div class="codetabs">
<div data-lang="scala">

    <p>有关API的更多详细信息，请参考<a href="api/scala/index.html#org.apache.spark.ml.feature.VectorSizeHint">VectorSizeHint Scala文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">org.apache.spark.ml.feature.</span><span class="o">{</span><span class="nc">VectorAssembler</span><span class="o">,</span> <span class="nc">VectorSizeHint</span><span class="o">}</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.linalg.Vectors</span>

<span class="k">val</span> <span class="n">dataset</span> <span class="k">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="o">(</span>
  <span class="nc">Seq</span><span class="o">(</span>
    <span class="o">(</span><span class="mi">0</span><span class="o">,</span> <span class="mi">18</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">,</span> <span class="nc">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="o">(</span><span class="mf">0.0</span><span class="o">,</span> <span class="mf">10.0</span><span class="o">,</span> <span class="mf">0.5</span><span class="o">),</span> <span class="mf">1.0</span><span class="o">),</span>
    <span class="o">(</span><span class="mi">0</span><span class="o">,</span> <span class="mi">18</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">,</span> <span class="nc">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="o">(</span><span class="mf">0.0</span><span class="o">,</span> <span class="mf">10.0</span><span class="o">),</span> <span class="mf">0.0</span><span class="o">))</span>
<span class="o">).</span><span class="n">toDF</span><span class="o">(</span><span class="s">&quot;id&quot;</span><span class="o">,</span> <span class="s">&quot;hour&quot;</span><span class="o">,</span> <span class="s">&quot;mobile&quot;</span><span class="o">,</span> <span class="s">&quot;userFeatures&quot;</span><span class="o">,</span> <span class="s">&quot;clicked&quot;</span><span class="o">)</span>

<span class="k">val</span> <span class="n">sizeHint</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">VectorSizeHint</span><span class="o">()</span>
  <span class="o">.</span><span class="n">setInputCol</span><span class="o">(</span><span class="s">&quot;userFeatures&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">setHandleInvalid</span><span class="o">(</span><span class="s">&quot;skip&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">setSize</span><span class="o">(</span><span class="mi">3</span><span class="o">)</span>

<span class="k">val</span> <span class="n">datasetWithSize</span> <span class="k">=</span> <span class="n">sizeHint</span><span class="o">.</span><span class="n">transform</span><span class="o">(</span><span class="n">dataset</span><span class="o">)</span>
<span class="n">println</span><span class="o">(</span><span class="s">&quot;Rows where &#39;userFeatures&#39; is not the right size are filtered out&quot;</span><span class="o">)</span>
<span class="n">datasetWithSize</span><span class="o">.</span><span class="n">show</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>

<span class="k">val</span> <span class="n">assembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">VectorAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="n">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">&quot;hour&quot;</span><span class="o">,</span> <span class="s">&quot;mobile&quot;</span><span class="o">,</span> <span class="s">&quot;userFeatures&quot;</span><span class="o">))</span>
  <span class="o">.</span><span class="n">setOutputCol</span><span class="o">(</span><span class="s">&quot;features&quot;</span><span class="o">)</span>

<span class="c1">// This dataframe can be used by downstream transformers as before</span>
<span class="k">val</span> <span class="n">output</span> <span class="k">=</span> <span class="n">assembler</span><span class="o">.</span><span class="n">transform</span><span class="o">(</span><span class="n">datasetWithSize</span><span class="o">)</span>
<span class="n">println</span><span class="o">(</span><span class="s">&quot;Assembled columns &#39;hour&#39;, &#39;mobile&#39;, &#39;userFeatures&#39; to vector column &#39;features&#39;&quot;</span><span class="o">)</span>
<span class="n">output</span><span class="o">.</span><span class="n">select</span><span class="o">(</span><span class="s">&quot;features&quot;</span><span class="o">,</span> <span class="s">&quot;clicked&quot;</span><span class="o">).</span><span class="n">show</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / scala / org / apache / spark / examples / ml / VectorSizeHintExample.scala”中找到完整的示例代码。</small></div>
  </div>

<div data-lang="java">

    <p>有关API的更多详细信息，请参考<a href="api/java/org/apache/spark/ml/feature/VectorSizeHint.html">VectorSizeHint Java文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">java.util.Arrays</span><span class="o">;</span>

<span class="kn">import</span> <span class="nn">org.apache.spark.ml.feature.VectorAssembler</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.ml.feature.VectorSizeHint</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.ml.linalg.VectorUDT</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.ml.linalg.Vectors</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.Dataset</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.Row</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.RowFactory</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.StructField</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.StructType</span><span class="o">;</span>
<span class="kn">import static</span> <span class="nn">org.apache.spark.sql.types.DataTypes.*</span><span class="o">;</span>

<span class="n">StructType</span> <span class="n">schema</span> <span class="o">=</span> <span class="n">createStructType</span><span class="o">(</span><span class="k">new</span> <span class="n">StructField</span><span class="o">[]{</span>
  <span class="n">createStructField</span><span class="o">(</span><span class="s">&quot;id&quot;</span><span class="o">,</span> <span class="n">IntegerType</span><span class="o">,</span> <span class="kc">false</span><span class="o">),</span>
  <span class="n">createStructField</span><span class="o">(</span><span class="s">&quot;hour&quot;</span><span class="o">,</span> <span class="n">IntegerType</span><span class="o">,</span> <span class="kc">false</span><span class="o">),</span>
  <span class="n">createStructField</span><span class="o">(</span><span class="s">&quot;mobile&quot;</span><span class="o">,</span> <span class="n">DoubleType</span><span class="o">,</span> <span class="kc">false</span><span class="o">),</span>
  <span class="n">createStructField</span><span class="o">(</span><span class="s">&quot;userFeatures&quot;</span><span class="o">,</span> <span class="k">new</span> <span class="n">VectorUDT</span><span class="o">(),</span> <span class="kc">false</span><span class="o">),</span>
  <span class="n">createStructField</span><span class="o">(</span><span class="s">&quot;clicked&quot;</span><span class="o">,</span> <span class="n">DoubleType</span><span class="o">,</span> <span class="kc">false</span><span class="o">)</span>
<span class="o">});</span>
<span class="n">Row</span> <span class="n">row0</span> <span class="o">=</span> <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">0</span><span class="o">,</span> <span class="mi">18</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">,</span> <span class="n">Vectors</span><span class="o">.</span><span class="na">dense</span><span class="o">(</span><span class="mf">0.0</span><span class="o">,</span> <span class="mf">10.0</span><span class="o">,</span> <span class="mf">0.5</span><span class="o">),</span> <span class="mf">1.0</span><span class="o">);</span>
<span class="n">Row</span> <span class="n">row1</span> <span class="o">=</span> <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">0</span><span class="o">,</span> <span class="mi">18</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">,</span> <span class="n">Vectors</span><span class="o">.</span><span class="na">dense</span><span class="o">(</span><span class="mf">0.0</span><span class="o">,</span> <span class="mf">10.0</span><span class="o">),</span> <span class="mf">0.0</span><span class="o">);</span>
<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">dataset</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="na">createDataFrame</span><span class="o">(</span><span class="n">Arrays</span><span class="o">.</span><span class="na">asList</span><span class="o">(</span><span class="n">row0</span><span class="o">,</span> <span class="n">row1</span><span class="o">),</span> <span class="n">schema</span><span class="o">);</span>

<span class="n">VectorSizeHint</span> <span class="n">sizeHint</span> <span class="o">=</span> <span class="k">new</span> <span class="n">VectorSizeHint</span><span class="o">()</span>
  <span class="o">.</span><span class="na">setInputCol</span><span class="o">(</span><span class="s">&quot;userFeatures&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">setHandleInvalid</span><span class="o">(</span><span class="s">&quot;skip&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">setSize</span><span class="o">(</span><span class="mi">3</span><span class="o">);</span>

<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">datasetWithSize</span> <span class="o">=</span> <span class="n">sizeHint</span><span class="o">.</span><span class="na">transform</span><span class="o">(</span><span class="n">dataset</span><span class="o">);</span>
<span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">&quot;Rows where &#39;userFeatures&#39; is not the right size are filtered out&quot;</span><span class="o">);</span>
<span class="n">datasetWithSize</span><span class="o">.</span><span class="na">show</span><span class="o">(</span><span class="kc">false</span><span class="o">);</span>

<span class="n">VectorAssembler</span> <span class="n">assembler</span> <span class="o">=</span> <span class="k">new</span> <span class="n">VectorAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="na">setInputCols</span><span class="o">(</span><span class="k">new</span> <span class="n">String</span><span class="o">[]{</span><span class="s">&quot;hour&quot;</span><span class="o">,</span> <span class="s">&quot;mobile&quot;</span><span class="o">,</span> <span class="s">&quot;userFeatures&quot;</span><span class="o">})</span>
  <span class="o">.</span><span class="na">setOutputCol</span><span class="o">(</span><span class="s">&quot;features&quot;</span><span class="o">);</span>

<span class="c1">// This dataframe can be used by downstream transformers as before</span>
<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">output</span> <span class="o">=</span> <span class="n">assembler</span><span class="o">.</span><span class="na">transform</span><span class="o">(</span><span class="n">datasetWithSize</span><span class="o">);</span>
<span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">&quot;Assembled columns &#39;hour&#39;, &#39;mobile&#39;, &#39;userFeatures&#39; to vector column &quot;</span> <span class="o">+</span>
    <span class="s">&quot;&#39;features&#39;&quot;</span><span class="o">);</span>
<span class="n">output</span><span class="o">.</span><span class="na">select</span><span class="o">(</span><span class="s">&quot;features&quot;</span><span class="o">,</span> <span class="s">&quot;clicked&quot;</span><span class="o">).</span><span class="na">show</span><span class="o">(</span><span class="kc">false</span><span class="o">);</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / java / org / apache / spark / examples / ml / JavaVectorSizeHintExample.java”中找到完整的示例代码。</small></div>
  </div>

<div data-lang="python">

    <p>有关API的更多详细信息，请参考<a href="api/python/pyspark.ml.html#pyspark.ml.feature.VectorSizeHint">VectorSizeHint Python文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pyspark.ml.linalg</span> <span class="kn">import</span> <span class="n">Vectors</span>
<span class="kn">from</span> <span class="nn">pyspark.ml.feature</span> <span class="kn">import</span> <span class="p">(</span><span class="n">VectorSizeHint</span><span class="p">,</span> <span class="n">VectorAssembler</span><span class="p">)</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">(</span>
    <span class="p">[(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">18</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">10.0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">]),</span> <span class="mf">1.0</span><span class="p">),</span>
     <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">18</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">10.0</span><span class="p">]),</span> <span class="mf">0.0</span><span class="p">)],</span>
    <span class="p">[</span><span class="s2">&quot;id&quot;</span><span class="p">,</span> <span class="s2">&quot;hour&quot;</span><span class="p">,</span> <span class="s2">&quot;mobile&quot;</span><span class="p">,</span> <span class="s2">&quot;userFeatures&quot;</span><span class="p">,</span> <span class="s2">&quot;clicked&quot;</span><span class="p">])</span>

<span class="n">sizeHint</span> <span class="o">=</span> <span class="n">VectorSizeHint</span><span class="p">(</span>
    <span class="n">inputCol</span><span class="o">=</span><span class="s2">&quot;userFeatures&quot;</span><span class="p">,</span>
    <span class="n">handleInvalid</span><span class="o">=</span><span class="s2">&quot;skip&quot;</span><span class="p">,</span>
    <span class="n">size</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>

<span class="n">datasetWithSize</span> <span class="o">=</span> <span class="n">sizeHint</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&quot;Rows where &#39;userFeatures&#39; is not the right size are filtered out&quot;</span><span class="p">)</span>
<span class="n">datasetWithSize</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

<span class="n">assembler</span> <span class="o">=</span> <span class="n">VectorAssembler</span><span class="p">(</span>
    <span class="n">inputCols</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;hour&quot;</span><span class="p">,</span> <span class="s2">&quot;mobile&quot;</span><span class="p">,</span> <span class="s2">&quot;userFeatures&quot;</span><span class="p">],</span>
    <span class="n">outputCol</span><span class="o">=</span><span class="s2">&quot;features&quot;</span><span class="p">)</span>

<span class="c1"># This dataframe can be used by downstream transformers as before</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">assembler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">datasetWithSize</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&quot;Assembled columns &#39;hour&#39;, &#39;mobile&#39;, &#39;userFeatures&#39; to vector column &#39;features&#39;&quot;</span><span class="p">)</span>
<span class="n">output</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s2">&quot;features&quot;</span><span class="p">,</span> <span class="s2">&quot;clicked&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / python / ml / vector_size_hint_example.py”中找到完整的示例代码。</small></div>
  </div>
</div>

<h2 id="quantilediscretizer">分位数离散器</h2>

<p><code>QuantileDiscretizer</code>接受具有连续特征的列，并输出具有合并分类特征的列。垃圾箱数量由<code>numBuckets</code>参数。例如，如果输入的不同值太少而无法创建足够的不同分位数，则所使用的存储桶的数量可能会小于该值。</p>

<p>NaN值：NaN值将在以下期间从列中删除<code>QuantileDiscretizer</code>配件。这将产生一个<code>Bucketizer</code>进行预测的模型。在转型期间， <code>Bucketizer</code>在数据集中找到NaN值时将引发错误，但用户也可以通过设置来选择保留还是删除数据集中的NaN值<code>handleInvalid</code> 。如果用户选择保留NaN值，则将对其进行特殊处理并将其放入自己的存储桶中，例如，如果使用4个存储桶，则将非NaN数据放入存储桶[0-3]中，但NaN将被存储放在一个特殊的桶中[4]。</p>

<p>算法：bin范围是使用近似算法选择的（有关详细说明，请参见<a href="api/scala/index.html#org.apache.spark.sql.DataFrameStatFunctions">aboutQuantile</a>的文档）。近似的精度可以用<code>relativeError</code>参数。设置为零时，将计算精确的分位数（ <strong>注意：</strong>计算精确的分位数是一项昂贵的操作）。下限和上限bin分别为<code>-Infinity</code>和<code>+Infinity</code>涵盖所有实际价值。</p>

<p><strong>例子</strong></p>

<p>假设我们有一个带有列的DataFrame <code>id</code> ， <code>hour</code> ：</p>

<pre><code> id | hour
----|------
 0  | 18.0
----|------
 1  | 19.0
----|------
 2  | 8.0
----|------
 3  | 5.0
----|------
 4  | 2.2
</code></pre>

<p><code>hour</code>是具有连续性<code>Double</code>类型。我们希望将连续特征转变为分类特征。给定<code>numBuckets = 3</code> ，我们应该获得以下DataFrame：</p>

<pre><code> id | hour | result
----|------|------
 0  | 18.0 | 2.0
----|------|------
 1  | 19.0 | 2.0
----|------|------
 2  | 8.0  | 1.0
----|------|------
 3  | 5.0  | 1.0
----|------|------
 4  | 2.2  | 0.0
</code></pre>

<div class="codetabs">
<div data-lang="scala">

    <p>有关该API的更多详细信息，请参考<a href="api/scala/index.html#org.apache.spark.ml.feature.QuantileDiscretizer">QuantileDiscretizer Scala文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">org.apache.spark.ml.feature.QuantileDiscretizer</span>

<span class="k">val</span> <span class="n">data</span> <span class="k">=</span> <span class="nc">Array</span><span class="o">((</span><span class="mi">0</span><span class="o">,</span> <span class="mf">18.0</span><span class="o">),</span> <span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="mf">19.0</span><span class="o">),</span> <span class="o">(</span><span class="mi">2</span><span class="o">,</span> <span class="mf">8.0</span><span class="o">),</span> <span class="o">(</span><span class="mi">3</span><span class="o">,</span> <span class="mf">5.0</span><span class="o">),</span> <span class="o">(</span><span class="mi">4</span><span class="o">,</span> <span class="mf">2.2</span><span class="o">))</span>
<span class="k">val</span> <span class="n">df</span> <span class="k">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="n">toDF</span><span class="o">(</span><span class="s">&quot;id&quot;</span><span class="o">,</span> <span class="s">&quot;hour&quot;</span><span class="o">)</span>

<span class="k">val</span> <span class="n">discretizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">QuantileDiscretizer</span><span class="o">()</span>
  <span class="o">.</span><span class="n">setInputCol</span><span class="o">(</span><span class="s">&quot;hour&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">setOutputCol</span><span class="o">(</span><span class="s">&quot;result&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">setNumBuckets</span><span class="o">(</span><span class="mi">3</span><span class="o">)</span>

<span class="k">val</span> <span class="n">result</span> <span class="k">=</span> <span class="n">discretizer</span><span class="o">.</span><span class="n">fit</span><span class="o">(</span><span class="n">df</span><span class="o">).</span><span class="n">transform</span><span class="o">(</span><span class="n">df</span><span class="o">)</span>
<span class="n">result</span><span class="o">.</span><span class="n">show</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / scala / org / apache / spark / examples / ml / QuantileDiscretizerExample.scala”中找到完整的示例代码。</small></div>
  </div>

<div data-lang="java">

    <p>有关API的更多详细信息，请参考<a href="api/java/org/apache/spark/ml/feature/QuantileDiscretizer.html">QuantileDiscretizer Java文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">java.util.Arrays</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">java.util.List</span><span class="o">;</span>

<span class="kn">import</span> <span class="nn">org.apache.spark.ml.feature.QuantileDiscretizer</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.Dataset</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.Row</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.RowFactory</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.DataTypes</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.Metadata</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.StructField</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.StructType</span><span class="o">;</span>

<span class="n">List</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">data</span> <span class="o">=</span> <span class="n">Arrays</span><span class="o">.</span><span class="na">asList</span><span class="o">(</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">0</span><span class="o">,</span> <span class="mf">18.0</span><span class="o">),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="mf">19.0</span><span class="o">),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">2</span><span class="o">,</span> <span class="mf">8.0</span><span class="o">),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">3</span><span class="o">,</span> <span class="mf">5.0</span><span class="o">),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">4</span><span class="o">,</span> <span class="mf">2.2</span><span class="o">)</span>
<span class="o">);</span>

<span class="n">StructType</span> <span class="n">schema</span> <span class="o">=</span> <span class="k">new</span> <span class="n">StructType</span><span class="o">(</span><span class="k">new</span> <span class="n">StructField</span><span class="o">[]{</span>
  <span class="k">new</span> <span class="n">StructField</span><span class="o">(</span><span class="s">&quot;id&quot;</span><span class="o">,</span> <span class="n">DataTypes</span><span class="o">.</span><span class="na">IntegerType</span><span class="o">,</span> <span class="kc">false</span><span class="o">,</span> <span class="n">Metadata</span><span class="o">.</span><span class="na">empty</span><span class="o">()),</span>
  <span class="k">new</span> <span class="n">StructField</span><span class="o">(</span><span class="s">&quot;hour&quot;</span><span class="o">,</span> <span class="n">DataTypes</span><span class="o">.</span><span class="na">DoubleType</span><span class="o">,</span> <span class="kc">false</span><span class="o">,</span> <span class="n">Metadata</span><span class="o">.</span><span class="na">empty</span><span class="o">())</span>
<span class="o">});</span>

<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="na">createDataFrame</span><span class="o">(</span><span class="n">data</span><span class="o">,</span> <span class="n">schema</span><span class="o">);</span>

<span class="n">QuantileDiscretizer</span> <span class="n">discretizer</span> <span class="o">=</span> <span class="k">new</span> <span class="n">QuantileDiscretizer</span><span class="o">()</span>
  <span class="o">.</span><span class="na">setInputCol</span><span class="o">(</span><span class="s">&quot;hour&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">setOutputCol</span><span class="o">(</span><span class="s">&quot;result&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">setNumBuckets</span><span class="o">(</span><span class="mi">3</span><span class="o">);</span>

<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">result</span> <span class="o">=</span> <span class="n">discretizer</span><span class="o">.</span><span class="na">fit</span><span class="o">(</span><span class="n">df</span><span class="o">).</span><span class="na">transform</span><span class="o">(</span><span class="n">df</span><span class="o">);</span>
<span class="n">result</span><span class="o">.</span><span class="na">show</span><span class="o">(</span><span class="kc">false</span><span class="o">);</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / java / org / apache / spark / examples / ml / JavaQuantileDiscretizerExample.java”中找到完整的示例代码。</small></div>
  </div>

<div data-lang="python">

    <p>有关API的更多详细信息，请参考<a href="api/python/pyspark.ml.html#pyspark.ml.feature.QuantileDiscretizer">QuantileDiscretizer Python文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pyspark.ml.feature</span> <span class="kn">import</span> <span class="n">QuantileDiscretizer</span>

<span class="n">data</span> <span class="o">=</span> <span class="p">[(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">18.0</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mf">19.0</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mf">8.0</span><span class="p">),</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mf">5.0</span><span class="p">),</span> <span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mf">2.2</span><span class="p">)]</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;id&quot;</span><span class="p">,</span> <span class="s2">&quot;hour&quot;</span><span class="p">])</span>

<span class="n">discretizer</span> <span class="o">=</span> <span class="n">QuantileDiscretizer</span><span class="p">(</span><span class="n">numBuckets</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">inputCol</span><span class="o">=</span><span class="s2">&quot;hour&quot;</span><span class="p">,</span> <span class="n">outputCol</span><span class="o">=</span><span class="s2">&quot;result&quot;</span><span class="p">)</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">discretizer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">df</span><span class="p">)</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
<span class="n">result</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / python / ml / quantile_discretizer_example.py”中找到完整的示例代码。</small></div>
  </div>

</div>

<h2 id="imputer">不通</h2>

<p>的<code>Imputer</code>估计器使用缺失值所在列的平均值或中位数来完成数据集中的缺失值。输入列应为<code>DoubleType</code>要么<code>FloatType</code> 。目前<code>Imputer</code>不支持分类特征，并且可能为包含分类特征的列创建不正确的值。Imputer可以通过以下方式估算“ NaN”以外的自定义值： <code>.setMissingValue(custom_value)</code> 。例如， <code>.setMissingValue(0)</code>将归因于所有出现的（0）。</p>

<p><strong>注意</strong>全部<code>null</code>输入列中的值被视为丢失，因此也被估算。</p>

<p><strong>例子</strong></p>

<p>假设我们有一个带有列的DataFrame <code>a</code>和<code>b</code> ：</p>

<pre><code>      a     |      b      
------------|-----------
     1.0    | Double.NaN
     2.0    | Double.NaN
 Double.NaN |     3.0   
     4.0    |     4.0   
     5.0    |     5.0   
</code></pre>

<p>在此示例中，Imputer将替换所有出现的<code>Double.NaN</code> （缺失值的默认值）以及根据相应列中其他值计算出的平均值（默认归位策略）。在此示例中，列的替代值<code>a</code>和<code>b</code>分别是3.0和4.0。转换后，输出列中的缺失值将由相关列的替代值代替。</p>

<pre><code>      a     |      b     | out_a | out_b   
------------|------------|-------|-------
     1.0    | Double.NaN |  1.0  |  4.0 
     2.0    | Double.NaN |  2.0  |  4.0 
 Double.NaN |     3.0    |  3.0  |  3.0 
     4.0    |     4.0    |  4.0  |  4.0
     5.0    |     5.0    |  5.0  |  5.0 
</code></pre>

<div class="codetabs">
<div data-lang="scala">

    <p>有关API的更多详细信息，请参阅<a href="api/scala/index.html#org.apache.spark.ml.feature.Imputer">Imputer Scala文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">org.apache.spark.ml.feature.Imputer</span>

<span class="k">val</span> <span class="n">df</span> <span class="k">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="o">(</span><span class="nc">Seq</span><span class="o">(</span>
  <span class="o">(</span><span class="mf">1.0</span><span class="o">,</span> <span class="nc">Double</span><span class="o">.</span><span class="nc">NaN</span><span class="o">),</span>
  <span class="o">(</span><span class="mf">2.0</span><span class="o">,</span> <span class="nc">Double</span><span class="o">.</span><span class="nc">NaN</span><span class="o">),</span>
  <span class="o">(</span><span class="nc">Double</span><span class="o">.</span><span class="nc">NaN</span><span class="o">,</span> <span class="mf">3.0</span><span class="o">),</span>
  <span class="o">(</span><span class="mf">4.0</span><span class="o">,</span> <span class="mf">4.0</span><span class="o">),</span>
  <span class="o">(</span><span class="mf">5.0</span><span class="o">,</span> <span class="mf">5.0</span><span class="o">)</span>
<span class="o">)).</span><span class="n">toDF</span><span class="o">(</span><span class="s">&quot;a&quot;</span><span class="o">,</span> <span class="s">&quot;b&quot;</span><span class="o">)</span>

<span class="k">val</span> <span class="n">imputer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Imputer</span><span class="o">()</span>
  <span class="o">.</span><span class="n">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">&quot;a&quot;</span><span class="o">,</span> <span class="s">&quot;b&quot;</span><span class="o">))</span>
  <span class="o">.</span><span class="n">setOutputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">&quot;out_a&quot;</span><span class="o">,</span> <span class="s">&quot;out_b&quot;</span><span class="o">))</span>

<span class="k">val</span> <span class="n">model</span> <span class="k">=</span> <span class="n">imputer</span><span class="o">.</span><span class="n">fit</span><span class="o">(</span><span class="n">df</span><span class="o">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">transform</span><span class="o">(</span><span class="n">df</span><span class="o">).</span><span class="n">show</span><span class="o">()</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / scala / org / apache / spark / examples / ml / ImputerExample.scala”中找到完整的示例代码。</small></div>
  </div>

<div data-lang="java">

    <p>有关API的更多详细信息，请参阅<a href="api/java/org/apache/spark/ml/feature/Imputer.html">Imputer Java文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">java.util.Arrays</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">java.util.List</span><span class="o">;</span>

<span class="kn">import</span> <span class="nn">org.apache.spark.ml.feature.Imputer</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.ml.feature.ImputerModel</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.Dataset</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.Row</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.RowFactory</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.SparkSession</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.*</span><span class="o">;</span>

<span class="n">List</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">data</span> <span class="o">=</span> <span class="n">Arrays</span><span class="o">.</span><span class="na">asList</span><span class="o">(</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mf">1.0</span><span class="o">,</span> <span class="n">Double</span><span class="o">.</span><span class="na">NaN</span><span class="o">),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mf">2.0</span><span class="o">,</span> <span class="n">Double</span><span class="o">.</span><span class="na">NaN</span><span class="o">),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="n">Double</span><span class="o">.</span><span class="na">NaN</span><span class="o">,</span> <span class="mf">3.0</span><span class="o">),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mf">4.0</span><span class="o">,</span> <span class="mf">4.0</span><span class="o">),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mf">5.0</span><span class="o">,</span> <span class="mf">5.0</span><span class="o">)</span>
<span class="o">);</span>
<span class="n">StructType</span> <span class="n">schema</span> <span class="o">=</span> <span class="k">new</span> <span class="n">StructType</span><span class="o">(</span><span class="k">new</span> <span class="n">StructField</span><span class="o">[]{</span>
  <span class="n">createStructField</span><span class="o">(</span><span class="s">&quot;a&quot;</span><span class="o">,</span> <span class="n">DoubleType</span><span class="o">,</span> <span class="kc">false</span><span class="o">),</span>
  <span class="n">createStructField</span><span class="o">(</span><span class="s">&quot;b&quot;</span><span class="o">,</span> <span class="n">DoubleType</span><span class="o">,</span> <span class="kc">false</span><span class="o">)</span>
<span class="o">});</span>
<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="na">createDataFrame</span><span class="o">(</span><span class="n">data</span><span class="o">,</span> <span class="n">schema</span><span class="o">);</span>

<span class="n">Imputer</span> <span class="n">imputer</span> <span class="o">=</span> <span class="k">new</span> <span class="n">Imputer</span><span class="o">()</span>
  <span class="o">.</span><span class="na">setInputCols</span><span class="o">(</span><span class="k">new</span> <span class="n">String</span><span class="o">[]{</span><span class="s">&quot;a&quot;</span><span class="o">,</span> <span class="s">&quot;b&quot;</span><span class="o">})</span>
  <span class="o">.</span><span class="na">setOutputCols</span><span class="o">(</span><span class="k">new</span> <span class="n">String</span><span class="o">[]{</span><span class="s">&quot;out_a&quot;</span><span class="o">,</span> <span class="s">&quot;out_b&quot;</span><span class="o">});</span>

<span class="n">ImputerModel</span> <span class="n">model</span> <span class="o">=</span> <span class="n">imputer</span><span class="o">.</span><span class="na">fit</span><span class="o">(</span><span class="n">df</span><span class="o">);</span>
<span class="n">model</span><span class="o">.</span><span class="na">transform</span><span class="o">(</span><span class="n">df</span><span class="o">).</span><span class="na">show</span><span class="o">();</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / java / org / apache / spark / examples / ml / JavaImputerExample.java”中找到完整的示例代码。</small></div>
  </div>

<div data-lang="python">

    <p>有关API的更多详细信息，请参阅<a href="api/python/pyspark.ml.html#pyspark.ml.feature.Imputer">Imputer Python文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pyspark.ml.feature</span> <span class="kn">import</span> <span class="n">Imputer</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">([</span>
    <span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="nb">float</span><span class="p">(</span><span class="s2">&quot;nan&quot;</span><span class="p">)),</span>
    <span class="p">(</span><span class="mf">2.0</span><span class="p">,</span> <span class="nb">float</span><span class="p">(</span><span class="s2">&quot;nan&quot;</span><span class="p">)),</span>
    <span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="s2">&quot;nan&quot;</span><span class="p">),</span> <span class="mf">3.0</span><span class="p">),</span>
    <span class="p">(</span><span class="mf">4.0</span><span class="p">,</span> <span class="mf">4.0</span><span class="p">),</span>
    <span class="p">(</span><span class="mf">5.0</span><span class="p">,</span> <span class="mf">5.0</span><span class="p">)</span>
<span class="p">],</span> <span class="p">[</span><span class="s2">&quot;a&quot;</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">])</span>

<span class="n">imputer</span> <span class="o">=</span> <span class="n">Imputer</span><span class="p">(</span><span class="n">inputCols</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;a&quot;</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">],</span> <span class="n">outputCols</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;out_a&quot;</span><span class="p">,</span> <span class="s2">&quot;out_b&quot;</span><span class="p">])</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">imputer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>

<span class="n">model</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">df</span><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / python / ml / imputer_example.py”中找到完整的示例代码。</small></div>
  </div>
</div>

<h1 id="feature-selectors">功能选择器</h1>

<h2 id="vectorslicer">VectorSlicer</h2>

<p><code>VectorSlicer</code>是一个采用特征向量并输出带有原始特征子数组的新特征向量的转换器。这对于从向量列中提取特征很有用。</p>

<p><code>VectorSlicer</code>接受具有指定索引的向量列，然后输出一个新的向量列，其值通过这些索引选择。索引有两种类型，</p>

<ol>
  <li>
    <p>整数索引，代表向量的索引， <code>setIndices()</code> 。</p>
  </li>
  <li>
    <p>字符串索引，表示向量中要素的名称， <code>setNames()</code> 。
 <em>这要求向量列必须有一个<code>AttributeGroup</code>因为实施与匹配的名称字段<code>Attribute</code> 。</em></p>
  </li>
</ol>

<p>以整数和字符串指定都可以接受。此外，您可以同时使用整数索引和字符串名称。必须至少选择一项功能。不允许重复的功能，因此所选索引和名称之间不能有重叠。请注意，如果选择了要素名称，则在遇到空的输入属性时将引发异常。</p>

<p>输出向量将首先按选定索引（按给定顺序）对要素进行排序，然后按选定名称（按给定顺序）对要素进行排序。</p>

<p><strong>例子</strong></p>

<p>假设我们有一个带有列的DataFrame <code>userFeatures</code> ：</p>

<pre><code> userFeatures
------------------
 [0.0, 10.0, 0.5]
</code></pre>

<p><code>userFeatures</code>是包含三个用户功能的向量列。假设<code>userFeatures</code>都是零，因此我们要删除它并仅选择最后两列。的<code>VectorSlicer</code>选择具有的最后两个元素<code>setIndices(1, 2)</code>然后产生一个新的向量列，名为<code>features</code> ：</p>

<pre><code> userFeatures     | features
------------------|-----------------------------
 [0.0, 10.0, 0.5] | [10.0, 0.5]
</code></pre>

<p>还假设我们具有潜在的输入属性<code>userFeatures</code> ，即<code>["f1", "f2", "f3"]</code> ，那么我们可以使用<code>setNames("f2", "f3")</code>选择它们。</p>

<pre><code> userFeatures     | features
------------------|-----------------------------
 [0.0, 10.0, 0.5] | [10.0, 0.5]
 ["f1", "f2", "f3"] | ["f2", "f3"]
</code></pre>

<div class="codetabs">
<div data-lang="scala">

    <p>有关API的更多详细信息，请参考<a href="api/scala/index.html#org.apache.spark.ml.feature.VectorSlicer">VectorSlicer Scala文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">java.util.Arrays</span>

<span class="k">import</span> <span class="nn">org.apache.spark.ml.attribute.</span><span class="o">{</span><span class="nc">Attribute</span><span class="o">,</span> <span class="nc">AttributeGroup</span><span class="o">,</span> <span class="nc">NumericAttribute</span><span class="o">}</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.feature.VectorSlicer</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.linalg.Vectors</span>
<span class="k">import</span> <span class="nn">org.apache.spark.sql.</span><span class="o">{</span><span class="nc">Row</span><span class="o">,</span> <span class="nc">SparkSession</span><span class="o">}</span>
<span class="k">import</span> <span class="nn">org.apache.spark.sql.types.StructType</span>

<span class="k">val</span> <span class="n">data</span> <span class="k">=</span> <span class="nc">Arrays</span><span class="o">.</span><span class="n">asList</span><span class="o">(</span>
  <span class="nc">Row</span><span class="o">(</span><span class="nc">Vectors</span><span class="o">.</span><span class="n">sparse</span><span class="o">(</span><span class="mi">3</span><span class="o">,</span> <span class="nc">Seq</span><span class="o">((</span><span class="mi">0</span><span class="o">,</span> <span class="o">-</span><span class="mf">2.0</span><span class="o">),</span> <span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="mf">2.3</span><span class="o">)))),</span>
  <span class="nc">Row</span><span class="o">(</span><span class="nc">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="o">(-</span><span class="mf">2.0</span><span class="o">,</span> <span class="mf">2.3</span><span class="o">,</span> <span class="mf">0.0</span><span class="o">))</span>
<span class="o">)</span>

<span class="k">val</span> <span class="n">defaultAttr</span> <span class="k">=</span> <span class="nc">NumericAttribute</span><span class="o">.</span><span class="n">defaultAttr</span>
<span class="k">val</span> <span class="n">attrs</span> <span class="k">=</span> <span class="nc">Array</span><span class="o">(</span><span class="s">&quot;f1&quot;</span><span class="o">,</span> <span class="s">&quot;f2&quot;</span><span class="o">,</span> <span class="s">&quot;f3&quot;</span><span class="o">).</span><span class="n">map</span><span class="o">(</span><span class="n">defaultAttr</span><span class="o">.</span><span class="n">withName</span><span class="o">)</span>
<span class="k">val</span> <span class="n">attrGroup</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">AttributeGroup</span><span class="o">(</span><span class="s">&quot;userFeatures&quot;</span><span class="o">,</span> <span class="n">attrs</span><span class="o">.</span><span class="n">asInstanceOf</span><span class="o">[</span><span class="kt">Array</span><span class="o">[</span><span class="kt">Attribute</span><span class="o">]])</span>

<span class="k">val</span> <span class="n">dataset</span> <span class="k">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="o">(</span><span class="n">data</span><span class="o">,</span> <span class="nc">StructType</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="n">attrGroup</span><span class="o">.</span><span class="n">toStructField</span><span class="o">())))</span>

<span class="k">val</span> <span class="n">slicer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">VectorSlicer</span><span class="o">().</span><span class="n">setInputCol</span><span class="o">(</span><span class="s">&quot;userFeatures&quot;</span><span class="o">).</span><span class="n">setOutputCol</span><span class="o">(</span><span class="s">&quot;features&quot;</span><span class="o">)</span>

<span class="n">slicer</span><span class="o">.</span><span class="n">setIndices</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="mi">1</span><span class="o">)).</span><span class="n">setNames</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">&quot;f3&quot;</span><span class="o">))</span>
<span class="c1">// or slicer.setIndices(Array(1, 2)), or slicer.setNames(Array(&quot;f2&quot;, &quot;f3&quot;))</span>

<span class="k">val</span> <span class="n">output</span> <span class="k">=</span> <span class="n">slicer</span><span class="o">.</span><span class="n">transform</span><span class="o">(</span><span class="n">dataset</span><span class="o">)</span>
<span class="n">output</span><span class="o">.</span><span class="n">show</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / scala / org / apache / spark / examples / ml / VectorSlicerExample.scala”中找到完整的示例代码。</small></div>
  </div>

<div data-lang="java">

    <p>有关API的更多详细信息，请参考<a href="api/java/org/apache/spark/ml/feature/VectorSlicer.html">VectorSlicer Java文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">java.util.Arrays</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">java.util.List</span><span class="o">;</span>

<span class="kn">import</span> <span class="nn">org.apache.spark.ml.attribute.Attribute</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.ml.attribute.AttributeGroup</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.ml.attribute.NumericAttribute</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.ml.feature.VectorSlicer</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.ml.linalg.Vectors</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.Dataset</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.Row</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.RowFactory</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.*</span><span class="o">;</span>

<span class="n">Attribute</span><span class="o">[]</span> <span class="n">attrs</span> <span class="o">=</span> <span class="o">{</span>
  <span class="n">NumericAttribute</span><span class="o">.</span><span class="na">defaultAttr</span><span class="o">().</span><span class="na">withName</span><span class="o">(</span><span class="s">&quot;f1&quot;</span><span class="o">),</span>
  <span class="n">NumericAttribute</span><span class="o">.</span><span class="na">defaultAttr</span><span class="o">().</span><span class="na">withName</span><span class="o">(</span><span class="s">&quot;f2&quot;</span><span class="o">),</span>
  <span class="n">NumericAttribute</span><span class="o">.</span><span class="na">defaultAttr</span><span class="o">().</span><span class="na">withName</span><span class="o">(</span><span class="s">&quot;f3&quot;</span><span class="o">)</span>
<span class="o">};</span>
<span class="n">AttributeGroup</span> <span class="n">group</span> <span class="o">=</span> <span class="k">new</span> <span class="n">AttributeGroup</span><span class="o">(</span><span class="s">&quot;userFeatures&quot;</span><span class="o">,</span> <span class="n">attrs</span><span class="o">);</span>

<span class="n">List</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">data</span> <span class="o">=</span> <span class="n">Arrays</span><span class="o">.</span><span class="na">asList</span><span class="o">(</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="n">Vectors</span><span class="o">.</span><span class="na">sparse</span><span class="o">(</span><span class="mi">3</span><span class="o">,</span> <span class="k">new</span> <span class="kt">int</span><span class="o">[]{</span><span class="mi">0</span><span class="o">,</span> <span class="mi">1</span><span class="o">},</span> <span class="k">new</span> <span class="kt">double</span><span class="o">[]{-</span><span class="mf">2.0</span><span class="o">,</span> <span class="mf">2.3</span><span class="o">})),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="n">Vectors</span><span class="o">.</span><span class="na">dense</span><span class="o">(-</span><span class="mf">2.0</span><span class="o">,</span> <span class="mf">2.3</span><span class="o">,</span> <span class="mf">0.0</span><span class="o">))</span>
<span class="o">);</span>

<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">dataset</span> <span class="o">=</span>
  <span class="n">spark</span><span class="o">.</span><span class="na">createDataFrame</span><span class="o">(</span><span class="n">data</span><span class="o">,</span> <span class="o">(</span><span class="k">new</span> <span class="n">StructType</span><span class="o">()).</span><span class="na">add</span><span class="o">(</span><span class="n">group</span><span class="o">.</span><span class="na">toStructField</span><span class="o">()));</span>

<span class="n">VectorSlicer</span> <span class="n">vectorSlicer</span> <span class="o">=</span> <span class="k">new</span> <span class="n">VectorSlicer</span><span class="o">()</span>
  <span class="o">.</span><span class="na">setInputCol</span><span class="o">(</span><span class="s">&quot;userFeatures&quot;</span><span class="o">).</span><span class="na">setOutputCol</span><span class="o">(</span><span class="s">&quot;features&quot;</span><span class="o">);</span>

<span class="n">vectorSlicer</span><span class="o">.</span><span class="na">setIndices</span><span class="o">(</span><span class="k">new</span> <span class="kt">int</span><span class="o">[]{</span><span class="mi">1</span><span class="o">}).</span><span class="na">setNames</span><span class="o">(</span><span class="k">new</span> <span class="n">String</span><span class="o">[]{</span><span class="s">&quot;f3&quot;</span><span class="o">});</span>
<span class="c1">// or slicer.setIndices(new int[]{1, 2}), or slicer.setNames(new String[]{&quot;f2&quot;, &quot;f3&quot;})</span>

<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">output</span> <span class="o">=</span> <span class="n">vectorSlicer</span><span class="o">.</span><span class="na">transform</span><span class="o">(</span><span class="n">dataset</span><span class="o">);</span>
<span class="n">output</span><span class="o">.</span><span class="na">show</span><span class="o">(</span><span class="kc">false</span><span class="o">);</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / java / org / apache / spark / examples / ml / JavaVectorSlicerExample.java”中找到完整的示例代码。</small></div>
  </div>

<div data-lang="python">

    <p>有关API的更多详细信息，请参考<a href="api/python/pyspark.ml.html#pyspark.ml.feature.VectorSlicer">VectorSlicer Python文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pyspark.ml.feature</span> <span class="kn">import</span> <span class="n">VectorSlicer</span>
<span class="kn">from</span> <span class="nn">pyspark.ml.linalg</span> <span class="kn">import</span> <span class="n">Vectors</span>
<span class="kn">from</span> <span class="nn">pyspark.sql.types</span> <span class="kn">import</span> <span class="n">Row</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">([</span>
    <span class="n">Row</span><span class="p">(</span><span class="n">userFeatures</span><span class="o">=</span><span class="n">Vectors</span><span class="o">.</span><span class="n">sparse</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="p">{</span><span class="mi">0</span><span class="p">:</span> <span class="o">-</span><span class="mf">2.0</span><span class="p">,</span> <span class="mi">1</span><span class="p">:</span> <span class="mf">2.3</span><span class="p">})),</span>
    <span class="n">Row</span><span class="p">(</span><span class="n">userFeatures</span><span class="o">=</span><span class="n">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="p">([</span><span class="o">-</span><span class="mf">2.0</span><span class="p">,</span> <span class="mf">2.3</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">]))])</span>

<span class="n">slicer</span> <span class="o">=</span> <span class="n">VectorSlicer</span><span class="p">(</span><span class="n">inputCol</span><span class="o">=</span><span class="s2">&quot;userFeatures&quot;</span><span class="p">,</span> <span class="n">outputCol</span><span class="o">=</span><span class="s2">&quot;features&quot;</span><span class="p">,</span> <span class="n">indices</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>

<span class="n">output</span> <span class="o">=</span> <span class="n">slicer</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>

<span class="n">output</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s2">&quot;userFeatures&quot;</span><span class="p">,</span> <span class="s2">&quot;features&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / python / ml / vector_slicer_example.py”中找到完整的示例代码。</small></div>
  </div>
</div>

<h2 id="rformula">公式</h2>

<p><code>RFormula</code>选择由<a href="https://stat.ethz.ch/R-manual/R-devel/library/stats/html/formula.html">R模型公式</a>指定的列。当前，我们支持R运算符的有限子集，包括“〜”，“。”，“：”，“ +”和“-”。基本运算符为：</p>

<ul>
  <li><code>~</code>目标和条款分开</li>
  <li><code>+</code> concat术语，“ + 0”表示删除拦截</li>
  <li><code>-</code>删除术语，“-1”表示删除拦截</li>
  <li><code>:</code>交互（数值或二进制类别值的乘法）</li>
  <li><code>.</code>除目标外的所有列</li>
</ul>

<p>假设<code>a</code>和<code>b</code>是双列，我们使用以下简单示例来说明<code>RFormula</code> ：</p>

<ul>
  <li><code>y ~ a + b</code>均值模型<code>y ~ w0 + w1 * a + w2 * b</code>哪里<code>w0</code>是截距和<code>w1, w2</code>是系数。</li>
  <li><code>y ~ a + b + a:b - 1</code>均值模型<code>y ~ w1 * a + w2 * b + w3 * a * b</code>哪里<code>w1, w2, w3</code>是系数。</li>
</ul>

<p><code>RFormula</code>产生要素的向量列和标签的双列或字符串列。就像在R中使用公式进行线性回归时一样，数字列将转换为双精度。对于字符串输入列，首先将使用<a href="ml-features.html#stringindexer">StringIndexer</a>使用由<code>stringOrderType</code> ，然后删除订购后的最后一个类别，则将对双打进行一次热编码。</p>

<p>假设包含值的字符串特征列<code>{'b', 'a', 'b', 'a', 'c', 'b'}</code> ， 我们设置<code>stringOrderType</code>控制编码：</p>
<pre><code>stringOrderType | Category mapped to 0 by StringIndexer |  Category dropped by RFormula
----------------|---------------------------------------|---------------------------------
'frequencyDesc' | most frequent category ('b')          | least frequent category ('c')
'frequencyAsc'  | least frequent category ('c')         | most frequent category ('b')
'alphabetDesc'  | last alphabetical category ('c')      | first alphabetical category ('a')
'alphabetAsc'   | first alphabetical category ('a')     | last alphabetical category ('c')
</code></pre>

<p>如果标签列的类型为字符串，则首先使用<a href="ml-features.html#stringindexer">StringIndexer</a>将其转换为double <code>frequencyDesc</code>订购。如果DataFrame中不存在label列，则将从公式中指定的响应变量创建输出label列。</p>

<p><strong>注意：</strong>订购选项<code>stringOrderType</code>不用于标签列。索引标签列后，它将使用默认的降序频率<code>StringIndexer</code> 。</p>

<p><strong>例子</strong></p>

<p>假设我们有一个带有列的DataFrame <code>id</code> ， <code>country</code> ， <code>hour</code>和<code>clicked</code> ：</p>

<pre><code>id | country | hour | clicked
---|---------|------|---------
 7 | "US"    | 18   | 1.0
 8 | "CA"    | 12   | 0.0
 9 | "NZ"    | 15   | 0.0
</code></pre>

<p>如果我们使用<code>RFormula</code>公式字符串为<code>clicked ~ country + hour</code> ，这表示我们要预测<code>clicked</code>基于<code>country</code>和<code>hour</code> ，转换后，我们应该获得以下DataFrame：</p>

<pre><code>id | country | hour | clicked | features         | label
---|---------|------|---------|------------------|-------
 7 | "US"    | 18   | 1.0     | [0.0, 0.0, 18.0] | 1.0
 8 | "CA"    | 12   | 0.0     | [0.0, 1.0, 12.0] | 0.0
 9 | "NZ"    | 15   | 0.0     | [1.0, 0.0, 15.0] | 0.0
</code></pre>

<div class="codetabs">
<div data-lang="scala">

    <p>有关API的更多详细信息，请参考<a href="api/scala/index.html#org.apache.spark.ml.feature.RFormula">RFormula Scala文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">org.apache.spark.ml.feature.RFormula</span>

<span class="k">val</span> <span class="n">dataset</span> <span class="k">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="o">(</span><span class="nc">Seq</span><span class="o">(</span>
  <span class="o">(</span><span class="mi">7</span><span class="o">,</span> <span class="s">&quot;US&quot;</span><span class="o">,</span> <span class="mi">18</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">),</span>
  <span class="o">(</span><span class="mi">8</span><span class="o">,</span> <span class="s">&quot;CA&quot;</span><span class="o">,</span> <span class="mi">12</span><span class="o">,</span> <span class="mf">0.0</span><span class="o">),</span>
  <span class="o">(</span><span class="mi">9</span><span class="o">,</span> <span class="s">&quot;NZ&quot;</span><span class="o">,</span> <span class="mi">15</span><span class="o">,</span> <span class="mf">0.0</span><span class="o">)</span>
<span class="o">)).</span><span class="n">toDF</span><span class="o">(</span><span class="s">&quot;id&quot;</span><span class="o">,</span> <span class="s">&quot;country&quot;</span><span class="o">,</span> <span class="s">&quot;hour&quot;</span><span class="o">,</span> <span class="s">&quot;clicked&quot;</span><span class="o">)</span>

<span class="k">val</span> <span class="n">formula</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">RFormula</span><span class="o">()</span>
  <span class="o">.</span><span class="n">setFormula</span><span class="o">(</span><span class="s">&quot;clicked ~ country + hour&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">setFeaturesCol</span><span class="o">(</span><span class="s">&quot;features&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">setLabelCol</span><span class="o">(</span><span class="s">&quot;label&quot;</span><span class="o">)</span>

<span class="k">val</span> <span class="n">output</span> <span class="k">=</span> <span class="n">formula</span><span class="o">.</span><span class="n">fit</span><span class="o">(</span><span class="n">dataset</span><span class="o">).</span><span class="n">transform</span><span class="o">(</span><span class="n">dataset</span><span class="o">)</span>
<span class="n">output</span><span class="o">.</span><span class="n">select</span><span class="o">(</span><span class="s">&quot;features&quot;</span><span class="o">,</span> <span class="s">&quot;label&quot;</span><span class="o">).</span><span class="n">show</span><span class="o">()</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / scala / org / apache / spark / examples / ml / RFormulaExample.scala”中找到完整的示例代码。</small></div>
  </div>

<div data-lang="java">

    <p>有关API的更多详细信息，请参考<a href="api/java/org/apache/spark/ml/feature/RFormula.html">RFormula Java文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">java.util.Arrays</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">java.util.List</span><span class="o">;</span>

<span class="kn">import</span> <span class="nn">org.apache.spark.ml.feature.RFormula</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.Dataset</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.Row</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.RowFactory</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.StructField</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.StructType</span><span class="o">;</span>

<span class="kn">import static</span> <span class="nn">org.apache.spark.sql.types.DataTypes.*</span><span class="o">;</span>

<span class="n">StructType</span> <span class="n">schema</span> <span class="o">=</span> <span class="n">createStructType</span><span class="o">(</span><span class="k">new</span> <span class="n">StructField</span><span class="o">[]{</span>
  <span class="n">createStructField</span><span class="o">(</span><span class="s">&quot;id&quot;</span><span class="o">,</span> <span class="n">IntegerType</span><span class="o">,</span> <span class="kc">false</span><span class="o">),</span>
  <span class="n">createStructField</span><span class="o">(</span><span class="s">&quot;country&quot;</span><span class="o">,</span> <span class="n">StringType</span><span class="o">,</span> <span class="kc">false</span><span class="o">),</span>
  <span class="n">createStructField</span><span class="o">(</span><span class="s">&quot;hour&quot;</span><span class="o">,</span> <span class="n">IntegerType</span><span class="o">,</span> <span class="kc">false</span><span class="o">),</span>
  <span class="n">createStructField</span><span class="o">(</span><span class="s">&quot;clicked&quot;</span><span class="o">,</span> <span class="n">DoubleType</span><span class="o">,</span> <span class="kc">false</span><span class="o">)</span>
<span class="o">});</span>

<span class="n">List</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">data</span> <span class="o">=</span> <span class="n">Arrays</span><span class="o">.</span><span class="na">asList</span><span class="o">(</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">7</span><span class="o">,</span> <span class="s">&quot;US&quot;</span><span class="o">,</span> <span class="mi">18</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">8</span><span class="o">,</span> <span class="s">&quot;CA&quot;</span><span class="o">,</span> <span class="mi">12</span><span class="o">,</span> <span class="mf">0.0</span><span class="o">),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">9</span><span class="o">,</span> <span class="s">&quot;NZ&quot;</span><span class="o">,</span> <span class="mi">15</span><span class="o">,</span> <span class="mf">0.0</span><span class="o">)</span>
<span class="o">);</span>

<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">dataset</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="na">createDataFrame</span><span class="o">(</span><span class="n">data</span><span class="o">,</span> <span class="n">schema</span><span class="o">);</span>
<span class="n">RFormula</span> <span class="n">formula</span> <span class="o">=</span> <span class="k">new</span> <span class="n">RFormula</span><span class="o">()</span>
  <span class="o">.</span><span class="na">setFormula</span><span class="o">(</span><span class="s">&quot;clicked ~ country + hour&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">setFeaturesCol</span><span class="o">(</span><span class="s">&quot;features&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">setLabelCol</span><span class="o">(</span><span class="s">&quot;label&quot;</span><span class="o">);</span>
<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">output</span> <span class="o">=</span> <span class="n">formula</span><span class="o">.</span><span class="na">fit</span><span class="o">(</span><span class="n">dataset</span><span class="o">).</span><span class="na">transform</span><span class="o">(</span><span class="n">dataset</span><span class="o">);</span>
<span class="n">output</span><span class="o">.</span><span class="na">select</span><span class="o">(</span><span class="s">&quot;features&quot;</span><span class="o">,</span> <span class="s">&quot;label&quot;</span><span class="o">).</span><span class="na">show</span><span class="o">();</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / java / org / apache / spark / examples / ml / JavaRFormulaExample.java”中找到完整的示例代码。</small></div>
  </div>

<div data-lang="python">

    <p>有关API的更多详细信息，请参考<a href="api/python/pyspark.ml.html#pyspark.ml.feature.RFormula">RFormula Python文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pyspark.ml.feature</span> <span class="kn">import</span> <span class="n">RFormula</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">(</span>
    <span class="p">[(</span><span class="mi">7</span><span class="p">,</span> <span class="s2">&quot;US&quot;</span><span class="p">,</span> <span class="mi">18</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">),</span>
     <span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="s2">&quot;CA&quot;</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">),</span>
     <span class="p">(</span><span class="mi">9</span><span class="p">,</span> <span class="s2">&quot;NZ&quot;</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">)],</span>
    <span class="p">[</span><span class="s2">&quot;id&quot;</span><span class="p">,</span> <span class="s2">&quot;country&quot;</span><span class="p">,</span> <span class="s2">&quot;hour&quot;</span><span class="p">,</span> <span class="s2">&quot;clicked&quot;</span><span class="p">])</span>

<span class="n">formula</span> <span class="o">=</span> <span class="n">RFormula</span><span class="p">(</span>
    <span class="n">formula</span><span class="o">=</span><span class="s2">&quot;clicked ~ country + hour&quot;</span><span class="p">,</span>
    <span class="n">featuresCol</span><span class="o">=</span><span class="s2">&quot;features&quot;</span><span class="p">,</span>
    <span class="n">labelCol</span><span class="o">=</span><span class="s2">&quot;label&quot;</span><span class="p">)</span>

<span class="n">output</span> <span class="o">=</span> <span class="n">formula</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
<span class="n">output</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s2">&quot;features&quot;</span><span class="p">,</span> <span class="s2">&quot;label&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / python / ml / rformula_example.py”中找到完整的示例代码。</small></div>
  </div>
</div>

<h2 id="chisqselector">ChiSqSelector</h2>

<p><code>ChiSqSelector</code>代表Chi-Squared特征选择。它对具有分类特征的标记数据进行操作。ChiSqSelector使用<a href="https://en.wikipedia.org/wiki/Chi-squared_test">卡方独立性检验</a>来决定选择哪些功能。它支持五种选择方法： <code>numTopFeatures</code> ， <code>percentile</code> ， <code>fpr</code> ， <code>fdr</code> ， <code>fwe</code> ：</p>
<ul>
  <li><code>numTopFeatures</code>根据卡方检验选择固定数量的顶部特征。这类似于产生具有最大预测能力的特征。</li>
  <li><code>percentile</code>类似于<code>numTopFeatures</code>但选择所有功能的一部分而不是固定数量。</li>
  <li><code>fpr</code>选择p值低于阈值的所有特征，从而控制选择的误报率。</li>
  <li><code>fdr</code>使用<a href="https://en.wikipedia.org/wiki/False_discovery_rate#Benjamini.E2.80.93Hochberg_procedure">Benjamini-Hochberg过程</a>选择错误发现率低于阈值的所有特征。</li>
  <li><code>fwe</code>选择p值低于阈值的所有特征。阈值按1 / numFeatures缩放，从而控制选择的家庭式错误率。默认情况下，选择方法是<code>numTopFeatures</code> ，顶部功能的默认数量设置为50。用户可以使用选择选择方法<code>setSelectorType</code> 。</li>
</ul>

<p><strong>例子</strong></p>

<p>假设我们有一个带有列的DataFrame <code>id</code> ， <code>features</code>和<code>clicked</code> ，这是我们可以预测的目标：</p>

<pre><code>id | features              | clicked
---|-----------------------|---------
 7 | [0.0, 0.0, 18.0, 1.0] | 1.0
 8 | [0.0, 1.0, 12.0, 0.0] | 0.0
 9 | [1.0, 0.0, 15.0, 0.1] | 0.0
</code></pre>

<p>如果我们使用<code>ChiSqSelector</code>与<code>numTopFeatures = 1</code> ，然后根据我们的标签<code>clicked</code>我们的最后一列<code>features</code>被选为最有用的功能：</p>

<pre><code>id | features              | clicked | selectedFeatures
---|-----------------------|---------|------------------
 7 | [0.0, 0.0, 18.0, 1.0] | 1.0     | [1.0]
 8 | [0.0, 1.0, 12.0, 0.0] | 0.0     | [0.0]
 9 | [1.0, 0.0, 15.0, 0.1] | 0.0     | [0.1]
</code></pre>

<div class="codetabs">
<div data-lang="scala">

    <p>有关API的更多详细信息，请参阅<a href="api/scala/index.html#org.apache.spark.ml.feature.ChiSqSelector">ChiSqSelector Scala文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">org.apache.spark.ml.feature.ChiSqSelector</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.linalg.Vectors</span>

<span class="k">val</span> <span class="n">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span>
  <span class="o">(</span><span class="mi">7</span><span class="o">,</span> <span class="nc">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="o">(</span><span class="mf">0.0</span><span class="o">,</span> <span class="mf">0.0</span><span class="o">,</span> <span class="mf">18.0</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">),</span> <span class="mf">1.0</span><span class="o">),</span>
  <span class="o">(</span><span class="mi">8</span><span class="o">,</span> <span class="nc">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="o">(</span><span class="mf">0.0</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">,</span> <span class="mf">12.0</span><span class="o">,</span> <span class="mf">0.0</span><span class="o">),</span> <span class="mf">0.0</span><span class="o">),</span>
  <span class="o">(</span><span class="mi">9</span><span class="o">,</span> <span class="nc">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="o">(</span><span class="mf">1.0</span><span class="o">,</span> <span class="mf">0.0</span><span class="o">,</span> <span class="mf">15.0</span><span class="o">,</span> <span class="mf">0.1</span><span class="o">),</span> <span class="mf">0.0</span><span class="o">)</span>
<span class="o">)</span>

<span class="k">val</span> <span class="n">df</span> <span class="k">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataset</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="n">toDF</span><span class="o">(</span><span class="s">&quot;id&quot;</span><span class="o">,</span> <span class="s">&quot;features&quot;</span><span class="o">,</span> <span class="s">&quot;clicked&quot;</span><span class="o">)</span>

<span class="k">val</span> <span class="n">selector</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">ChiSqSelector</span><span class="o">()</span>
  <span class="o">.</span><span class="n">setNumTopFeatures</span><span class="o">(</span><span class="mi">1</span><span class="o">)</span>
  <span class="o">.</span><span class="n">setFeaturesCol</span><span class="o">(</span><span class="s">&quot;features&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">setLabelCol</span><span class="o">(</span><span class="s">&quot;clicked&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">setOutputCol</span><span class="o">(</span><span class="s">&quot;selectedFeatures&quot;</span><span class="o">)</span>

<span class="k">val</span> <span class="n">result</span> <span class="k">=</span> <span class="n">selector</span><span class="o">.</span><span class="n">fit</span><span class="o">(</span><span class="n">df</span><span class="o">).</span><span class="n">transform</span><span class="o">(</span><span class="n">df</span><span class="o">)</span>

<span class="n">println</span><span class="o">(</span><span class="s">s&quot;ChiSqSelector output with top </span><span class="si">${</span><span class="n">selector</span><span class="o">.</span><span class="n">getNumTopFeatures</span><span class="si">}</span><span class="s"> features selected&quot;</span><span class="o">)</span>
<span class="n">result</span><span class="o">.</span><span class="n">show</span><span class="o">()</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / scala / org / apache / spark / examples / ml / ChiSqSelectorExample.scala”中找到完整的示例代码。</small></div>
  </div>

<div data-lang="java">

    <p>有关API的更多详细信息，请参阅<a href="api/java/org/apache/spark/ml/feature/ChiSqSelector.html">ChiSqSelector Java文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">java.util.Arrays</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">java.util.List</span><span class="o">;</span>

<span class="kn">import</span> <span class="nn">org.apache.spark.ml.feature.ChiSqSelector</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.ml.linalg.VectorUDT</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.ml.linalg.Vectors</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.Row</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.RowFactory</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.DataTypes</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.Metadata</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.StructField</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.StructType</span><span class="o">;</span>

<span class="n">List</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">data</span> <span class="o">=</span> <span class="n">Arrays</span><span class="o">.</span><span class="na">asList</span><span class="o">(</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">7</span><span class="o">,</span> <span class="n">Vectors</span><span class="o">.</span><span class="na">dense</span><span class="o">(</span><span class="mf">0.0</span><span class="o">,</span> <span class="mf">0.0</span><span class="o">,</span> <span class="mf">18.0</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">),</span> <span class="mf">1.0</span><span class="o">),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">8</span><span class="o">,</span> <span class="n">Vectors</span><span class="o">.</span><span class="na">dense</span><span class="o">(</span><span class="mf">0.0</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">,</span> <span class="mf">12.0</span><span class="o">,</span> <span class="mf">0.0</span><span class="o">),</span> <span class="mf">0.0</span><span class="o">),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">9</span><span class="o">,</span> <span class="n">Vectors</span><span class="o">.</span><span class="na">dense</span><span class="o">(</span><span class="mf">1.0</span><span class="o">,</span> <span class="mf">0.0</span><span class="o">,</span> <span class="mf">15.0</span><span class="o">,</span> <span class="mf">0.1</span><span class="o">),</span> <span class="mf">0.0</span><span class="o">)</span>
<span class="o">);</span>
<span class="n">StructType</span> <span class="n">schema</span> <span class="o">=</span> <span class="k">new</span> <span class="n">StructType</span><span class="o">(</span><span class="k">new</span> <span class="n">StructField</span><span class="o">[]{</span>
  <span class="k">new</span> <span class="n">StructField</span><span class="o">(</span><span class="s">&quot;id&quot;</span><span class="o">,</span> <span class="n">DataTypes</span><span class="o">.</span><span class="na">IntegerType</span><span class="o">,</span> <span class="kc">false</span><span class="o">,</span> <span class="n">Metadata</span><span class="o">.</span><span class="na">empty</span><span class="o">()),</span>
  <span class="k">new</span> <span class="n">StructField</span><span class="o">(</span><span class="s">&quot;features&quot;</span><span class="o">,</span> <span class="k">new</span> <span class="n">VectorUDT</span><span class="o">(),</span> <span class="kc">false</span><span class="o">,</span> <span class="n">Metadata</span><span class="o">.</span><span class="na">empty</span><span class="o">()),</span>
  <span class="k">new</span> <span class="n">StructField</span><span class="o">(</span><span class="s">&quot;clicked&quot;</span><span class="o">,</span> <span class="n">DataTypes</span><span class="o">.</span><span class="na">DoubleType</span><span class="o">,</span> <span class="kc">false</span><span class="o">,</span> <span class="n">Metadata</span><span class="o">.</span><span class="na">empty</span><span class="o">())</span>
<span class="o">});</span>

<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="na">createDataFrame</span><span class="o">(</span><span class="n">data</span><span class="o">,</span> <span class="n">schema</span><span class="o">);</span>

<span class="n">ChiSqSelector</span> <span class="n">selector</span> <span class="o">=</span> <span class="k">new</span> <span class="n">ChiSqSelector</span><span class="o">()</span>
  <span class="o">.</span><span class="na">setNumTopFeatures</span><span class="o">(</span><span class="mi">1</span><span class="o">)</span>
  <span class="o">.</span><span class="na">setFeaturesCol</span><span class="o">(</span><span class="s">&quot;features&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">setLabelCol</span><span class="o">(</span><span class="s">&quot;clicked&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">setOutputCol</span><span class="o">(</span><span class="s">&quot;selectedFeatures&quot;</span><span class="o">);</span>

<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">result</span> <span class="o">=</span> <span class="n">selector</span><span class="o">.</span><span class="na">fit</span><span class="o">(</span><span class="n">df</span><span class="o">).</span><span class="na">transform</span><span class="o">(</span><span class="n">df</span><span class="o">);</span>

<span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">&quot;ChiSqSelector output with top &quot;</span> <span class="o">+</span> <span class="n">selector</span><span class="o">.</span><span class="na">getNumTopFeatures</span><span class="o">()</span>
    <span class="o">+</span> <span class="s">&quot; features selected&quot;</span><span class="o">);</span>
<span class="n">result</span><span class="o">.</span><span class="na">show</span><span class="o">();</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / java / org / apache / spark / examples / ml / JavaChiSqSelectorExample.java”中找到完整的示例代码。</small></div>
  </div>

<div data-lang="python">

    <p>有关API的更多详细信息，请参阅<a href="api/python/pyspark.ml.html#pyspark.ml.feature.ChiSqSelector">ChiSqSelector Python文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pyspark.ml.feature</span> <span class="kn">import</span> <span class="n">ChiSqSelector</span>
<span class="kn">from</span> <span class="nn">pyspark.ml.linalg</span> <span class="kn">import</span> <span class="n">Vectors</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">([</span>
    <span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="n">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">18.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">]),</span> <span class="mf">1.0</span><span class="p">,),</span>
    <span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="n">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">12.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">]),</span> <span class="mf">0.0</span><span class="p">,),</span>
    <span class="p">(</span><span class="mi">9</span><span class="p">,</span> <span class="n">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">15.0</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">]),</span> <span class="mf">0.0</span><span class="p">,)],</span> <span class="p">[</span><span class="s2">&quot;id&quot;</span><span class="p">,</span> <span class="s2">&quot;features&quot;</span><span class="p">,</span> <span class="s2">&quot;clicked&quot;</span><span class="p">])</span>

<span class="n">selector</span> <span class="o">=</span> <span class="n">ChiSqSelector</span><span class="p">(</span><span class="n">numTopFeatures</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">featuresCol</span><span class="o">=</span><span class="s2">&quot;features&quot;</span><span class="p">,</span>
                         <span class="n">outputCol</span><span class="o">=</span><span class="s2">&quot;selectedFeatures&quot;</span><span class="p">,</span> <span class="n">labelCol</span><span class="o">=</span><span class="s2">&quot;clicked&quot;</span><span class="p">)</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">selector</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">df</span><span class="p">)</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s2">&quot;ChiSqSelector output with top </span><span class="si">%d</span><span class="s2"> features selected&quot;</span> <span class="o">%</span> <span class="n">selector</span><span class="o">.</span><span class="n">getNumTopFeatures</span><span class="p">())</span>
<span class="n">result</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / python / ml / chisq_selector_example.py”中找到完整的示例代码。</small></div>
  </div>
</div>

<h1 id="locality-sensitive-hashing">局部敏感哈希</h1>
<p><a href="https://en.wikipedia.org/wiki/Locality-sensitive_hashing">位置敏感散列（LSH）</a>是一类重要的散列技术，通常用于大型数据集的聚类，近似最近邻搜索和离群值检测。</p>

<p>LSH的一般想法是使用一个函数族（“ LSH族”）将数据点散列到存储桶中，以便彼此靠近的数据点很有可能位于同一存储桶中，而彼此相距很远的情况很可能在不同的存储桶中。LSH族的正式定义如下。</p>

<p>在公制空间<code>(M, d)</code> ，在哪里<code>M</code>是一组<code>d</code>是距离函数<code>M</code> ，一个LSH家族是一个功能家族<code>h</code>满足以下属性： <code>\[ \forall p, q \in M,\\ d(p,q) \leq r1 \Rightarrow Pr(h(p)=h(q)) \geq p1\\ d(p,q) \geq r2 \Rightarrow Pr(h(p)=h(q)) \leq p2 \]</code>这个LSH家庭被称为<code>(r1, r2, p1, p2)</code> -敏感。</p>

<p>在Spark中，不同的LSH系列在单独的类中实现（例如， <code>MinHash</code> ），并在每个类中提供用于特征转换，近似相似连接和近似最近邻居的API。</p>

<p>在LSH中，我们将误报定义为一对遥远的输入要素（ <code>$d(p,q) \geq r2$</code> ）散列到同一存储桶中，然后我们将假阴性定义为一对相邻要素（带有<code>$d(p,q) \leq r1$</code> ），然后散列到不同的存储桶中。</p>

<h2 id="lsh-operations">LSH运作</h2>

<p>我们描述了LSH可以用于的主要操作类型。拟合的LSH模型具有用于每个操作的方法。</p>

<h3 id="feature-transformation">特征转换</h3>
<p>特征转换是将哈希值添加为新列的基本功能。这对于减少尺寸很有用。用户可以通过设置来指定输入和输出列名称<code>inputCol</code>和<code>outputCol</code> 。</p>

<p>LSH还支持多个LSH哈希表。用户可以通过设置来指定哈希表的数量<code>numHashTables</code> 。这也用于近似相似连接和近似最近邻中的<a href="https://en.wikipedia.org/wiki/Locality-sensitive_hashing#Amplification">OR放大</a> 。散列表的数量增加将提高准确性，但也会增加通信成本和运行时间。</p>

<p>的类型<code>outputCol</code>是<code>Seq[Vector]</code>数组的维数等于<code>numHashTables</code> ，向量的尺寸当前设置为1。在将来的版本中，我们将实现AND放大，以便用户可以指定这些向量的尺寸。</p>

<h3 id="approximate-similarity-join">近似相似度加入</h3>
<p>近似相似联接采用两个数据集，并近似返回数据集中距离小于用户定义阈值的行对。近似相似联接既支持联接两个不同的数据集，又支持自联接。自连接会产生一些重复的对。</p>

<p>近似相似联接接受已转换和未转换的数据集作为输入。如果使用了未转换的数据集，它将被自动转换。在这种情况下，哈希签名将创建为<code>outputCol</code> 。</p>

<p>在合并的数据集中，可以查询原始数据集<code>datasetA</code>和<code>datasetB</code> 。距离列将添加到输出数据集中，以显示返回的每对行之间的真实距离。</p>

<h3 id="approximate-nearest-neighbor-search">近似最近邻居搜索</h3>
<p>近似最近邻居搜索采用（特征向量的）数据集和键（单个特征向量），并且近似返回数据集中最接近向量的指定行数。</p>

<p>近似最近邻居搜索接受已转换和未转换的数据集作为输入。如果使用了未转换的数据集，它将被自动转换。在这种情况下，哈希签名将创建为<code>outputCol</code> 。</p>

<p>距离列将添加到输出数据集中，以显示每个输出行和搜索到的键之间的真实距离。</p>

<p><strong>注意：</strong>近似最近邻居搜索将返回少于<code>k</code>哈希存储桶中没有足够候选者时的第几行。</p>

<h2 id="lsh-algorithms">LSH算法</h2>

<h3 id="bucketed-random-projection-for-euclidean-distance">欧氏距离的桶式随机投影</h3>

<p><a href="https://en.wikipedia.org/wiki/Locality-sensitive_hashing#Stable_distributions">桶装随机投影</a>是欧氏距离的LSH族。欧几里得距离的定义如下： <code>\[ d(\mathbf{x}, \mathbf{y}) = \sqrt{\sum_i (x_i - y_i)^2} \]</code>它的LSH系列项目具有特征向量<code>$\mathbf{x}$</code>到随机单位向量上<code>$\mathbf{v}$</code>并将预测结果分配到哈希桶中： <code>\[ h(\mathbf{x}) = \Big\lfloor \frac{\mathbf{x} \cdot \mathbf{v}}{r} \Big\rfloor \]</code>哪里<code>r</code>是用户定义的存储区长度。存储桶长度可用于控制哈希存储桶的平均大小（以及存储桶的数量）。较大的存储桶长度（即，较少的存储桶）增加了将特征散列到同一存储桶的可能性（增加了真假肯定数）。</p>

<p>桶状随机投影接受任意矢量作为输入特征，并支持稀疏矢量和密集矢量。</p>

<div class="codetabs">
<div data-lang="scala">

    <p>有关API的更多详细信息，请参阅<a href="api/scala/index.html#org.apache.spark.ml.feature.BucketedRandomProjectionLSH">BucketedRandomProjectionLSH Scala文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">org.apache.spark.ml.feature.BucketedRandomProjectionLSH</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.linalg.Vectors</span>
<span class="k">import</span> <span class="nn">org.apache.spark.sql.SparkSession</span>
<span class="k">import</span> <span class="nn">org.apache.spark.sql.functions.col</span>

<span class="k">val</span> <span class="n">dfA</span> <span class="k">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="o">(</span><span class="nc">Seq</span><span class="o">(</span>
  <span class="o">(</span><span class="mi">0</span><span class="o">,</span> <span class="nc">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="o">(</span><span class="mf">1.0</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">)),</span>
  <span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="nc">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="o">(</span><span class="mf">1.0</span><span class="o">,</span> <span class="o">-</span><span class="mf">1.0</span><span class="o">)),</span>
  <span class="o">(</span><span class="mi">2</span><span class="o">,</span> <span class="nc">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="o">(-</span><span class="mf">1.0</span><span class="o">,</span> <span class="o">-</span><span class="mf">1.0</span><span class="o">)),</span>
  <span class="o">(</span><span class="mi">3</span><span class="o">,</span> <span class="nc">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="o">(-</span><span class="mf">1.0</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">))</span>
<span class="o">)).</span><span class="n">toDF</span><span class="o">(</span><span class="s">&quot;id&quot;</span><span class="o">,</span> <span class="s">&quot;features&quot;</span><span class="o">)</span>

<span class="k">val</span> <span class="n">dfB</span> <span class="k">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="o">(</span><span class="nc">Seq</span><span class="o">(</span>
  <span class="o">(</span><span class="mi">4</span><span class="o">,</span> <span class="nc">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="o">(</span><span class="mf">1.0</span><span class="o">,</span> <span class="mf">0.0</span><span class="o">)),</span>
  <span class="o">(</span><span class="mi">5</span><span class="o">,</span> <span class="nc">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="o">(-</span><span class="mf">1.0</span><span class="o">,</span> <span class="mf">0.0</span><span class="o">)),</span>
  <span class="o">(</span><span class="mi">6</span><span class="o">,</span> <span class="nc">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="o">(</span><span class="mf">0.0</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">)),</span>
  <span class="o">(</span><span class="mi">7</span><span class="o">,</span> <span class="nc">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="o">(</span><span class="mf">0.0</span><span class="o">,</span> <span class="o">-</span><span class="mf">1.0</span><span class="o">))</span>
<span class="o">)).</span><span class="n">toDF</span><span class="o">(</span><span class="s">&quot;id&quot;</span><span class="o">,</span> <span class="s">&quot;features&quot;</span><span class="o">)</span>

<span class="k">val</span> <span class="n">key</span> <span class="k">=</span> <span class="nc">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="o">(</span><span class="mf">1.0</span><span class="o">,</span> <span class="mf">0.0</span><span class="o">)</span>

<span class="k">val</span> <span class="n">brp</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">BucketedRandomProjectionLSH</span><span class="o">()</span>
  <span class="o">.</span><span class="n">setBucketLength</span><span class="o">(</span><span class="mf">2.0</span><span class="o">)</span>
  <span class="o">.</span><span class="n">setNumHashTables</span><span class="o">(</span><span class="mi">3</span><span class="o">)</span>
  <span class="o">.</span><span class="n">setInputCol</span><span class="o">(</span><span class="s">&quot;features&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">setOutputCol</span><span class="o">(</span><span class="s">&quot;hashes&quot;</span><span class="o">)</span>

<span class="k">val</span> <span class="n">model</span> <span class="k">=</span> <span class="n">brp</span><span class="o">.</span><span class="n">fit</span><span class="o">(</span><span class="n">dfA</span><span class="o">)</span>

<span class="c1">// Feature Transformation</span>
<span class="n">println</span><span class="o">(</span><span class="s">&quot;The hashed dataset where hashed values are stored in the column &#39;hashes&#39;:&quot;</span><span class="o">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">transform</span><span class="o">(</span><span class="n">dfA</span><span class="o">).</span><span class="n">show</span><span class="o">()</span>

<span class="c1">// Compute the locality sensitive hashes for the input rows, then perform approximate</span>
<span class="c1">// similarity join.</span>
<span class="c1">// We could avoid computing hashes by passing in the already-transformed dataset, e.g.</span>
<span class="c1">// `model.approxSimilarityJoin(transformedA, transformedB, 1.5)`</span>
<span class="n">println</span><span class="o">(</span><span class="s">&quot;Approximately joining dfA and dfB on Euclidean distance smaller than 1.5:&quot;</span><span class="o">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">approxSimilarityJoin</span><span class="o">(</span><span class="n">dfA</span><span class="o">,</span> <span class="n">dfB</span><span class="o">,</span> <span class="mf">1.5</span><span class="o">,</span> <span class="s">&quot;EuclideanDistance&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">select</span><span class="o">(</span><span class="n">col</span><span class="o">(</span><span class="s">&quot;datasetA.id&quot;</span><span class="o">).</span><span class="n">alias</span><span class="o">(</span><span class="s">&quot;idA&quot;</span><span class="o">),</span>
    <span class="n">col</span><span class="o">(</span><span class="s">&quot;datasetB.id&quot;</span><span class="o">).</span><span class="n">alias</span><span class="o">(</span><span class="s">&quot;idB&quot;</span><span class="o">),</span>
    <span class="n">col</span><span class="o">(</span><span class="s">&quot;EuclideanDistance&quot;</span><span class="o">)).</span><span class="n">show</span><span class="o">()</span>

<span class="c1">// Compute the locality sensitive hashes for the input rows, then perform approximate nearest</span>
<span class="c1">// neighbor search.</span>
<span class="c1">// We could avoid computing hashes by passing in the already-transformed dataset, e.g.</span>
<span class="c1">// `model.approxNearestNeighbors(transformedA, key, 2)`</span>
<span class="n">println</span><span class="o">(</span><span class="s">&quot;Approximately searching dfA for 2 nearest neighbors of the key:&quot;</span><span class="o">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">approxNearestNeighbors</span><span class="o">(</span><span class="n">dfA</span><span class="o">,</span> <span class="n">key</span><span class="o">,</span> <span class="mi">2</span><span class="o">).</span><span class="n">show</span><span class="o">()</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / scala / org / apache / spark / examples / ml / BucketedRandomProjectionLSHExample.scala”中找到完整的示例代码。</small></div>
  </div>

<div data-lang="java">

    <p>有关API的更多详细信息，请参见<a href="api/java/org/apache/spark/ml/feature/BucketedRandomProjectionLSH.html">BucketedRandomProjectionLSH Java文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">java.util.Arrays</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">java.util.List</span><span class="o">;</span>

<span class="kn">import</span> <span class="nn">org.apache.spark.ml.feature.BucketedRandomProjectionLSH</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.ml.feature.BucketedRandomProjectionLSHModel</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.ml.linalg.Vector</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.ml.linalg.Vectors</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.ml.linalg.VectorUDT</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.Dataset</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.Row</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.RowFactory</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.DataTypes</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.Metadata</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.StructField</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.StructType</span><span class="o">;</span>

<span class="kn">import static</span> <span class="nn">org.apache.spark.sql.functions.col</span><span class="o">;</span>

<span class="n">List</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">dataA</span> <span class="o">=</span> <span class="n">Arrays</span><span class="o">.</span><span class="na">asList</span><span class="o">(</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">0</span><span class="o">,</span> <span class="n">Vectors</span><span class="o">.</span><span class="na">dense</span><span class="o">(</span><span class="mf">1.0</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">)),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="n">Vectors</span><span class="o">.</span><span class="na">dense</span><span class="o">(</span><span class="mf">1.0</span><span class="o">,</span> <span class="o">-</span><span class="mf">1.0</span><span class="o">)),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">2</span><span class="o">,</span> <span class="n">Vectors</span><span class="o">.</span><span class="na">dense</span><span class="o">(-</span><span class="mf">1.0</span><span class="o">,</span> <span class="o">-</span><span class="mf">1.0</span><span class="o">)),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">3</span><span class="o">,</span> <span class="n">Vectors</span><span class="o">.</span><span class="na">dense</span><span class="o">(-</span><span class="mf">1.0</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">))</span>
<span class="o">);</span>

<span class="n">List</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">dataB</span> <span class="o">=</span> <span class="n">Arrays</span><span class="o">.</span><span class="na">asList</span><span class="o">(</span>
    <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">4</span><span class="o">,</span> <span class="n">Vectors</span><span class="o">.</span><span class="na">dense</span><span class="o">(</span><span class="mf">1.0</span><span class="o">,</span> <span class="mf">0.0</span><span class="o">)),</span>
    <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">5</span><span class="o">,</span> <span class="n">Vectors</span><span class="o">.</span><span class="na">dense</span><span class="o">(-</span><span class="mf">1.0</span><span class="o">,</span> <span class="mf">0.0</span><span class="o">)),</span>
    <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">6</span><span class="o">,</span> <span class="n">Vectors</span><span class="o">.</span><span class="na">dense</span><span class="o">(</span><span class="mf">0.0</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">)),</span>
    <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">7</span><span class="o">,</span> <span class="n">Vectors</span><span class="o">.</span><span class="na">dense</span><span class="o">(</span><span class="mf">0.0</span><span class="o">,</span> <span class="o">-</span><span class="mf">1.0</span><span class="o">))</span>
<span class="o">);</span>

<span class="n">StructType</span> <span class="n">schema</span> <span class="o">=</span> <span class="k">new</span> <span class="n">StructType</span><span class="o">(</span><span class="k">new</span> <span class="n">StructField</span><span class="o">[]{</span>
  <span class="k">new</span> <span class="n">StructField</span><span class="o">(</span><span class="s">&quot;id&quot;</span><span class="o">,</span> <span class="n">DataTypes</span><span class="o">.</span><span class="na">IntegerType</span><span class="o">,</span> <span class="kc">false</span><span class="o">,</span> <span class="n">Metadata</span><span class="o">.</span><span class="na">empty</span><span class="o">()),</span>
  <span class="k">new</span> <span class="n">StructField</span><span class="o">(</span><span class="s">&quot;features&quot;</span><span class="o">,</span> <span class="k">new</span> <span class="n">VectorUDT</span><span class="o">(),</span> <span class="kc">false</span><span class="o">,</span> <span class="n">Metadata</span><span class="o">.</span><span class="na">empty</span><span class="o">())</span>
<span class="o">});</span>
<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">dfA</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="na">createDataFrame</span><span class="o">(</span><span class="n">dataA</span><span class="o">,</span> <span class="n">schema</span><span class="o">);</span>
<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">dfB</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="na">createDataFrame</span><span class="o">(</span><span class="n">dataB</span><span class="o">,</span> <span class="n">schema</span><span class="o">);</span>

<span class="n">Vector</span> <span class="n">key</span> <span class="o">=</span> <span class="n">Vectors</span><span class="o">.</span><span class="na">dense</span><span class="o">(</span><span class="mf">1.0</span><span class="o">,</span> <span class="mf">0.0</span><span class="o">);</span>

<span class="n">BucketedRandomProjectionLSH</span> <span class="n">mh</span> <span class="o">=</span> <span class="k">new</span> <span class="n">BucketedRandomProjectionLSH</span><span class="o">()</span>
  <span class="o">.</span><span class="na">setBucketLength</span><span class="o">(</span><span class="mf">2.0</span><span class="o">)</span>
  <span class="o">.</span><span class="na">setNumHashTables</span><span class="o">(</span><span class="mi">3</span><span class="o">)</span>
  <span class="o">.</span><span class="na">setInputCol</span><span class="o">(</span><span class="s">&quot;features&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">setOutputCol</span><span class="o">(</span><span class="s">&quot;hashes&quot;</span><span class="o">);</span>

<span class="n">BucketedRandomProjectionLSHModel</span> <span class="n">model</span> <span class="o">=</span> <span class="n">mh</span><span class="o">.</span><span class="na">fit</span><span class="o">(</span><span class="n">dfA</span><span class="o">);</span>

<span class="c1">// Feature Transformation</span>
<span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">&quot;The hashed dataset where hashed values are stored in the column &#39;hashes&#39;:&quot;</span><span class="o">);</span>
<span class="n">model</span><span class="o">.</span><span class="na">transform</span><span class="o">(</span><span class="n">dfA</span><span class="o">).</span><span class="na">show</span><span class="o">();</span>

<span class="c1">// Compute the locality sensitive hashes for the input rows, then perform approximate</span>
<span class="c1">// similarity join.</span>
<span class="c1">// We could avoid computing hashes by passing in the already-transformed dataset, e.g.</span>
<span class="c1">// `model.approxSimilarityJoin(transformedA, transformedB, 1.5)`</span>
<span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">&quot;Approximately joining dfA and dfB on distance smaller than 1.5:&quot;</span><span class="o">);</span>
<span class="n">model</span><span class="o">.</span><span class="na">approxSimilarityJoin</span><span class="o">(</span><span class="n">dfA</span><span class="o">,</span> <span class="n">dfB</span><span class="o">,</span> <span class="mf">1.5</span><span class="o">,</span> <span class="s">&quot;EuclideanDistance&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">select</span><span class="o">(</span><span class="n">col</span><span class="o">(</span><span class="s">&quot;datasetA.id&quot;</span><span class="o">).</span><span class="na">alias</span><span class="o">(</span><span class="s">&quot;idA&quot;</span><span class="o">),</span>
    <span class="n">col</span><span class="o">(</span><span class="s">&quot;datasetB.id&quot;</span><span class="o">).</span><span class="na">alias</span><span class="o">(</span><span class="s">&quot;idB&quot;</span><span class="o">),</span>
    <span class="n">col</span><span class="o">(</span><span class="s">&quot;EuclideanDistance&quot;</span><span class="o">)).</span><span class="na">show</span><span class="o">();</span>

<span class="c1">// Compute the locality sensitive hashes for the input rows, then perform approximate nearest</span>
<span class="c1">// neighbor search.</span>
<span class="c1">// We could avoid computing hashes by passing in the already-transformed dataset, e.g.</span>
<span class="c1">// `model.approxNearestNeighbors(transformedA, key, 2)`</span>
<span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">&quot;Approximately searching dfA for 2 nearest neighbors of the key:&quot;</span><span class="o">);</span>
<span class="n">model</span><span class="o">.</span><span class="na">approxNearestNeighbors</span><span class="o">(</span><span class="n">dfA</span><span class="o">,</span> <span class="n">key</span><span class="o">,</span> <span class="mi">2</span><span class="o">).</span><span class="na">show</span><span class="o">();</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / java / org / apache / spark / examples / ml / JavaBucketedRandomProjectionLSHExample.java”中找到完整的示例代码。</small></div>
  </div>

<div data-lang="python">

    <p>有关API的更多详细信息，请参考<a href="api/python/pyspark.ml.html#pyspark.ml.feature.BucketedRandomProjectionLSH">BucketedRandomProjectionLSH Python文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pyspark.ml.feature</span> <span class="kn">import</span> <span class="n">BucketedRandomProjectionLSH</span>
<span class="kn">from</span> <span class="nn">pyspark.ml.linalg</span> <span class="kn">import</span> <span class="n">Vectors</span>
<span class="kn">from</span> <span class="nn">pyspark.sql.functions</span> <span class="kn">import</span> <span class="n">col</span>

<span class="n">dataA</span> <span class="o">=</span> <span class="p">[(</span><span class="mi">0</span><span class="p">,</span> <span class="n">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">]),),</span>
         <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.0</span><span class="p">]),),</span>
         <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="p">([</span><span class="o">-</span><span class="mf">1.0</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.0</span><span class="p">]),),</span>
         <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="p">([</span><span class="o">-</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">]),)]</span>
<span class="n">dfA</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">(</span><span class="n">dataA</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;id&quot;</span><span class="p">,</span> <span class="s2">&quot;features&quot;</span><span class="p">])</span>

<span class="n">dataB</span> <span class="o">=</span> <span class="p">[(</span><span class="mi">4</span><span class="p">,</span> <span class="n">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">]),),</span>
         <span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="n">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="p">([</span><span class="o">-</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">]),),</span>
         <span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="n">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">]),),</span>
         <span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="n">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.0</span><span class="p">]),)]</span>
<span class="n">dfB</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">(</span><span class="n">dataB</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;id&quot;</span><span class="p">,</span> <span class="s2">&quot;features&quot;</span><span class="p">])</span>

<span class="n">key</span> <span class="o">=</span> <span class="n">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">])</span>

<span class="n">brp</span> <span class="o">=</span> <span class="n">BucketedRandomProjectionLSH</span><span class="p">(</span><span class="n">inputCol</span><span class="o">=</span><span class="s2">&quot;features&quot;</span><span class="p">,</span> <span class="n">outputCol</span><span class="o">=</span><span class="s2">&quot;hashes&quot;</span><span class="p">,</span> <span class="n">bucketLength</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span>
                                  <span class="n">numHashTables</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">brp</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">dfA</span><span class="p">)</span>

<span class="c1"># Feature Transformation</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&quot;The hashed dataset where hashed values are stored in the column &#39;hashes&#39;:&quot;</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">dfA</span><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Compute the locality sensitive hashes for the input rows, then perform approximate</span>
<span class="c1"># similarity join.</span>
<span class="c1"># We could avoid computing hashes by passing in the already-transformed dataset, e.g.</span>
<span class="c1"># `model.approxSimilarityJoin(transformedA, transformedB, 1.5)`</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&quot;Approximately joining dfA and dfB on Euclidean distance smaller than 1.5:&quot;</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">approxSimilarityJoin</span><span class="p">(</span><span class="n">dfA</span><span class="p">,</span> <span class="n">dfB</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">,</span> <span class="n">distCol</span><span class="o">=</span><span class="s2">&quot;EuclideanDistance&quot;</span><span class="p">)</span>\
    <span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;datasetA.id&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s2">&quot;idA&quot;</span><span class="p">),</span>
            <span class="n">col</span><span class="p">(</span><span class="s2">&quot;datasetB.id&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s2">&quot;idB&quot;</span><span class="p">),</span>
            <span class="n">col</span><span class="p">(</span><span class="s2">&quot;EuclideanDistance&quot;</span><span class="p">))</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Compute the locality sensitive hashes for the input rows, then perform approximate nearest</span>
<span class="c1"># neighbor search.</span>
<span class="c1"># We could avoid computing hashes by passing in the already-transformed dataset, e.g.</span>
<span class="c1"># `model.approxNearestNeighbors(transformedA, key, 2)`</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&quot;Approximately searching dfA for 2 nearest neighbors of the key:&quot;</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">approxNearestNeighbors</span><span class="p">(</span><span class="n">dfA</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / python / ml / bucketed_random_projection_lsh_example.py”中找到完整的示例代码。</small></div>
  </div>

</div>

<h3 id="minhash-for-jaccard-distance">贾卡距离的MinHash</h3>
<p><a href="https://en.wikipedia.org/wiki/MinHash">MinHash</a>是Jaccard距离的LSH系列，其中输入要素是自然数集。两组的Jaccard距离由其交集和并集的基数定义： <code>\[ d(\mathbf{A}, \mathbf{B}) = 1 - \frac{|\mathbf{A} \cap \mathbf{B}|}{|\mathbf{A} \cup \mathbf{B}|} \]</code> MinHash应用随机哈希函数<code>g</code>到集合中的每个元素，并采用所有哈希值中的最小值：<code>\[ h(\mathbf{A}) = \min_{a \in \mathbf{A}}(g(a)) \]</code></p>

<p>MinHash的输入集表示为二进制向量，其中向量索引表示元素本身，向量中的非零值表示该元素在集合中的存在。虽然同时支持密集和稀疏向量，但通常建议使用稀疏向量以提高效率。例如， <code>Vectors.sparse(10, Array[(2, 1.0), (3, 1.0), (5, 1.0)])</code>表示空间中有10个元素。这组包含elem 2，elem 3和elem 5。所有非零值均视为二进制“ 1”值。</p>

<p><strong>注意：</strong> MinHash不能转换空集，这意味着任何输入向量必须至少具有1个非零条目。</p>

<div class="codetabs">
<div data-lang="scala">

    <p>有关API的更多详细信息，请参考<a href="api/scala/index.html#org.apache.spark.ml.feature.MinHashLSH">MinHashLSH Scala文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">org.apache.spark.ml.feature.MinHashLSH</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.linalg.Vectors</span>
<span class="k">import</span> <span class="nn">org.apache.spark.sql.SparkSession</span>
<span class="k">import</span> <span class="nn">org.apache.spark.sql.functions.col</span>

<span class="k">val</span> <span class="n">dfA</span> <span class="k">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="o">(</span><span class="nc">Seq</span><span class="o">(</span>
  <span class="o">(</span><span class="mi">0</span><span class="o">,</span> <span class="nc">Vectors</span><span class="o">.</span><span class="n">sparse</span><span class="o">(</span><span class="mi">6</span><span class="o">,</span> <span class="nc">Seq</span><span class="o">((</span><span class="mi">0</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">),</span> <span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">),</span> <span class="o">(</span><span class="mi">2</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">)))),</span>
  <span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="nc">Vectors</span><span class="o">.</span><span class="n">sparse</span><span class="o">(</span><span class="mi">6</span><span class="o">,</span> <span class="nc">Seq</span><span class="o">((</span><span class="mi">2</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">),</span> <span class="o">(</span><span class="mi">3</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">),</span> <span class="o">(</span><span class="mi">4</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">)))),</span>
  <span class="o">(</span><span class="mi">2</span><span class="o">,</span> <span class="nc">Vectors</span><span class="o">.</span><span class="n">sparse</span><span class="o">(</span><span class="mi">6</span><span class="o">,</span> <span class="nc">Seq</span><span class="o">((</span><span class="mi">0</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">),</span> <span class="o">(</span><span class="mi">2</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">),</span> <span class="o">(</span><span class="mi">4</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">))))</span>
<span class="o">)).</span><span class="n">toDF</span><span class="o">(</span><span class="s">&quot;id&quot;</span><span class="o">,</span> <span class="s">&quot;features&quot;</span><span class="o">)</span>

<span class="k">val</span> <span class="n">dfB</span> <span class="k">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="o">(</span><span class="nc">Seq</span><span class="o">(</span>
  <span class="o">(</span><span class="mi">3</span><span class="o">,</span> <span class="nc">Vectors</span><span class="o">.</span><span class="n">sparse</span><span class="o">(</span><span class="mi">6</span><span class="o">,</span> <span class="nc">Seq</span><span class="o">((</span><span class="mi">1</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">),</span> <span class="o">(</span><span class="mi">3</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">),</span> <span class="o">(</span><span class="mi">5</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">)))),</span>
  <span class="o">(</span><span class="mi">4</span><span class="o">,</span> <span class="nc">Vectors</span><span class="o">.</span><span class="n">sparse</span><span class="o">(</span><span class="mi">6</span><span class="o">,</span> <span class="nc">Seq</span><span class="o">((</span><span class="mi">2</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">),</span> <span class="o">(</span><span class="mi">3</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">),</span> <span class="o">(</span><span class="mi">5</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">)))),</span>
  <span class="o">(</span><span class="mi">5</span><span class="o">,</span> <span class="nc">Vectors</span><span class="o">.</span><span class="n">sparse</span><span class="o">(</span><span class="mi">6</span><span class="o">,</span> <span class="nc">Seq</span><span class="o">((</span><span class="mi">1</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">),</span> <span class="o">(</span><span class="mi">2</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">),</span> <span class="o">(</span><span class="mi">4</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">))))</span>
<span class="o">)).</span><span class="n">toDF</span><span class="o">(</span><span class="s">&quot;id&quot;</span><span class="o">,</span> <span class="s">&quot;features&quot;</span><span class="o">)</span>

<span class="k">val</span> <span class="n">key</span> <span class="k">=</span> <span class="nc">Vectors</span><span class="o">.</span><span class="n">sparse</span><span class="o">(</span><span class="mi">6</span><span class="o">,</span> <span class="nc">Seq</span><span class="o">((</span><span class="mi">1</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">),</span> <span class="o">(</span><span class="mi">3</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">)))</span>

<span class="k">val</span> <span class="n">mh</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">MinHashLSH</span><span class="o">()</span>
  <span class="o">.</span><span class="n">setNumHashTables</span><span class="o">(</span><span class="mi">5</span><span class="o">)</span>
  <span class="o">.</span><span class="n">setInputCol</span><span class="o">(</span><span class="s">&quot;features&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">setOutputCol</span><span class="o">(</span><span class="s">&quot;hashes&quot;</span><span class="o">)</span>

<span class="k">val</span> <span class="n">model</span> <span class="k">=</span> <span class="n">mh</span><span class="o">.</span><span class="n">fit</span><span class="o">(</span><span class="n">dfA</span><span class="o">)</span>

<span class="c1">// Feature Transformation</span>
<span class="n">println</span><span class="o">(</span><span class="s">&quot;The hashed dataset where hashed values are stored in the column &#39;hashes&#39;:&quot;</span><span class="o">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">transform</span><span class="o">(</span><span class="n">dfA</span><span class="o">).</span><span class="n">show</span><span class="o">()</span>

<span class="c1">// Compute the locality sensitive hashes for the input rows, then perform approximate</span>
<span class="c1">// similarity join.</span>
<span class="c1">// We could avoid computing hashes by passing in the already-transformed dataset, e.g.</span>
<span class="c1">// `model.approxSimilarityJoin(transformedA, transformedB, 0.6)`</span>
<span class="n">println</span><span class="o">(</span><span class="s">&quot;Approximately joining dfA and dfB on Jaccard distance smaller than 0.6:&quot;</span><span class="o">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">approxSimilarityJoin</span><span class="o">(</span><span class="n">dfA</span><span class="o">,</span> <span class="n">dfB</span><span class="o">,</span> <span class="mf">0.6</span><span class="o">,</span> <span class="s">&quot;JaccardDistance&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">select</span><span class="o">(</span><span class="n">col</span><span class="o">(</span><span class="s">&quot;datasetA.id&quot;</span><span class="o">).</span><span class="n">alias</span><span class="o">(</span><span class="s">&quot;idA&quot;</span><span class="o">),</span>
    <span class="n">col</span><span class="o">(</span><span class="s">&quot;datasetB.id&quot;</span><span class="o">).</span><span class="n">alias</span><span class="o">(</span><span class="s">&quot;idB&quot;</span><span class="o">),</span>
    <span class="n">col</span><span class="o">(</span><span class="s">&quot;JaccardDistance&quot;</span><span class="o">)).</span><span class="n">show</span><span class="o">()</span>

<span class="c1">// Compute the locality sensitive hashes for the input rows, then perform approximate nearest</span>
<span class="c1">// neighbor search.</span>
<span class="c1">// We could avoid computing hashes by passing in the already-transformed dataset, e.g.</span>
<span class="c1">// `model.approxNearestNeighbors(transformedA, key, 2)`</span>
<span class="c1">// It may return less than 2 rows when not enough approximate near-neighbor candidates are</span>
<span class="c1">// found.</span>
<span class="n">println</span><span class="o">(</span><span class="s">&quot;Approximately searching dfA for 2 nearest neighbors of the key:&quot;</span><span class="o">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">approxNearestNeighbors</span><span class="o">(</span><span class="n">dfA</span><span class="o">,</span> <span class="n">key</span><span class="o">,</span> <span class="mi">2</span><span class="o">).</span><span class="n">show</span><span class="o">()</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / scala / org / apache / spark / examples / ml / MinHashLSHExample.scala”中找到完整的示例代码。</small></div>
  </div>

<div data-lang="java">

    <p>有关该API的更多详细信息，请参考<a href="api/java/org/apache/spark/ml/feature/MinHashLSH.html">MinHashLSH Java文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">java.util.Arrays</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">java.util.List</span><span class="o">;</span>

<span class="kn">import</span> <span class="nn">org.apache.spark.ml.feature.MinHashLSH</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.ml.feature.MinHashLSHModel</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.ml.linalg.Vector</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.ml.linalg.VectorUDT</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.ml.linalg.Vectors</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.Dataset</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.Row</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.RowFactory</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.DataTypes</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.Metadata</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.StructField</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.StructType</span><span class="o">;</span>

<span class="kn">import static</span> <span class="nn">org.apache.spark.sql.functions.col</span><span class="o">;</span>

<span class="n">List</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">dataA</span> <span class="o">=</span> <span class="n">Arrays</span><span class="o">.</span><span class="na">asList</span><span class="o">(</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">0</span><span class="o">,</span> <span class="n">Vectors</span><span class="o">.</span><span class="na">sparse</span><span class="o">(</span><span class="mi">6</span><span class="o">,</span> <span class="k">new</span> <span class="kt">int</span><span class="o">[]{</span><span class="mi">0</span><span class="o">,</span> <span class="mi">1</span><span class="o">,</span> <span class="mi">2</span><span class="o">},</span> <span class="k">new</span> <span class="kt">double</span><span class="o">[]{</span><span class="mf">1.0</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">})),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="n">Vectors</span><span class="o">.</span><span class="na">sparse</span><span class="o">(</span><span class="mi">6</span><span class="o">,</span> <span class="k">new</span> <span class="kt">int</span><span class="o">[]{</span><span class="mi">2</span><span class="o">,</span> <span class="mi">3</span><span class="o">,</span> <span class="mi">4</span><span class="o">},</span> <span class="k">new</span> <span class="kt">double</span><span class="o">[]{</span><span class="mf">1.0</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">})),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">2</span><span class="o">,</span> <span class="n">Vectors</span><span class="o">.</span><span class="na">sparse</span><span class="o">(</span><span class="mi">6</span><span class="o">,</span> <span class="k">new</span> <span class="kt">int</span><span class="o">[]{</span><span class="mi">0</span><span class="o">,</span> <span class="mi">2</span><span class="o">,</span> <span class="mi">4</span><span class="o">},</span> <span class="k">new</span> <span class="kt">double</span><span class="o">[]{</span><span class="mf">1.0</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">}))</span>
<span class="o">);</span>

<span class="n">List</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">dataB</span> <span class="o">=</span> <span class="n">Arrays</span><span class="o">.</span><span class="na">asList</span><span class="o">(</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">0</span><span class="o">,</span> <span class="n">Vectors</span><span class="o">.</span><span class="na">sparse</span><span class="o">(</span><span class="mi">6</span><span class="o">,</span> <span class="k">new</span> <span class="kt">int</span><span class="o">[]{</span><span class="mi">1</span><span class="o">,</span> <span class="mi">3</span><span class="o">,</span> <span class="mi">5</span><span class="o">},</span> <span class="k">new</span> <span class="kt">double</span><span class="o">[]{</span><span class="mf">1.0</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">})),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="n">Vectors</span><span class="o">.</span><span class="na">sparse</span><span class="o">(</span><span class="mi">6</span><span class="o">,</span> <span class="k">new</span> <span class="kt">int</span><span class="o">[]{</span><span class="mi">2</span><span class="o">,</span> <span class="mi">3</span><span class="o">,</span> <span class="mi">5</span><span class="o">},</span> <span class="k">new</span> <span class="kt">double</span><span class="o">[]{</span><span class="mf">1.0</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">})),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">2</span><span class="o">,</span> <span class="n">Vectors</span><span class="o">.</span><span class="na">sparse</span><span class="o">(</span><span class="mi">6</span><span class="o">,</span> <span class="k">new</span> <span class="kt">int</span><span class="o">[]{</span><span class="mi">1</span><span class="o">,</span> <span class="mi">2</span><span class="o">,</span> <span class="mi">4</span><span class="o">},</span> <span class="k">new</span> <span class="kt">double</span><span class="o">[]{</span><span class="mf">1.0</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">}))</span>
<span class="o">);</span>

<span class="n">StructType</span> <span class="n">schema</span> <span class="o">=</span> <span class="k">new</span> <span class="n">StructType</span><span class="o">(</span><span class="k">new</span> <span class="n">StructField</span><span class="o">[]{</span>
  <span class="k">new</span> <span class="n">StructField</span><span class="o">(</span><span class="s">&quot;id&quot;</span><span class="o">,</span> <span class="n">DataTypes</span><span class="o">.</span><span class="na">IntegerType</span><span class="o">,</span> <span class="kc">false</span><span class="o">,</span> <span class="n">Metadata</span><span class="o">.</span><span class="na">empty</span><span class="o">()),</span>
  <span class="k">new</span> <span class="n">StructField</span><span class="o">(</span><span class="s">&quot;features&quot;</span><span class="o">,</span> <span class="k">new</span> <span class="n">VectorUDT</span><span class="o">(),</span> <span class="kc">false</span><span class="o">,</span> <span class="n">Metadata</span><span class="o">.</span><span class="na">empty</span><span class="o">())</span>
<span class="o">});</span>
<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">dfA</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="na">createDataFrame</span><span class="o">(</span><span class="n">dataA</span><span class="o">,</span> <span class="n">schema</span><span class="o">);</span>
<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">dfB</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="na">createDataFrame</span><span class="o">(</span><span class="n">dataB</span><span class="o">,</span> <span class="n">schema</span><span class="o">);</span>

<span class="kt">int</span><span class="o">[]</span> <span class="n">indices</span> <span class="o">=</span> <span class="o">{</span><span class="mi">1</span><span class="o">,</span> <span class="mi">3</span><span class="o">};</span>
<span class="kt">double</span><span class="o">[]</span> <span class="n">values</span> <span class="o">=</span> <span class="o">{</span><span class="mf">1.0</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">};</span>
<span class="n">Vector</span> <span class="n">key</span> <span class="o">=</span> <span class="n">Vectors</span><span class="o">.</span><span class="na">sparse</span><span class="o">(</span><span class="mi">6</span><span class="o">,</span> <span class="n">indices</span><span class="o">,</span> <span class="n">values</span><span class="o">);</span>

<span class="n">MinHashLSH</span> <span class="n">mh</span> <span class="o">=</span> <span class="k">new</span> <span class="n">MinHashLSH</span><span class="o">()</span>
  <span class="o">.</span><span class="na">setNumHashTables</span><span class="o">(</span><span class="mi">5</span><span class="o">)</span>
  <span class="o">.</span><span class="na">setInputCol</span><span class="o">(</span><span class="s">&quot;features&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">setOutputCol</span><span class="o">(</span><span class="s">&quot;hashes&quot;</span><span class="o">);</span>

<span class="n">MinHashLSHModel</span> <span class="n">model</span> <span class="o">=</span> <span class="n">mh</span><span class="o">.</span><span class="na">fit</span><span class="o">(</span><span class="n">dfA</span><span class="o">);</span>

<span class="c1">// Feature Transformation</span>
<span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">&quot;The hashed dataset where hashed values are stored in the column &#39;hashes&#39;:&quot;</span><span class="o">);</span>
<span class="n">model</span><span class="o">.</span><span class="na">transform</span><span class="o">(</span><span class="n">dfA</span><span class="o">).</span><span class="na">show</span><span class="o">();</span>

<span class="c1">// Compute the locality sensitive hashes for the input rows, then perform approximate</span>
<span class="c1">// similarity join.</span>
<span class="c1">// We could avoid computing hashes by passing in the already-transformed dataset, e.g.</span>
<span class="c1">// `model.approxSimilarityJoin(transformedA, transformedB, 0.6)`</span>
<span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">&quot;Approximately joining dfA and dfB on Jaccard distance smaller than 0.6:&quot;</span><span class="o">);</span>
<span class="n">model</span><span class="o">.</span><span class="na">approxSimilarityJoin</span><span class="o">(</span><span class="n">dfA</span><span class="o">,</span> <span class="n">dfB</span><span class="o">,</span> <span class="mf">0.6</span><span class="o">,</span> <span class="s">&quot;JaccardDistance&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">select</span><span class="o">(</span><span class="n">col</span><span class="o">(</span><span class="s">&quot;datasetA.id&quot;</span><span class="o">).</span><span class="na">alias</span><span class="o">(</span><span class="s">&quot;idA&quot;</span><span class="o">),</span>
    <span class="n">col</span><span class="o">(</span><span class="s">&quot;datasetB.id&quot;</span><span class="o">).</span><span class="na">alias</span><span class="o">(</span><span class="s">&quot;idB&quot;</span><span class="o">),</span>
    <span class="n">col</span><span class="o">(</span><span class="s">&quot;JaccardDistance&quot;</span><span class="o">)).</span><span class="na">show</span><span class="o">();</span>

<span class="c1">// Compute the locality sensitive hashes for the input rows, then perform approximate nearest</span>
<span class="c1">// neighbor search.</span>
<span class="c1">// We could avoid computing hashes by passing in the already-transformed dataset, e.g.</span>
<span class="c1">// `model.approxNearestNeighbors(transformedA, key, 2)`</span>
<span class="c1">// It may return less than 2 rows when not enough approximate near-neighbor candidates are</span>
<span class="c1">// found.</span>
<span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">&quot;Approximately searching dfA for 2 nearest neighbors of the key:&quot;</span><span class="o">);</span>
<span class="n">model</span><span class="o">.</span><span class="na">approxNearestNeighbors</span><span class="o">(</span><span class="n">dfA</span><span class="o">,</span> <span class="n">key</span><span class="o">,</span> <span class="mi">2</span><span class="o">).</span><span class="na">show</span><span class="o">();</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / java / org / apache / spark / examples / ml / JavaMinHashLSHExample.java”中找到完整的示例代码。</small></div>
  </div>

<div data-lang="python">

    <p>有关API的更多详细信息，请参考<a href="api/python/pyspark.ml.html#pyspark.ml.feature.MinHashLSH">MinHashLSH Python文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pyspark.ml.feature</span> <span class="kn">import</span> <span class="n">MinHashLSH</span>
<span class="kn">from</span> <span class="nn">pyspark.ml.linalg</span> <span class="kn">import</span> <span class="n">Vectors</span>
<span class="kn">from</span> <span class="nn">pyspark.sql.functions</span> <span class="kn">import</span> <span class="n">col</span>

<span class="n">dataA</span> <span class="o">=</span> <span class="p">[(</span><span class="mi">0</span><span class="p">,</span> <span class="n">Vectors</span><span class="o">.</span><span class="n">sparse</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">]),),</span>
         <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">Vectors</span><span class="o">.</span><span class="n">sparse</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">]),),</span>
         <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">Vectors</span><span class="o">.</span><span class="n">sparse</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">]),)]</span>
<span class="n">dfA</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">(</span><span class="n">dataA</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;id&quot;</span><span class="p">,</span> <span class="s2">&quot;features&quot;</span><span class="p">])</span>

<span class="n">dataB</span> <span class="o">=</span> <span class="p">[(</span><span class="mi">3</span><span class="p">,</span> <span class="n">Vectors</span><span class="o">.</span><span class="n">sparse</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">]),),</span>
         <span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="n">Vectors</span><span class="o">.</span><span class="n">sparse</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">]),),</span>
         <span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="n">Vectors</span><span class="o">.</span><span class="n">sparse</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">]),)]</span>
<span class="n">dfB</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">(</span><span class="n">dataB</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;id&quot;</span><span class="p">,</span> <span class="s2">&quot;features&quot;</span><span class="p">])</span>

<span class="n">key</span> <span class="o">=</span> <span class="n">Vectors</span><span class="o">.</span><span class="n">sparse</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">])</span>

<span class="n">mh</span> <span class="o">=</span> <span class="n">MinHashLSH</span><span class="p">(</span><span class="n">inputCol</span><span class="o">=</span><span class="s2">&quot;features&quot;</span><span class="p">,</span> <span class="n">outputCol</span><span class="o">=</span><span class="s2">&quot;hashes&quot;</span><span class="p">,</span> <span class="n">numHashTables</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">mh</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">dfA</span><span class="p">)</span>

<span class="c1"># Feature Transformation</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&quot;The hashed dataset where hashed values are stored in the column &#39;hashes&#39;:&quot;</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">dfA</span><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Compute the locality sensitive hashes for the input rows, then perform approximate</span>
<span class="c1"># similarity join.</span>
<span class="c1"># We could avoid computing hashes by passing in the already-transformed dataset, e.g.</span>
<span class="c1"># `model.approxSimilarityJoin(transformedA, transformedB, 0.6)`</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&quot;Approximately joining dfA and dfB on distance smaller than 0.6:&quot;</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">approxSimilarityJoin</span><span class="p">(</span><span class="n">dfA</span><span class="p">,</span> <span class="n">dfB</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">,</span> <span class="n">distCol</span><span class="o">=</span><span class="s2">&quot;JaccardDistance&quot;</span><span class="p">)</span>\
    <span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;datasetA.id&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s2">&quot;idA&quot;</span><span class="p">),</span>
            <span class="n">col</span><span class="p">(</span><span class="s2">&quot;datasetB.id&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s2">&quot;idB&quot;</span><span class="p">),</span>
            <span class="n">col</span><span class="p">(</span><span class="s2">&quot;JaccardDistance&quot;</span><span class="p">))</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Compute the locality sensitive hashes for the input rows, then perform approximate nearest</span>
<span class="c1"># neighbor search.</span>
<span class="c1"># We could avoid computing hashes by passing in the already-transformed dataset, e.g.</span>
<span class="c1"># `model.approxNearestNeighbors(transformedA, key, 2)`</span>
<span class="c1"># It may return less than 2 rows when not enough approximate near-neighbor candidates are</span>
<span class="c1"># found.</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&quot;Approximately searching dfA for 2 nearest neighbors of the key:&quot;</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">approxNearestNeighbors</span><span class="p">(</span><span class="n">dfA</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / python / ml / min_hash_lsh_example.py”中找到完整的示例代码。</small></div>
  </div>
</div>


                </div>
            
             <!-- /container -->
        </div>

        <script src="js/vendor/jquery-3.4.1.min.js"></script>
        <script src="js/vendor/bootstrap.min.js"></script>
        <script src="js/vendor/anchor.min.js"></script>
        <script src="js/main.js"></script>

        <!-- MathJax Section -->
        <script type="text/x-mathjax-config">
            MathJax.Hub.Config({
                TeX: { equationNumbers: { autoNumber: "AMS" } }
            });
        </script>
        <script>
            // Note that we load MathJax this way to work with local file (file://), HTTP and HTTPS.
            // We could use "//cdn.mathjax...", but that won't support "file://".
            (function(d, script) {
                script = d.createElement('script');
                script.type = 'text/javascript';
                script.async = true;
                script.onload = function(){
                    MathJax.Hub.Config({
                        tex2jax: {
                            inlineMath: [ ["$", "$"], ["\\\\(","\\\\)"] ],
                            displayMath: [ ["$$","$$"], ["\\[", "\\]"] ],
                            processEscapes: true,
                            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre']
                        }
                    });
                };
                script.src = ('https:' == document.location.protocol ? 'https://' : 'http://') +
                    'cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js' +
                    '?config=TeX-AMS-MML_HTMLorMML';
                d.getElementsByTagName('head')[0].appendChild(script);
            }(document));
        </script>
    

</body></html>