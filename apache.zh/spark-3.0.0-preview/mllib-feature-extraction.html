<html class="no-js" ><!--<![endif]--><head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
        <title>特征提取和转换-基于RDD的API-Spark 3.0.0-预览文档</title>
        

        

        <link rel="stylesheet" href="css/bootstrap.min.css">
        <style>
            body {
                padding-top: 60px;
                padding-bottom: 40px;
            }
        </style>
        <meta name="viewport" content="width=device-width">
        <link rel="stylesheet" href="css/bootstrap-responsive.min.css">
        <link rel="stylesheet" href="css/main.css">

        <script src="js/vendor/modernizr-2.6.1-respond-1.1.0.min.js"></script>

        <link rel="stylesheet" href="css/pygments-default.css">

        
        <!-- Google analytics script -->
        <script type="text/javascript">
          var _gaq = _gaq || [];
          _gaq.push(['_setAccount', 'UA-32518208-2']);
          _gaq.push(['_trackPageview']);

          (function() {
            var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
            ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
            var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
          })();
        </script>
        

    </head>
    <body >
        <!--[if lt IE 7]>
            <p class="chromeframe">You are using an outdated browser. <a href="https://browsehappy.com/">Upgrade your browser today</a> or <a href="http://www.google.com/chromeframe/?redirect=true">install Google Chrome Frame</a> to better experience this site.</p>
        <![endif]-->

        <!-- This code is taken from http://twitter.github.com/bootstrap/examples/hero.html -->

        <div class="navbar navbar-fixed-top" id="topbar">
            <div class="navbar-inner">
                <div class="container">
                    <div class="brand"><a href="index.html"><img src="img/spark-logo-hd.png" style="height:50px"></a> <span class="version">3.0.0预览版</span>
                    </div>
                    <ul class="nav">
                        <!--TODO(andyk): Add class="active" attribute to li some how.-->
                        <li><a href="index.html">总览</a></li>

                        <li class="dropdown">
                            <a href="#" class="dropdown-toggle" data-toggle="dropdown">编程指南<b class="caret"></b></a>
                            <ul class="dropdown-menu">
                                <li><a href="quick-start.html">快速开始</a></li>
                                <li><a href="rdd-programming-guide.html">RDD，累加器，广播变量</a></li>
                                <li><a href="sql-programming-guide.html">SQL，数据框和数据集</a></li>
                                <li><a href="structured-streaming-programming-guide.html">结构化流</a></li>
                                <li><a href="streaming-programming-guide.html">火花流（DStreams）</a></li>
                                <li><a href="ml-guide.html">MLlib（机器学习）</a></li>
                                <li><a href="graphx-programming-guide.html">GraphX（图形处理）</a></li>
                                <li><a href="sparkr.html">SparkR（Spark上的R）</a></li>
                            </ul>
                        </li>

                        <li class="dropdown">
                            <a href="#" class="dropdown-toggle" data-toggle="dropdown">API文件<b class="caret"></b></a>
                            <ul class="dropdown-menu">
                                <li><a href="api/scala/index.html#org.apache.spark.package">斯卡拉</a></li>
                                <li><a href="api/java/index.html">爪哇</a></li>
                                <li><a href="api/python/index.html">蟒蛇</a></li>
                                <li><a href="api/R/index.html">[R</a></li>
                                <li><a href="api/sql/index.html">SQL，内置函数</a></li>
                            </ul>
                        </li>

                        <li class="dropdown">
                            <a href="#" class="dropdown-toggle" data-toggle="dropdown">部署中<b class="caret"></b></a>
                            <ul class="dropdown-menu">
                                <li><a href="cluster-overview.html">总览</a></li>
                                <li><a href="submitting-applications.html">提交申请</a></li>
                                <li class="divider"></li>
                                <li><a href="spark-standalone.html">Spark独立</a></li>
                                <li><a href="running-on-mesos.html">梅索斯</a></li>
                                <li><a href="running-on-yarn.html">纱</a></li>
                                <li><a href="running-on-kubernetes.html">Kubernetes</a></li>
                            </ul>
                        </li>

                        <li class="dropdown">
                            <a href="api.html" class="dropdown-toggle" data-toggle="dropdown">更多<b class="caret"></b></a>
                            <ul class="dropdown-menu">
                                <li><a href="configuration.html">组态</a></li>
                                <li><a href="monitoring.html">监控方式</a></li>
                                <li><a href="tuning.html">调音指南</a></li>
                                <li><a href="job-scheduling.html">作业调度</a></li>
                                <li><a href="security.html">安全</a></li>
                                <li><a href="hardware-provisioning.html">硬件配置</a></li>
                                <li><a href="migration-guide.html">迁移指南</a></li>
                                <li class="divider"></li>
                                <li><a href="building-spark.html">建筑火花</a></li>
                                <li><a href="https://spark.apache.org/contributing.html">为Spark贡献</a></li>
                                <li><a href="https://spark.apache.org/third-party-projects.html">第三方项目</a></li>
                            </ul>
                        </li>
                    </ul>
                    <!--<p class="navbar-text pull-right"><span class="version-text">v3.0.0-preview</span></p>-->
                </div>
            </div>
        </div>

        <div class="container-wrapper">

            
                
                    <div class="left-menu-wrapper">
    <div class="left-menu">
        <h3><a href="ml-guide.html">MLlib：主要指南</a></h3>
        
<ul>

    <li>
        <a href="ml-statistics.html">基本统计</a>
    </li>
    
    

    <li>
        <a href="ml-datasource.html">数据源</a>
    </li>
    
    

    <li>
        <a href="ml-pipeline.html">流水线</a>
    </li>
    
    

    <li>
        <a href="ml-features.html">提取，转换和选择特征</a>
    </li>
    
    

    <li>
        <a href="ml-classification-regression.html">分类与回归</a>
    </li>
    
    

    <li>
        <a href="ml-clustering.html">聚类</a>
    </li>
    
    

    <li>
        <a href="ml-collaborative-filtering.html">协同过滤</a>
    </li>
    
    

    <li>
        <a href="ml-frequent-pattern-mining.html">频繁模式挖掘</a>
    </li>
    
    

    <li>
        <a href="ml-tuning.html">模型选择和调整</a>
    </li>
    
    

    <li>
        <a href="ml-advanced.html">进阶主题</a>
    </li>
    
    

</ul>

        <h3><a href="mllib-guide.html">MLlib：基于RDD的API指南</a></h3>
        
<ul>

    <li>
        <a href="mllib-data-types.html">资料类型</a>
    </li>
    
    

    <li>
        <a href="mllib-statistics.html">基本统计</a>
    </li>
    
    

    <li>
        <a href="mllib-classification-regression.html">分类与回归</a>
    </li>
    
    

    <li>
        <a href="mllib-collaborative-filtering.html">协同过滤</a>
    </li>
    
    

    <li>
        <a href="mllib-clustering.html">聚类</a>
    </li>
    
    

    <li>
        <a href="mllib-dimensionality-reduction.html">降维</a>
    </li>
    
    

    <li>
        <a href="mllib-feature-extraction.html">
            
                <b>特征提取和转换</b>
            
        </a>
    </li>
    
    

    <li>
        <a href="mllib-frequent-pattern-mining.html">频繁模式挖掘</a>
    </li>
    
    

    <li>
        <a href="mllib-evaluation-metrics.html">评估指标</a>
    </li>
    
    

    <li>
        <a href="mllib-pmml-model-export.html">PMML模型导出</a>
    </li>
    
    

    <li>
        <a href="mllib-optimization.html">优化（开发人员）</a>
    </li>
    
    

</ul>

    </div>
</div>
                
                <input id="nav-trigger" class="nav-trigger" type="checkbox" checked>
                <label for="nav-trigger"></label>
                <div class="content-with-sidebar" id="content">
                    
                        <h1 class="title">特征提取和转换-基于RDD的API</h1>
                    

                    <ul id="markdown-toc">
  <li><a href="#tf-idf" id="markdown-toc-tf-idf">特遣部队</a></li>
  <li><a href="#word2vec" id="markdown-toc-word2vec">Word2Vec</a>    <ul>
      <li><a href="#model" id="markdown-toc-model">模型</a></li>
      <li><a href="#example" id="markdown-toc-example">例</a></li>
    </ul>
  </li>
  <li><a href="#standardscaler" id="markdown-toc-standardscaler">标准缩放器</a>    <ul>
      <li><a href="#model-fitting" id="markdown-toc-model-fitting">模型拟合</a></li>
      <li><a href="#example-1" id="markdown-toc-example-1">例</a></li>
    </ul>
  </li>
  <li><a href="#normalizer" id="markdown-toc-normalizer">归一化</a>    <ul>
      <li><a href="#example-2" id="markdown-toc-example-2">例</a></li>
    </ul>
  </li>
  <li><a href="#chisqselector" id="markdown-toc-chisqselector">ChiSqSelector</a>    <ul>
      <li><a href="#model-fitting-1" id="markdown-toc-model-fitting-1">模型拟合</a></li>
      <li><a href="#example-3" id="markdown-toc-example-3">例</a></li>
    </ul>
  </li>
  <li><a href="#elementwiseproduct" id="markdown-toc-elementwiseproduct">Elementwise产品</a>    <ul>
      <li><a href="#example-4" id="markdown-toc-example-4">例</a></li>
    </ul>
  </li>
  <li><a href="#pca" id="markdown-toc-pca">PCA</a></li>
</ul>

<h2 id="tf-idf">特遣部队</h2>

<p><strong>注意</strong>我们建议您使用基于DataFrame的API，该API <a href="ml-features.html#tf-idf">在TF-IDF</a>的<a href="ml-features.html#tf-idf">ML用户指南中</a>有详细介绍。</p>

<p><a href="http://en.wikipedia.org/wiki/Tf%E2%80%93idf">术语频率逆文档频率（TF-IDF）</a>是一种特征向量化方法，广泛用于文本挖掘中，以反映术语对语料库中文档的重要性。用一个词来表示<code>$t$</code> ，文档由<code>$d$</code>和语料库<code>$D$</code> 。词频<code>$TF(t, d)$</code>是该词的次数<code>$t$</code>出现在文件中<code>$d$</code> ，而文件频率<code>$DF(t, D)$</code>是包含术语的文档数<code>$t$</code> 。如果我们仅使用术语频率来衡量重要性，那么过分强调那些经常出现但携带很少有关文档信息的术语是很容易的，例如“ a”，“ the”和“ of”。如果术语经常出现在整个语料库中，则表示该术语不包含有关特定文档的特殊信息。反向文档频率是一个术语提供多少信息的数字度量： <code>\[ IDF(t, D) = \log \frac{|D| + 1}{DF(t, D) + 1}, \]</code>哪里<code>$|D|$</code>是语料库中文档的总数。由于使用对数，因此如果一个术语出现在所有文档中，则其IDF值将变为0。请注意，应用了平滑项来避免对主体外的项除以零。TF-IDF度量只是TF和IDF的乘积： <code>\[ TFIDF(t, d, D) = TF(t, d) \cdot IDF(t, D). \]</code>术语频率和文档频率的定义有几种变体。在<code>spark.mllib</code> ，我们将TF和IDF分开以使其更加灵活。</p>

<p>我们对术语频率的实现利用了<a href="http://en.wikipedia.org/wiki/Feature_hashing">哈希技巧</a> 。通过应用哈希函数将原始特征映射到索引（项）。然后根据映射的索引计算词频。这种方法避免了需要计算全局项到索引图的情况，这对于大型语料库可能是昂贵的，但是它会遭受潜在的哈希冲突，即哈希后不同的原始特征可能变成相同的术语。为了减少冲突的机会，我们可以增加目标特征的维数，即哈希表的存储桶数。默认特征尺寸为<code>$2^{20} = 1,048,576$</code> 。</p>

<p><strong>注意：</strong> <code>spark.mllib</code>不提供用于文本分割的工具。我们将用户推荐给<a href="http://nlp.stanford.edu/">Stanford NLP Group</a>和<a href="https://github.com/scalanlp/chalk">scalanlp / chalk</a> 。</p>

<div class="codetabs">
<div data-lang="scala">

    <p>TF和IDF在<a href="api/scala/index.html#org.apache.spark.mllib.feature.HashingTF">HashingTF</a>和<a href="api/scala/index.html#org.apache.spark.mllib.feature.IDF">IDF</a>中实现。 <code>HashingTF</code>需要一个<code>RDD[Iterable[_]]</code>作为输入。每个记录可以是字符串的迭代形式或其他类型。</p>

    <p>请参阅<a href="api/scala/index.html#org.apache.spark.mllib.feature.HashingTF"><code>HashingTF</code></a>有关API的详细信息，请参见<a href="api/scala/index.html#org.apache.spark.mllib.feature.HashingTF">Scala文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">org.apache.spark.mllib.feature.</span><span class="o">{</span><span class="nc">HashingTF</span><span class="o">,</span> <span class="nc">IDF</span><span class="o">}</span>
<span class="k">import</span> <span class="nn">org.apache.spark.mllib.linalg.Vector</span>
<span class="k">import</span> <span class="nn">org.apache.spark.rdd.RDD</span>

<span class="c1">// Load documents (one per line).</span>
<span class="k">val</span> <span class="n">documents</span><span class="k">:</span> <span class="kt">RDD</span><span class="o">[</span><span class="kt">Seq</span><span class="o">[</span><span class="kt">String</span><span class="o">]]</span> <span class="k">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">textFile</span><span class="o">(</span><span class="s">&quot;data/mllib/kmeans_data.txt&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="k">_</span><span class="o">.</span><span class="n">split</span><span class="o">(</span><span class="s">&quot; &quot;</span><span class="o">).</span><span class="n">toSeq</span><span class="o">)</span>

<span class="k">val</span> <span class="n">hashingTF</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">HashingTF</span><span class="o">()</span>
<span class="k">val</span> <span class="n">tf</span><span class="k">:</span> <span class="kt">RDD</span><span class="o">[</span><span class="kt">Vector</span><span class="o">]</span> <span class="k">=</span> <span class="n">hashingTF</span><span class="o">.</span><span class="n">transform</span><span class="o">(</span><span class="n">documents</span><span class="o">)</span>

<span class="c1">// While applying HashingTF only needs a single pass to the data, applying IDF needs two passes:</span>
<span class="c1">// First to compute the IDF vector and second to scale the term frequencies by IDF.</span>
<span class="n">tf</span><span class="o">.</span><span class="n">cache</span><span class="o">()</span>
<span class="k">val</span> <span class="n">idf</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">IDF</span><span class="o">().</span><span class="n">fit</span><span class="o">(</span><span class="n">tf</span><span class="o">)</span>
<span class="k">val</span> <span class="n">tfidf</span><span class="k">:</span> <span class="kt">RDD</span><span class="o">[</span><span class="kt">Vector</span><span class="o">]</span> <span class="k">=</span> <span class="n">idf</span><span class="o">.</span><span class="n">transform</span><span class="o">(</span><span class="n">tf</span><span class="o">)</span>

<span class="c1">// spark.mllib IDF implementation provides an option for ignoring terms which occur in less than</span>
<span class="c1">// a minimum number of documents. In such cases, the IDF for these terms is set to 0.</span>
<span class="c1">// This feature can be used by passing the minDocFreq value to the IDF constructor.</span>
<span class="k">val</span> <span class="n">idfIgnore</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">IDF</span><span class="o">(</span><span class="n">minDocFreq</span> <span class="k">=</span> <span class="mi">2</span><span class="o">).</span><span class="n">fit</span><span class="o">(</span><span class="n">tf</span><span class="o">)</span>
<span class="k">val</span> <span class="n">tfidfIgnore</span><span class="k">:</span> <span class="kt">RDD</span><span class="o">[</span><span class="kt">Vector</span><span class="o">]</span> <span class="k">=</span> <span class="n">idfIgnore</span><span class="o">.</span><span class="n">transform</span><span class="o">(</span><span class="n">tf</span><span class="o">)</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / scala / org / apache / spark / examples / mllib / TFIDFExample.scala”中找到完整的示例代码。</small></div>
  </div>
<div data-lang="python">

    <p>TF和IDF在<a href="api/python/pyspark.mllib.html#pyspark.mllib.feature.HashingTF">HashingTF</a>和<a href="api/python/pyspark.mllib.html#pyspark.mllib.feature.IDF">IDF</a>中实现。 <code>HashingTF</code>将列表的RDD作为输入。每个记录可以是字符串的迭代形式或其他类型。</p>

    <p>请参阅<a href="api/python/pyspark.mllib.html#pyspark.mllib.feature.HashingTF"><code>HashingTF</code></a>有关该API的详细信息的<a href="api/python/pyspark.mllib.html#pyspark.mllib.feature.HashingTF">Python文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pyspark.mllib.feature</span> <span class="kn">import</span> <span class="n">HashingTF</span><span class="p">,</span> <span class="n">IDF</span>

<span class="c1"># Load documents (one per line).</span>
<span class="n">documents</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">textFile</span><span class="p">(</span><span class="s2">&quot;data/mllib/kmeans_data.txt&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">line</span><span class="p">:</span> <span class="n">line</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="p">))</span>

<span class="n">hashingTF</span> <span class="o">=</span> <span class="n">HashingTF</span><span class="p">()</span>
<span class="n">tf</span> <span class="o">=</span> <span class="n">hashingTF</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">documents</span><span class="p">)</span>

<span class="c1"># While applying HashingTF only needs a single pass to the data, applying IDF needs two passes:</span>
<span class="c1"># First to compute the IDF vector and second to scale the term frequencies by IDF.</span>
<span class="n">tf</span><span class="o">.</span><span class="n">cache</span><span class="p">()</span>
<span class="n">idf</span> <span class="o">=</span> <span class="n">IDF</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">tf</span><span class="p">)</span>
<span class="n">tfidf</span> <span class="o">=</span> <span class="n">idf</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">tf</span><span class="p">)</span>

<span class="c1"># spark.mllib&#39;s IDF implementation provides an option for ignoring terms</span>
<span class="c1"># which occur in less than a minimum number of documents.</span>
<span class="c1"># In such cases, the IDF for these terms is set to 0.</span>
<span class="c1"># This feature can be used by passing the minDocFreq value to the IDF constructor.</span>
<span class="n">idfIgnore</span> <span class="o">=</span> <span class="n">IDF</span><span class="p">(</span><span class="n">minDocFreq</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">tf</span><span class="p">)</span>
<span class="n">tfidfIgnore</span> <span class="o">=</span> <span class="n">idfIgnore</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">tf</span><span class="p">)</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / python / mllib / tf_idf_example.py”中找到完整的示例代码。</small></div>
  </div>
</div>

<h2 id="word2vec">Word2Vec</h2>

<p><a href="https://code.google.com/p/word2vec/">Word2Vec</a>计算单词的分布式矢量表示。分布式表示的主要优点是向量空间中相似的词很接近，这使得对新颖模式的泛化更加容易，并且模型估计更加可靠。分布式矢量表示被证明在许多自然语言处理应用程序中很有用，例如命名实体识别，歧义消除，解析，标记和机器翻译。</p>

<h3 id="model">模型</h3>

<p>在Word2Vec的实现中，我们使用了跳过语法模型。跳过语法的训练目标是学习能够很好地预测同一句子中上下文的单词向量表示。数学上，给出一系列训练词<code>$w_1, w_2, \dots, w_T$</code> ，跳过文法模型的目标是最大化平均对数似然率<code>\[ \frac{1}{T} \sum_{t = 1}^{T}\sum_{j=-k}^{j=k} \log p(w_{t+j} | w_t) \]</code>其中$ k $是训练窗口的大小。</p>

<p>在跳过语法模型中，每个单词$ w $与两个向量$ u_w $和$ v_w $相关联，这两个向量分别是$ w $作为单词和上下文的向量表示。给定单词$ w_j $正确预测单词$ w_i $的概率由softmax模型确定，即<code>\[ p(w_i | w_j ) = \frac{\exp(u_{w_i}^{\top}v_{w_j})}{\sum_{l=1}^{V} \exp(u_l^{\top}v_{w_j})} \]</code>其中$ V $是词汇量。</p>

<p>使用softmax的跳过语法模型非常昂贵，因为计算$ \ log p（w_i | w_j）$的成本与$ V $成正比，这很容易达到数百万美元的数量级。为了加快Word2Vec的训练速度，我们使用了层次化softmax，将$ \ log p（w_i | w_j）$的计算复杂度降低为$ O（\ log（V））$。</p>

<h3 id="example">例</h3>

<p>下面的示例演示了如何加载文本文件，将其解析为RDD <code>Seq[String]</code> ，构造一个<code>Word2Vec</code>实例，然后适合<code>Word2VecModel</code>输入的数据。最后，我们显示指定单词的前40个同义词。要运行该示例，请首先下载<a href="http://mattmahoney.net/dc/text8.zip">text8</a>数据并将其提取到您的首选目录中。这里我们假设提取的文件是<code>text8</code>并在与运行spark shell相同的目录中。</p>

<div class="codetabs">
<div data-lang="scala">
    <p>请参阅<a href="api/scala/index.html#org.apache.spark.mllib.feature.Word2Vec"><code>Word2Vec</code></a>有关API的详细信息，请参见<a href="api/scala/index.html#org.apache.spark.mllib.feature.Word2Vec">Scala文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">org.apache.spark.mllib.feature.</span><span class="o">{</span><span class="nc">Word2Vec</span><span class="o">,</span> <span class="nc">Word2VecModel</span><span class="o">}</span>

<span class="k">val</span> <span class="n">input</span> <span class="k">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">textFile</span><span class="o">(</span><span class="s">&quot;data/mllib/sample_lda_data.txt&quot;</span><span class="o">).</span><span class="n">map</span><span class="o">(</span><span class="n">line</span> <span class="k">=&gt;</span> <span class="n">line</span><span class="o">.</span><span class="n">split</span><span class="o">(</span><span class="s">&quot; &quot;</span><span class="o">).</span><span class="n">toSeq</span><span class="o">)</span>

<span class="k">val</span> <span class="n">word2vec</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Word2Vec</span><span class="o">()</span>

<span class="k">val</span> <span class="n">model</span> <span class="k">=</span> <span class="n">word2vec</span><span class="o">.</span><span class="n">fit</span><span class="o">(</span><span class="n">input</span><span class="o">)</span>

<span class="k">val</span> <span class="n">synonyms</span> <span class="k">=</span> <span class="n">model</span><span class="o">.</span><span class="n">findSynonyms</span><span class="o">(</span><span class="s">&quot;1&quot;</span><span class="o">,</span> <span class="mi">5</span><span class="o">)</span>

<span class="k">for</span><span class="o">((</span><span class="n">synonym</span><span class="o">,</span> <span class="n">cosineSimilarity</span><span class="o">)</span> <span class="k">&lt;-</span> <span class="n">synonyms</span><span class="o">)</span> <span class="o">{</span>
  <span class="n">println</span><span class="o">(</span><span class="s">s&quot;</span><span class="si">$synonym</span><span class="s"> </span><span class="si">$cosineSimilarity</span><span class="s">&quot;</span><span class="o">)</span>
<span class="o">}</span>

<span class="c1">// Save and load model</span>
<span class="n">model</span><span class="o">.</span><span class="n">save</span><span class="o">(</span><span class="n">sc</span><span class="o">,</span> <span class="s">&quot;myModelPath&quot;</span><span class="o">)</span>
<span class="k">val</span> <span class="n">sameModel</span> <span class="k">=</span> <span class="nc">Word2VecModel</span><span class="o">.</span><span class="n">load</span><span class="o">(</span><span class="n">sc</span><span class="o">,</span> <span class="s">&quot;myModelPath&quot;</span><span class="o">)</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / scala / org / apache / spark / examples / mllib / Word2VecExample.scala”中找到完整的示例代码。</small></div>
  </div>
<div data-lang="python">
    <p>请参阅<a href="api/python/pyspark.mllib.html#pyspark.mllib.feature.Word2Vec"><code>Word2Vec</code></a>有关该API的更多详细信息的<a href="api/python/pyspark.mllib.html#pyspark.mllib.feature.Word2Vec">Python文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pyspark.mllib.feature</span> <span class="kn">import</span> <span class="n">Word2Vec</span>

<span class="n">inp</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">textFile</span><span class="p">(</span><span class="s2">&quot;data/mllib/sample_lda_data.txt&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">row</span><span class="p">:</span> <span class="n">row</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="p">))</span>

<span class="n">word2vec</span> <span class="o">=</span> <span class="n">Word2Vec</span><span class="p">()</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">word2vec</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">inp</span><span class="p">)</span>

<span class="n">synonyms</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">findSynonyms</span><span class="p">(</span><span class="s1">&#39;1&#39;</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>

<span class="k">for</span> <span class="n">word</span><span class="p">,</span> <span class="n">cosine_distance</span> <span class="ow">in</span> <span class="n">synonyms</span><span class="p">:</span>
    <span class="k">print</span><span class="p">(</span><span class="s2">&quot;{}: {}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">word</span><span class="p">,</span> <span class="n">cosine_distance</span><span class="p">))</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / python / mllib / word2vec_example.py”中找到完整的示例代码。</small></div>
  </div>
</div>

<h2 id="standardscaler">标准缩放器</h2>

<p>通过缩放到单位方差和/或使用训练集中样本上的列摘要统计信息去除均值来对特征进行标准化。这是非常常见的预处理步骤。</p>

<p>例如，当所有特征均具有单位方差和/或均值为零时，支持向量机的RBF内核或L1和L2正则化线性模型通常会更好地工作。</p>

<p>标准化可以提高优化过程中的收敛速度，还可以防止差异很大的特征在模型训练期间产生过大的影响。</p>

<h3 id="model-fitting">模型拟合</h3>

<p><a href="api/scala/index.html#org.apache.spark.mllib.feature.StandardScaler"><code>StandardScaler</code></a>在构造函数中具有以下参数：</p>

<ul>
  <li><code>withMean</code>默认为False。在缩放之前，将数据以均值居中。它将生成密集的输出，因此在应用于稀疏输入时要小心。</li>
  <li><code>withStd</code>默认为True。将数据缩放到单位标准偏差。</li>
</ul>

<p>我们提供<a href="api/scala/index.html#org.apache.spark.mllib.feature.StandardScaler"><code>fit</code></a>方法中<code>StandardScaler</code>可以输入<code>RDD[Vector]</code> ，了解汇总统计信息，然后返回一个模型，该模型可以将输入数据集转换为单位标准差和/或零均值特征，具体取决于我们如何配置<code>StandardScaler</code> 。</p>

<p>该模型实现<a href="api/scala/index.html#org.apache.spark.mllib.feature.VectorTransformer"><code>VectorTransformer</code></a>可以将标准化应用于<code>Vector</code>产生转化<code>Vector</code>或<code>RDD[Vector]</code>产生转化<code>RDD[Vector]</code> 。</p>

<p>请注意，如果要素的方差为零，它将返回默认值<code>0.0</code>的价值<code>Vector</code>该功能。</p>

<h3 id="example-1">例</h3>

<p>下面的示例演示了如何以libsvm格式加载数据集并标准化功能，以便新功能具有单位标准差和/或零均值。</p>

<div class="codetabs">
<div data-lang="scala">
    <p>请参阅<a href="api/scala/index.html#org.apache.spark.mllib.feature.StandardScaler"><code>StandardScaler</code></a>有关API的详细信息，请参见<a href="api/scala/index.html#org.apache.spark.mllib.feature.StandardScaler">Scala文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">org.apache.spark.mllib.feature.</span><span class="o">{</span><span class="nc">StandardScaler</span><span class="o">,</span> <span class="nc">StandardScalerModel</span><span class="o">}</span>
<span class="k">import</span> <span class="nn">org.apache.spark.mllib.linalg.Vectors</span>
<span class="k">import</span> <span class="nn">org.apache.spark.mllib.util.MLUtils</span>

<span class="k">val</span> <span class="n">data</span> <span class="k">=</span> <span class="nc">MLUtils</span><span class="o">.</span><span class="n">loadLibSVMFile</span><span class="o">(</span><span class="n">sc</span><span class="o">,</span> <span class="s">&quot;data/mllib/sample_libsvm_data.txt&quot;</span><span class="o">)</span>

<span class="k">val</span> <span class="n">scaler1</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">StandardScaler</span><span class="o">().</span><span class="n">fit</span><span class="o">(</span><span class="n">data</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="n">x</span> <span class="k">=&gt;</span> <span class="n">x</span><span class="o">.</span><span class="n">features</span><span class="o">))</span>
<span class="k">val</span> <span class="n">scaler2</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">StandardScaler</span><span class="o">(</span><span class="n">withMean</span> <span class="k">=</span> <span class="kc">true</span><span class="o">,</span> <span class="n">withStd</span> <span class="k">=</span> <span class="kc">true</span><span class="o">).</span><span class="n">fit</span><span class="o">(</span><span class="n">data</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="n">x</span> <span class="k">=&gt;</span> <span class="n">x</span><span class="o">.</span><span class="n">features</span><span class="o">))</span>
<span class="c1">// scaler3 is an identical model to scaler2, and will produce identical transformations</span>
<span class="k">val</span> <span class="n">scaler3</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">StandardScalerModel</span><span class="o">(</span><span class="n">scaler2</span><span class="o">.</span><span class="n">std</span><span class="o">,</span> <span class="n">scaler2</span><span class="o">.</span><span class="n">mean</span><span class="o">)</span>

<span class="c1">// data1 will be unit variance.</span>
<span class="k">val</span> <span class="n">data1</span> <span class="k">=</span> <span class="n">data</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="n">x</span> <span class="k">=&gt;</span> <span class="o">(</span><span class="n">x</span><span class="o">.</span><span class="n">label</span><span class="o">,</span> <span class="n">scaler1</span><span class="o">.</span><span class="n">transform</span><span class="o">(</span><span class="n">x</span><span class="o">.</span><span class="n">features</span><span class="o">)))</span>

<span class="c1">// data2 will be unit variance and zero mean.</span>
<span class="k">val</span> <span class="n">data2</span> <span class="k">=</span> <span class="n">data</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="n">x</span> <span class="k">=&gt;</span> <span class="o">(</span><span class="n">x</span><span class="o">.</span><span class="n">label</span><span class="o">,</span> <span class="n">scaler2</span><span class="o">.</span><span class="n">transform</span><span class="o">(</span><span class="nc">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="o">(</span><span class="n">x</span><span class="o">.</span><span class="n">features</span><span class="o">.</span><span class="n">toArray</span><span class="o">))))</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / scala / org / apache / spark / examples / mllib / StandardScalerExample.scala”中找到完整的示例代码。</small></div>
  </div>

<div data-lang="python">
    <p>请参阅<a href="api/python/pyspark.mllib.html#pyspark.mllib.feature.StandardScaler"><code>StandardScaler</code></a>有关该API的更多详细信息的<a href="api/python/pyspark.mllib.html#pyspark.mllib.feature.StandardScaler">Python文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pyspark.mllib.feature</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">from</span> <span class="nn">pyspark.mllib.linalg</span> <span class="kn">import</span> <span class="n">Vectors</span>
<span class="kn">from</span> <span class="nn">pyspark.mllib.util</span> <span class="kn">import</span> <span class="n">MLUtils</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">MLUtils</span><span class="o">.</span><span class="n">loadLibSVMFile</span><span class="p">(</span><span class="n">sc</span><span class="p">,</span> <span class="s2">&quot;data/mllib/sample_libsvm_data.txt&quot;</span><span class="p">)</span>
<span class="n">label</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">label</span><span class="p">)</span>
<span class="n">features</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">features</span><span class="p">)</span>

<span class="n">scaler1</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>
<span class="n">scaler2</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">(</span><span class="n">withMean</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">withStd</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>

<span class="c1"># data1 will be unit variance.</span>
<span class="n">data1</span> <span class="o">=</span> <span class="n">label</span><span class="o">.</span><span class="n">zip</span><span class="p">(</span><span class="n">scaler1</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">features</span><span class="p">))</span>

<span class="c1"># data2 will be unit variance and zero mean.</span>
<span class="n">data2</span> <span class="o">=</span> <span class="n">label</span><span class="o">.</span><span class="n">zip</span><span class="p">(</span><span class="n">scaler2</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">features</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">toArray</span><span class="p">()))))</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / python / mllib / standard_scaler_example.py”中找到完整的示例代码。</small></div>
  </div>
</div>

<h2 id="normalizer">归一化</h2>

<p>归一化器将单个样本缩放为具有单位$ L ^ p $范数。这是文本分类或聚类的常用操作。例如，两个$ L ^ 2 $归一化TF-IDF向量的点积是向量的余弦相似度。</p>

<p><a href="api/scala/index.html#org.apache.spark.mllib.feature.Normalizer"><code>Normalizer</code></a>在构造函数中具有以下参数：</p>

<ul>
  <li><code>p</code>在$ L ^ p $空间中进行规范化，默认情况下$ p = 2 $。</li>
</ul>

<p><code>Normalizer</code>贯彻<a href="api/scala/index.html#org.apache.spark.mllib.feature.VectorTransformer"><code>VectorTransformer</code></a>可以将归一化应用于<code>Vector</code>产生转化<code>Vector</code>或<code>RDD[Vector]</code>产生转化<code>RDD[Vector]</code> 。</p>

<p>请注意，如果输入范数为零，则它将返回输入向量。</p>

<h3 id="example-2">例</h3>

<p>下面的示例演示如何以libsvm格式加载数据集，并使用$ L ^ 2 $规范和$ L ^ \ infty $规范对功能进行规范化。</p>

<div class="codetabs">
<div data-lang="scala">
    <p>请参阅<a href="api/scala/index.html#org.apache.spark.mllib.feature.Normalizer"><code>Normalizer</code></a>有关API的详细信息，请参见<a href="api/scala/index.html#org.apache.spark.mllib.feature.Normalizer">Scala文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">org.apache.spark.mllib.feature.Normalizer</span>
<span class="k">import</span> <span class="nn">org.apache.spark.mllib.util.MLUtils</span>

<span class="k">val</span> <span class="n">data</span> <span class="k">=</span> <span class="nc">MLUtils</span><span class="o">.</span><span class="n">loadLibSVMFile</span><span class="o">(</span><span class="n">sc</span><span class="o">,</span> <span class="s">&quot;data/mllib/sample_libsvm_data.txt&quot;</span><span class="o">)</span>

<span class="k">val</span> <span class="n">normalizer1</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Normalizer</span><span class="o">()</span>
<span class="k">val</span> <span class="n">normalizer2</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Normalizer</span><span class="o">(</span><span class="n">p</span> <span class="k">=</span> <span class="nc">Double</span><span class="o">.</span><span class="nc">PositiveInfinity</span><span class="o">)</span>

<span class="c1">// Each sample in data1 will be normalized using $L^2$ norm.</span>
<span class="k">val</span> <span class="n">data1</span> <span class="k">=</span> <span class="n">data</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="n">x</span> <span class="k">=&gt;</span> <span class="o">(</span><span class="n">x</span><span class="o">.</span><span class="n">label</span><span class="o">,</span> <span class="n">normalizer1</span><span class="o">.</span><span class="n">transform</span><span class="o">(</span><span class="n">x</span><span class="o">.</span><span class="n">features</span><span class="o">)))</span>

<span class="c1">// Each sample in data2 will be normalized using $L^\infty$ norm.</span>
<span class="k">val</span> <span class="n">data2</span> <span class="k">=</span> <span class="n">data</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="n">x</span> <span class="k">=&gt;</span> <span class="o">(</span><span class="n">x</span><span class="o">.</span><span class="n">label</span><span class="o">,</span> <span class="n">normalizer2</span><span class="o">.</span><span class="n">transform</span><span class="o">(</span><span class="n">x</span><span class="o">.</span><span class="n">features</span><span class="o">)))</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / scala / org / apache / spark / examples / mllib / NormalizerExample.scala”中找到完整的示例代码。</small></div>
  </div>

<div data-lang="python">
    <p>请参阅<a href="api/python/pyspark.mllib.html#pyspark.mllib.feature.Normalizer"><code>Normalizer</code></a>有关该API的更多详细信息的<a href="api/python/pyspark.mllib.html#pyspark.mllib.feature.Normalizer">Python文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pyspark.mllib.feature</span> <span class="kn">import</span> <span class="n">Normalizer</span>
<span class="kn">from</span> <span class="nn">pyspark.mllib.util</span> <span class="kn">import</span> <span class="n">MLUtils</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">MLUtils</span><span class="o">.</span><span class="n">loadLibSVMFile</span><span class="p">(</span><span class="n">sc</span><span class="p">,</span> <span class="s2">&quot;data/mllib/sample_libsvm_data.txt&quot;</span><span class="p">)</span>
<span class="n">labels</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">label</span><span class="p">)</span>
<span class="n">features</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">features</span><span class="p">)</span>

<span class="n">normalizer1</span> <span class="o">=</span> <span class="n">Normalizer</span><span class="p">()</span>
<span class="n">normalizer2</span> <span class="o">=</span> <span class="n">Normalizer</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="nb">float</span><span class="p">(</span><span class="s2">&quot;inf&quot;</span><span class="p">))</span>

<span class="c1"># Each sample in data1 will be normalized using $L^2$ norm.</span>
<span class="n">data1</span> <span class="o">=</span> <span class="n">labels</span><span class="o">.</span><span class="n">zip</span><span class="p">(</span><span class="n">normalizer1</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">features</span><span class="p">))</span>

<span class="c1"># Each sample in data2 will be normalized using $L^\infty$ norm.</span>
<span class="n">data2</span> <span class="o">=</span> <span class="n">labels</span><span class="o">.</span><span class="n">zip</span><span class="p">(</span><span class="n">normalizer2</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">features</span><span class="p">))</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / python / mllib / normalizer_example.py”中找到完整的示例代码。</small></div>
  </div>
</div>

<h2 id="chisqselector">ChiSqSelector</h2>

<p><a href="http://en.wikipedia.org/wiki/Feature_selection">特征选择</a>试图识别用于模型构建的相关特征。它减小了特征空间的大小，从而可以提高速度和统计学习行为。</p>

<p><a href="api/scala/index.html#org.apache.spark.mllib.feature.ChiSqSelector"><code>ChiSqSelector</code></a>实现Chi-Squared特征选择。它对具有分类特征的标记数据进行操作。ChiSqSelector使用<a href="https://en.wikipedia.org/wiki/Chi-squared_test">卡方独立性检验</a>来决定选择哪些功能。它支持五种选择方法： <code>numTopFeatures</code> ， <code>percentile</code> ， <code>fpr</code> ， <code>fdr</code> ， <code>fwe</code> ：</p>

<ul>
  <li><code>numTopFeatures</code>根据卡方检验选择固定数量的顶部特征。这类似于产生具有最大预测能力的特征。</li>
  <li><code>percentile</code>类似于<code>numTopFeatures</code>但选择所有功能的一部分而不是固定数量。</li>
  <li><code>fpr</code>选择p值低于阈值的所有特征，从而控制选择的误报率。</li>
  <li><code>fdr</code>使用<a href="https://en.wikipedia.org/wiki/False_discovery_rate#Benjamini.E2.80.93Hochberg_procedure">Benjamini-Hochberg过程</a>选择错误发现率低于阈值的所有特征。</li>
  <li><code>fwe</code>选择p值低于阈值的所有特征。阈值按1 / numFeatures缩放，从而控制选择的家庭式错误率。</li>
</ul>

<p>默认情况下，选择方法是<code>numTopFeatures</code> ，顶部功能的默认数量设置为50。用户可以使用选择选择方法<code>setSelectorType</code> 。</p>

<p>可以使用保留的验证集来调整要选择的功能的数量。</p>

<h3 id="model-fitting-1">模型拟合</h3>

<p>的<a href="api/scala/index.html#org.apache.spark.mllib.feature.ChiSqSelector"><code>fit</code></a>方法需要输入<code>RDD[LabeledPoint]</code>具有分类特征，了解摘要统计信息，然后返回<code>ChiSqSelectorModel</code>可以将输入数据集转换为精简特征空间。的<code>ChiSqSelectorModel</code>可以应用于<code>Vector</code>产生减少<code>Vector</code> ，或<code>RDD[Vector]</code>产生减少<code>RDD[Vector]</code> 。</p>

<p>请注意，用户还可以构造一个<code>ChiSqSelectorModel</code>通过提供一组选定的特征索引（必须按升序排序）来手工创建。</p>

<h3 id="example-3">例</h3>

<p>以下示例显示了ChiSqSelector的基本用法。所使用的数据集具有一个由灰度值组成的特征矩阵，每个值的灰度值从0到255不等。</p>

<div class="codetabs">
<div data-lang="scala">

    <p>请参阅<a href="api/scala/index.html#org.apache.spark.mllib.feature.ChiSqSelector"><code>ChiSqSelector</code></a>有关API的详细信息，请参见<a href="api/scala/index.html#org.apache.spark.mllib.feature.ChiSqSelector">Scala文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">org.apache.spark.mllib.feature.ChiSqSelector</span>
<span class="k">import</span> <span class="nn">org.apache.spark.mllib.linalg.Vectors</span>
<span class="k">import</span> <span class="nn">org.apache.spark.mllib.regression.LabeledPoint</span>
<span class="k">import</span> <span class="nn">org.apache.spark.mllib.util.MLUtils</span>

<span class="c1">// Load some data in libsvm format</span>
<span class="k">val</span> <span class="n">data</span> <span class="k">=</span> <span class="nc">MLUtils</span><span class="o">.</span><span class="n">loadLibSVMFile</span><span class="o">(</span><span class="n">sc</span><span class="o">,</span> <span class="s">&quot;data/mllib/sample_libsvm_data.txt&quot;</span><span class="o">)</span>
<span class="c1">// Discretize data in 16 equal bins since ChiSqSelector requires categorical features</span>
<span class="c1">// Even though features are doubles, the ChiSqSelector treats each unique value as a category</span>
<span class="k">val</span> <span class="n">discretizedData</span> <span class="k">=</span> <span class="n">data</span><span class="o">.</span><span class="n">map</span> <span class="o">{</span> <span class="n">lp</span> <span class="k">=&gt;</span>
  <span class="nc">LabeledPoint</span><span class="o">(</span><span class="n">lp</span><span class="o">.</span><span class="n">label</span><span class="o">,</span> <span class="nc">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="o">(</span><span class="n">lp</span><span class="o">.</span><span class="n">features</span><span class="o">.</span><span class="n">toArray</span><span class="o">.</span><span class="n">map</span> <span class="o">{</span> <span class="n">x</span> <span class="k">=&gt;</span> <span class="o">(</span><span class="n">x</span> <span class="o">/</span> <span class="mi">16</span><span class="o">).</span><span class="n">floor</span> <span class="o">}))</span>
<span class="o">}</span>
<span class="c1">// Create ChiSqSelector that will select top 50 of 692 features</span>
<span class="k">val</span> <span class="n">selector</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">ChiSqSelector</span><span class="o">(</span><span class="mi">50</span><span class="o">)</span>
<span class="c1">// Create ChiSqSelector model (selecting features)</span>
<span class="k">val</span> <span class="n">transformer</span> <span class="k">=</span> <span class="n">selector</span><span class="o">.</span><span class="n">fit</span><span class="o">(</span><span class="n">discretizedData</span><span class="o">)</span>
<span class="c1">// Filter the top 50 features from each feature vector</span>
<span class="k">val</span> <span class="n">filteredData</span> <span class="k">=</span> <span class="n">discretizedData</span><span class="o">.</span><span class="n">map</span> <span class="o">{</span> <span class="n">lp</span> <span class="k">=&gt;</span>
  <span class="nc">LabeledPoint</span><span class="o">(</span><span class="n">lp</span><span class="o">.</span><span class="n">label</span><span class="o">,</span> <span class="n">transformer</span><span class="o">.</span><span class="n">transform</span><span class="o">(</span><span class="n">lp</span><span class="o">.</span><span class="n">features</span><span class="o">))</span>
<span class="o">}</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / scala / org / apache / spark / examples / mllib / ChiSqSelectorExample.scala”中找到完整的示例代码。</small></div>
  </div>

<div data-lang="java">

    <p>请参阅<a href="api/java/org/apache/spark/mllib/feature/ChiSqSelector.html"><code>ChiSqSelector</code></a>有关该API的详细信息的<a href="api/java/org/apache/spark/mllib/feature/ChiSqSelector.html">Java文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">org.apache.spark.api.java.JavaRDD</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.mllib.feature.ChiSqSelector</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.mllib.feature.ChiSqSelectorModel</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.mllib.linalg.Vectors</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.mllib.regression.LabeledPoint</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.mllib.util.MLUtils</span><span class="o">;</span>

<span class="n">JavaRDD</span><span class="o">&lt;</span><span class="n">LabeledPoint</span><span class="o">&gt;</span> <span class="n">points</span> <span class="o">=</span> <span class="n">MLUtils</span><span class="o">.</span><span class="na">loadLibSVMFile</span><span class="o">(</span><span class="n">jsc</span><span class="o">.</span><span class="na">sc</span><span class="o">(),</span>
  <span class="s">&quot;data/mllib/sample_libsvm_data.txt&quot;</span><span class="o">).</span><span class="na">toJavaRDD</span><span class="o">().</span><span class="na">cache</span><span class="o">();</span>

<span class="c1">// Discretize data in 16 equal bins since ChiSqSelector requires categorical features</span>
<span class="c1">// Although features are doubles, the ChiSqSelector treats each unique value as a category</span>
<span class="n">JavaRDD</span><span class="o">&lt;</span><span class="n">LabeledPoint</span><span class="o">&gt;</span> <span class="n">discretizedData</span> <span class="o">=</span> <span class="n">points</span><span class="o">.</span><span class="na">map</span><span class="o">(</span><span class="n">lp</span> <span class="o">-&gt;</span> <span class="o">{</span>
  <span class="kt">double</span><span class="o">[]</span> <span class="n">discretizedFeatures</span> <span class="o">=</span> <span class="k">new</span> <span class="kt">double</span><span class="o">[</span><span class="n">lp</span><span class="o">.</span><span class="na">features</span><span class="o">().</span><span class="na">size</span><span class="o">()];</span>
  <span class="k">for</span> <span class="o">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="o">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">lp</span><span class="o">.</span><span class="na">features</span><span class="o">().</span><span class="na">size</span><span class="o">();</span> <span class="o">++</span><span class="n">i</span><span class="o">)</span> <span class="o">{</span>
    <span class="n">discretizedFeatures</span><span class="o">[</span><span class="n">i</span><span class="o">]</span> <span class="o">=</span> <span class="n">Math</span><span class="o">.</span><span class="na">floor</span><span class="o">(</span><span class="n">lp</span><span class="o">.</span><span class="na">features</span><span class="o">().</span><span class="na">apply</span><span class="o">(</span><span class="n">i</span><span class="o">)</span> <span class="o">/</span> <span class="mi">16</span><span class="o">);</span>
  <span class="o">}</span>
  <span class="k">return</span> <span class="k">new</span> <span class="n">LabeledPoint</span><span class="o">(</span><span class="n">lp</span><span class="o">.</span><span class="na">label</span><span class="o">(),</span> <span class="n">Vectors</span><span class="o">.</span><span class="na">dense</span><span class="o">(</span><span class="n">discretizedFeatures</span><span class="o">));</span>
<span class="o">});</span>

<span class="c1">// Create ChiSqSelector that will select top 50 of 692 features</span>
<span class="n">ChiSqSelector</span> <span class="n">selector</span> <span class="o">=</span> <span class="k">new</span> <span class="n">ChiSqSelector</span><span class="o">(</span><span class="mi">50</span><span class="o">);</span>
<span class="c1">// Create ChiSqSelector model (selecting features)</span>
<span class="n">ChiSqSelectorModel</span> <span class="n">transformer</span> <span class="o">=</span> <span class="n">selector</span><span class="o">.</span><span class="na">fit</span><span class="o">(</span><span class="n">discretizedData</span><span class="o">.</span><span class="na">rdd</span><span class="o">());</span>
<span class="c1">// Filter the top 50 features from each feature vector</span>
<span class="n">JavaRDD</span><span class="o">&lt;</span><span class="n">LabeledPoint</span><span class="o">&gt;</span> <span class="n">filteredData</span> <span class="o">=</span> <span class="n">discretizedData</span><span class="o">.</span><span class="na">map</span><span class="o">(</span><span class="n">lp</span> <span class="o">-&gt;</span>
  <span class="k">new</span> <span class="n">LabeledPoint</span><span class="o">(</span><span class="n">lp</span><span class="o">.</span><span class="na">label</span><span class="o">(),</span> <span class="n">transformer</span><span class="o">.</span><span class="na">transform</span><span class="o">(</span><span class="n">lp</span><span class="o">.</span><span class="na">features</span><span class="o">())));</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / java / org / apache / spark / examples / mllib / JavaChiSqSelectorExample.java”中找到完整的示例代码。</small></div>
  </div>
</div>

<h2 id="elementwiseproduct">Elementwise产品</h2>

<p><code>ElementwiseProduct</code>使用逐元素乘法将每个输入向量与提供的“权重”向量相乘。换句话说，它通过标量乘法器缩放数据集的每一列。这表示输入向量之间的<a href="https://en.wikipedia.org/wiki/Hadamard_product_%28matrices%29">Hadamard乘积</a> ， <code>v</code>和转换向量<code>scalingVec</code> ，以产生结果向量。</p>

<p>表示<code>scalingVec</code>作为“ <code>w</code> ”，则此转换可以写为：</p>

<p><code>\[ \begin{pmatrix} v_1 \\ \vdots \\ v_N \end{pmatrix} \circ \begin{pmatrix} w_1 \\ \vdots \\ w_N \end{pmatrix} = \begin{pmatrix} v_1 w_1 \\ \vdots \\ v_N w_N \end{pmatrix} \]</code></p>

<p><a href="api/scala/index.html#org.apache.spark.mllib.feature.ElementwiseProduct"><code>ElementwiseProduct</code></a>在构造函数中具有以下参数：</p>

<ul>
  <li><code>scalingVec</code> ：转换向量。</li>
</ul>

<p><code>ElementwiseProduct</code>贯彻<a href="api/scala/index.html#org.apache.spark.mllib.feature.VectorTransformer"><code>VectorTransformer</code></a>可以将权重应用于<code>Vector</code>产生转化<code>Vector</code>或<code>RDD[Vector]</code>产生转化<code>RDD[Vector]</code> 。</p>

<h3 id="example-4">例</h3>

<p>下面的示例演示了如何使用转换向量值转换向量。</p>

<div class="codetabs">
<div data-lang="scala">

    <p>请参阅<a href="api/scala/index.html#org.apache.spark.mllib.feature.ElementwiseProduct"><code>ElementwiseProduct</code></a>有关API的详细信息，请参见<a href="api/scala/index.html#org.apache.spark.mllib.feature.ElementwiseProduct">Scala文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">org.apache.spark.mllib.feature.ElementwiseProduct</span>
<span class="k">import</span> <span class="nn">org.apache.spark.mllib.linalg.Vectors</span>

<span class="c1">// Create some vector data; also works for sparse vectors</span>
<span class="k">val</span> <span class="n">data</span> <span class="k">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">parallelize</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="nc">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="o">(</span><span class="mf">1.0</span><span class="o">,</span> <span class="mf">2.0</span><span class="o">,</span> <span class="mf">3.0</span><span class="o">),</span> <span class="nc">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="o">(</span><span class="mf">4.0</span><span class="o">,</span> <span class="mf">5.0</span><span class="o">,</span> <span class="mf">6.0</span><span class="o">)))</span>

<span class="k">val</span> <span class="n">transformingVector</span> <span class="k">=</span> <span class="nc">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="o">(</span><span class="mf">0.0</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">,</span> <span class="mf">2.0</span><span class="o">)</span>
<span class="k">val</span> <span class="n">transformer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">ElementwiseProduct</span><span class="o">(</span><span class="n">transformingVector</span><span class="o">)</span>

<span class="c1">// Batch transform and per-row transform give the same results:</span>
<span class="k">val</span> <span class="n">transformedData</span> <span class="k">=</span> <span class="n">transformer</span><span class="o">.</span><span class="n">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>
<span class="k">val</span> <span class="n">transformedData2</span> <span class="k">=</span> <span class="n">data</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="n">x</span> <span class="k">=&gt;</span> <span class="n">transformer</span><span class="o">.</span><span class="n">transform</span><span class="o">(</span><span class="n">x</span><span class="o">))</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / scala / org / apache / spark / examples / mllib / ElementwiseProductExample.scala”中找到完整的示例代码。</small></div>
  </div>

<div data-lang="java">
    <p>请参阅<a href="api/java/org/apache/spark/mllib/feature/ElementwiseProduct.html"><code>ElementwiseProduct</code></a>有关该API的详细信息的<a href="api/java/org/apache/spark/mllib/feature/ElementwiseProduct.html">Java文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">java.util.Arrays</span><span class="o">;</span>

<span class="kn">import</span> <span class="nn">org.apache.spark.api.java.JavaRDD</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.mllib.feature.ElementwiseProduct</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.mllib.linalg.Vector</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.mllib.linalg.Vectors</span><span class="o">;</span>

<span class="c1">// Create some vector data; also works for sparse vectors</span>
<span class="n">JavaRDD</span><span class="o">&lt;</span><span class="n">Vector</span><span class="o">&gt;</span> <span class="n">data</span> <span class="o">=</span> <span class="n">jsc</span><span class="o">.</span><span class="na">parallelize</span><span class="o">(</span><span class="n">Arrays</span><span class="o">.</span><span class="na">asList</span><span class="o">(</span>
  <span class="n">Vectors</span><span class="o">.</span><span class="na">dense</span><span class="o">(</span><span class="mf">1.0</span><span class="o">,</span> <span class="mf">2.0</span><span class="o">,</span> <span class="mf">3.0</span><span class="o">),</span> <span class="n">Vectors</span><span class="o">.</span><span class="na">dense</span><span class="o">(</span><span class="mf">4.0</span><span class="o">,</span> <span class="mf">5.0</span><span class="o">,</span> <span class="mf">6.0</span><span class="o">)));</span>
<span class="n">Vector</span> <span class="n">transformingVector</span> <span class="o">=</span> <span class="n">Vectors</span><span class="o">.</span><span class="na">dense</span><span class="o">(</span><span class="mf">0.0</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">,</span> <span class="mf">2.0</span><span class="o">);</span>
<span class="n">ElementwiseProduct</span> <span class="n">transformer</span> <span class="o">=</span> <span class="k">new</span> <span class="n">ElementwiseProduct</span><span class="o">(</span><span class="n">transformingVector</span><span class="o">);</span>

<span class="c1">// Batch transform and per-row transform give the same results:</span>
<span class="n">JavaRDD</span><span class="o">&lt;</span><span class="n">Vector</span><span class="o">&gt;</span> <span class="n">transformedData</span> <span class="o">=</span> <span class="n">transformer</span><span class="o">.</span><span class="na">transform</span><span class="o">(</span><span class="n">data</span><span class="o">);</span>
<span class="n">JavaRDD</span><span class="o">&lt;</span><span class="n">Vector</span><span class="o">&gt;</span> <span class="n">transformedData2</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="na">map</span><span class="o">(</span><span class="n">transformer</span><span class="o">::</span><span class="n">transform</span><span class="o">);</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / java / org / apache / spark / examples / mllib / JavaElementwiseProductExample.java”中找到完整的示例代码。</small></div>
  </div>

<div data-lang="python">
    <p>请参阅<a href="api/python/pyspark.mllib.html#pyspark.mllib.feature.ElementwiseProduct"><code>ElementwiseProduct</code></a>有关该API的更多详细信息的<a href="api/python/pyspark.mllib.html#pyspark.mllib.feature.ElementwiseProduct">Python文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pyspark.mllib.feature</span> <span class="kn">import</span> <span class="n">ElementwiseProduct</span>
<span class="kn">from</span> <span class="nn">pyspark.mllib.linalg</span> <span class="kn">import</span> <span class="n">Vectors</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">textFile</span><span class="p">(</span><span class="s2">&quot;data/mllib/kmeans_data.txt&quot;</span><span class="p">)</span>
<span class="n">parsedData</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="p">[</span><span class="nb">float</span><span class="p">(</span><span class="n">t</span><span class="p">)</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">x</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="p">)])</span>

<span class="c1"># Create weight vector.</span>
<span class="n">transformingVector</span> <span class="o">=</span> <span class="n">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">])</span>
<span class="n">transformer</span> <span class="o">=</span> <span class="n">ElementwiseProduct</span><span class="p">(</span><span class="n">transformingVector</span><span class="p">)</span>

<span class="c1"># Batch transform</span>
<span class="n">transformedData</span> <span class="o">=</span> <span class="n">transformer</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">parsedData</span><span class="p">)</span>
<span class="c1"># Single-row transform</span>
<span class="n">transformedData2</span> <span class="o">=</span> <span class="n">transformer</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">parsedData</span><span class="o">.</span><span class="n">first</span><span class="p">())</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / python / mllib / elementwise_product_example.py”中找到完整的示例代码。</small></div>
  </div>
</div>

<h2 id="pca">PCA</h2>

<p>使用PCA将向量投影到低维空间的特征转换器。您可以在<a href="mllib-dimensionality-reduction.html">降维时</a>阅读的详细信息。</p>


                </div>
            
             <!-- /container -->
        </div>

        <script src="js/vendor/jquery-3.4.1.min.js"></script>
        <script src="js/vendor/bootstrap.min.js"></script>
        <script src="js/vendor/anchor.min.js"></script>
        <script src="js/main.js"></script>

        <!-- MathJax Section -->
        <script type="text/x-mathjax-config">
            MathJax.Hub.Config({
                TeX: { equationNumbers: { autoNumber: "AMS" } }
            });
        </script>
        <script>
            // Note that we load MathJax this way to work with local file (file://), HTTP and HTTPS.
            // We could use "//cdn.mathjax...", but that won't support "file://".
            (function(d, script) {
                script = d.createElement('script');
                script.type = 'text/javascript';
                script.async = true;
                script.onload = function(){
                    MathJax.Hub.Config({
                        tex2jax: {
                            inlineMath: [ ["$", "$"], ["\\\\(","\\\\)"] ],
                            displayMath: [ ["$$","$$"], ["\\[", "\\]"] ],
                            processEscapes: true,
                            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre']
                        }
                    });
                };
                script.src = ('https:' == document.location.protocol ? 'https://' : 'http://') +
                    'cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js' +
                    '?config=TeX-AMS-MML_HTMLorMML';
                d.getElementsByTagName('head')[0].appendChild(script);
            }(document));
        </script>
    

</body></html>