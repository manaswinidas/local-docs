<html class="no-js" ><!--<![endif]--><head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
        <title>在YARN上运行Spark-Spark 3.0.0-预览文档</title>
        

        

        <link rel="stylesheet" href="css/bootstrap.min.css">
        <style>
            body {
                padding-top: 60px;
                padding-bottom: 40px;
            }
        </style>
        <meta name="viewport" content="width=device-width">
        <link rel="stylesheet" href="css/bootstrap-responsive.min.css">
        <link rel="stylesheet" href="css/main.css">

        <script src="js/vendor/modernizr-2.6.1-respond-1.1.0.min.js"></script>

        <link rel="stylesheet" href="css/pygments-default.css">

        
        <!-- Google analytics script -->
        <script type="text/javascript">
          var _gaq = _gaq || [];
          _gaq.push(['_setAccount', 'UA-32518208-2']);
          _gaq.push(['_trackPageview']);

          (function() {
            var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
            ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
            var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
          })();
        </script>
        

    </head>
    <body >
        <!--[if lt IE 7]>
            <p class="chromeframe">You are using an outdated browser. <a href="https://browsehappy.com/">Upgrade your browser today</a> or <a href="http://www.google.com/chromeframe/?redirect=true">install Google Chrome Frame</a> to better experience this site.</p>
        <![endif]-->

        <!-- This code is taken from http://twitter.github.com/bootstrap/examples/hero.html -->

        <div class="navbar navbar-fixed-top" id="topbar">
            <div class="navbar-inner">
                <div class="container">
                    <div class="brand"><a href="index.html"><img src="img/spark-logo-hd.png" style="height:50px"></a> <span class="version">3.0.0预览版</span>
                    </div>
                    <ul class="nav">
                        <!--TODO(andyk): Add class="active" attribute to li some how.-->
                        <li><a href="index.html">总览</a></li>

                        <li class="dropdown">
                            <a href="#" class="dropdown-toggle" data-toggle="dropdown">编程指南<b class="caret"></b></a>
                            <ul class="dropdown-menu">
                                <li><a href="quick-start.html">快速开始</a></li>
                                <li><a href="rdd-programming-guide.html">RDD，累加器，广播变量</a></li>
                                <li><a href="sql-programming-guide.html">SQL，数据框和数据集</a></li>
                                <li><a href="structured-streaming-programming-guide.html">结构化流</a></li>
                                <li><a href="streaming-programming-guide.html">火花流（DStreams）</a></li>
                                <li><a href="ml-guide.html">MLlib（机器学习）</a></li>
                                <li><a href="graphx-programming-guide.html">GraphX（图形处理）</a></li>
                                <li><a href="sparkr.html">SparkR（Spark上的R）</a></li>
                            </ul>
                        </li>

                        <li class="dropdown">
                            <a href="#" class="dropdown-toggle" data-toggle="dropdown">API文件<b class="caret"></b></a>
                            <ul class="dropdown-menu">
                                <li><a href="api/scala/index.html#org.apache.spark.package">斯卡拉</a></li>
                                <li><a href="api/java/index.html">爪哇</a></li>
                                <li><a href="api/python/index.html">蟒蛇</a></li>
                                <li><a href="api/R/index.html">[R</a></li>
                                <li><a href="api/sql/index.html">SQL，内置函数</a></li>
                            </ul>
                        </li>

                        <li class="dropdown">
                            <a href="#" class="dropdown-toggle" data-toggle="dropdown">部署中<b class="caret"></b></a>
                            <ul class="dropdown-menu">
                                <li><a href="cluster-overview.html">总览</a></li>
                                <li><a href="submitting-applications.html">提交申请</a></li>
                                <li class="divider"></li>
                                <li><a href="spark-standalone.html">Spark独立</a></li>
                                <li><a href="running-on-mesos.html">梅索斯</a></li>
                                <li><a href="running-on-yarn.html">纱</a></li>
                                <li><a href="running-on-kubernetes.html">Kubernetes</a></li>
                            </ul>
                        </li>

                        <li class="dropdown">
                            <a href="api.html" class="dropdown-toggle" data-toggle="dropdown">更多<b class="caret"></b></a>
                            <ul class="dropdown-menu">
                                <li><a href="configuration.html">组态</a></li>
                                <li><a href="monitoring.html">监控方式</a></li>
                                <li><a href="tuning.html">调音指南</a></li>
                                <li><a href="job-scheduling.html">作业调度</a></li>
                                <li><a href="security.html">安全</a></li>
                                <li><a href="hardware-provisioning.html">硬件配置</a></li>
                                <li><a href="migration-guide.html">迁移指南</a></li>
                                <li class="divider"></li>
                                <li><a href="building-spark.html">建筑火花</a></li>
                                <li><a href="https://spark.apache.org/contributing.html">为Spark贡献</a></li>
                                <li><a href="https://spark.apache.org/third-party-projects.html">第三方项目</a></li>
                            </ul>
                        </li>
                    </ul>
                    <!--<p class="navbar-text pull-right"><span class="version-text">v3.0.0-preview</span></p>-->
                </div>
            </div>
        </div>

        <div class="container-wrapper">

            
                <div class="content" id="content">
                    
                        <h1 class="title">在YARN上运行Spark</h1>
                    

                    <ul id="markdown-toc">
  <li><a href="#security" id="markdown-toc-security">安全</a></li>
  <li><a href="#launching-spark-on-yarn" id="markdown-toc-launching-spark-on-yarn">在YARN上启动Spark</a>    <ul>
      <li><a href="#adding-other-jars" id="markdown-toc-adding-other-jars">添加其他JAR</a></li>
    </ul>
  </li>
  <li><a href="#preparations" id="markdown-toc-preparations">准备工作</a></li>
  <li><a href="#configuration" id="markdown-toc-configuration">组态</a></li>
  <li><a href="#debugging-your-application" id="markdown-toc-debugging-your-application">调试您的应用程序</a>    <ul>
      <li><a href="#spark-properties" id="markdown-toc-spark-properties">火花特性</a></li>
      <li><a href="#available-patterns-for-shs-custom-executor-log-url" id="markdown-toc-available-patterns-for-shs-custom-executor-log-url">SHS定制执行程序日志URL的可用模式</a></li>
    </ul>
  </li>
  <li><a href="#resource-allocation-and-configuration-overview" id="markdown-toc-resource-allocation-and-configuration-overview">资源分配和配置概述</a></li>
  <li><a href="#important-notes" id="markdown-toc-important-notes">重要笔记</a></li>
  <li><a href="#kerberos" id="markdown-toc-kerberos">的Kerberos</a>    <ul>
      <li><a href="#yarn-specific-kerberos-configuration" id="markdown-toc-yarn-specific-kerberos-configuration">YARN特定的Kerberos配置</a></li>
      <li><a href="#troubleshooting-kerberos" id="markdown-toc-troubleshooting-kerberos">Kerberos故障排除</a></li>
    </ul>
  </li>
  <li><a href="#configuring-the-external-shuffle-service" id="markdown-toc-configuring-the-external-shuffle-service">配置外部随机播放服务</a></li>
  <li><a href="#launching-your-application-with-apache-oozie" id="markdown-toc-launching-your-application-with-apache-oozie">使用Apache Oozie启动您的应用程序</a></li>
  <li><a href="#using-the-spark-history-server-to-replace-the-spark-web-ui" id="markdown-toc-using-the-spark-history-server-to-replace-the-spark-web-ui">使用Spark History Server替换Spark Web UI</a></li>
</ul>

<p>在0.6.0版中，Spark添加了对在<a href="http://hadoop.apache.org/docs/stable/hadoop-yarn/hadoop-yarn-site/YARN.html">YARN（Hadoop NextGen）</a>上运行的支持，并在后续发行版中进行了改进。</p>

<h1 id="security">安全</h1>

<p>默认情况下，Spark中的安全性处于关闭状态。这可能意味着您默认情况下容易受到攻击。在运行Spark之前，请参阅<a href="security.html">Spark Security</a>和本文档中的特定安全性部分。</p>

<h1 id="launching-spark-on-yarn">在YARN上启动Spark</h1>

<p>确保这件事<code>HADOOP_CONF_DIR</code>要么<code>YARN_CONF_DIR</code>指向包含Hadoop集群的（客户端）配置文件的目录。这些配置用于写入HDFS并连接到YARN ResourceManager。此目录中包含的配置将分发到YARN群集，以便应用程序使用的所有容器都使用相同的配置。如果配置引用不是由YARN管理的Java系统属性或环境变量，则还应该在Spark应用程序的配置（在客户端模式下运行时的驱动程序，执行程序和AM）中进行设置。</p>

<p>有两种部署模式可用于在YARN上启动Spark应用程序。在<code>cluster</code>模式下，Spark驱动程序在由YARN在群集上管理的应用程序主进程中运行，并且客户端可以在启动应用程序后消失。在<code>client</code>模式，驱动程序在客户端进程中运行，而应用程序主控仅用于从YARN请求资源。</p>

<p>与Spark支持的其他集群管理器不同，Spark支持在其中指定主服务器的地址<code>--master</code>参数，在YARN模式下，从Hadoop配置中获取ResourceManager的地址。就这样<code>--master</code>参数是<code>yarn</code> 。</p>

<p>在中启动Spark应用程序<code>cluster</code>模式：</p>

<pre><code>$ ./bin/spark-submit --class path.to.your.Class --master yarn --deploy-mode cluster [options] &lt;app jar&gt; [app options]
</code></pre>

<p>例如：</p>

<pre><code>$ ./bin/spark-submit --class org.apache.spark.examples.SparkPi \
    --master yarn \
    --deploy-mode cluster \
    --driver-memory 4g \
    --executor-memory 2g \
    --executor-cores 1 \
    --queue thequeue \
    examples/jars/spark-examples*.jar \
    10
</code></pre>

<p>上面启动了一个YARN客户端程序，该程序启动了默认的Application Master。然后，SparkPi将作为Application Master的子线程运行。客户端将定期轮询Application Master以获取状态更新，并将其显示在控制台中。应用程序完成运行后，客户端将退出。请参阅下面的“调试应用程序”部分，以了解如何查看驱动程序和执行程序日志。</p>

<p>在中启动Spark应用程序<code>client</code>模式，执行相同操作，但替换<code>cluster</code>与<code>client</code> 。下面显示了如何运行<code>spark-shell</code>在<code>client</code>模式：</p>

<pre><code>$ ./bin/spark-shell --master yarn --deploy-mode client
</code></pre>

<h2 id="adding-other-jars">添加其他JAR</h2>

<p>在<code>cluster</code>模式下，驱动程序与客户端运行在不同的计算机上，因此<code>SparkContext.addJar</code>不适用于客户端本地文件。使客户端上的文件可用于<code>SparkContext.addJar</code> ，将它们包含在<code>--jars</code>启动命令中的选项。</p>

<pre><code>$ ./bin/spark-submit --class my.main.Class \
    --master yarn \
    --deploy-mode cluster \
    --jars my-other-jar.jar,my-other-other-jar.jar \
    my-main-jar.jar \
    app_arg1 app_arg2
</code></pre>

<h1 id="preparations">准备工作</h1>

<p>在YARN上运行Spark需要使用YARN支持构建的Spark二进制分发版。二进制发行版可以从项目网站的<a href="https://spark.apache.org/downloads.html">下载页面下载</a> 。要自己构建Spark，请参阅<a href="building-spark.html">构建Spark</a> 。</p>

<p>要使YARN端可以访问Spark运行时jar，可以指定<code>spark.yarn.archive</code>要么<code>spark.yarn.jars</code> 。有关详细信息，请参阅<a href="running-on-yarn.html#spark-properties">Spark属性</a> 。如果两者都不<code>spark.yarn.archive</code>也不<code>spark.yarn.jars</code>指定后，Spark将创建一个zip文件，其中所有jar <code>$SPARK_HOME/jars</code>并将其上传到分布式缓存。</p>

<h1 id="configuration">组态</h1>

<p>YARN上的Spark的大多数配置与其他部署模式相同。有关这些的更多信息，请参见<a href="configuration.html">配置页面</a> 。这些是特定于YARN上Spark的配置。</p>

<h1 id="debugging-your-application">调试您的应用程序</h1>

<p>在YARN术语中，执行者和应用程序主管在“容器”内部运行。在应用程序完成之后，YARN有两种处理容器日志的模式。如果启用了日志聚合（通过<code>yarn.log-aggregation-enable</code> config），将容器日志复制到HDFS并在本地计算机上删除。可以使用以下命令从群集的任何位置查看这些日志： <code>yarn logs</code>命令。</p>

<pre><code>yarn logs -applicationId &lt;app ID&gt;
</code></pre>

<p>将从给定应用程序的所有容器中打印出所有日志文件的内容。您还可以使用HDFS Shell或API在HDFS中直接查看容器日志文件。通过查看您的YARN配置，可以找到它们的目录（ <code>yarn.nodemanager.remote-app-log-dir</code>和<code>yarn.nodemanager.remote-app-log-dir-suffix</code> ）。日志也可在Spark Web UI的“执行程序”选项卡下使用。您需要同时运行Spark历史记录服务器和MapReduce历史记录服务器并进行配置<code>yarn.log.server.url</code>在<code>yarn-site.xml</code>正确地。Spark历史记录服务器UI上的日志URL将您重定向到MapReduce历史记录服务器以显示聚合的日志。</p>

<p>如果未打开日志聚合，则日志将在以下位置的每台计算机上本地保留<code>YARN_APP_LOGS_DIR</code> ，通常配置为<code>/tmp/logs</code>要么<code>$HADOOP_HOME/logs/userlogs</code>取决于Hadoop版本和安装。要查看容器的日志，需要转到包含它们的主机并在此目录中查找。子目录按应用程序ID和容器ID组织日志文件。日志也可在Spark Web UI的“执行程序”选项卡下使用，并且不需要运行MapReduce历史记录服务器。</p>

<p>要查看每个容器的启动环境，请增加<code>yarn.nodemanager.delete.debug-delay-sec</code>很大的价值（例如<code>36000</code> ），然后通过访问应用程序缓存<code>yarn.nodemanager.local-dirs</code>在启动容器的节点上。该目录包含启动脚本，JAR和用于启动每个容器的所有环境变量。该过程对于调试类路径问题特别有用。（请注意，启用此功能需要对群集设置具有管理员权限，并重新启动所有节点管理器。因此，这不适用于托管群集。</p>

<p>要将自定义log4j配置用于应用程序主服务器或执行程序，请使用以下选项：</p>

<ul>
  <li>上传自定义<code>log4j.properties</code>使用<code>spark-submit</code> ，将其添加到<code>--files</code>与应用程序一起上传的文件列表。</li>
  <li>加<code>-Dlog4j.configuration=<location of configuration file></code>至<code>spark.driver.extraJavaOptions</code> （对于驾驶员）或<code>spark.executor.extraJavaOptions</code> （对于执行人）。请注意，如果使用文件， <code>file:</code>应该明确提供协议，并且文件必须在所有节点上本地存在。</li>
  <li>更新<code>$SPARK_CONF_DIR/log4j.properties</code>文件，它将与其他配置一起自动上传。请注意，如果指定了多个选项，则其他2个选项的优先级高于此选项。</li>
</ul>

<p>请注意，对于第一个选项，执行程序和应用程序主程序将共享相同的log4j配置，这可能在它们在同一节点上运行时引起问题（例如，尝试写入同一日志文件）。</p>

<p>如果您需要引用适当的位置以将日志文件放入YARN中，以便YARN可以正确显示和聚合它们，请使用<code>spark.yarn.app.container.log.dir</code>在你的<code>log4j.properties</code> 。例如， <code>log4j.appender.file_appender.File=${spark.yarn.app.container.log.dir}/spark.log</code> 。对于流应用程序，配置<code>RollingFileAppender</code>并将文件位置设置为YARN的日志目录将避免因大型日志文件而导致磁盘溢出，并且可以使用YARN的日志实用程序访问日志。</p>

<p>要将自定义metrics.properties用于应用程序主程序和执行程序，请更新<code>$SPARK_CONF_DIR/metrics.properties</code>文件。它会自动以其他配置上传，因此您无需手动指定<code>--files</code> 。</p>

<h4 id="spark-properties">火花特性</h4>

<table class="table">
<tbody><tr><th>物业名称</th><th>默认</th><th>含义</th></tr>
<tr>
  <td><code>spark.yarn.am.memory</code></td>
  <td><code>512m</code></td>
  <td>客户端模式下用于YARN Application Master的内存量，格式与JVM内存字符串相同（例如<code>512m</code> ， <code>2g</code> ）。在群集模式下，使用<code>spark.driver.memory</code>代替。
    <p></p>使用小写后缀，例如<code>k</code> ， <code>m</code> ， <code>g</code> ， <code>t</code>和<code>p</code> ，分别用于kibi-，mebi-，gibi-，tebi-和pebibytes。
  </td>
</tr>
<tr>
  <td><code>spark.yarn.am.resource.{resource-type}.amount</code></td>
  <td><code>(none)</code></td>
  <td>客户端模式下用于YARN Application Master的资源量。在群集模式下，使用<code>spark.yarn.driver.resource.<resource-type>.amount</code>代替。请注意，此功能只能与YARN 3.0+一起使用。有关参考，请参阅YARN资源模型文档：https://hadoop.apache.org/docs/r3.0.1/hadoop-yarn/hadoop-yarn-site/ResourceModel。 html<p></p>示例：要从YARN请求GPU资源，请使用： <code>spark.yarn.am.resource.yarn.io/gpu.amount</code>
  </td>
</tr>
<tr>
  <td><code>spark.yarn.driver.resource.{resource-type}.amount</code></td>
  <td><code>(none)</code></td>
  <td>群集模式下用于YARN Application Master的资源量。请注意，此功能只能与YARN 3.0+一起使用。有关参考，请参阅YARN资源模型文档：https://hadoop.apache.org/docs/r3.0.1/hadoop-yarn/hadoop-yarn-site/ResourceModel。 html<p></p>示例：要从YARN请求GPU资源，请使用： <code>spark.yarn.driver.resource.yarn.io/gpu.amount</code>
  </td>
</tr>
<tr>
  <td><code>spark.yarn.executor.resource.{resource-type}.amount</code></td>
  <td><code>(none)</code></td>
 <td>每个执行程序进程要使用的资源量。请注意，此功能只能与YARN 3.0+一起使用。有关参考，请参阅YARN资源模型文档：https://hadoop.apache.org/docs/r3.0.1/hadoop-yarn/hadoop-yarn-site/ResourceModel。 html<p></p>示例：要从YARN请求GPU资源，请使用： <code>spark.yarn.executor.resource.yarn.io/gpu.amount</code>
 </td>
</tr>
<tr>
  <td><code>spark.yarn.am.cores</code></td>
  <td><code>1</code></td>
  <td>客户端模式下用于YARN Application Master的内核数。在群集模式下，使用<code>spark.driver.cores</code>代替。
  </td>
</tr>
<tr>
  <td><code>spark.yarn.am.waitTime</code></td>
  <td><code>100s</code></td>
  <td>仅用于<code>cluster</code>模式。YARN Application Master等待SparkContext初始化的时间。
  </td>
</tr>
<tr>
  <td><code>spark.yarn.submit.file.replication</code></td>
  <td>默认的HDFS复制（通常<code>3</code> ）</td>
  <td>上传到应用程序HDFS中的文件的HDFS复制级别。其中包括Spark jar，应用程序jar和任何分布式缓存文件/归档之类的东西。
  </td>
</tr>
<tr>
  <td><code>spark.yarn.stagingDir</code></td>
  <td>文件系统中当前用户的主目录</td>
  <td>提交应用程序时使用的登台目录。
  </td>
</tr>
<tr>
  <td><code>spark.yarn.preserve.staging.files</code></td>
  <td><code>false</code></td>
  <td>调成<code>true</code>在工作结束时保留暂存文件（Spark jar，app jar，分布式缓存文件），而不是删除它们。
  </td>
</tr>
<tr>
  <td><code>spark.yarn.scheduler.heartbeat.interval-ms</code></td>
  <td><code>3000</code></td>
  <td>Spark应用程序主设备心跳到YARN ResourceManager中的时间间隔（以毫秒为单位）。该值的上限为YARN配置值的一半，即有效期限<code>yarn.am.liveness-monitor.expiry-interval-ms</code> 。
  </td>
</tr>
<tr>
  <td><code>spark.yarn.scheduler.initial-allocation.interval</code></td>
  <td><code>200ms</code></td>
  <td>当存在挂起的容器分配请求时，Spark应用程序主服务器急切地向YARN ResourceManager发出心跳的初始时间间隔。它不应大于<code>spark.yarn.scheduler.heartbeat.interval-ms</code> 。如果仍存在挂起的容器，则在连续不断的心跳中，分配间隔将加倍，直到<code>spark.yarn.scheduler.heartbeat.interval-ms</code>到达了。
  </td>
</tr>
<tr>
  <td><code>spark.yarn.max.executor.failures</code></td>
  <td>numExecutors * 2，最少3个</td>
  <td>在使应用程序失败之前，执行程序失败的最大次数。
  </td>
</tr>
<tr>
  <td><code>spark.yarn.historyServer.address</code></td>
  <td>（没有）</td>
  <td>Spark历史记录服务器的地址，例如<code>host.com:18080</code> 。该地址不应包含方案（ <code>http://</code> ）。由于历史记录服务器是一项可选服务，因此默认情况下未设置。当Spark应用程序完成将应用程序从ResourceManager UI链接到Spark历史记录服务器UI时，此地址将提供给YARN ResourceManager。对于此属性，可以将YARN属性用作变量，并且在运行时将其替换为Spark。例如，如果Spark历史记录服务器与YARN ResourceManager在同一节点上运行，则可以将其设置为<code>${hadoopconf-yarn.resourcemanager.hostname}:18080</code> 。
  </td>
</tr>
<tr>
  <td><code>spark.yarn.dist.archives</code></td>
  <td>（没有）</td>
  <td>以逗号分隔的归档列表，将其提取到每个执行程序的工作目录中。
  </td>
</tr>
<tr>
  <td><code>spark.yarn.dist.files</code></td>
  <td>（没有）</td>
  <td>以逗号分隔的文件列表，将其放置在每个执行程序的工作目录中。
  </td>
</tr>
<tr>
  <td><code>spark.yarn.dist.jars</code></td>
  <td>（没有）</td>
  <td>将以逗号分隔的jar列表放置在每个执行程序的工作目录中。
  </td>
</tr>
<tr>
  <td><code>spark.yarn.dist.forceDownloadSchemes</code></td>
  <td><code>(none)</code></td>
  <td>以逗号分隔的方案列表，其资源将在添加到YARN的分布式缓存之前先下载到本地磁盘。适用于YARN服务不支持Spark支持的方案（例如http，https和ftp）或本地YARN客户端的类路径中需要的jar的情况。表示通配符“ *”以下载所有方案的资源。
  </td>
</tr>
<tr>
 <td><code>spark.executor.instances</code></td>
  <td><code>2</code></td>
  <td>静态分配的执行程序数。用<code>spark.dynamicAllocation.enabled</code> ，则执行程序的初始集合至少会如此之大。
  </td>
</tr>
<tr>
  <td><code>spark.yarn.am.memoryOverhead</code></td>
  <td>AM内存* 0.10，最少384</td>
  <td>和...一样<code>spark.driver.memoryOverhead</code> ，但适用于客户端模式下的YARN Application Master。
  </td>
</tr>
<tr>
  <td><code>spark.yarn.queue</code></td>
  <td><code>default</code></td>
  <td>提交应用程序的YARN队列的名称。
  </td>
</tr>
<tr>
  <td><code>spark.yarn.jars</code></td>
  <td>（没有）</td>
  <td>包含要分发到YARN容器的Spark代码的库列表。默认情况下，YARN上的Spark将使用本地安装的Spark jar，但是Spark jar也可以位于HDFS上的世界可读位置。这使YARN可以将其缓存在节点上，因此无需在每次运行应用程序时将其分发。例如，要指向HDFS上的jar，请将此配置设置为<code>hdfs:///some/path</code> 。允许使用小球。
  </td>
</tr>
<tr>
  <td><code>spark.yarn.archive</code></td>
  <td>（没有）</td>
  <td>包含所需Spark jar的归档文件，用于分发到YARN缓存。如果设置，此配置将替换<code>spark.yarn.jars</code>存档将在所有应用程序容器中使用。归档文件应在其根目录中包含jar文件。与上一个选项一样，存档文件也可以托管在HDFS上，以加快文件分发速度。
  </td>
</tr>
<tr>
  <td><code>spark.yarn.appMasterEnv.[EnvironmentVariableName]</code></td>
  <td>（没有）</td>
  <td>添加环境变量指定<code>EnvironmentVariableName</code>到在YARN上启动的Application Master流程。用户可以指定多个，并设置多个环境变量。在<code>cluster</code>模式控制着Spark驱动程序的环境<code>client</code>模式，它仅控制执行程序启动器的环境。
  </td>
</tr>
<tr>
  <td><code>spark.yarn.containerLauncherMaxThreads</code></td>
  <td><code>25</code></td>
  <td>YARN Application Master中用于启动执行程序容器的最大线程数。
  </td>
</tr>
<tr>
  <td><code>spark.yarn.am.extraJavaOptions</code></td>
  <td>（没有）</td>
  <td>在客户端模式下传递给YARN Application Master的一串额外的JVM选项。在群集模式下，使用<code>spark.driver.extraJavaOptions</code>代替。请注意，使用此选项设置最大堆大小（-Xmx）设置是非法的。最大堆大小设置可以使用<code>spark.yarn.am.memory</code>
  </td>
</tr>
<tr>
  <td><code>spark.yarn.am.extraLibraryPath</code></td>
  <td>（没有）</td>
  <td>设置在客户端模式下启动YARN Application Master时要使用的特殊库路径。
  </td>
</tr>
<tr>
  <td><code>spark.yarn.maxAppAttempts</code></td>
  <td><code>yarn.resourcemanager.am.max-attempts</code>在纱</td>
  <td>提交申请的最大尝试次数。它不应大于YARN配置中的最大最大尝试次数。
  </td>
</tr>
<tr>
  <td><code>spark.yarn.am.attemptFailuresValidityInterval</code></td>
  <td>（没有）</td>
  <td>定义AM故障跟踪的有效间隔。如果AM已经运行了至少已定义的间隔，则AM故障计数将被重置。如果未配置，则不会启用此功能。
  </td>
</tr>
<tr>
  <td><code>spark.yarn.executor.failuresValidityInterval</code></td>
  <td>（没有）</td>
  <td>定义执行程序失败跟踪的有效间隔。超过有效间隔的执行器故障将被忽略。
  </td>
</tr>
<tr>
  <td><code>spark.yarn.submit.waitAppCompletion</code></td>
  <td><code>true</code></td>
  <td>在YARN群集模式下，控制客户端是否等待退出直到应用程序完成。如果设置为<code>true</code> ，客户端进程将保持活动状态，报告应用程序的状态。否则，客户端进程将在提交后退出。
  </td>
</tr>
<tr>
  <td><code>spark.yarn.am.nodeLabelExpression</code></td>
  <td>（没有）</td>
  <td>将调度限制节点AM组的YARN节点标签表达式。只有大于或等于2.6的YARN版本才支持节点标签表达式，因此在针对早期版本运行时，将忽略此属性。
  </td>
</tr>
<tr>
  <td><code>spark.yarn.executor.nodeLabelExpression</code></td>
  <td>（没有）</td>
  <td>将调度限制节点执行程序集的YARN节点标签表达式。只有大于或等于2.6的YARN版本才支持节点标签表达式，因此在针对早期版本运行时，将忽略此属性。
  </td>
</tr>
<tr>
  <td><code>spark.yarn.tags</code></td>
  <td>（没有）</td>
  <td>逗号分隔的字符串列表，作为YARN ApplicationReports中显示的YARN应用程序标签传递，可用于查询YARN应用程序时进行过滤。
  </td>
</tr>
<tr>
  <td><code>spark.yarn.config.gatewayPath</code></td>
  <td>（没有）</td>
  <td>在网关主机（启动Spark应用程序的主机）上有效的路径，但对于集群中其他节点中相同资源的路径可能会有所不同。加上<code>spark.yarn.config.replacementPath</code> ，它用于支持具有异构配置的集群，以便Spark可以正确启动远程进程。
  <p></p>替换路径通常将包含对YARN导出的某些环境变量的引用（因此对Spark容器可见）。
  <p></p>例如，如果网关节点上安装了Hadoop库， <code>/disk1/hadoop</code> ，并且Hadoop安装的位置由YARN导出为<code>HADOOP_HOME</code>环境变量，将此值设置为<code>/disk1/hadoop</code>以及替换路径<code>$HADOOP_HOME</code>将确保用于启动远程进程的路径正确引用本地YARN配置。
  </td>
</tr>
<tr>
  <td><code>spark.yarn.config.replacementPath</code></td>
  <td>（没有）</td>
  <td>看到<code>spark.yarn.config.gatewayPath</code> 。
  </td>
</tr>
<tr>
  <td><code>spark.yarn.rolledLog.includePattern</code></td>
  <td>（没有）</td>
  <td>Java Regex过滤与定义的包含模式匹配的日志文件，这些日志文件将以滚动方式聚合。这将与YARN的滚动日志聚合一起使用，以在YARN端启用此功能<code>yarn.nodemanager.log-aggregation.roll-monitoring-interval-seconds</code>应该在yarn-site.xml中配置。需要将Spark log4j附加程序更改为使用FileAppender或另一个附加程序，该附加程序可以在运行时处理要删除的文件。基于在log4j配置中配置的文件名（例如spark.log），用户应将正则表达式（spark *）设置为包括所有需要汇总的日志文件。
  </td>
</tr>
<tr>
  <td><code>spark.yarn.rolledLog.excludePattern</code></td>
  <td>（没有）</td>
  <td>Java Regex可以过滤与定义的排除模式匹配的日志文件，并且这些日志文件不会以滚动方式聚合。如果日志文件名与包含和排除模式均匹配，则该文件最终将被排除。
  </td>
</tr>
<tr>
  <td><code>spark.yarn.blacklist.executor.launch.blacklisting.enabled</code></td>
  <td>假</td>
  <td>启用对具有YARN资源分配问题的节点的黑名单的标记。可以将黑名单的错误限制配置为<code>spark.blacklist.application.maxFailedExecutorsPerNode</code> 。
  </td>
</tr>
<tr>
  <td><code>spark.yarn.exclude.nodes</code></td>
  <td>（没有）</td>
  <td>以逗号分隔的YARN节点名称列表，这些节点名称不包括在资源分配中。
  </td>
</tr>
<tr>
  <td><code>spark.yarn.metrics.namespace</code></td>
  <td>（没有）</td>
  <td>AM指标报告的根名称空间。如果未设置，则使用YARN应用程序ID。
  </td>
</tr>
</tbody></table>

<h4 id="available-patterns-for-shs-custom-executor-log-url">SHS定制执行程序日志URL的可用模式</h4>

<table class="table">
    <tbody><tr><th>图案</th><th>含义</th></tr>
    <tr>
      <td></td>
      <td>根据YARN HTTP策略使用的是http：//或https：//。（通过`yarn.http.policy`配置）</td>
    </tr>
    <tr>
      <td></td>
      <td>运行容器的节点的“主机”。</td>
    </tr>
    <tr>
      <td></td>
      <td>运行容器的节点管理器的“端口”。</td>
    </tr>
    <tr>
      <td></td>
      <td>运行容器的节点管理器的http服务器的“端口”。</td>
    </tr>
    <tr>
      <td></td>
      <td>分配容器的节点的Http URI。</td>
    </tr>
    <tr>
      <td></td>
      <td>资源管理器的集群ID。（通过`yarn.resourcemanager.cluster-id`配置）</td>
    </tr>
    <tr>
      <td></td>
      <td>容器的ID。</td>
    </tr>
    <tr>
      <td></td>
      <td>系统环境上的“ SPARK_USER”。</td>
    </tr>
    <tr>
      <td></td>
      <td>`stdout`，`stderr`。</td>
    </tr>
</tbody></table>

<p>例如，假设您想直接将日志URL链接指向Job History Server，而不是让NodeManager http服务器将其重定向，则可以配置<code>spark.history.custom.executor.log.url</code>如下：</p>

<p><code><JHS_HOST>:<JHS_PORT>/jobhistory/logs/:////?start=-4096</code></p>

<p>注意：您需要更换<code><JHS_POST></code>和<code><JHS_PORT></code>具有实际价值。</p>

<h1 id="resource-allocation-and-configuration-overview">资源分配和配置概述</h1>

<p>请确保已阅读<a href="configuration.html">配置页面</a>上的“自定义资源调度和配置概述”部分。本节仅讨论YARN资源调度的特定方面。</p>

<p>YARN需要配置为支持用户想要与Spark一起使用的任何资源。在YARN 3.1.0中添加了对YARN的资源调度。有关配置资源和正确设置隔离的更多信息，请参见YARN文档。理想情况下，资源是隔离设置的，因此执行者只能看到分配给它的资源。如果未启用隔离，则用户负责创建发现脚本，以确保执行者之间不共享资源。</p>

<p>YARN当前支持任何用户定义的资源类型，但已为GPU内置了类型（ <code>yarn.io/gpu</code> ）和FPGA（ <code>yarn.io/fpga</code> ）。因此，如果您使用这些资源中的任何一个，Spark可以将您对Spark资源的请求转换为YARN资源，而您只需指定<code>spark.{driver/executor}.resource.</code>配置。如果您使用的是FPGA或GPU以外的资源，则用户负责指定两个YARN（ <code>spark.yarn.{driver/executor}.resource.</code> ）和Spark（ <code>spark.{driver/executor}.resource.</code> ）。</p>

<p>例如，用户想要为每个执行器请求2个GPU。用户只需指定<code>spark.executor.resource.gpu.amount=2</code>然后Spark将处理请求<code>yarn.io/gpu</code> YARN的资源类型。</p>

<p>如果用户具有用户定义的YARN资源，请调用它<code>acceleratorX</code>然后用户必须指定<code>spark.yarn.executor.resource.acceleratorX.amount=2</code>和<code>spark.executor.resource.acceleratorX.amount=2</code> 。</p>

<p>YARN不会告诉Spark分配给每个容器的资源的地址。因此，用户必须指定一个由执行程序在启动时运行的发现脚本，以发现该执行程序可用的资源。您可以在以下位置找到示例脚本<code>examples/src/main/scripts/getGpusResources.sh</code> 。该脚本必须设置执行权限，并且用户应设置权限以不允许恶意用户对其进行修改。该脚本应以ResourceInformation类的格式向STDOUT写入JSON字符串。它具有资源名称和仅可用于该执行程序的资源地址数组。</p>

<h1 id="important-notes">重要笔记</h1>

<ul>
  <li>在调度决策中是否遵循核心请求取决于所使用的调度程序及其配置方式。</li>
  <li>在<code>cluster</code>模式，Spark执行程序和Spark驱动程序使用的本地目录将是为YARN配置的本地目录（Hadoop YARN配置<code>yarn.nodemanager.local-dirs</code> ）。如果用户指定<code>spark.local.dir</code> ，它将被忽略。在<code>client</code>模式，Spark执行程序将使用为YARN配置的本地目录，而Spark驱动程序将使用在<code>spark.local.dir</code> 。这是因为Spark驱动程序未在以下站点的YARN群集上运行<code>client</code>模式，只有Spark执行程序执行。</li>
  <li>的<code>--files</code>和<code>--archives</code>选项支持使用与Hadoop类似的＃指定文件名。例如，您可以指定： <code>--files localtest.txt#appSees.txt</code>这将上传您在本地命名的文件<code>localtest.txt</code>进入HDFS，但这将通过名称链接到<code>appSees.txt</code> ，并且您的应用程序应使用以下名称： <code>appSees.txt</code>在YARN上运行时引用它。</li>
  <li>的<code>--jars</code>选项允许<code>SparkContext.addJar</code>如果将其与本地文件一起使用并在<code>cluster</code>模式。如果将它与HDFS，HTTP，HTTPS或FTP文件一起使用，则无需使用它。</li>
</ul>

<h1 id="kerberos">的Kerberos</h1>

<p>“ <a href="security.html#kerberos">安全性”</a>页面涵盖了Spark中的标准Kerberos支持。</p>

<p>在YARN模式下，当访问Hadoop文件系统时，除了hadoop配置中的默认文件系统外，Spark还将自动获取托管Spark应用程序登台目录的服务的委派令牌。</p>

<h2 id="yarn-specific-kerberos-configuration">YARN特定的Kerberos配置</h2>

<table class="table">
<tbody><tr><th>物业名称</th><th>默认</th><th>含义</th></tr>
<tr>
  <td><code>spark.kerberos.keytab</code></td>
  <td>（没有）</td>
  <td>包含上面指定的主体的密钥表的文件的完整路径。该密钥表将通过YARN分布式缓存复制到运行YARN Application Master的节点，并将用于定期更新登录票证和委托令牌。相当于<code>--keytab</code>命令行参数。

  <br>（也可以与“本地”母版一起使用。）
  </td>
</tr>
<tr>
  <td><code>spark.kerberos.principal</code></td>
  <td>（没有）</td>
  <td>在安全群集上运行时用于登录KDC的主体。相当于<code>--principal</code>命令行参数。

  <br>（也可以与“本地”母版一起使用。）
  </td>
</tr>
<tr>
  <td><code>spark.yarn.kerberos.relogin.period</code></td>
  <td>1m</td>
  <td>多久检查一次是否应更新kerberos TGT。该值应设置为短于TGT更新周期（或如果未启用TGT更新，则为TGT生存期）。对于大多数部署，默认值应该足够。
  </td>
</tr>
</tbody></table>

<h2 id="troubleshooting-kerberos">Kerberos故障排除</h2>

<p>调试Hadoop / Kerberos问题可能很“困难”。一种有用的技术是通过设置以下操作在Hadoop中启用Kerberos操作的额外日志记录： <code>HADOOP_JAAS_DEBUG</code>环境变量。</p>

<pre><code class="language-bash">export HADOOP_JAAS_DEBUG=true
</code></pre>

<p>可以将JDK类配置为通过系统属性启用其Kerberos和SPNEGO / REST身份验证的额外日志记录<code>sun.security.krb5.debug</code>和<code>sun.security.spnego.debug=true</code></p>

<pre><code>-Dsun.security.krb5.debug=true -Dsun.security.spnego.debug=true
</code></pre>

<p>所有这些选项都可以在Application Master中启用：</p>

<pre><code>spark.yarn.appMasterEnv.HADOOP_JAAS_DEBUG true
spark.yarn.am.extraJavaOptions -Dsun.security.krb5.debug=true -Dsun.security.spnego.debug=true
</code></pre>

<p>最后，如果日志级别为<code>org.apache.spark.deploy.yarn.Client</code>被设定为<code>DEBUG</code> ，该日志将包含获得的所有令牌的列表及其有效期详细信息</p>

<h1 id="configuring-the-external-shuffle-service">配置外部随机播放服务</h1>

<p>在每个上启动Spark Shuffle服务<code>NodeManager</code>在您的YARN群集中，请按照以下说明进行操作：</p>

<ol>
  <li>使用<a href="building-spark.html">YARN配置文件</a>构建Spark。如果您使用预打包的发行版，请跳过此步骤。</li>
  <li>找到<code>spark-<version>-yarn-shuffle.jar</code> 。这应该在<code>$SPARK_HOME/common/network-yarn/target/scala-<version></code>如果您自己构建Spark，并且在<code>yarn</code>如果您使用的是发行版。</li>
  <li>将此jar添加到所有的classpath中<code>NodeManager</code>在您的集群中。</li>
  <li>在里面<code>yarn-site.xml</code>在每个节点上，添加<code>spark_shuffle</code>至<code>yarn.nodemanager.aux-services</code> ，然后设定<code>yarn.nodemanager.aux-services.spark_shuffle.class</code>至<code>org.apache.spark.network.yarn.YarnShuffleService</code> 。</li>
  <li>增加<code>NodeManager's</code>通过设置堆大小<code>YARN_HEAPSIZE</code> （默认为1000）在<code>etc/hadoop/yarn-env.sh</code>以避免在随机播放期间出现垃圾收集问题。</li>
  <li>重新启动所有<code>NodeManager</code>在您的集群中。</li>
</ol>

<p>在YARN上运行随机播放服务时，可以使用以下附加配置选项：</p>

<table class="table">
<tbody><tr><th>物业名称</th><th>默认</th><th>含义</th></tr>
<tr>
  <td><code>spark.yarn.shuffle.stopOnFailure</code></td>
  <td><code>false</code></td>
  <td>Spark Shuffle Service初始化失败时是否停止NodeManager。这样可以防止由于未运行Spark Shuffle服务的NodeManager上运行容器而导致应用程序故障。
  </td>
</tr>
</tbody></table>

<h1 id="launching-your-application-with-apache-oozie">使用Apache Oozie启动您的应用程序</h1>

<p>Apache Oozie可以在工作流程中启动Spark应用程序。在安全集群中，启动的应用程序将需要相关令牌来访问集群的服务。如果使用密钥表启动Spark，这是自动的。但是，如果要在没有密钥表的情况下启动Spark，则必须将设置安全性的职责移交给Oozie。</p>

<p>在特定发行版文档的“身份验证”部分的<a href="http://oozie.apache.org/">Oozie网站上</a>可以找到为安全群集配置Oozie和获取作业凭据的详细信息。</p>

<p>对于Spark应用程序，必须为Oozie设置Oozie工作流，以请求该应用程序需要的所有令牌，包括：</p>

<ul>
  <li>YARN资源管理器。</li>
  <li>本地Hadoop文件系统。</li>
  <li>任何用作I / O源或目标的远程Hadoop文件系统。</li>
  <li>蜂巢-如果使用的话。</li>
  <li>HBase-如果使用的话。</li>
  <li>YARN时间轴服务器（如果应用程序与此交互）。</li>
</ul>

<p>为了避免Spark尝试（然后失败）获取Hive，HBase和远程HDFS令牌，必须将Spark配置设置为禁用服务的令牌收集。</p>

<p>Spark配置必须包括以下几行：</p>

<pre><code>spark.security.credentials.hive.enabled   false
spark.security.credentials.hbase.enabled  false
</code></pre>

<p>配置选项<code>spark.kerberos.access.hadoopFileSystems</code>必须未设置。</p>

<h1 id="using-the-spark-history-server-to-replace-the-spark-web-ui">使用Spark History Server替换Spark Web UI</h1>

<p>禁用应用程序UI时，可以将Spark History Server应用程序页面用作运行应用程序的跟踪URL。在安全群集上或减少Spark驱动程序的内存使用量可能是理想的。要通过Spark History Server设置跟踪，请执行以下操作：</p>

<ul>
  <li>在应用程序端，设置<code>spark.yarn.historyServer.allowTracking=true</code>在Spark的配置中。如果禁用了应用程序的UI，这将告诉Spark使用历史服务器的URL作为跟踪URL。</li>
  <li>在Spark History Server上，添加<code>org.apache.spark.deploy.yarn.YarnProxyRedirectFilter</code>到<code>spark.ui.filters</code>组态。</li>
</ul>

<p>请注意，历史记录服务器信息可能不是与应用程序状态有关的最新信息。</p>


                </div>
            
             <!-- /container -->
        </div>

        <script src="js/vendor/jquery-3.4.1.min.js"></script>
        <script src="js/vendor/bootstrap.min.js"></script>
        <script src="js/vendor/anchor.min.js"></script>
        <script src="js/main.js"></script>

        <!-- MathJax Section -->
        <script type="text/x-mathjax-config">
            MathJax.Hub.Config({
                TeX: { equationNumbers: { autoNumber: "AMS" } }
            });
        </script>
        <script>
            // Note that we load MathJax this way to work with local file (file://), HTTP and HTTPS.
            // We could use "//cdn.mathjax...", but that won't support "file://".
            (function(d, script) {
                script = d.createElement('script');
                script.type = 'text/javascript';
                script.async = true;
                script.onload = function(){
                    MathJax.Hub.Config({
                        tex2jax: {
                            inlineMath: [ ["$", "$"], ["\\\\(","\\\\)"] ],
                            displayMath: [ ["$$","$$"], ["\\[", "\\]"] ],
                            processEscapes: true,
                            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre']
                        }
                    });
                };
                script.src = ('https:' == document.location.protocol ? 'https://' : 'http://') +
                    'cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js' +
                    '?config=TeX-AMS-MML_HTMLorMML';
                d.getElementsByTagName('head')[0].appendChild(script);
            }(document));
        </script>
    

</body></html>