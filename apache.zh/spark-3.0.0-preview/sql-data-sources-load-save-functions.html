<html class="no-js" ><!--<![endif]--><head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
        <title>通用加载/保存功能-Spark 3.0.0-预览文档</title>
        

        

        <link rel="stylesheet" href="css/bootstrap.min.css">
        <style>
            body {
                padding-top: 60px;
                padding-bottom: 40px;
            }
        </style>
        <meta name="viewport" content="width=device-width">
        <link rel="stylesheet" href="css/bootstrap-responsive.min.css">
        <link rel="stylesheet" href="css/main.css">

        <script src="js/vendor/modernizr-2.6.1-respond-1.1.0.min.js"></script>

        <link rel="stylesheet" href="css/pygments-default.css">

        
        <!-- Google analytics script -->
        <script type="text/javascript">
          var _gaq = _gaq || [];
          _gaq.push(['_setAccount', 'UA-32518208-2']);
          _gaq.push(['_trackPageview']);

          (function() {
            var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
            ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
            var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
          })();
        </script>
        

    </head>
    <body >
        <!--[if lt IE 7]>
            <p class="chromeframe">You are using an outdated browser. <a href="https://browsehappy.com/">Upgrade your browser today</a> or <a href="http://www.google.com/chromeframe/?redirect=true">install Google Chrome Frame</a> to better experience this site.</p>
        <![endif]-->

        <!-- This code is taken from http://twitter.github.com/bootstrap/examples/hero.html -->

        <div class="navbar navbar-fixed-top" id="topbar">
            <div class="navbar-inner">
                <div class="container">
                    <div class="brand"><a href="index.html"><img src="img/spark-logo-hd.png" style="height:50px"></a> <span class="version">3.0.0预览版</span>
                    </div>
                    <ul class="nav">
                        <!--TODO(andyk): Add class="active" attribute to li some how.-->
                        <li><a href="index.html">总览</a></li>

                        <li class="dropdown">
                            <a href="#" class="dropdown-toggle" data-toggle="dropdown">编程指南<b class="caret"></b></a>
                            <ul class="dropdown-menu">
                                <li><a href="quick-start.html">快速开始</a></li>
                                <li><a href="rdd-programming-guide.html">RDD，累加器，广播变量</a></li>
                                <li><a href="sql-programming-guide.html">SQL，数据框和数据集</a></li>
                                <li><a href="structured-streaming-programming-guide.html">结构化流</a></li>
                                <li><a href="streaming-programming-guide.html">火花流（DStreams）</a></li>
                                <li><a href="ml-guide.html">MLlib（机器学习）</a></li>
                                <li><a href="graphx-programming-guide.html">GraphX（图形处理）</a></li>
                                <li><a href="sparkr.html">SparkR（Spark上的R）</a></li>
                            </ul>
                        </li>

                        <li class="dropdown">
                            <a href="#" class="dropdown-toggle" data-toggle="dropdown">API文件<b class="caret"></b></a>
                            <ul class="dropdown-menu">
                                <li><a href="api/scala/index.html#org.apache.spark.package">斯卡拉</a></li>
                                <li><a href="api/java/index.html">爪哇</a></li>
                                <li><a href="api/python/index.html">蟒蛇</a></li>
                                <li><a href="api/R/index.html">[R</a></li>
                                <li><a href="api/sql/index.html">SQL，内置函数</a></li>
                            </ul>
                        </li>

                        <li class="dropdown">
                            <a href="#" class="dropdown-toggle" data-toggle="dropdown">部署中<b class="caret"></b></a>
                            <ul class="dropdown-menu">
                                <li><a href="cluster-overview.html">总览</a></li>
                                <li><a href="submitting-applications.html">提交申请</a></li>
                                <li class="divider"></li>
                                <li><a href="spark-standalone.html">Spark独立</a></li>
                                <li><a href="running-on-mesos.html">梅索斯</a></li>
                                <li><a href="running-on-yarn.html">纱</a></li>
                                <li><a href="running-on-kubernetes.html">Kubernetes</a></li>
                            </ul>
                        </li>

                        <li class="dropdown">
                            <a href="api.html" class="dropdown-toggle" data-toggle="dropdown">更多<b class="caret"></b></a>
                            <ul class="dropdown-menu">
                                <li><a href="configuration.html">组态</a></li>
                                <li><a href="monitoring.html">监控方式</a></li>
                                <li><a href="tuning.html">调音指南</a></li>
                                <li><a href="job-scheduling.html">作业调度</a></li>
                                <li><a href="security.html">安全</a></li>
                                <li><a href="hardware-provisioning.html">硬件配置</a></li>
                                <li><a href="migration-guide.html">迁移指南</a></li>
                                <li class="divider"></li>
                                <li><a href="building-spark.html">建筑火花</a></li>
                                <li><a href="https://spark.apache.org/contributing.html">为Spark贡献</a></li>
                                <li><a href="https://spark.apache.org/third-party-projects.html">第三方项目</a></li>
                            </ul>
                        </li>
                    </ul>
                    <!--<p class="navbar-text pull-right"><span class="version-text">v3.0.0-preview</span></p>-->
                </div>
            </div>
        </div>

        <div class="container-wrapper">

            
                
                    <div class="left-menu-wrapper">
    <div class="left-menu">
        <h3><a href="sql-programming-guide.html">Spark SQL指南</a></h3>
        
<ul>

    <li>
        <a href="sql-getting-started.html">入门</a>
    </li>
    
    

    <li>
        <a href="sql-data-sources.html">数据源</a>
    </li>
    
    
        
<ul>

    <li>
        <a href="sql-data-sources-load-save-functions.html">
            
                <b>通用加载/保存功能</b>
            
        </a>
    </li>
    
    

    <li>
        <a href="sql-data-sources-parquet.html">实木复合地板文件</a>
    </li>
    
    

    <li>
        <a href="sql-data-sources-orc.html">ORC文件</a>
    </li>
    
    

    <li>
        <a href="sql-data-sources-json.html">JSON文件</a>
    </li>
    
    

    <li>
        <a href="sql-data-sources-hive-tables.html">蜂巢表</a>
    </li>
    
    

    <li>
        <a href="sql-data-sources-jdbc.html">JDBC到其他数据库</a>
    </li>
    
    

    <li>
        <a href="sql-data-sources-avro.html">Avro文件</a>
    </li>
    
    

    <li>
        <a href="sql-data-sources-troubleshooting.html">故障排除</a>
    </li>
    
    

</ul>

    

    <li>
        <a href="sql-performance-tuning.html">性能调优</a>
    </li>
    
    

    <li>
        <a href="sql-distributed-sql-engine.html">分布式SQL引擎</a>
    </li>
    
    

    <li>
        <a href="sql-pyspark-pandas-with-arrow.html">PySpark使用Apache Arrow的熊猫使用指南</a>
    </li>
    
    

    <li>
        <a href="sql-migration-old.html">迁移指南</a>
    </li>
    
    

    <li>
        <a href="sql-ref.html">SQL参考</a>
    </li>
    
    

</ul>

    </div>
</div>
                
                <input id="nav-trigger" class="nav-trigger" type="checkbox" checked>
                <label for="nav-trigger"></label>
                <div class="content-with-sidebar" id="content">
                    
                        <h1 class="title">通用加载/保存功能</h1>
                    

                    <ul id="markdown-toc">
  <li><a href="#manually-specifying-options" id="markdown-toc-manually-specifying-options">手动指定选项</a></li>
  <li><a href="#run-sql-on-files-directly" id="markdown-toc-run-sql-on-files-directly">直接在文件上运行SQL</a></li>
  <li><a href="#save-modes" id="markdown-toc-save-modes">保存模式</a></li>
  <li><a href="#saving-to-persistent-tables" id="markdown-toc-saving-to-persistent-tables">保存到永久表</a></li>
  <li><a href="#bucketing-sorting-and-partitioning" id="markdown-toc-bucketing-sorting-and-partitioning">桶，分类和分区</a></li>
</ul>

<p>以最简单的形式，默认数据源（ <code>parquet</code>除非有其他配置<code>spark.sql.sources.default</code> ）将用于所有操作。</p>

<div class="codetabs">
<div data-lang="scala">
    <div class="highlight"><pre><span></span><span class="k">val</span> <span class="n">usersDF</span> <span class="k">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">load</span><span class="o">(</span><span class="s">&quot;examples/src/main/resources/users.parquet&quot;</span><span class="o">)</span>
<span class="n">usersDF</span><span class="o">.</span><span class="n">select</span><span class="o">(</span><span class="s">&quot;name&quot;</span><span class="o">,</span> <span class="s">&quot;favorite_color&quot;</span><span class="o">).</span><span class="n">write</span><span class="o">.</span><span class="n">save</span><span class="o">(</span><span class="s">&quot;namesAndFavColors.parquet&quot;</span><span class="o">)</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / scala / org / apache / spark / examples / sql / SQLDataSourceExample.scala”中找到完整的示例代码。</small></div>
  </div>

<div data-lang="java">
    <div class="highlight"><pre><span></span><span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">usersDF</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="na">read</span><span class="o">().</span><span class="na">load</span><span class="o">(</span><span class="s">&quot;examples/src/main/resources/users.parquet&quot;</span><span class="o">);</span>
<span class="n">usersDF</span><span class="o">.</span><span class="na">select</span><span class="o">(</span><span class="s">&quot;name&quot;</span><span class="o">,</span> <span class="s">&quot;favorite_color&quot;</span><span class="o">).</span><span class="na">write</span><span class="o">().</span><span class="na">save</span><span class="o">(</span><span class="s">&quot;namesAndFavColors.parquet&quot;</span><span class="o">);</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / java / org / apache / spark / examples / sql / JavaSQLDataSourceExample.java”中找到完整的示例代码。</small></div>
  </div>

<div data-lang="python">

    <div class="highlight"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;examples/src/main/resources/users.parquet&quot;</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s2">&quot;name&quot;</span><span class="p">,</span> <span class="s2">&quot;favorite_color&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">write</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">&quot;namesAndFavColors.parquet&quot;</span><span class="p">)</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / python / sql / datasource.py”中找到完整的示例代码。</small></div>
  </div>

<div data-lang="r">

    <div class="highlight"><pre><span></span>df <span class="o">&lt;-</span> read.df<span class="p">(</span><span class="s">&quot;examples/src/main/resources/users.parquet&quot;</span><span class="p">)</span>
write.df<span class="p">(</span>select<span class="p">(</span>df<span class="p">,</span> <span class="s">&quot;name&quot;</span><span class="p">,</span> <span class="s">&quot;favorite_color&quot;</span><span class="p">),</span> <span class="s">&quot;namesAndFavColors.parquet&quot;</span><span class="p">)</span>
</pre></div>
    <div><small>在“ examples / src / main / r / RSparkSQLExample”中找到完整的示例代码。Spark仓库中的R”。</small></div>

  </div>
</div>

<h3 id="manually-specifying-options">手动指定选项</h3>

<p>您还可以手动指定将要使用的数据源以及要传递给数据源的任何其他选项。数据源以其完全限定的名称（即， <code>org.apache.spark.sql.parquet</code> ），但对于内置源，您也可以使用其简称（ <code>json</code> ， <code>parquet</code> ， <code>jdbc</code> ， <code>orc</code> ， <code>libsvm</code> ， <code>csv</code> ， <code>text</code> ）。从任何数据源类型加载的DataFrame都可以使用此语法转换为其他类型。</p>

<p>请参阅API文档以获取内置源的可用选项，例如， <code>org.apache.spark.sql.DataFrameReader</code>和<code>org.apache.spark.sql.DataFrameWriter</code> 。此处记录的选项也应通过非Scala Spark API（例如PySpark）应用。对于其他格式，请参阅特定格式的API文档。</p>

<p>要加载JSON文件，您可以使用：</p>

<div class="codetabs">
<div data-lang="scala">
    <div class="highlight"><pre><span></span><span class="k">val</span> <span class="n">peopleDF</span> <span class="k">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">format</span><span class="o">(</span><span class="s">&quot;json&quot;</span><span class="o">).</span><span class="n">load</span><span class="o">(</span><span class="s">&quot;examples/src/main/resources/people.json&quot;</span><span class="o">)</span>
<span class="n">peopleDF</span><span class="o">.</span><span class="n">select</span><span class="o">(</span><span class="s">&quot;name&quot;</span><span class="o">,</span> <span class="s">&quot;age&quot;</span><span class="o">).</span><span class="n">write</span><span class="o">.</span><span class="n">format</span><span class="o">(</span><span class="s">&quot;parquet&quot;</span><span class="o">).</span><span class="n">save</span><span class="o">(</span><span class="s">&quot;namesAndAges.parquet&quot;</span><span class="o">)</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / scala / org / apache / spark / examples / sql / SQLDataSourceExample.scala”中找到完整的示例代码。</small></div>
  </div>

<div data-lang="java">
    <div class="highlight"><pre><span></span><span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">peopleDF</span> <span class="o">=</span>
  <span class="n">spark</span><span class="o">.</span><span class="na">read</span><span class="o">().</span><span class="na">format</span><span class="o">(</span><span class="s">&quot;json&quot;</span><span class="o">).</span><span class="na">load</span><span class="o">(</span><span class="s">&quot;examples/src/main/resources/people.json&quot;</span><span class="o">);</span>
<span class="n">peopleDF</span><span class="o">.</span><span class="na">select</span><span class="o">(</span><span class="s">&quot;name&quot;</span><span class="o">,</span> <span class="s">&quot;age&quot;</span><span class="o">).</span><span class="na">write</span><span class="o">().</span><span class="na">format</span><span class="o">(</span><span class="s">&quot;parquet&quot;</span><span class="o">).</span><span class="na">save</span><span class="o">(</span><span class="s">&quot;namesAndAges.parquet&quot;</span><span class="o">);</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / java / org / apache / spark / examples / sql / JavaSQLDataSourceExample.java”中找到完整的示例代码。</small></div>
  </div>

<div data-lang="python">
    <div class="highlight"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;examples/src/main/resources/people.json&quot;</span><span class="p">,</span> <span class="n">format</span><span class="o">=</span><span class="s2">&quot;json&quot;</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s2">&quot;name&quot;</span><span class="p">,</span> <span class="s2">&quot;age&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">write</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">&quot;namesAndAges.parquet&quot;</span><span class="p">,</span> <span class="n">format</span><span class="o">=</span><span class="s2">&quot;parquet&quot;</span><span class="p">)</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / python / sql / datasource.py”中找到完整的示例代码。</small></div>
  </div>

<div data-lang="r">
    <div class="highlight"><pre><span></span>df <span class="o">&lt;-</span> read.df<span class="p">(</span><span class="s">&quot;examples/src/main/resources/people.json&quot;</span><span class="p">,</span> <span class="s">&quot;json&quot;</span><span class="p">)</span>
namesAndAges <span class="o">&lt;-</span> select<span class="p">(</span>df<span class="p">,</span> <span class="s">&quot;name&quot;</span><span class="p">,</span> <span class="s">&quot;age&quot;</span><span class="p">)</span>
write.df<span class="p">(</span>namesAndAges<span class="p">,</span> <span class="s">&quot;namesAndAges.parquet&quot;</span><span class="p">,</span> <span class="s">&quot;parquet&quot;</span><span class="p">)</span>
</pre></div>
    <div><small>在“ examples / src / main / r / RSparkSQLExample”中找到完整的示例代码。Spark仓库中的R”。</small></div>
  </div>
</div>

<p>要加载CSV文件，您可以使用：</p>

<div class="codetabs">
<div data-lang="scala">
    <div class="highlight"><pre><span></span><span class="k">val</span> <span class="n">peopleDFCsv</span> <span class="k">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">format</span><span class="o">(</span><span class="s">&quot;csv&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">option</span><span class="o">(</span><span class="s">&quot;sep&quot;</span><span class="o">,</span> <span class="s">&quot;;&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">option</span><span class="o">(</span><span class="s">&quot;inferSchema&quot;</span><span class="o">,</span> <span class="s">&quot;true&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">option</span><span class="o">(</span><span class="s">&quot;header&quot;</span><span class="o">,</span> <span class="s">&quot;true&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">load</span><span class="o">(</span><span class="s">&quot;examples/src/main/resources/people.csv&quot;</span><span class="o">)</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / scala / org / apache / spark / examples / sql / SQLDataSourceExample.scala”中找到完整的示例代码。</small></div>
  </div>

<div data-lang="java">
    <div class="highlight"><pre><span></span><span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">peopleDFCsv</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="na">read</span><span class="o">().</span><span class="na">format</span><span class="o">(</span><span class="s">&quot;csv&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">option</span><span class="o">(</span><span class="s">&quot;sep&quot;</span><span class="o">,</span> <span class="s">&quot;;&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">option</span><span class="o">(</span><span class="s">&quot;inferSchema&quot;</span><span class="o">,</span> <span class="s">&quot;true&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">option</span><span class="o">(</span><span class="s">&quot;header&quot;</span><span class="o">,</span> <span class="s">&quot;true&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">load</span><span class="o">(</span><span class="s">&quot;examples/src/main/resources/people.csv&quot;</span><span class="o">);</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / java / org / apache / spark / examples / sql / JavaSQLDataSourceExample.java”中找到完整的示例代码。</small></div>
  </div>

<div data-lang="python">
    <div class="highlight"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;examples/src/main/resources/people.csv&quot;</span><span class="p">,</span>
                     <span class="n">format</span><span class="o">=</span><span class="s2">&quot;csv&quot;</span><span class="p">,</span> <span class="n">sep</span><span class="o">=</span><span class="s2">&quot;:&quot;</span><span class="p">,</span> <span class="n">inferSchema</span><span class="o">=</span><span class="s2">&quot;true&quot;</span><span class="p">,</span> <span class="n">header</span><span class="o">=</span><span class="s2">&quot;true&quot;</span><span class="p">)</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / python / sql / datasource.py”中找到完整的示例代码。</small></div>
  </div>

<div data-lang="r">
    <div class="highlight"><pre><span></span>df <span class="o">&lt;-</span> read.df<span class="p">(</span><span class="s">&quot;examples/src/main/resources/people.csv&quot;</span><span class="p">,</span> <span class="s">&quot;csv&quot;</span><span class="p">,</span> sep <span class="o">=</span> <span class="s">&quot;;&quot;</span><span class="p">,</span> inferSchema <span class="o">=</span> <span class="kc">TRUE</span><span class="p">,</span> header <span class="o">=</span> <span class="kc">TRUE</span><span class="p">)</span>
namesAndAges <span class="o">&lt;-</span> select<span class="p">(</span>df<span class="p">,</span> <span class="s">&quot;name&quot;</span><span class="p">,</span> <span class="s">&quot;age&quot;</span><span class="p">)</span>
</pre></div>
    <div><small>在“ examples / src / main / r / RSparkSQLExample”中找到完整的示例代码。Spark仓库中的R”。</small></div>

  </div>
</div>

<p>要加载具有与给定全局模式匹配的路径的文件，同时保持分区发现的行为，可以使用：</p>

<div class="codetabs">
<div data-lang="scala">
    <div class="highlight"><pre><span></span><span class="k">val</span> <span class="n">partitionedUsersDF</span> <span class="k">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">format</span><span class="o">(</span><span class="s">&quot;orc&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">option</span><span class="o">(</span><span class="s">&quot;pathGlobFilter&quot;</span><span class="o">,</span> <span class="s">&quot;*.orc&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">load</span><span class="o">(</span><span class="s">&quot;examples/src/main/resources/partitioned_users.orc&quot;</span><span class="o">)</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / scala / org / apache / spark / examples / sql / SQLDataSourceExample.scala”中找到完整的示例代码。</small></div>
  </div>

<div data-lang="java">
    <div class="highlight"><pre><span></span><span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">partitionedUsersDF</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="na">read</span><span class="o">().</span><span class="na">format</span><span class="o">(</span><span class="s">&quot;orc&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">option</span><span class="o">(</span><span class="s">&quot;pathGlobFilter&quot;</span><span class="o">,</span> <span class="s">&quot;*.orc&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">load</span><span class="o">(</span><span class="s">&quot;examples/src/main/resources/partitioned_users.orc&quot;</span><span class="o">);</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / java / org / apache / spark / examples / sql / JavaSQLDataSourceExample.java”中找到完整的示例代码。</small></div>
  </div>

<div data-lang="python">
    <div class="highlight"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;examples/src/main/resources/partitioned_users.orc&quot;</span><span class="p">,</span>
                     <span class="n">format</span><span class="o">=</span><span class="s2">&quot;orc&quot;</span><span class="p">,</span> <span class="n">pathGlobFilter</span><span class="o">=</span><span class="s2">&quot;*.orc&quot;</span><span class="p">)</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / python / sql / datasource.py”中找到完整的示例代码。</small></div>
  </div>

<div data-lang="r">
    <div class="highlight"><pre><span></span>df <span class="o">&lt;-</span> read.df<span class="p">(</span><span class="s">&quot;examples/src/main/resources/partitioned_users.orc&quot;</span><span class="p">,</span> <span class="s">&quot;orc&quot;</span><span class="p">,</span> pathGlobFilter <span class="o">=</span> <span class="s">&quot;*.orc&quot;</span><span class="p">)</span>
</pre></div>
    <div><small>在“ examples / src / main / r / RSparkSQLExample”中找到完整的示例代码。Spark仓库中的R”。</small></div>
  </div>
</div>

<p>额外选项在写操作期间也使用。例如，您可以控制ORC数据源的Bloom过滤器和字典编码。以下ORC示例将创建Bloom过滤器，并仅将字典编码用于<code>favorite_color</code> 。对于实木复合地板，存在<code>parquet.enable.dictionary</code>也一样要查找有关其他ORC / Parquet选项的更多详细信息，请访问Apache ORC / Parquet官方网站。</p>

<div class="codetabs">

<div data-lang="scala">
    <div class="highlight"><pre><span></span><span class="n">usersDF</span><span class="o">.</span><span class="n">write</span><span class="o">.</span><span class="n">format</span><span class="o">(</span><span class="s">&quot;orc&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">option</span><span class="o">(</span><span class="s">&quot;orc.bloom.filter.columns&quot;</span><span class="o">,</span> <span class="s">&quot;favorite_color&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">option</span><span class="o">(</span><span class="s">&quot;orc.dictionary.key.threshold&quot;</span><span class="o">,</span> <span class="s">&quot;1.0&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">option</span><span class="o">(</span><span class="s">&quot;orc.column.encoding.direct&quot;</span><span class="o">,</span> <span class="s">&quot;name&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">save</span><span class="o">(</span><span class="s">&quot;users_with_options.orc&quot;</span><span class="o">)</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / scala / org / apache / spark / examples / sql / SQLDataSourceExample.scala”中找到完整的示例代码。</small></div>
  </div>

<div data-lang="java">
    <div class="highlight"><pre><span></span><span class="n">usersDF</span><span class="o">.</span><span class="na">write</span><span class="o">().</span><span class="na">format</span><span class="o">(</span><span class="s">&quot;orc&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">option</span><span class="o">(</span><span class="s">&quot;orc.bloom.filter.columns&quot;</span><span class="o">,</span> <span class="s">&quot;favorite_color&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">option</span><span class="o">(</span><span class="s">&quot;orc.dictionary.key.threshold&quot;</span><span class="o">,</span> <span class="s">&quot;1.0&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">option</span><span class="o">(</span><span class="s">&quot;orc.column.encoding.direct&quot;</span><span class="o">,</span> <span class="s">&quot;name&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">save</span><span class="o">(</span><span class="s">&quot;users_with_options.orc&quot;</span><span class="o">);</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / java / org / apache / spark / examples / sql / JavaSQLDataSourceExample.java”中找到完整的示例代码。</small></div>
  </div>

<div data-lang="python">
    <div class="highlight"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">orc</span><span class="p">(</span><span class="s2">&quot;examples/src/main/resources/users.orc&quot;</span><span class="p">)</span>
<span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">write</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot;orc&quot;</span><span class="p">)</span>
    <span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;orc.bloom.filter.columns&quot;</span><span class="p">,</span> <span class="s2">&quot;favorite_color&quot;</span><span class="p">)</span>
    <span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;orc.dictionary.key.threshold&quot;</span><span class="p">,</span> <span class="s2">&quot;1.0&quot;</span><span class="p">)</span>
    <span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;orc.column.encoding.direct&quot;</span><span class="p">,</span> <span class="s2">&quot;name&quot;</span><span class="p">)</span>
    <span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">&quot;users_with_options.orc&quot;</span><span class="p">))</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / python / sql / datasource.py”中找到完整的示例代码。</small></div>
  </div>

<div data-lang="r">
    <div class="highlight"><pre><span></span>df <span class="o">&lt;-</span> read.df<span class="p">(</span><span class="s">&quot;examples/src/main/resources/users.orc&quot;</span><span class="p">,</span> <span class="s">&quot;orc&quot;</span><span class="p">)</span>
write.orc<span class="p">(</span>df<span class="p">,</span> <span class="s">&quot;users_with_options.orc&quot;</span><span class="p">,</span> orc.bloom.filter.columns <span class="o">=</span> <span class="s">&quot;favorite_color&quot;</span><span class="p">,</span> orc.dictionary.key.threshold <span class="o">=</span> <span class="m">1.0</span><span class="p">,</span> orc.column.encoding.direct <span class="o">=</span> <span class="s">&quot;name&quot;</span><span class="p">)</span>
</pre></div>
    <div><small>在“ examples / src / main / r / RSparkSQLExample”中找到完整的示例代码。Spark仓库中的R”。</small></div>
  </div>

<div data-lang="sql">

    <figure class="highlight"><pre><code class="language-sql" data-lang="sql"><span></span><span class="k">CREATE</span> <span class="k">TABLE</span> <span class="n">users_with_options</span> <span class="p">(</span>
  <span class="n">name</span> <span class="n">STRING</span><span class="p">,</span>
  <span class="n">favorite_color</span> <span class="n">STRING</span><span class="p">,</span>
  <span class="n">favorite_numbers</span> <span class="nb">array</span><span class="o">&lt;</span><span class="nb">integer</span><span class="o">&gt;</span>
<span class="p">)</span> <span class="k">USING</span> <span class="n">ORC</span>
<span class="k">OPTIONS</span> <span class="p">(</span>
  <span class="n">orc</span><span class="p">.</span><span class="n">bloom</span><span class="p">.</span><span class="n">filter</span><span class="p">.</span><span class="n">columns</span> <span class="s1">&#39;favorite_color&#39;</span><span class="p">,</span>
  <span class="n">orc</span><span class="p">.</span><span class="k">dictionary</span><span class="p">.</span><span class="k">key</span><span class="p">.</span><span class="n">threshold</span> <span class="s1">&#39;1.0&#39;</span><span class="p">,</span>
  <span class="n">orc</span><span class="p">.</span><span class="k">column</span><span class="p">.</span><span class="k">encoding</span><span class="p">.</span><span class="n">direct</span> <span class="s1">&#39;name&#39;</span>
<span class="p">)</span></code></pre></figure>

  </div>

</div>

<h3 id="run-sql-on-files-directly">直接在文件上运行SQL</h3>

<p>除了使用读取API将文件加载到DataFrame中并进行查询之外，您还可以直接使用SQL查询该文件。</p>

<div class="codetabs">
<div data-lang="scala">
    <div class="highlight"><pre><span></span><span class="k">val</span> <span class="n">sqlDF</span> <span class="k">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">sql</span><span class="o">(</span><span class="s">&quot;SELECT * FROM parquet.`examples/src/main/resources/users.parquet`&quot;</span><span class="o">)</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / scala / org / apache / spark / examples / sql / SQLDataSourceExample.scala”中找到完整的示例代码。</small></div>
  </div>

<div data-lang="java">
    <div class="highlight"><pre><span></span><span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">sqlDF</span> <span class="o">=</span>
  <span class="n">spark</span><span class="o">.</span><span class="na">sql</span><span class="o">(</span><span class="s">&quot;SELECT * FROM parquet.`examples/src/main/resources/users.parquet`&quot;</span><span class="o">);</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / java / org / apache / spark / examples / sql / JavaSQLDataSourceExample.java”中找到完整的示例代码。</small></div>
  </div>

<div data-lang="python">
    <div class="highlight"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">sql</span><span class="p">(</span><span class="s2">&quot;SELECT * FROM parquet.`examples/src/main/resources/users.parquet`&quot;</span><span class="p">)</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / python / sql / datasource.py”中找到完整的示例代码。</small></div>
  </div>

<div data-lang="r">
    <div class="highlight"><pre><span></span>df <span class="o">&lt;-</span> sql<span class="p">(</span><span class="s">&quot;SELECT * FROM parquet.`examples/src/main/resources/users.parquet`&quot;</span><span class="p">)</span>
</pre></div>
    <div><small>在“ examples / src / main / r / RSparkSQLExample”中找到完整的示例代码。Spark仓库中的R”。</small></div>

  </div>
</div>

<h3 id="save-modes">保存模式</h3>

<p>保存操作可以选择执行<code>SaveMode</code> ，它指定如何处理现有数据（如果存在）。重要的是要认识到这些保存模式不利用任何锁定，也不是原子的。此外，执行<code>Overwrite</code> ，则数据将在写出新数据之前被删除。</p>

<table class="table">
<tbody><tr><th>Scala / Java</th><th>任何语言</th><th>含义</th></tr>
<tr>
  <td><code>SaveMode.ErrorIfExists</code> （默认）</td>
  <td><code>"error" or "errorifexists"</code> （默认）</td>
  <td>将DataFrame保存到数据源时，如果已经存在数据，则将引发异常。
  </td>
</tr>
<tr>
  <td><code>SaveMode.Append</code></td>
  <td><code>"append"</code></td>
  <td>将DataFrame保存到数据源时，如果已经存在数据/表，则应该将DataFrame的内容附加到现有数据中。
  </td>
</tr>
<tr>
  <td><code>SaveMode.Overwrite</code></td>
  <td><code>"overwrite"</code></td>
  <td>覆盖模式意味着将DataFrame保存到数据源时，如果已经存在数据/表，则预期现有数据将被DataFrame的内容覆盖。
  </td>
</tr>
<tr>
  <td><code>SaveMode.Ignore</code></td>
  <td><code>"ignore"</code></td>
  <td>忽略模式意味着在将DataFrame保存到数据源时，如果已经存在数据，则预期保存操作将不保存DataFrame的内容并且不更改现有数据。这类似于一个<code>CREATE TABLE IF NOT EXISTS</code>在SQL中。</td>
</tr>
</tbody></table>

<h3 id="saving-to-persistent-tables">保存到永久表</h3>

<p><code>DataFrames</code>也可以使用以下命令作为持久表保存到Hive Metastore中： <code>saveAsTable</code>命令。请注意，使用此功能不需要现有的Hive部署。Spark将为您创建一个默认的本地Hive Metastore（使用Derby）。不像<code>createOrReplaceTempView</code>命令， <code>saveAsTable</code>将具体化DataFrame的内容并在Hive元存储中创建一个指向数据的指针。即使您重新启动Spark程序，持久表仍将存在，只要您保持与同一metastore的连接即可。持久表的DataFrame可以通过调用<code>table</code>上的方法<code>SparkSession</code>表的名称。</p>

<p>对于基于文件的数据源，例如文本，镶木地板，json等，您可以通过<code>path</code>选项，例如<code>df.write.option("path", "/some/path").saveAsTable("t")</code> 。删除表后，自定义表路径将不会删除，并且表数据仍然存在。如果未指定自定义表路径，Spark会将数据写入仓库目录下的默认表路径。删除表后，默认表路径也将被删除。</p>

<p>从Spark 2.1开始，持久数据源表在Hive元存储中存储了按分区的元数据。这带来了几个好处：</p>

<ul>
  <li>由于元存储只能返回查询的必要分区，因此不再需要在第一个查询中将所有分区发现到表中。</li>
  <li>配置单元DDL，例如<code>ALTER TABLE PARTITION ... SET LOCATION</code>现在可用于使用数据源API创建的表。</li>
</ul>

<p>请注意，创建外部数据源表（带有<code>path</code>选项）。要同步元存储中的分区信息，您可以调用<code>MSCK REPAIR TABLE</code> 。</p>

<h3 id="bucketing-sorting-and-partitioning">桶，分类和分区</h3>

<p>对于基于文件的数据源，也可以对输出进行存储和分类或分区。存储桶和排序仅适用于持久表：</p>

<div class="codetabs">

<div data-lang="scala">
    <div class="highlight"><pre><span></span><span class="n">peopleDF</span><span class="o">.</span><span class="n">write</span><span class="o">.</span><span class="n">bucketBy</span><span class="o">(</span><span class="mi">42</span><span class="o">,</span> <span class="s">&quot;name&quot;</span><span class="o">).</span><span class="n">sortBy</span><span class="o">(</span><span class="s">&quot;age&quot;</span><span class="o">).</span><span class="n">saveAsTable</span><span class="o">(</span><span class="s">&quot;people_bucketed&quot;</span><span class="o">)</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / scala / org / apache / spark / examples / sql / SQLDataSourceExample.scala”中找到完整的示例代码。</small></div>
  </div>

<div data-lang="java">
    <div class="highlight"><pre><span></span><span class="n">peopleDF</span><span class="o">.</span><span class="na">write</span><span class="o">().</span><span class="na">bucketBy</span><span class="o">(</span><span class="mi">42</span><span class="o">,</span> <span class="s">&quot;name&quot;</span><span class="o">).</span><span class="na">sortBy</span><span class="o">(</span><span class="s">&quot;age&quot;</span><span class="o">).</span><span class="na">saveAsTable</span><span class="o">(</span><span class="s">&quot;people_bucketed&quot;</span><span class="o">);</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / java / org / apache / spark / examples / sql / JavaSQLDataSourceExample.java”中找到完整的示例代码。</small></div>
  </div>

<div data-lang="python">
    <div class="highlight"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">write</span><span class="o">.</span><span class="n">bucketBy</span><span class="p">(</span><span class="mi">42</span><span class="p">,</span> <span class="s2">&quot;name&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">sortBy</span><span class="p">(</span><span class="s2">&quot;age&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">saveAsTable</span><span class="p">(</span><span class="s2">&quot;people_bucketed&quot;</span><span class="p">)</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / python / sql / datasource.py”中找到完整的示例代码。</small></div>
  </div>

<div data-lang="sql">

    <figure class="highlight"><pre><code class="language-sql" data-lang="sql"><span></span><span class="k">CREATE</span> <span class="k">TABLE</span> <span class="n">users_bucketed_by_name</span><span class="p">(</span>
  <span class="n">name</span> <span class="n">STRING</span><span class="p">,</span>
  <span class="n">favorite_color</span> <span class="n">STRING</span><span class="p">,</span>
  <span class="n">favorite_numbers</span> <span class="nb">array</span><span class="o">&lt;</span><span class="nb">integer</span><span class="o">&gt;</span>
<span class="p">)</span> <span class="k">USING</span> <span class="n">parquet</span>
<span class="n">CLUSTERED</span> <span class="k">BY</span><span class="p">(</span><span class="n">name</span><span class="p">)</span> <span class="k">INTO</span> <span class="mi">42</span> <span class="n">BUCKETS</span><span class="p">;</span></code></pre></figure>

  </div>

</div>

<p>虽然分区可以与<code>save</code>和<code>saveAsTable</code>使用数据集API时。</p>

<div class="codetabs">

<div data-lang="scala">
    <div class="highlight"><pre><span></span><span class="n">usersDF</span><span class="o">.</span><span class="n">write</span><span class="o">.</span><span class="n">partitionBy</span><span class="o">(</span><span class="s">&quot;favorite_color&quot;</span><span class="o">).</span><span class="n">format</span><span class="o">(</span><span class="s">&quot;parquet&quot;</span><span class="o">).</span><span class="n">save</span><span class="o">(</span><span class="s">&quot;namesPartByColor.parquet&quot;</span><span class="o">)</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / scala / org / apache / spark / examples / sql / SQLDataSourceExample.scala”中找到完整的示例代码。</small></div>
  </div>

<div data-lang="java">
    <div class="highlight"><pre><span></span><span class="n">usersDF</span>
  <span class="o">.</span><span class="na">write</span><span class="o">()</span>
  <span class="o">.</span><span class="na">partitionBy</span><span class="o">(</span><span class="s">&quot;favorite_color&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">format</span><span class="o">(</span><span class="s">&quot;parquet&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">save</span><span class="o">(</span><span class="s">&quot;namesPartByColor.parquet&quot;</span><span class="o">);</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / java / org / apache / spark / examples / sql / JavaSQLDataSourceExample.java”中找到完整的示例代码。</small></div>
  </div>

<div data-lang="python">
    <div class="highlight"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">write</span><span class="o">.</span><span class="n">partitionBy</span><span class="p">(</span><span class="s2">&quot;favorite_color&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot;parquet&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">&quot;namesPartByColor.parquet&quot;</span><span class="p">)</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / python / sql / datasource.py”中找到完整的示例代码。</small></div>
  </div>

<div data-lang="sql">

    <figure class="highlight"><pre><code class="language-sql" data-lang="sql"><span></span><span class="k">CREATE</span> <span class="k">TABLE</span> <span class="n">users_by_favorite_color</span><span class="p">(</span>
  <span class="n">name</span> <span class="n">STRING</span><span class="p">,</span>
  <span class="n">favorite_color</span> <span class="n">STRING</span><span class="p">,</span>
  <span class="n">favorite_numbers</span> <span class="nb">array</span><span class="o">&lt;</span><span class="nb">integer</span><span class="o">&gt;</span>
<span class="p">)</span> <span class="k">USING</span> <span class="n">csv</span> <span class="n">PARTITIONED</span> <span class="k">BY</span><span class="p">(</span><span class="n">favorite_color</span><span class="p">);</span></code></pre></figure>

  </div>

</div>

<p>可以对单个表使用分区和存储桶：</p>

<div class="codetabs">

<div data-lang="scala">
    <div class="highlight"><pre><span></span><span class="n">usersDF</span>
  <span class="o">.</span><span class="n">write</span>
  <span class="o">.</span><span class="n">partitionBy</span><span class="o">(</span><span class="s">&quot;favorite_color&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">bucketBy</span><span class="o">(</span><span class="mi">42</span><span class="o">,</span> <span class="s">&quot;name&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">saveAsTable</span><span class="o">(</span><span class="s">&quot;users_partitioned_bucketed&quot;</span><span class="o">)</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / scala / org / apache / spark / examples / sql / SQLDataSourceExample.scala”中找到完整的示例代码。</small></div>
  </div>

<div data-lang="java">
    <div class="highlight"><pre><span></span><span class="n">peopleDF</span>
  <span class="o">.</span><span class="na">write</span><span class="o">()</span>
  <span class="o">.</span><span class="na">partitionBy</span><span class="o">(</span><span class="s">&quot;favorite_color&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">bucketBy</span><span class="o">(</span><span class="mi">42</span><span class="o">,</span> <span class="s">&quot;name&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">saveAsTable</span><span class="o">(</span><span class="s">&quot;people_partitioned_bucketed&quot;</span><span class="o">);</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / java / org / apache / spark / examples / sql / JavaSQLDataSourceExample.java”中找到完整的示例代码。</small></div>
  </div>

<div data-lang="python">
    <div class="highlight"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">parquet</span><span class="p">(</span><span class="s2">&quot;examples/src/main/resources/users.parquet&quot;</span><span class="p">)</span>
<span class="p">(</span><span class="n">df</span>
    <span class="o">.</span><span class="n">write</span>
    <span class="o">.</span><span class="n">partitionBy</span><span class="p">(</span><span class="s2">&quot;favorite_color&quot;</span><span class="p">)</span>
    <span class="o">.</span><span class="n">bucketBy</span><span class="p">(</span><span class="mi">42</span><span class="p">,</span> <span class="s2">&quot;name&quot;</span><span class="p">)</span>
    <span class="o">.</span><span class="n">saveAsTable</span><span class="p">(</span><span class="s2">&quot;people_partitioned_bucketed&quot;</span><span class="p">))</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / python / sql / datasource.py”中找到完整的示例代码。</small></div>
  </div>

<div data-lang="sql">

    <figure class="highlight"><pre><code class="language-sql" data-lang="sql"><span></span><span class="k">CREATE</span> <span class="k">TABLE</span> <span class="n">users_bucketed_and_partitioned</span><span class="p">(</span>
  <span class="n">name</span> <span class="n">STRING</span><span class="p">,</span>
  <span class="n">favorite_color</span> <span class="n">STRING</span><span class="p">,</span>
  <span class="n">favorite_numbers</span> <span class="nb">array</span><span class="o">&lt;</span><span class="nb">integer</span><span class="o">&gt;</span>
<span class="p">)</span> <span class="k">USING</span> <span class="n">parquet</span>
<span class="n">PARTITIONED</span> <span class="k">BY</span> <span class="p">(</span><span class="n">favorite_color</span><span class="p">)</span>
<span class="n">CLUSTERED</span> <span class="k">BY</span><span class="p">(</span><span class="n">name</span><span class="p">)</span> <span class="n">SORTED</span> <span class="k">BY</span> <span class="p">(</span><span class="n">favorite_numbers</span><span class="p">)</span> <span class="k">INTO</span> <span class="mi">42</span> <span class="n">BUCKETS</span><span class="p">;</span></code></pre></figure>

  </div>

</div>

<p><code>partitionBy</code>创建一个<a href="sql-data-sources-parquet.html#partition-discovery">分区</a>结构，如“ <a href="sql-data-sources-parquet.html#partition-discovery">分区发现”</a>部分所述。因此，它对具有高基数的列的适用性有限。相反<code>bucketBy</code>将数据分布在固定数量的存储桶中，并且当唯一值的数量不受限制时可以使用。</p>


                </div>
            
             <!-- /container -->
        </div>

        <script src="js/vendor/jquery-3.4.1.min.js"></script>
        <script src="js/vendor/bootstrap.min.js"></script>
        <script src="js/vendor/anchor.min.js"></script>
        <script src="js/main.js"></script>

        <!-- MathJax Section -->
        <script type="text/x-mathjax-config">
            MathJax.Hub.Config({
                TeX: { equationNumbers: { autoNumber: "AMS" } }
            });
        </script>
        <script>
            // Note that we load MathJax this way to work with local file (file://), HTTP and HTTPS.
            // We could use "//cdn.mathjax...", but that won't support "file://".
            (function(d, script) {
                script = d.createElement('script');
                script.type = 'text/javascript';
                script.async = true;
                script.onload = function(){
                    MathJax.Hub.Config({
                        tex2jax: {
                            inlineMath: [ ["$", "$"], ["\\\\(","\\\\)"] ],
                            displayMath: [ ["$$","$$"], ["\\[", "\\]"] ],
                            processEscapes: true,
                            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre']
                        }
                    });
                };
                script.src = ('https:' == document.location.protocol ? 'https://' : 'http://') +
                    'cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js' +
                    '?config=TeX-AMS-MML_HTMLorMML';
                d.getElementsByTagName('head')[0].appendChild(script);
            }(document));
        </script>
    

</body></html>