<html class="no-js" ><!--<![endif]--><head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
        <title>提交申请-Spark 3.0.0-预览文档</title>
        

        

        <link rel="stylesheet" href="css/bootstrap.min.css">
        <style>
            body {
                padding-top: 60px;
                padding-bottom: 40px;
            }
        </style>
        <meta name="viewport" content="width=device-width">
        <link rel="stylesheet" href="css/bootstrap-responsive.min.css">
        <link rel="stylesheet" href="css/main.css">

        <script src="js/vendor/modernizr-2.6.1-respond-1.1.0.min.js"></script>

        <link rel="stylesheet" href="css/pygments-default.css">

        
        <!-- Google analytics script -->
        <script type="text/javascript">
          var _gaq = _gaq || [];
          _gaq.push(['_setAccount', 'UA-32518208-2']);
          _gaq.push(['_trackPageview']);

          (function() {
            var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
            ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
            var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
          })();
        </script>
        

    </head>
    <body >
        <!--[if lt IE 7]>
            <p class="chromeframe">You are using an outdated browser. <a href="https://browsehappy.com/">Upgrade your browser today</a> or <a href="http://www.google.com/chromeframe/?redirect=true">install Google Chrome Frame</a> to better experience this site.</p>
        <![endif]-->

        <!-- This code is taken from http://twitter.github.com/bootstrap/examples/hero.html -->

        <div class="navbar navbar-fixed-top" id="topbar">
            <div class="navbar-inner">
                <div class="container">
                    <div class="brand"><a href="index.html"><img src="img/spark-logo-hd.png" style="height:50px"></a> <span class="version">3.0.0预览版</span>
                    </div>
                    <ul class="nav">
                        <!--TODO(andyk): Add class="active" attribute to li some how.-->
                        <li><a href="index.html">总览</a></li>

                        <li class="dropdown">
                            <a href="#" class="dropdown-toggle" data-toggle="dropdown">编程指南<b class="caret"></b></a>
                            <ul class="dropdown-menu">
                                <li><a href="quick-start.html">快速开始</a></li>
                                <li><a href="rdd-programming-guide.html">RDD，累加器，广播变量</a></li>
                                <li><a href="sql-programming-guide.html">SQL，数据框和数据集</a></li>
                                <li><a href="structured-streaming-programming-guide.html">结构化流</a></li>
                                <li><a href="streaming-programming-guide.html">火花流（DStreams）</a></li>
                                <li><a href="ml-guide.html">MLlib（机器学习）</a></li>
                                <li><a href="graphx-programming-guide.html">GraphX（图形处理）</a></li>
                                <li><a href="sparkr.html">SparkR（Spark上的R）</a></li>
                            </ul>
                        </li>

                        <li class="dropdown">
                            <a href="#" class="dropdown-toggle" data-toggle="dropdown">API文件<b class="caret"></b></a>
                            <ul class="dropdown-menu">
                                <li><a href="api/scala/index.html#org.apache.spark.package">斯卡拉</a></li>
                                <li><a href="api/java/index.html">爪哇</a></li>
                                <li><a href="api/python/index.html">蟒蛇</a></li>
                                <li><a href="api/R/index.html">[R</a></li>
                                <li><a href="api/sql/index.html">SQL，内置函数</a></li>
                            </ul>
                        </li>

                        <li class="dropdown">
                            <a href="#" class="dropdown-toggle" data-toggle="dropdown">部署中<b class="caret"></b></a>
                            <ul class="dropdown-menu">
                                <li><a href="cluster-overview.html">总览</a></li>
                                <li><a href="submitting-applications.html">提交申请</a></li>
                                <li class="divider"></li>
                                <li><a href="spark-standalone.html">Spark独立</a></li>
                                <li><a href="running-on-mesos.html">梅索斯</a></li>
                                <li><a href="running-on-yarn.html">纱</a></li>
                                <li><a href="running-on-kubernetes.html">Kubernetes</a></li>
                            </ul>
                        </li>

                        <li class="dropdown">
                            <a href="api.html" class="dropdown-toggle" data-toggle="dropdown">更多<b class="caret"></b></a>
                            <ul class="dropdown-menu">
                                <li><a href="configuration.html">组态</a></li>
                                <li><a href="monitoring.html">监控方式</a></li>
                                <li><a href="tuning.html">调音指南</a></li>
                                <li><a href="job-scheduling.html">作业调度</a></li>
                                <li><a href="security.html">安全</a></li>
                                <li><a href="hardware-provisioning.html">硬件配置</a></li>
                                <li><a href="migration-guide.html">迁移指南</a></li>
                                <li class="divider"></li>
                                <li><a href="building-spark.html">建筑火花</a></li>
                                <li><a href="https://spark.apache.org/contributing.html">为Spark贡献</a></li>
                                <li><a href="https://spark.apache.org/third-party-projects.html">第三方项目</a></li>
                            </ul>
                        </li>
                    </ul>
                    <!--<p class="navbar-text pull-right"><span class="version-text">v3.0.0-preview</span></p>-->
                </div>
            </div>
        </div>

        <div class="container-wrapper">

            
                <div class="content" id="content">
                    
                        <h1 class="title">提交申请</h1>
                    

                    <p>的<code>spark-submit</code> Spark的脚本<code>bin</code>目录用于在群集上启动应用程序。它可以通过统一的界面使用Spark所有受支持的<a href="cluster-overview.html#cluster-manager-types">集群管理器</a> ，因此您无需特别为每个应用程序配置应用程序。</p>

<h1 id="bundling-your-applications-dependencies">捆绑应用程序的依赖项</h1>
<p>如果您的代码依赖于其他项目，则需要将它们打包在您的应用程序旁边，以便将代码分发到Spark集群。为此，创建一个包含您的代码及其依赖项的程序集jar（或“超级” jar）。<a href="https://github.com/sbt/sbt-assembly">sbt</a>和<a href="http://maven.apache.org/plugins/maven-shade-plugin/">Maven</a>都有程序集插件。创建程序集jar时，将Spark和Hadoop列出为<code>provided</code>依赖这些不需要捆绑在一起，因为它们是由集群管理器在运行时提供的。装好罐子后，您可以致电<code>bin/spark-submit</code>传递jar时，脚本如下所示。</p>

<p>对于Python，您可以使用<code>--py-files</code>的论点<code>spark-submit</code>添加<code>.py</code> ， <code>.zip</code>要么<code>.egg</code>与您的应用程序一起分发的文件。如果您依赖多个Python文件，我们建议将它们打包到一个<code>.zip</code>要么<code>.egg</code> 。</p>

<h1 id="launching-applications-with-spark-submit">通过提交火花启动应用程序</h1>

<p>捆绑用户应用程序后，可以使用<code>bin/spark-submit</code>脚本。该脚本负责使用Spark及其依赖项设置类路径，并且可以支持不同的集群管理器和Spark支持的部署模式：</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span></span>./bin/spark-submit <span class="se">\</span>
  --class &lt;main-class&gt; <span class="se">\</span>
  --master &lt;master-url&gt; <span class="se">\</span>
  --deploy-mode &lt;deploy-mode&gt; <span class="se">\</span>
  --conf &lt;key&gt;<span class="o">=</span>&lt;value&gt; <span class="se">\</span>
  ... <span class="c1"># other options</span>
  &lt;application-jar&gt; <span class="se">\</span>
  <span class="o">[</span>application-arguments<span class="o">]</span></code></pre></figure>

<p>一些常用的选项是：</p>

<ul>
  <li><code>--class</code> ：您的应用程序的入口点（例如<code>org.apache.spark.examples.SparkPi</code> ）</li>
  <li><code>--master</code> ：集群的<a href="#master-urls">主URL</a> （例如<code>spark://23.195.26.187:7077</code> ）</li>
  <li><code>--deploy-mode</code> ：是否在工作程序节点上部署驱动程序（ <code>cluster</code> ）或本地作为外部客户（ <code>client</code> ）（默认值： <code>client</code> ） <b>†</b></li>
  <li><code>--conf</code> ：键=值格式的任意Spark配置属性。对于包含空格的值，将“ key = value”用引号引起来（如图所示）。多个配置应作为单独的参数传递。 （例如<code>--conf <key>=<value> --conf <key2>=<value2></code> ）</li>
  <li><code>application-jar</code> ：捆绑jar的路径，包括您的应用程序和所有依赖项。该URL必须在集群内部全局可见，例如， <code>hdfs://</code>路径或<code>file://</code>所有节点上存在的路径。</li>
  <li><code>application-arguments</code> ：参数传递给您的主类的main方法（如果有）</li>
</ul>

<p><b>†</b>常见的部署策略是从与工作计算机物理位于同一位置的网关计算机（例如，独立EC2群集中的主节点）提交应用程序。在此设置中， <code>client</code>模式是合适的。在<code>client</code>模式下，驱动程序直接在<code>spark-submit</code>作为集群<em>客户端的</em>进程。应用程序的输入和输出已附加到控制台。因此，此模式特别适用于涉及REPL的应用程序（例如Spark Shell）。</p>

<p>或者，如果您的应用程序是从远离工作计算机的计算机（例如，在笔记本电脑本地）提交的，则通常使用<code>cluster</code>模式以最小化驱动程序和执行程序之间的网络延迟。当前，独立模式不支持Python应用程序的群集模式。</p>

<p>对于Python应用程序，只需传递一个<code>.py</code>文件代替<code><application-jar></code>而不是JAR，然后添加Python <code>.zip</code> ， <code>.egg</code>要么<code>.py</code>文件到搜索路径<code>--py-files</code> 。</p>

<p>有一些特定于所使用的<a href="cluster-overview.html#cluster-manager-types">集群管理器的</a>可用选项。例如，具有一个<a href="spark-standalone.html">火花独立簇</a>与<code>cluster</code>部署模式，您还可以指定<code>--supervise</code>确保驱动程序在非零退出代码失败的情况下自动重新启动。列举所有可用的此类选项<code>spark-submit</code> ，用<code>--help</code> 。以下是一些常见选项的示例：</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span></span><span class="c1"># Run application locally on 8 cores</span>
./bin/spark-submit <span class="se">\</span>
  --class org.apache.spark.examples.SparkPi <span class="se">\</span>
  --master local<span class="o">[</span><span class="m">8</span><span class="o">]</span> <span class="se">\</span>
  /path/to/examples.jar <span class="se">\</span>
  <span class="m">100</span>

<span class="c1"># Run on a Spark standalone cluster in client deploy mode</span>
./bin/spark-submit <span class="se">\</span>
  --class org.apache.spark.examples.SparkPi <span class="se">\</span>
  --master spark://207.184.161.138:7077 <span class="se">\</span>
  --executor-memory 20G <span class="se">\</span>
  --total-executor-cores <span class="m">100</span> <span class="se">\</span>
  /path/to/examples.jar <span class="se">\</span>
  <span class="m">1000</span>

<span class="c1"># Run on a Spark standalone cluster in cluster deploy mode with supervise</span>
./bin/spark-submit <span class="se">\</span>
  --class org.apache.spark.examples.SparkPi <span class="se">\</span>
  --master spark://207.184.161.138:7077 <span class="se">\</span>
  --deploy-mode cluster <span class="se">\</span>
  --supervise <span class="se">\</span>
  --executor-memory 20G <span class="se">\</span>
  --total-executor-cores <span class="m">100</span> <span class="se">\</span>
  /path/to/examples.jar <span class="se">\</span>
  <span class="m">1000</span>

<span class="c1"># Run on a YARN cluster</span>
<span class="nb">export</span> <span class="nv">HADOOP_CONF_DIR</span><span class="o">=</span>XXX
./bin/spark-submit <span class="se">\</span>
  --class org.apache.spark.examples.SparkPi <span class="se">\</span>
  --master yarn <span class="se">\</span>
  --deploy-mode cluster <span class="se">\ </span> <span class="c1"># can be client for client mode</span>
  --executor-memory 20G <span class="se">\</span>
  --num-executors <span class="m">50</span> <span class="se">\</span>
  /path/to/examples.jar <span class="se">\</span>
  <span class="m">1000</span>

<span class="c1"># Run a Python application on a Spark standalone cluster</span>
./bin/spark-submit <span class="se">\</span>
  --master spark://207.184.161.138:7077 <span class="se">\</span>
  examples/src/main/python/pi.py <span class="se">\</span>
  <span class="m">1000</span>

<span class="c1"># Run on a Mesos cluster in cluster deploy mode with supervise</span>
./bin/spark-submit <span class="se">\</span>
  --class org.apache.spark.examples.SparkPi <span class="se">\</span>
  --master mesos://207.184.161.138:7077 <span class="se">\</span>
  --deploy-mode cluster <span class="se">\</span>
  --supervise <span class="se">\</span>
  --executor-memory 20G <span class="se">\</span>
  --total-executor-cores <span class="m">100</span> <span class="se">\</span>
  http://path/to/examples.jar <span class="se">\</span>
  <span class="m">1000</span>

<span class="c1"># Run on a Kubernetes cluster in cluster deploy mode</span>
./bin/spark-submit <span class="se">\</span>
  --class org.apache.spark.examples.SparkPi <span class="se">\</span>
  --master k8s://xx.yy.zz.ww:443 <span class="se">\</span>
  --deploy-mode cluster <span class="se">\</span>
  --executor-memory 20G <span class="se">\</span>
  --num-executors <span class="m">50</span> <span class="se">\</span>
  http://path/to/examples.jar <span class="se">\</span>
  <span class="m">1000</span></code></pre></figure>

<h1 id="master-urls">主网址</h1>

<p>传递给Spark的主URL可以采用以下格式之一：</p>

<table class="table">
<tbody><tr><th>主网址</th><th>含义</th></tr>
<tr><td> <code>local</code> </td><td>使用一个工作线程在本地运行Spark（即完全没有并行性）。</td></tr>
<tr><td> <code>local[K]</code> </td><td>使用K个工作线程在本地运行Spark（最好将其设置为计算机上的内核数）。</td></tr>
<tr><td> <code>local[K,F]</code> </td><td>使用K个工作线程和F个maxFailures在本地运行Spark（有关此变量的说明，请参见<a href="configuration.html#scheduling">spark.task.maxFailures</a> ）</td></tr>
<tr><td> <code>local[*]</code> </td><td>在本地运行Spark，其工作线程数与计算机上的逻辑核心数量相同。</td></tr>
<tr><td> <code>local[*,F]</code> </td><td>在本地运行Spark，其工作线程数与计算机和F maxFailures上的逻辑核心数量相同。</td></tr>
<tr><td> <code>spark://HOST:PORT</code> </td><td>连接到给定的<a href="spark-standalone.html">Spark独立集群</a>主服务器。该端口必须是您的主服务器配置为使用的端口，默认情况下为7077。
</td></tr>
<tr><td> <code>spark://HOST1:PORT1,HOST2:PORT2</code> </td><td><a href="spark-standalone.html#standby-masters-with-zookeeper">使用Zookeeper与备用主服务器</a>连接到给定的<a href="spark-standalone.html#standby-masters-with-zookeeper">Spark独立集群</a> 。该列表必须具有使用Zookeeper设置的高可用性群集中的所有主控主机。该端口必须是每个主服务器配置为使用的端口，默认情况下为7077。
</td></tr>
<tr><td> <code>mesos://HOST:PORT</code> </td><td>连接到给定的<a href="running-on-mesos.html">Mesos</a>群集。该端口必须是您配置使用的端口，默认情况下为5050。或者，对于使用ZooKeeper的Mesos集群，请使用<code>mesos://zk://...</code> 。与提交<code>--deploy-mode cluster</code> ，应将HOST：PORT配置为连接到<a href="running-on-mesos.html#cluster-mode">MesosClusterDispatcher</a> 。
</td></tr>
<tr><td> <code>yarn</code> </td><td>连接到<a href="running-on-yarn.html">YARN</a>群集<code>client</code>要么<code>cluster</code>模式取决于值<code>--deploy-mode</code> 。群集位置将根据<code>HADOOP_CONF_DIR</code>要么<code>YARN_CONF_DIR</code>变量。
</td></tr>
<tr><td> <code>k8s://HOST:PORT</code> </td><td>连接到<a href="running-on-kubernetes.html">Kubernetes</a>集群<code>cluster</code>模式。当前不支持客户端模式，将来的版本将支持该模式。的<code>HOST</code>和<code>PORT</code>请参阅<a href="https://kubernetes.io/docs/reference/generated/kube-apiserver/">Kubernetes API服务器</a> 。默认情况下，它使用TLS连接。为了强制它使用不安全的连接，可以使用<code>k8s://http://HOST:PORT</code> 。
</td></tr>
</tbody></table>

<h1 id="loading-configuration-from-a-file">从文件加载配置</h1>

<p>的<code>spark-submit</code>脚本可以从属性文件加载默认的<a href="configuration.html">Spark配置值</a> ，并将其传递给您的应用程序。默认情况下，它将从<code>conf/spark-defaults.conf</code>在Spark目录中。有关更多详细信息，请参阅“ <a href="configuration.html#loading-default-configurations">加载默认配置</a> ”部分。</p>

<p>通过这种方式加载默认的Spark配置可以消除对某些标志的需要<code>spark-submit</code> 。例如，如果<code>spark.master</code>属性已设置，您可以安全地省略<code>--master</code>标记来自<code>spark-submit</code> 。通常，在服务器上显式设置的配置值<code>SparkConf</code>优先级最高，然后将标志传递给<code>spark-submit</code> ，然后是默认文件中的值。</p>

<p>如果您不清楚配置选项来自何处，可以通过运行以下命令打印出细粒度的调试信息<code>spark-submit</code>与<code>--verbose</code>选项。</p>

<h1 id="advanced-dependency-management">高级依赖管理</h1>
<p>使用时<code>spark-submit</code> ，应用程序jar以及<code>--jars</code>选项将自动转移到群集。之后提供的网址<code>--jars</code>必须以逗号分隔。该列表包含在驱动程序和执行程序的类路径中。目录扩展不适用于<code>--jars</code> 。</p>

<p>Spark使用以下URL方案来允许不同的策略来传播jar：</p>

<ul>
  <li><strong>文件：</strong> -绝对路径和<code>file:/</code> URI由驱动程序的HTTP文件服务器提供，并且每个执行程序都从驱动程序HTTP服务器提取文件。</li>
  <li><strong>hdfs：</strong> ， <strong>http：</strong> ， <strong>https：</strong> ， <strong>ftp：</strong> -按预期从URI中提取文件和JAR</li>
  <li><strong>本地：</strong> -以local：/开头的URI应该作为每个工作节点上的本地文件存在。这意味着将不会产生网络IO，并且对于推送到每个工作程序或通过NFS，GlusterFS等共享的大文件/ JAR来说效果很好。</li>
</ul>

<p>请注意，JAR和文件已复制到执行程序节点上每个SparkContext的工作目录中。随着时间的流逝，这可能会占用大量空间，并且需要清理。使用YARN，清理将自动进行；如果使用Spark独立服务器，则可以使用以下命令配置自动清理<code>spark.worker.cleanup.appDataTtl</code>属性。</p>

<p>用户还可以通过提供以逗号分隔的Maven坐标列表来包含任何其他依赖项<code>--packages</code> 。使用此命令时，将处理所有传递依赖项。附加存储库（或SBT中的解析器）可以以逗号分隔的方式添加带有标志<code>--repositories</code> 。（请注意，在某些情况下，可以在存储库URI中提供受密码保护的存储库的凭据，例如在<code>https://user:password@host/...</code> 。以这种方式提供凭据时要小心。）这些命令可以与<code>pyspark</code> ， <code>spark-shell</code>和<code>spark-submit</code>包括Spark软件包。</p>

<p>对于Python，等效<code>--py-files</code>选项可用于分发<code>.egg</code> ， <code>.zip</code>和<code>.py</code>库给执行者。</p>

<h1 id="more-information">更多信息</h1>

<p>部署应用程序后， <a href="cluster-overview.html">集群模式概述</a>将描述分布式执行中涉及的组件以及如何监视和调试应用程序。</p>


                </div>
            
             <!-- /container -->
        </div>

        <script src="js/vendor/jquery-3.4.1.min.js"></script>
        <script src="js/vendor/bootstrap.min.js"></script>
        <script src="js/vendor/anchor.min.js"></script>
        <script src="js/main.js"></script>

        <!-- MathJax Section -->
        <script type="text/x-mathjax-config">
            MathJax.Hub.Config({
                TeX: { equationNumbers: { autoNumber: "AMS" } }
            });
        </script>
        <script>
            // Note that we load MathJax this way to work with local file (file://), HTTP and HTTPS.
            // We could use "//cdn.mathjax...", but that won't support "file://".
            (function(d, script) {
                script = d.createElement('script');
                script.type = 'text/javascript';
                script.async = true;
                script.onload = function(){
                    MathJax.Hub.Config({
                        tex2jax: {
                            inlineMath: [ ["$", "$"], ["\\\\(","\\\\)"] ],
                            displayMath: [ ["$$","$$"], ["\\[", "\\]"] ],
                            processEscapes: true,
                            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre']
                        }
                    });
                };
                script.src = ('https:' == document.location.protocol ? 'https://' : 'http://') +
                    'cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js' +
                    '?config=TeX-AMS-MML_HTMLorMML';
                d.getElementsByTagName('head')[0].appendChild(script);
            }(document));
        </script>
    

</body></html>