<html class="no-js" ><!--<![endif]--><head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
        <title>Web UI-Spark 3.0.0-预览文档</title>
        
          <meta name="description" content="Web UI guide for Spark 3.0.0-preview">
        

        

        <link rel="stylesheet" href="css/bootstrap.min.css">
        <style>
            body {
                padding-top: 60px;
                padding-bottom: 40px;
            }
        </style>
        <meta name="viewport" content="width=device-width">
        <link rel="stylesheet" href="css/bootstrap-responsive.min.css">
        <link rel="stylesheet" href="css/main.css">

        <script src="js/vendor/modernizr-2.6.1-respond-1.1.0.min.js"></script>

        <link rel="stylesheet" href="css/pygments-default.css">

        
        <!-- Google analytics script -->
        <script type="text/javascript">
          var _gaq = _gaq || [];
          _gaq.push(['_setAccount', 'UA-32518208-2']);
          _gaq.push(['_trackPageview']);

          (function() {
            var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
            ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
            var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
          })();
        </script>
        

    </head>
    <body >
        <!--[if lt IE 7]>
            <p class="chromeframe">You are using an outdated browser. <a href="https://browsehappy.com/">Upgrade your browser today</a> or <a href="http://www.google.com/chromeframe/?redirect=true">install Google Chrome Frame</a> to better experience this site.</p>
        <![endif]-->

        <!-- This code is taken from http://twitter.github.com/bootstrap/examples/hero.html -->

        <div class="navbar navbar-fixed-top" id="topbar">
            <div class="navbar-inner">
                <div class="container">
                    <div class="brand"><a href="index.html"><img src="img/spark-logo-hd.png" style="height:50px"></a> <span class="version">3.0.0预览版</span>
                    </div>
                    <ul class="nav">
                        <!--TODO(andyk): Add class="active" attribute to li some how.-->
                        <li><a href="index.html">总览</a></li>

                        <li class="dropdown">
                            <a href="#" class="dropdown-toggle" data-toggle="dropdown">编程指南<b class="caret"></b></a>
                            <ul class="dropdown-menu">
                                <li><a href="quick-start.html">快速开始</a></li>
                                <li><a href="rdd-programming-guide.html">RDD，累加器，广播变量</a></li>
                                <li><a href="sql-programming-guide.html">SQL，数据框和数据集</a></li>
                                <li><a href="structured-streaming-programming-guide.html">结构化流</a></li>
                                <li><a href="streaming-programming-guide.html">火花流（DStreams）</a></li>
                                <li><a href="ml-guide.html">MLlib（机器学习）</a></li>
                                <li><a href="graphx-programming-guide.html">GraphX（图形处理）</a></li>
                                <li><a href="sparkr.html">SparkR（Spark上的R）</a></li>
                            </ul>
                        </li>

                        <li class="dropdown">
                            <a href="#" class="dropdown-toggle" data-toggle="dropdown">API文件<b class="caret"></b></a>
                            <ul class="dropdown-menu">
                                <li><a href="api/scala/index.html#org.apache.spark.package">斯卡拉</a></li>
                                <li><a href="api/java/index.html">爪哇</a></li>
                                <li><a href="api/python/index.html">蟒蛇</a></li>
                                <li><a href="api/R/index.html">[R</a></li>
                                <li><a href="api/sql/index.html">SQL，内置函数</a></li>
                            </ul>
                        </li>

                        <li class="dropdown">
                            <a href="#" class="dropdown-toggle" data-toggle="dropdown">部署中<b class="caret"></b></a>
                            <ul class="dropdown-menu">
                                <li><a href="cluster-overview.html">总览</a></li>
                                <li><a href="submitting-applications.html">提交申请</a></li>
                                <li class="divider"></li>
                                <li><a href="spark-standalone.html">Spark独立</a></li>
                                <li><a href="running-on-mesos.html">梅索斯</a></li>
                                <li><a href="running-on-yarn.html">纱</a></li>
                                <li><a href="running-on-kubernetes.html">Kubernetes</a></li>
                            </ul>
                        </li>

                        <li class="dropdown">
                            <a href="api.html" class="dropdown-toggle" data-toggle="dropdown">更多<b class="caret"></b></a>
                            <ul class="dropdown-menu">
                                <li><a href="configuration.html">组态</a></li>
                                <li><a href="monitoring.html">监控方式</a></li>
                                <li><a href="tuning.html">调音指南</a></li>
                                <li><a href="job-scheduling.html">作业调度</a></li>
                                <li><a href="security.html">安全</a></li>
                                <li><a href="hardware-provisioning.html">硬件配置</a></li>
                                <li><a href="migration-guide.html">迁移指南</a></li>
                                <li class="divider"></li>
                                <li><a href="building-spark.html">建筑火花</a></li>
                                <li><a href="https://spark.apache.org/contributing.html">为Spark贡献</a></li>
                                <li><a href="https://spark.apache.org/third-party-projects.html">第三方项目</a></li>
                            </ul>
                        </li>
                    </ul>
                    <!--<p class="navbar-text pull-right"><span class="version-text">v3.0.0-preview</span></p>-->
                </div>
            </div>
        </div>

        <div class="container-wrapper">

            
                <div class="content" id="content">
                    
                        <h1 class="title">网页界面</h1>
                    

                    <p>Apache Spark提供了一套Web用户界面（UI），可用于监视Spark集群的状态和资源消耗。</p>

<p><strong>目录</strong></p>

<ul id="markdown-toc">
  <li><a href="#jobs-tab" id="markdown-toc-jobs-tab">作业标签</a>    <ul>
      <li><a href="#jobs-detail" id="markdown-toc-jobs-detail">职位详情</a></li>
    </ul>
  </li>
  <li><a href="#stages-tab" id="markdown-toc-stages-tab">阶段标签</a>    <ul>
      <li><a href="#stage-detail" id="markdown-toc-stage-detail">舞台细节</a></li>
    </ul>
  </li>
  <li><a href="#storage-tab" id="markdown-toc-storage-tab">储存标签</a></li>
  <li><a href="#environment-tab" id="markdown-toc-environment-tab">环境标签</a></li>
  <li><a href="#executors-tab" id="markdown-toc-executors-tab">执行器选项卡</a></li>
  <li><a href="#sql-tab" id="markdown-toc-sql-tab">SQL选项卡</a>    <ul>
      <li><a href="#sql-metrics" id="markdown-toc-sql-metrics">SQL指标</a></li>
    </ul>
  </li>
  <li><a href="#streaming-tab" id="markdown-toc-streaming-tab">流标签</a></li>
  <li><a href="#jdbcodbc-server-tab" id="markdown-toc-jdbcodbc-server-tab">JDBC / ODBC服务器选项卡</a></li>
</ul>

<h2 id="jobs-tab">作业标签</h2>
<p>“作业”选项卡显示Spark应用程序中所有作业的摘要页面以及每个作业的详细信息页面。摘要页面显示高级信息，例如所有作业的状态，持续时间和进度以及整个事件时间线。在摘要页面上单击某个作业时，您会看到该作业的详细信息页面。详细信息页面进一步显示事件时间轴，DAG可视化以及作业的所有阶段。</p>

<p>本节中显示的信息是</p>
<ul>
  <li>用户：Spark当前用户</li>
  <li>总正常运行时间：自Spark应用启动以来的时间</li>
  <li>计划模式：请参阅<a href="job-scheduling.html#configuring-pool-properties">作业计划</a></li>
  <li>每个状态的作业数：活动，已完成，失败</li>
</ul>

<p style="text-align:center">
  <img src="img/AllJobsPageDetail1.png" title="基本信息" alt="基本信息" width="20%">
</p>

<ul>
  <li>事件时间表：按时间顺序显示与执行者（添加，删除）和作业相关的事件</li>
</ul>

<p style="text-align:center">
  <img src="img/AllJobsPageDetail2.png" title="活动时间表" alt="活动时间表">
</p>

<ul>
  <li>按状态分组的作业详细信息：显示作业的详细信息，包括作业ID，描述（带有指向详细作业页面的链接），提交时间，持续时间，阶段摘要和任务进度栏</li>
</ul>

<p style="text-align:center">
  <img src="img/AllJobsPageDetail3.png" title="按状态分组的工作详细信息" alt="按状态分组的工作详细信息">
</p>

<p>单击特定作业时，您可以看到该作业的详细信息。</p>

<h3 id="jobs-detail">职位详情</h3>

<p>此页面显示由作业ID标识的特定作业的详细信息。</p>
<ul>
  <li>作业状态：（正在运行，成功，失败）</li>
  <li>每个状态的阶段数（活动，挂起，完成，跳过，失败）</li>
  <li>关联的SQL查询：链接到该作业的sql选项卡</li>
  <li>事件时间表：按时间顺序显示与执行者（添加，删除）和工作阶段有关的事件</li>
</ul>

<p style="text-align:center">
  <img src="img/JobPageDetail1.png" title="活动时间表" alt="活动时间表">
</p>

<ul>
  <li>DAG可视化：此作业的有向无环图的直观表示，其中顶点表示RDD或DataFrame，而边缘表示要在RDD上应用的操作。</li>
</ul>

<p style="text-align:center">
  <img src="img/JobPageDetail2.png" title="达格" alt="达格" width="40%">
</p>

<ul>
  <li>阶段列表（按活动，未决，完成，跳过和失败的状态分组）<ul>
      <li>阶段ID</li>
      <li>阶段说明</li>
      <li>提交的时间戳</li>
      <li>阶段的持续时间</li>
      <li>任务进度条</li>
      <li>输入：在此阶段从存储读取的字节</li>
      <li>输出：在此阶段写入存储的字节</li>
      <li>随机读取：总计随机字节和记录读取，包括本地读取的数据和从远程执行者读取的数据</li>
      <li>随机写入：将字节和记录写入磁盘，以便在将来阶段由随机读取</li>
    </ul>
  </li>
</ul>

<p style="text-align:center">
  <img src="img/JobPageDetail3.png" title="达格" alt="达格">
</p>

<h2 id="stages-tab">阶段标签</h2>

<p>“阶段”选项卡显示摘要页面，该页面显示Spark应用程序中所有作业的所有阶段的当前状态。</p>

<p>页面的开头是摘要，其中包含按状态（活动，待处理，已完成，已跳过和失败）的所有阶段的计数</p>

<p style="text-align:center">
  <img src="img/AllStagesPageDetail1.png" title="阶段头" alt="阶段头" width="30%">
</p>

<p>在<a href="job-scheduling.html#scheduling-within-an-application">公平调度模式下，</a>有一个表显示<a href="job-scheduling.html#configuring-pool-properties">池属性</a></p>

<p style="text-align:center">
  <img src="img/AllStagesPageDetail2.png" title="泳池物业" alt="泳池物业">
</p>

<p>之后是每个状态的阶段详细信息（活动，挂起，完成，跳过，失败）。在活动阶段，可以使用kill链接杀死该阶段。仅在失败阶段显示失败原因。通过单击描述可以访问任务详细信息。</p>

<p style="text-align:center">
  <img src="img/AllStagesPageDetail3.png" title="阶段细节" alt="阶段细节">
</p>

<h3 id="stage-detail">舞台细节</h3>
<p>阶段详细信息页面以所有任务的总时间， <a href="tuning.html#data-locality">位置级别摘要</a> ， <a href="rdd-programming-guide.html#shuffle-operations">随机读取大小/记录</a>和关联的作业ID之类的信息开头。</p>

<p style="text-align:center">
  <img src="img/AllStagesPageDetail4.png" title="舞台标题" alt="舞台标题" width="30%">
</p>

<p>此阶段的有向无环图（DAG）的直观表示，其中顶点表示RDD或DataFrame，而边缘表示要应用的操作。</p>

<p style="text-align:center">
  <img src="img/AllStagesPageDetail5.png" title="舞台DAG" alt="舞台DAG" width="50%">
</p>

<p>在表格和时间轴中表示所有任务的摘要指标。</p>
<ul>
  <li><strong><a href="configuration.html#compression-and-serialization">任务反序列化时间</a></strong></li>
  <li><strong>任务持续时间</strong> 。</li>
  <li><strong>GC时间</strong>是JVM垃圾回收的总时间。</li>
  <li><strong>结果序列化时间</strong>是在将任务结果发送回驱动程序之前，在执行程序上序列化任务结果所花费的时间。</li>
  <li><strong>获得结果时间</strong>是驾驶员花费时间从工作人员那里获取任务结果的时间。</li>
  <li><strong>计划程序延迟</strong>是任务等待计划执行的时间。</li>
  <li><strong>峰值执行内存</strong>是在改组，聚合和联接期间创建的内部数据结构所使用的最大内存。</li>
  <li><strong>随机读取大小/记录</strong> 。读取的总混洗字节，包括本地读取的数据和从远程执行程序读取的数据。</li>
  <li><strong>随机读取阻止时间</strong>是指任务等待等待从远程计算机读取随机数据所花费的时间。</li>
  <li><strong>Shuffle Remote Reads</strong>是从远程执行程序<strong>读取</strong>的总shuffle字节。</li>
  <li><strong>随机溢出（内存）</strong>是<strong>内存中随机</strong>数据反序列化形式的大小。</li>
  <li><strong>随机溢出（磁盘）</strong>是磁盘上数据序列化形式的大小。</li>
</ul>

<p style="text-align:center">
  <img src="img/AllStagesPageDetail6.png" title="阶段指标" alt="阶段指标">
</p>

<p>执行者汇总的度量标准显示执行者汇总的相同信息。</p>

<p style="text-align:center">
  <img src="img/AllStagesPageDetail7.png" title="为每个执行者分级指标" alt="为每个执行者分段指标">
</p>

<p><strong><a href="rdd-programming-guide.html#accumulators">累加器</a></strong>是一种共享变量。它提供了一个可变变量，可以在各种转换中进行更新。可以创建带名称或不带名称的累加器，但是仅显示命名的累加器。</p>

<p style="text-align:center">
  <img src="img/AllStagesPageDetail8.png" title="舞台蓄能器" alt="舞台蓄能器">
</p>

<p>任务详细信息基本上包括与摘要部分相同的信息，但按任务进行了详细说明。它还包括用于查看日志和任务尝试编号（如果由于任何原因失败）的链接。如果有命名的累加器，则可以在每个任务的末尾看到累加器的值。</p>

<p style="text-align:center">
  <img src="img/AllStagesPageDetail9.png" title="任务" alt="任务">
</p>

<h2 id="storage-tab">储存标签</h2>
<p>“存储”选项卡显示应用程序中保留的RDD和DataFrame（如果有）。摘要页面显示所有RDD的存储级别，大小和分区，而详细信息页面显示RDD或DataFrame中所有分区的大小和使用执行程序。</p>

<figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span></span><span class="n">scala</span><span class="o">&gt;</span> <span class="k">import</span> <span class="nn">org.apache.spark.storage.StorageLevel._</span>
<span class="k">import</span> <span class="nn">org.apache.spark.storage.StorageLevel._</span>

<span class="n">scala</span><span class="o">&gt;</span> <span class="k">val</span> <span class="n">rdd</span> <span class="k">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">range</span><span class="o">(</span><span class="mi">0</span><span class="o">,</span> <span class="mi">100</span><span class="o">,</span> <span class="mi">1</span><span class="o">,</span> <span class="mi">5</span><span class="o">).</span><span class="n">setName</span><span class="o">(</span><span class="s">&quot;rdd&quot;</span><span class="o">)</span>
<span class="n">rdd</span><span class="k">:</span> <span class="kt">org.apache.spark.rdd.RDD</span><span class="o">[</span><span class="kt">Long</span><span class="o">]</span> <span class="k">=</span> <span class="n">rdd</span> <span class="nc">MapPartitionsRDD</span><span class="o">[</span><span class="err">1</span><span class="o">]</span> <span class="n">at</span> <span class="n">range</span> <span class="n">at</span> <span class="o">&lt;</span><span class="n">console</span><span class="k">&gt;:</span><span class="mi">27</span>

<span class="n">scala</span><span class="o">&gt;</span> <span class="n">rdd</span><span class="o">.</span><span class="n">persist</span><span class="o">(</span><span class="nc">MEMORY_ONLY_SER</span><span class="o">)</span>
<span class="n">res0</span><span class="k">:</span> <span class="kt">rdd.</span><span class="k">type</span> <span class="o">=</span> <span class="n">rdd</span> <span class="nc">MapPartitionsRDD</span><span class="o">[</span><span class="err">1</span><span class="o">]</span> <span class="n">at</span> <span class="n">range</span> <span class="n">at</span> <span class="o">&lt;</span><span class="n">console</span><span class="k">&gt;:</span><span class="mi">27</span>

<span class="n">scala</span><span class="o">&gt;</span> <span class="n">rdd</span><span class="o">.</span><span class="n">count</span>
<span class="n">res1</span><span class="k">:</span> <span class="kt">Long</span> <span class="o">=</span> <span class="mi">100</span>                                                                

<span class="n">scala</span><span class="o">&gt;</span> <span class="k">val</span> <span class="n">df</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">((</span><span class="mi">1</span><span class="o">,</span> <span class="s">&quot;andy&quot;</span><span class="o">),</span> <span class="o">(</span><span class="mi">2</span><span class="o">,</span> <span class="s">&quot;bob&quot;</span><span class="o">),</span> <span class="o">(</span><span class="mi">2</span><span class="o">,</span> <span class="s">&quot;andy&quot;</span><span class="o">)).</span><span class="n">toDF</span><span class="o">(</span><span class="s">&quot;count&quot;</span><span class="o">,</span> <span class="s">&quot;name&quot;</span><span class="o">)</span>
<span class="n">df</span><span class="k">:</span> <span class="kt">org.apache.spark.sql.DataFrame</span> <span class="o">=</span> <span class="o">[</span><span class="kt">count:</span> <span class="kt">int</span>, <span class="kt">name:</span> <span class="kt">string</span><span class="o">]</span>

<span class="n">scala</span><span class="o">&gt;</span> <span class="n">df</span><span class="o">.</span><span class="n">persist</span><span class="o">(</span><span class="nc">DISK_ONLY</span><span class="o">)</span>
<span class="n">res2</span><span class="k">:</span> <span class="kt">df.</span><span class="k">type</span> <span class="o">=</span> <span class="o">[</span><span class="kt">count:</span> <span class="kt">int</span>, <span class="kt">name:</span> <span class="kt">string</span><span class="o">]</span>

<span class="n">scala</span><span class="o">&gt;</span> <span class="n">df</span><span class="o">.</span><span class="n">count</span>
<span class="n">res3</span><span class="k">:</span> <span class="kt">Long</span> <span class="o">=</span> <span class="mi">3</span></code></pre></figure>

<p style="text-align:center">
  <img src="img/webui-storage-tab.png" title="储存标签" alt="储存标签" width="100%">
  <!-- Images are downsized intentionally to improve quality on retina displays -->
</p>

<p>运行以上示例后，我们可以在“存储”选项卡中找到两个RDD。提供了基本信息，例如存储级别，分区数和内存开销。请注意，新持久的RDD或DataFrame在实现之前未显示在选项卡中。要监视特定的RDD或DataFrame，请确保已触发动作操作。</p>

<p style="text-align:center">
  <img src="img/webui-storage-detail.png" title="储存细节" alt="储存细节" width="100%">
  <!-- Images are downsized intentionally to improve quality on retina displays -->
</p>

<p>您可以单击RDD名称“ rdd”以获取数据持久性的详细信息，例如群集上的数据分布。</p>

<h2 id="environment-tab">环境标签</h2>
<p>Environment选项卡显示不同环境和配置变量的值，包括JVM，Spark和系统属性。</p>

<p style="text-align:center">
  <img src="img/webui-env-tab.png" title="环保标签" alt="环保标签" width="100%">
  <!-- Images are downsized intentionally to improve quality on retina displays -->
</p>

<p>该环境页面分为五个部分。这是检查属性是否正确设置的有用位置。第一部分“运行时信息”仅包含<a href="configuration.html#runtime-environment">运行时属性，</a>例如Java和Scala的版本。第二部分“ Spark属性”列出了<a href="configuration.html#application-properties">应用程序属性，</a>例如<a href="configuration.html#application-properties">“ spark.app.name”</a>和“ spark.driver.memory”。</p>

<p style="text-align:center">
  <img src="img/webui-env-hadoop.png" title="Hadoop属性" alt="Hadoop属性" width="100%">
  <!-- Images are downsized intentionally to improve quality on retina displays -->
</p>
<p>单击“ Hadoop属性”链接将显示与Hadoop和YARN相关的属性。请注意， <a href="configuration.html#execution-behavior">“ spark.hadoop。*”之</a>类<a href="configuration.html#execution-behavior">的</a>属性未在此部分中显示，而是在“ Spark属性”中显示。</p>

<p style="text-align:center">
  <img src="img/webui-env-sys.png" title="系统属性" alt="系统属性" width="100%">
  <!-- Images are downsized intentionally to improve quality on retina displays -->
</p>
<p>“系统属性”显示有关JVM的更多详细信息。</p>

<p style="text-align:center">
  <img src="img/webui-env-class.png" title="类路径条目" alt="类路径条目" width="100%">
  <!-- Images are downsized intentionally to improve quality on retina displays -->
</p>

<p>最后一部分“类路径条目”列出了从不同来源加载的类，这对于解决类冲突非常有用。</p>

<h2 id="executors-tab">执行器选项卡</h2>
<p>“执行程序”选项卡显示有关为应用程序创建的执行程序的摘要信息，包括内存和磁盘使用情况以及任务和随机播放信息。“存储内存”列显示已使用和保留用于缓存数据的内存量。</p>

<p style="text-align:center">
  <img src="img/webui-exe-tab.png" title="执行器选项卡" alt="执行器选项卡" width="80%">
  <!-- Images are downsized intentionally to improve quality on retina displays -->
</p>

<p>“执行程序”选项卡不仅提供资源信息（每个执行程序使用的内存，磁盘和内核的数量），而且还提供性能信息（ <a href="tuning.html#garbage-collection-tuning">GC时间</a>和随机播放信息）。</p>

<p style="text-align:center">
  <img src="img/webui-exe-err.png" title="斯特德·洛格" alt="斯特德·洛格" width="80%">
  <!-- Images are downsized intentionally to improve quality on retina displays -->
</p>

<p>单击执行程序0的“ stderr”链接，将在其控制台中显示详细的<a href="spark-standalone.html#monitoring-and-logging">标准错误日志</a> 。</p>

<p style="text-align:center">
  <img src="img/webui-exe-thread.png" title="线程转储" alt="线程转储" width="80%">
  <!-- Images are downsized intentionally to improve quality on retina displays -->
</p>

<p>单击执行程序0的“线程转储”链接可在执行程序0上显示JVM的线程转储，这对于性能分析非常有用。</p>

<h2 id="sql-tab">SQL选项卡</h2>
<p>如果应用程序执行Spark SQL查询，则“ SQL”选项卡将显示信息，例如查询的持续时间，作业以及物理和逻辑计划。在这里，我们包括一个基本示例来说明此选项卡：</p>

<figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span></span><span class="n">scala</span><span class="o">&gt;</span> <span class="k">val</span> <span class="n">df</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">((</span><span class="mi">1</span><span class="o">,</span> <span class="s">&quot;andy&quot;</span><span class="o">),</span> <span class="o">(</span><span class="mi">2</span><span class="o">,</span> <span class="s">&quot;bob&quot;</span><span class="o">),</span> <span class="o">(</span><span class="mi">2</span><span class="o">,</span> <span class="s">&quot;andy&quot;</span><span class="o">)).</span><span class="n">toDF</span><span class="o">(</span><span class="s">&quot;count&quot;</span><span class="o">,</span> <span class="s">&quot;name&quot;</span><span class="o">)</span>
<span class="n">df</span><span class="k">:</span> <span class="kt">org.apache.spark.sql.DataFrame</span> <span class="o">=</span> <span class="o">[</span><span class="kt">count:</span> <span class="kt">int</span>, <span class="kt">name:</span> <span class="kt">string</span><span class="o">]</span>

<span class="n">scala</span><span class="o">&gt;</span> <span class="n">df</span><span class="o">.</span><span class="n">count</span>
<span class="n">res0</span><span class="k">:</span> <span class="kt">Long</span> <span class="o">=</span> <span class="mi">3</span>                                                                  

<span class="n">scala</span><span class="o">&gt;</span> <span class="n">df</span><span class="o">.</span><span class="n">createGlobalTempView</span><span class="o">(</span><span class="s">&quot;df&quot;</span><span class="o">)</span>

<span class="n">scala</span><span class="o">&gt;</span> <span class="n">spark</span><span class="o">.</span><span class="n">sql</span><span class="o">(</span><span class="s">&quot;select name,sum(count) from global_temp.df group by name&quot;</span><span class="o">).</span><span class="n">show</span>
<span class="o">+----+----------+</span>
<span class="o">|</span><span class="n">name</span><span class="o">|</span><span class="n">sum</span><span class="o">(</span><span class="n">count</span><span class="o">)|</span>
<span class="o">+----+----------+</span>
<span class="o">|</span><span class="n">andy</span><span class="o">|</span>         <span class="mi">3</span><span class="o">|</span>
<span class="o">|</span> <span class="n">bob</span><span class="o">|</span>         <span class="mi">2</span><span class="o">|</span>
<span class="o">+----+----------+</span></code></pre></figure>

<p style="text-align:center">
  <img src="img/webui-sql-tab.png" title="SQL选项卡" alt="SQL选项卡" width="80%">
  <!-- Images are downsized intentionally to improve quality on retina displays -->
</p>

<p>现在，上面的三个dataframe / SQL运算符显示在列表中。如果单击<console>上一个查询</console>的“显示于<console>：24”链接，我们将看到作业的DAG。</console></p>

<p style="text-align:center">
  <img src="img/webui-sql-dag.png" title="SQL DAG" alt="SQL DAG" width="50%">
  <!-- Images are downsized intentionally to improve quality on retina displays -->
</p>

<p>我们可以看到每个阶段的详细信息。第一个块“ WholeStageCodegen”<br>将多个运算符（“ LocalTableScan”和“ HashAggregate”）一起编译为单个Java函数以提高性能，并且该行中列出了行数和溢出大小等度量。第二块“交换”显示了洗牌交换的指标，包括写入的洗牌记录数，总数据大小等。</p>

<p style="text-align:center">
  <img src="img/webui-sql-plan.png" title="逻辑计划和物理计划" alt="逻辑计划和物理计划" width="80%">
  <!-- Images are downsized intentionally to improve quality on retina displays -->
</p>
<p>单击底部的“详细信息”链接将显示逻辑计划和物理计划，它们说明了Spark如何解析，分析，优化和执行查询。</p>

<h3 id="sql-metrics">SQL指标</h3>

<p>SQL运算符的指标显示在物理运算符块中。当我们想深入了解每个运算符的执行细节时，SQL指标可能会很有用。例如，“输出行数”可以回答在Filter运算符之后输出多少行，Exchange运算符中的“合计混洗字节总数”显示混洗所写入的字节数。</p>

<p>这是SQL指标的列表：</p>

<table class="table">
<tbody><tr><th>SQL指标</th><th>含义</th><th>经营者</th></tr>
<tr><td> <code>number of output rows</code> </td><td>运算符的输出行数</td><td>聚合运算符，联接运算符，样本，范围，扫描运算符，过滤器等。</td></tr>
<tr><td> <code>data size</code> </td><td>运营商的广播/混洗/收集数据的大小</td><td>BroadcastExchange，ShuffleExchange，子查询</td></tr>
<tr><td> <code>time to collect</code> </td><td>收集数据上花费的时间</td><td>BroadcastExchange，子查询</td></tr>
<tr><td> <code>scan time</code> </td><td>扫描数据所花费的时间</td><td>ColumnarBatchScan，FileSourceScan</td></tr>
<tr><td> <code>metadata time</code> </td><td>获取元数据（如分区数，文件数）所花费的时间</td><td>FileSourceScan</td></tr>
<tr><td> <code>shuffle bytes written</code> </td><td>写入的字节数</td><td>CollectLimit，TakeOrderedAndProject，ShuffleExchange</td></tr>
<tr><td> <code>shuffle records written</code> </td><td>写入的记录数</td><td>CollectLimit，TakeOrderedAndProject，ShuffleExchange</td></tr>
<tr><td> <code>shuffle write time</code> </td><td>花在洗牌上的时间</td><td>CollectLimit，TakeOrderedAndProject，ShuffleExchange</td></tr>
<tr><td> <code>remote blocks read</code> </td><td>远程读取的块数</td><td>CollectLimit，TakeOrderedAndProject，ShuffleExchange</td></tr>
<tr><td> <code>remote bytes read</code> </td><td>远程读取的字节数</td><td>CollectLimit，TakeOrderedAndProject，ShuffleExchange</td></tr>
<tr><td> <code>remote bytes read to disk</code> </td><td>从远程磁盘读取到本地磁盘的字节数</td><td>CollectLimit，TakeOrderedAndProject，ShuffleExchange</td></tr>
<tr><td> <code>local blocks read</code> </td><td>本地读取的块数</td><td>CollectLimit，TakeOrderedAndProject，ShuffleExchange</td></tr>
<tr><td> <code>local bytes read</code> </td><td>本地读取的字节数</td><td>CollectLimit，TakeOrderedAndProject，ShuffleExchange</td></tr>
<tr><td> <code>fetch wait time</code> </td><td>读取数据所花费的时间（本地和远程）</td><td>CollectLimit，TakeOrderedAndProject，ShuffleExchange</td></tr>
<tr><td> <code>records read</code> </td><td>读取记录数</td><td>CollectLimit，TakeOrderedAndProject，ShuffleExchange</td></tr>
<tr><td> <code>sort time</code> </td><td>排序所花费的时间</td><td>分类</td></tr>
<tr><td> <code>peak memory</code> </td><td>运算符中的峰值内存使用量</td><td>排序，哈希汇总</td></tr>
<tr><td> <code>spill size</code> </td><td>从运算符的内存溢出到磁盘的字节数</td><td>排序，哈希汇总</td></tr>
<tr><td> <code>time in aggregation build</code> </td><td>聚集所花费的时间</td><td>HashAggregate，ObjectHashAggregate</td></tr>
<tr><td> <code>avg hash probe bucket list iters</code> </td><td>汇总期间每次查找的平均存储桶列表迭代</td><td>哈希汇总</td></tr>
<tr><td> <code>data size of build side</code> </td><td>散列图的大小</td><td>随机哈希联接</td></tr>
<tr><td> <code>time to build hash map</code> </td><td>在构建哈希图上花费的时间</td><td>随机哈希联接</td></tr>

</tbody></table>

<h2 id="streaming-tab">流标签</h2>
<p>如果应用程序使用Spark流，则Web UI包括“流”选项卡。此选项卡显示数据流中每个微批处理的计划延迟和处理时间，这对于故障排除流应用程序很有用。</p>

<h2 id="jdbcodbc-server-tab">JDBC / ODBC服务器选项卡</h2>
<p>当Spark作为<a href="sql-distributed-sql-engine.html">分布式SQL引擎</a>运行时，我们可以看到此选项卡。它显示有关会话和已提交的SQL操作的信息。</p>

<p>页面的第一部分显示有关JDBC / ODBC服务器的常规信息：启动时间和正常运行时间。</p>

<p style="text-align:center">
  <img src="img/JDBCServer1.png" width="40%" title="JDBC / ODBC标头" alt="JDBC / ODBC标头">
</p>

<p>第二部分包含有关活动会话和结束会话的信息。</p>
<ul>
  <li>连接的<strong>用户</strong>和<strong>IP</strong> 。</li>
  <li><strong>会话ID</strong>链接，用于访问会话信息。</li>
  <li>会话的<strong>开始时间</strong> ， <strong>结束时间</strong>和<strong>持续时间</strong> 。</li>
  <li><strong>执行总数</strong>是此会话中提交的操作数。</li>
</ul>

<p style="text-align:center">
  <img src="img/JDBCServer2.png" title="JDBC / ODBC会话" alt="JDBC / ODBC会话">
</p>

<p>第三部分具有提交操作的SQL统计信息。</p>
<ul>
  <li>提交操作的<strong>用户</strong> 。</li>
  <li><strong>作业ID</strong>链接到“ <a href="web-ui.html#jobs-tab">作业”标签</a> 。</li>
  <li>将所有作业分组在一起的查询的<strong>组ID</strong> 。应用程序可以使用该组ID取消所有正在运行的作业。</li>
  <li>操作<strong>开始时间</strong> 。</li>
  <li>在获取结果之前<strong>完成</strong>执行<strong>时间</strong> 。</li>
  <li>取得结果后，操作的<strong>关闭时间</strong> 。</li>
  <li><strong>执行时间</strong>是完成时间和开始时间之间的差。</li>
  <li><strong>持续时间</strong>是关闭时间与开始时间之间的差。</li>
  <li><strong>语句</strong>是正在执行的操作。</li>
  <li>该过程的<strong>状态</strong> 。
    <ul>
      <li><em>Started</em> （开始状态），过程开始时的第一种状态</li>
      <li><em>编译完成</em> ，生成执行计划。</li>
      <li>执行失败或发生错误时<em>失败的</em>最终状态。</li>
      <li><em>已取消</em> ，取消执行时的最终状态。</li>
      <li>处理<em>完成</em> ，等待获取结果。</li>
      <li><em>Closed</em> ，客户关闭语句时的最终状态。</li>
    </ul>
  </li>
  <li>执行计划的<strong>详细信息</strong> ，包括已解析的逻辑计划，已分析的逻辑计划，优化的逻辑计划和物理计划或SQL语句中的错误。</li>
</ul>

<p style="text-align:center">
  <img src="img/JDBCServer3.png" title="JDBC / ODBC SQL统计信息" alt="JDBC / ODBC SQL统计信息">
</p>


                </div>
            
             <!-- /container -->
        </div>

        <script src="js/vendor/jquery-3.4.1.min.js"></script>
        <script src="js/vendor/bootstrap.min.js"></script>
        <script src="js/vendor/anchor.min.js"></script>
        <script src="js/main.js"></script>

        <!-- MathJax Section -->
        <script type="text/x-mathjax-config">
            MathJax.Hub.Config({
                TeX: { equationNumbers: { autoNumber: "AMS" } }
            });
        </script>
        <script>
            // Note that we load MathJax this way to work with local file (file://), HTTP and HTTPS.
            // We could use "//cdn.mathjax...", but that won't support "file://".
            (function(d, script) {
                script = d.createElement('script');
                script.type = 'text/javascript';
                script.async = true;
                script.onload = function(){
                    MathJax.Hub.Config({
                        tex2jax: {
                            inlineMath: [ ["$", "$"], ["\\\\(","\\\\)"] ],
                            displayMath: [ ["$$","$$"], ["\\[", "\\]"] ],
                            processEscapes: true,
                            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre']
                        }
                    });
                };
                script.src = ('https:' == document.location.protocol ? 'https://' : 'http://') +
                    'cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js' +
                    '?config=TeX-AMS-MML_HTMLorMML';
                d.getElementsByTagName('head')[0].appendChild(script);
            }(document));
        </script>
    

</body></html>