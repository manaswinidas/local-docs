<html class="no-js" ><!--<![endif]--><head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
        <title>结构化流+ Kafka集成指南（Kafka代理版本0.10.0或更高版本）-Spark 3.0.0-预览文档</title>
        

        

        <link rel="stylesheet" href="css/bootstrap.min.css">
        <style>
            body {
                padding-top: 60px;
                padding-bottom: 40px;
            }
        </style>
        <meta name="viewport" content="width=device-width">
        <link rel="stylesheet" href="css/bootstrap-responsive.min.css">
        <link rel="stylesheet" href="css/main.css">

        <script src="js/vendor/modernizr-2.6.1-respond-1.1.0.min.js"></script>

        <link rel="stylesheet" href="css/pygments-default.css">

        
        <!-- Google analytics script -->
        <script type="text/javascript">
          var _gaq = _gaq || [];
          _gaq.push(['_setAccount', 'UA-32518208-2']);
          _gaq.push(['_trackPageview']);

          (function() {
            var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
            ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
            var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
          })();
        </script>
        

    </head>
    <body >
        <!--[if lt IE 7]>
            <p class="chromeframe">You are using an outdated browser. <a href="https://browsehappy.com/">Upgrade your browser today</a> or <a href="http://www.google.com/chromeframe/?redirect=true">install Google Chrome Frame</a> to better experience this site.</p>
        <![endif]-->

        <!-- This code is taken from http://twitter.github.com/bootstrap/examples/hero.html -->

        <div class="navbar navbar-fixed-top" id="topbar">
            <div class="navbar-inner">
                <div class="container">
                    <div class="brand"><a href="index.html"><img src="img/spark-logo-hd.png" style="height:50px"></a> <span class="version">3.0.0预览版</span>
                    </div>
                    <ul class="nav">
                        <!--TODO(andyk): Add class="active" attribute to li some how.-->
                        <li><a href="index.html">总览</a></li>

                        <li class="dropdown">
                            <a href="#" class="dropdown-toggle" data-toggle="dropdown">编程指南<b class="caret"></b></a>
                            <ul class="dropdown-menu">
                                <li><a href="quick-start.html">快速开始</a></li>
                                <li><a href="rdd-programming-guide.html">RDD，累加器，广播变量</a></li>
                                <li><a href="sql-programming-guide.html">SQL，数据框和数据集</a></li>
                                <li><a href="structured-streaming-programming-guide.html">结构化流</a></li>
                                <li><a href="streaming-programming-guide.html">火花流（DStreams）</a></li>
                                <li><a href="ml-guide.html">MLlib（机器学习）</a></li>
                                <li><a href="graphx-programming-guide.html">GraphX（图形处理）</a></li>
                                <li><a href="sparkr.html">SparkR（Spark上的R）</a></li>
                            </ul>
                        </li>

                        <li class="dropdown">
                            <a href="#" class="dropdown-toggle" data-toggle="dropdown">API文件<b class="caret"></b></a>
                            <ul class="dropdown-menu">
                                <li><a href="api/scala/index.html#org.apache.spark.package">斯卡拉</a></li>
                                <li><a href="api/java/index.html">爪哇</a></li>
                                <li><a href="api/python/index.html">蟒蛇</a></li>
                                <li><a href="api/R/index.html">[R</a></li>
                                <li><a href="api/sql/index.html">SQL，内置函数</a></li>
                            </ul>
                        </li>

                        <li class="dropdown">
                            <a href="#" class="dropdown-toggle" data-toggle="dropdown">部署中<b class="caret"></b></a>
                            <ul class="dropdown-menu">
                                <li><a href="cluster-overview.html">总览</a></li>
                                <li><a href="submitting-applications.html">提交申请</a></li>
                                <li class="divider"></li>
                                <li><a href="spark-standalone.html">Spark独立</a></li>
                                <li><a href="running-on-mesos.html">梅索斯</a></li>
                                <li><a href="running-on-yarn.html">纱</a></li>
                                <li><a href="running-on-kubernetes.html">Kubernetes</a></li>
                            </ul>
                        </li>

                        <li class="dropdown">
                            <a href="api.html" class="dropdown-toggle" data-toggle="dropdown">更多<b class="caret"></b></a>
                            <ul class="dropdown-menu">
                                <li><a href="configuration.html">组态</a></li>
                                <li><a href="monitoring.html">监控方式</a></li>
                                <li><a href="tuning.html">调音指南</a></li>
                                <li><a href="job-scheduling.html">作业调度</a></li>
                                <li><a href="security.html">安全</a></li>
                                <li><a href="hardware-provisioning.html">硬件配置</a></li>
                                <li><a href="migration-guide.html">迁移指南</a></li>
                                <li class="divider"></li>
                                <li><a href="building-spark.html">建筑火花</a></li>
                                <li><a href="https://spark.apache.org/contributing.html">为Spark贡献</a></li>
                                <li><a href="https://spark.apache.org/third-party-projects.html">第三方项目</a></li>
                            </ul>
                        </li>
                    </ul>
                    <!--<p class="navbar-text pull-right"><span class="version-text">v3.0.0-preview</span></p>-->
                </div>
            </div>
        </div>

        <div class="container-wrapper">

            
                <div class="content" id="content">
                    
                        <h1 class="title">结构化流+ Kafka集成指南（Kafka代理版本0.10.0或更高版本）</h1>
                    

                    <p>Kafka 0.10的结构化流集成，可从Kafka读取数据或向Kafka写入数据。</p>

<h2 id="linking">连结中</h2>
<p>对于使用SBT / Maven项目定义的Scala / Java应用程序，将您的应用程序与以下工件链接：</p>

<pre><code>groupId = org.apache.spark
artifactId = spark-sql-kafka-0-10_2.12
version = 3.0.0-preview
</code></pre>

<p>请注意，要使用标头功能，您的Kafka客户端版本应为0.11.0.0或更高版本。</p>

<p>对于Python应用程序，在部署应用程序时需要添加上述库及其依赖项。请参阅下面的“ <a href="#deploying">部署”</a>小节。</p>

<p>为了实验<code>spark-shell</code> ，您在调用时也需要在库及其相关性上添加此库<code>spark-shell</code> 。另外，请参见下面的“ <a href="#deploying">部署”</a>小节。</p>

<h2 id="reading-data-from-kafka">从卡夫卡读取数据</h2>

<h3 id="creating-a-kafka-source-for-streaming-queries">创建用于流式查询的Kafka源</h3>

<div class="codetabs">
<div data-lang="scala">

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span></span><span class="c1">// Subscribe to 1 topic</span>
<span class="k">val</span> <span class="n">df</span> <span class="k">=</span> <span class="n">spark</span>
  <span class="o">.</span><span class="n">readStream</span>
  <span class="o">.</span><span class="n">format</span><span class="o">(</span><span class="s">&quot;kafka&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">option</span><span class="o">(</span><span class="s">&quot;kafka.bootstrap.servers&quot;</span><span class="o">,</span> <span class="s">&quot;host1:port1,host2:port2&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">option</span><span class="o">(</span><span class="s">&quot;subscribe&quot;</span><span class="o">,</span> <span class="s">&quot;topic1&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">load</span><span class="o">()</span>
<span class="n">df</span><span class="o">.</span><span class="n">selectExpr</span><span class="o">(</span><span class="s">&quot;CAST(key AS STRING)&quot;</span><span class="o">,</span> <span class="s">&quot;CAST(value AS STRING)&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">as</span><span class="o">[(</span><span class="kt">String</span>, <span class="kt">String</span><span class="o">)]</span>

<span class="c1">// Subscribe to 1 topic, with headers</span>
<span class="k">val</span> <span class="n">df</span> <span class="k">=</span> <span class="n">spark</span>
  <span class="o">.</span><span class="n">readStream</span>
  <span class="o">.</span><span class="n">format</span><span class="o">(</span><span class="s">&quot;kafka&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">option</span><span class="o">(</span><span class="s">&quot;kafka.bootstrap.servers&quot;</span><span class="o">,</span> <span class="s">&quot;host1:port1,host2:port2&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">option</span><span class="o">(</span><span class="s">&quot;subscribe&quot;</span><span class="o">,</span> <span class="s">&quot;topic1&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">option</span><span class="o">(</span><span class="s">&quot;includeHeaders&quot;</span><span class="o">,</span> <span class="s">&quot;true&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">load</span><span class="o">()</span>
<span class="n">df</span><span class="o">.</span><span class="n">selectExpr</span><span class="o">(</span><span class="s">&quot;CAST(key AS STRING)&quot;</span><span class="o">,</span> <span class="s">&quot;CAST(value AS STRING)&quot;</span><span class="o">,</span> <span class="s">&quot;headers&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">as</span><span class="o">[(</span><span class="kt">String</span>, <span class="kt">String</span>, <span class="kt">Map</span><span class="o">)]</span>

<span class="c1">// Subscribe to multiple topics</span>
<span class="k">val</span> <span class="n">df</span> <span class="k">=</span> <span class="n">spark</span>
  <span class="o">.</span><span class="n">readStream</span>
  <span class="o">.</span><span class="n">format</span><span class="o">(</span><span class="s">&quot;kafka&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">option</span><span class="o">(</span><span class="s">&quot;kafka.bootstrap.servers&quot;</span><span class="o">,</span> <span class="s">&quot;host1:port1,host2:port2&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">option</span><span class="o">(</span><span class="s">&quot;subscribe&quot;</span><span class="o">,</span> <span class="s">&quot;topic1,topic2&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">load</span><span class="o">()</span>
<span class="n">df</span><span class="o">.</span><span class="n">selectExpr</span><span class="o">(</span><span class="s">&quot;CAST(key AS STRING)&quot;</span><span class="o">,</span> <span class="s">&quot;CAST(value AS STRING)&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">as</span><span class="o">[(</span><span class="kt">String</span>, <span class="kt">String</span><span class="o">)]</span>

<span class="c1">// Subscribe to a pattern</span>
<span class="k">val</span> <span class="n">df</span> <span class="k">=</span> <span class="n">spark</span>
  <span class="o">.</span><span class="n">readStream</span>
  <span class="o">.</span><span class="n">format</span><span class="o">(</span><span class="s">&quot;kafka&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">option</span><span class="o">(</span><span class="s">&quot;kafka.bootstrap.servers&quot;</span><span class="o">,</span> <span class="s">&quot;host1:port1,host2:port2&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">option</span><span class="o">(</span><span class="s">&quot;subscribePattern&quot;</span><span class="o">,</span> <span class="s">&quot;topic.*&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">load</span><span class="o">()</span>
<span class="n">df</span><span class="o">.</span><span class="n">selectExpr</span><span class="o">(</span><span class="s">&quot;CAST(key AS STRING)&quot;</span><span class="o">,</span> <span class="s">&quot;CAST(value AS STRING)&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">as</span><span class="o">[(</span><span class="kt">String</span>, <span class="kt">String</span><span class="o">)]</span></code></pre></figure>

  </div>
<div data-lang="java">

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span></span><span class="c1">// Subscribe to 1 topic</span>
<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">df</span> <span class="o">=</span> <span class="n">spark</span>
  <span class="o">.</span><span class="na">readStream</span><span class="o">()</span>
  <span class="o">.</span><span class="na">format</span><span class="o">(</span><span class="s">&quot;kafka&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">option</span><span class="o">(</span><span class="s">&quot;kafka.bootstrap.servers&quot;</span><span class="o">,</span> <span class="s">&quot;host1:port1,host2:port2&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">option</span><span class="o">(</span><span class="s">&quot;subscribe&quot;</span><span class="o">,</span> <span class="s">&quot;topic1&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">load</span><span class="o">();</span>
<span class="n">df</span><span class="o">.</span><span class="na">selectExpr</span><span class="o">(</span><span class="s">&quot;CAST(key AS STRING)&quot;</span><span class="o">,</span> <span class="s">&quot;CAST(value AS STRING)&quot;</span><span class="o">);</span>

<span class="c1">// Subscribe to 1 topic, with headers</span>
<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">df</span> <span class="o">=</span> <span class="n">spark</span>
  <span class="o">.</span><span class="na">readStream</span><span class="o">()</span>
  <span class="o">.</span><span class="na">format</span><span class="o">(</span><span class="s">&quot;kafka&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">option</span><span class="o">(</span><span class="s">&quot;kafka.bootstrap.servers&quot;</span><span class="o">,</span> <span class="s">&quot;host1:port1,host2:port2&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">option</span><span class="o">(</span><span class="s">&quot;subscribe&quot;</span><span class="o">,</span> <span class="s">&quot;topic1&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">option</span><span class="o">(</span><span class="s">&quot;includeHeaders&quot;</span><span class="o">,</span> <span class="s">&quot;true&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">load</span><span class="o">()</span>
<span class="n">df</span><span class="o">.</span><span class="na">selectExpr</span><span class="o">(</span><span class="s">&quot;CAST(key AS STRING)&quot;</span><span class="o">,</span> <span class="s">&quot;CAST(value AS STRING)&quot;</span><span class="o">,</span> <span class="s">&quot;headers&quot;</span><span class="o">);</span>

<span class="c1">// Subscribe to multiple topics</span>
<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">df</span> <span class="o">=</span> <span class="n">spark</span>
  <span class="o">.</span><span class="na">readStream</span><span class="o">()</span>
  <span class="o">.</span><span class="na">format</span><span class="o">(</span><span class="s">&quot;kafka&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">option</span><span class="o">(</span><span class="s">&quot;kafka.bootstrap.servers&quot;</span><span class="o">,</span> <span class="s">&quot;host1:port1,host2:port2&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">option</span><span class="o">(</span><span class="s">&quot;subscribe&quot;</span><span class="o">,</span> <span class="s">&quot;topic1,topic2&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">load</span><span class="o">();</span>
<span class="n">df</span><span class="o">.</span><span class="na">selectExpr</span><span class="o">(</span><span class="s">&quot;CAST(key AS STRING)&quot;</span><span class="o">,</span> <span class="s">&quot;CAST(value AS STRING)&quot;</span><span class="o">);</span>

<span class="c1">// Subscribe to a pattern</span>
<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">df</span> <span class="o">=</span> <span class="n">spark</span>
  <span class="o">.</span><span class="na">readStream</span><span class="o">()</span>
  <span class="o">.</span><span class="na">format</span><span class="o">(</span><span class="s">&quot;kafka&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">option</span><span class="o">(</span><span class="s">&quot;kafka.bootstrap.servers&quot;</span><span class="o">,</span> <span class="s">&quot;host1:port1,host2:port2&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">option</span><span class="o">(</span><span class="s">&quot;subscribePattern&quot;</span><span class="o">,</span> <span class="s">&quot;topic.*&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">load</span><span class="o">();</span>
<span class="n">df</span><span class="o">.</span><span class="na">selectExpr</span><span class="o">(</span><span class="s">&quot;CAST(key AS STRING)&quot;</span><span class="o">,</span> <span class="s">&quot;CAST(value AS STRING)&quot;</span><span class="o">);</span></code></pre></figure>

  </div>
<div data-lang="python">

    <figure class="highlight"><pre><code class="language-python" data-lang="python"><span></span><span class="c1"># Subscribe to 1 topic</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">spark</span> \
  <span class="o">.</span><span class="n">readStream</span> \
  <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot;kafka&quot;</span><span class="p">)</span> \
  <span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;kafka.bootstrap.servers&quot;</span><span class="p">,</span> <span class="s2">&quot;host1:port1,host2:port2&quot;</span><span class="p">)</span> \
  <span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;subscribe&quot;</span><span class="p">,</span> <span class="s2">&quot;topic1&quot;</span><span class="p">)</span> \
  <span class="o">.</span><span class="n">load</span><span class="p">()</span>
<span class="n">df</span><span class="o">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s2">&quot;CAST(key AS STRING)&quot;</span><span class="p">,</span> <span class="s2">&quot;CAST(value AS STRING)&quot;</span><span class="p">)</span>

<span class="c1"># Subscribe to 1 topic, with headers</span>
<span class="n">val</span> <span class="n">df</span> <span class="o">=</span> <span class="n">spark</span> \
  <span class="o">.</span><span class="n">readStream</span> \
  <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot;kafka&quot;</span><span class="p">)</span> \
  <span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;kafka.bootstrap.servers&quot;</span><span class="p">,</span> <span class="s2">&quot;host1:port1,host2:port2&quot;</span><span class="p">)</span> \
  <span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;subscribe&quot;</span><span class="p">,</span> <span class="s2">&quot;topic1&quot;</span><span class="p">)</span> \
  <span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;includeHeaders&quot;</span><span class="p">,</span> <span class="s2">&quot;true&quot;</span><span class="p">)</span> \
  <span class="o">.</span><span class="n">load</span><span class="p">()</span>
<span class="n">df</span><span class="o">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s2">&quot;CAST(key AS STRING)&quot;</span><span class="p">,</span> <span class="s2">&quot;CAST(value AS STRING)&quot;</span><span class="p">,</span> <span class="s2">&quot;headers&quot;</span><span class="p">)</span>

<span class="c1"># Subscribe to multiple topics</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">spark</span> \
  <span class="o">.</span><span class="n">readStream</span> \
  <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot;kafka&quot;</span><span class="p">)</span> \
  <span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;kafka.bootstrap.servers&quot;</span><span class="p">,</span> <span class="s2">&quot;host1:port1,host2:port2&quot;</span><span class="p">)</span> \
  <span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;subscribe&quot;</span><span class="p">,</span> <span class="s2">&quot;topic1,topic2&quot;</span><span class="p">)</span> \
  <span class="o">.</span><span class="n">load</span><span class="p">()</span>
<span class="n">df</span><span class="o">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s2">&quot;CAST(key AS STRING)&quot;</span><span class="p">,</span> <span class="s2">&quot;CAST(value AS STRING)&quot;</span><span class="p">)</span>

<span class="c1"># Subscribe to a pattern</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">spark</span> \
  <span class="o">.</span><span class="n">readStream</span> \
  <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot;kafka&quot;</span><span class="p">)</span> \
  <span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;kafka.bootstrap.servers&quot;</span><span class="p">,</span> <span class="s2">&quot;host1:port1,host2:port2&quot;</span><span class="p">)</span> \
  <span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;subscribePattern&quot;</span><span class="p">,</span> <span class="s2">&quot;topic.*&quot;</span><span class="p">)</span> \
  <span class="o">.</span><span class="n">load</span><span class="p">()</span>
<span class="n">df</span><span class="o">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s2">&quot;CAST(key AS STRING)&quot;</span><span class="p">,</span> <span class="s2">&quot;CAST(value AS STRING)&quot;</span><span class="p">)</span></code></pre></figure>

  </div>
</div>

<h3 id="creating-a-kafka-source-for-batch-queries">为批量查询创建Kafka源</h3>
<p>如果您有一个更适合批处理的用例，则可以为定义的偏移量范围创建一个Dataset / DataFrame。</p>

<div class="codetabs">
<div data-lang="scala">

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span></span><span class="c1">// Subscribe to 1 topic defaults to the earliest and latest offsets</span>
<span class="k">val</span> <span class="n">df</span> <span class="k">=</span> <span class="n">spark</span>
  <span class="o">.</span><span class="n">read</span>
  <span class="o">.</span><span class="n">format</span><span class="o">(</span><span class="s">&quot;kafka&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">option</span><span class="o">(</span><span class="s">&quot;kafka.bootstrap.servers&quot;</span><span class="o">,</span> <span class="s">&quot;host1:port1,host2:port2&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">option</span><span class="o">(</span><span class="s">&quot;subscribe&quot;</span><span class="o">,</span> <span class="s">&quot;topic1&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">load</span><span class="o">()</span>
<span class="n">df</span><span class="o">.</span><span class="n">selectExpr</span><span class="o">(</span><span class="s">&quot;CAST(key AS STRING)&quot;</span><span class="o">,</span> <span class="s">&quot;CAST(value AS STRING)&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">as</span><span class="o">[(</span><span class="kt">String</span>, <span class="kt">String</span><span class="o">)]</span>

<span class="c1">// Subscribe to multiple topics, specifying explicit Kafka offsets</span>
<span class="k">val</span> <span class="n">df</span> <span class="k">=</span> <span class="n">spark</span>
  <span class="o">.</span><span class="n">read</span>
  <span class="o">.</span><span class="n">format</span><span class="o">(</span><span class="s">&quot;kafka&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">option</span><span class="o">(</span><span class="s">&quot;kafka.bootstrap.servers&quot;</span><span class="o">,</span> <span class="s">&quot;host1:port1,host2:port2&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">option</span><span class="o">(</span><span class="s">&quot;subscribe&quot;</span><span class="o">,</span> <span class="s">&quot;topic1,topic2&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">option</span><span class="o">(</span><span class="s">&quot;startingOffsets&quot;</span><span class="o">,</span> <span class="s">&quot;&quot;&quot;{&quot;topic1&quot;:{&quot;0&quot;:23,&quot;1&quot;:-2},&quot;topic2&quot;:{&quot;0&quot;:-2}}&quot;&quot;&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">option</span><span class="o">(</span><span class="s">&quot;endingOffsets&quot;</span><span class="o">,</span> <span class="s">&quot;&quot;&quot;{&quot;topic1&quot;:{&quot;0&quot;:50,&quot;1&quot;:-1},&quot;topic2&quot;:{&quot;0&quot;:-1}}&quot;&quot;&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">load</span><span class="o">()</span>
<span class="n">df</span><span class="o">.</span><span class="n">selectExpr</span><span class="o">(</span><span class="s">&quot;CAST(key AS STRING)&quot;</span><span class="o">,</span> <span class="s">&quot;CAST(value AS STRING)&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">as</span><span class="o">[(</span><span class="kt">String</span>, <span class="kt">String</span><span class="o">)]</span>

<span class="c1">// Subscribe to a pattern, at the earliest and latest offsets</span>
<span class="k">val</span> <span class="n">df</span> <span class="k">=</span> <span class="n">spark</span>
  <span class="o">.</span><span class="n">read</span>
  <span class="o">.</span><span class="n">format</span><span class="o">(</span><span class="s">&quot;kafka&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">option</span><span class="o">(</span><span class="s">&quot;kafka.bootstrap.servers&quot;</span><span class="o">,</span> <span class="s">&quot;host1:port1,host2:port2&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">option</span><span class="o">(</span><span class="s">&quot;subscribePattern&quot;</span><span class="o">,</span> <span class="s">&quot;topic.*&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">option</span><span class="o">(</span><span class="s">&quot;startingOffsets&quot;</span><span class="o">,</span> <span class="s">&quot;earliest&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">option</span><span class="o">(</span><span class="s">&quot;endingOffsets&quot;</span><span class="o">,</span> <span class="s">&quot;latest&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">load</span><span class="o">()</span>
<span class="n">df</span><span class="o">.</span><span class="n">selectExpr</span><span class="o">(</span><span class="s">&quot;CAST(key AS STRING)&quot;</span><span class="o">,</span> <span class="s">&quot;CAST(value AS STRING)&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">as</span><span class="o">[(</span><span class="kt">String</span>, <span class="kt">String</span><span class="o">)]</span></code></pre></figure>

  </div>
<div data-lang="java">

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span></span><span class="c1">// Subscribe to 1 topic defaults to the earliest and latest offsets</span>
<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">df</span> <span class="o">=</span> <span class="n">spark</span>
  <span class="o">.</span><span class="na">read</span><span class="o">()</span>
  <span class="o">.</span><span class="na">format</span><span class="o">(</span><span class="s">&quot;kafka&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">option</span><span class="o">(</span><span class="s">&quot;kafka.bootstrap.servers&quot;</span><span class="o">,</span> <span class="s">&quot;host1:port1,host2:port2&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">option</span><span class="o">(</span><span class="s">&quot;subscribe&quot;</span><span class="o">,</span> <span class="s">&quot;topic1&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">load</span><span class="o">();</span>
<span class="n">df</span><span class="o">.</span><span class="na">selectExpr</span><span class="o">(</span><span class="s">&quot;CAST(key AS STRING)&quot;</span><span class="o">,</span> <span class="s">&quot;CAST(value AS STRING)&quot;</span><span class="o">);</span>

<span class="c1">// Subscribe to multiple topics, specifying explicit Kafka offsets</span>
<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">df</span> <span class="o">=</span> <span class="n">spark</span>
  <span class="o">.</span><span class="na">read</span><span class="o">()</span>
  <span class="o">.</span><span class="na">format</span><span class="o">(</span><span class="s">&quot;kafka&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">option</span><span class="o">(</span><span class="s">&quot;kafka.bootstrap.servers&quot;</span><span class="o">,</span> <span class="s">&quot;host1:port1,host2:port2&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">option</span><span class="o">(</span><span class="s">&quot;subscribe&quot;</span><span class="o">,</span> <span class="s">&quot;topic1,topic2&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">option</span><span class="o">(</span><span class="s">&quot;startingOffsets&quot;</span><span class="o">,</span> <span class="s">&quot;{\&quot;topic1\&quot;:{\&quot;0\&quot;:23,\&quot;1\&quot;:-2},\&quot;topic2\&quot;:{\&quot;0\&quot;:-2}}&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">option</span><span class="o">(</span><span class="s">&quot;endingOffsets&quot;</span><span class="o">,</span> <span class="s">&quot;{\&quot;topic1\&quot;:{\&quot;0\&quot;:50,\&quot;1\&quot;:-1},\&quot;topic2\&quot;:{\&quot;0\&quot;:-1}}&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">load</span><span class="o">();</span>
<span class="n">df</span><span class="o">.</span><span class="na">selectExpr</span><span class="o">(</span><span class="s">&quot;CAST(key AS STRING)&quot;</span><span class="o">,</span> <span class="s">&quot;CAST(value AS STRING)&quot;</span><span class="o">);</span>

<span class="c1">// Subscribe to a pattern, at the earliest and latest offsets</span>
<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">df</span> <span class="o">=</span> <span class="n">spark</span>
  <span class="o">.</span><span class="na">read</span><span class="o">()</span>
  <span class="o">.</span><span class="na">format</span><span class="o">(</span><span class="s">&quot;kafka&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">option</span><span class="o">(</span><span class="s">&quot;kafka.bootstrap.servers&quot;</span><span class="o">,</span> <span class="s">&quot;host1:port1,host2:port2&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">option</span><span class="o">(</span><span class="s">&quot;subscribePattern&quot;</span><span class="o">,</span> <span class="s">&quot;topic.*&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">option</span><span class="o">(</span><span class="s">&quot;startingOffsets&quot;</span><span class="o">,</span> <span class="s">&quot;earliest&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">option</span><span class="o">(</span><span class="s">&quot;endingOffsets&quot;</span><span class="o">,</span> <span class="s">&quot;latest&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">load</span><span class="o">();</span>
<span class="n">df</span><span class="o">.</span><span class="na">selectExpr</span><span class="o">(</span><span class="s">&quot;CAST(key AS STRING)&quot;</span><span class="o">,</span> <span class="s">&quot;CAST(value AS STRING)&quot;</span><span class="o">);</span></code></pre></figure>

  </div>
<div data-lang="python">

    <figure class="highlight"><pre><code class="language-python" data-lang="python"><span></span><span class="c1"># Subscribe to 1 topic defaults to the earliest and latest offsets</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">spark</span> \
  <span class="o">.</span><span class="n">read</span> \
  <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot;kafka&quot;</span><span class="p">)</span> \
  <span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;kafka.bootstrap.servers&quot;</span><span class="p">,</span> <span class="s2">&quot;host1:port1,host2:port2&quot;</span><span class="p">)</span> \
  <span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;subscribe&quot;</span><span class="p">,</span> <span class="s2">&quot;topic1&quot;</span><span class="p">)</span> \
  <span class="o">.</span><span class="n">load</span><span class="p">()</span>
<span class="n">df</span><span class="o">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s2">&quot;CAST(key AS STRING)&quot;</span><span class="p">,</span> <span class="s2">&quot;CAST(value AS STRING)&quot;</span><span class="p">)</span>

<span class="c1"># Subscribe to multiple topics, specifying explicit Kafka offsets</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">spark</span> \
  <span class="o">.</span><span class="n">read</span> \
  <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot;kafka&quot;</span><span class="p">)</span> \
  <span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;kafka.bootstrap.servers&quot;</span><span class="p">,</span> <span class="s2">&quot;host1:port1,host2:port2&quot;</span><span class="p">)</span> \
  <span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;subscribe&quot;</span><span class="p">,</span> <span class="s2">&quot;topic1,topic2&quot;</span><span class="p">)</span> \
  <span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;startingOffsets&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;&quot;{&quot;topic1&quot;:{&quot;0&quot;:23,&quot;1&quot;:-2},&quot;topic2&quot;:{&quot;0&quot;:-2}}&quot;&quot;&quot;</span><span class="p">)</span> \
  <span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;endingOffsets&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;&quot;{&quot;topic1&quot;:{&quot;0&quot;:50,&quot;1&quot;:-1},&quot;topic2&quot;:{&quot;0&quot;:-1}}&quot;&quot;&quot;</span><span class="p">)</span> \
  <span class="o">.</span><span class="n">load</span><span class="p">()</span>
<span class="n">df</span><span class="o">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s2">&quot;CAST(key AS STRING)&quot;</span><span class="p">,</span> <span class="s2">&quot;CAST(value AS STRING)&quot;</span><span class="p">)</span>

<span class="c1"># Subscribe to a pattern, at the earliest and latest offsets</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">spark</span> \
  <span class="o">.</span><span class="n">read</span> \
  <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot;kafka&quot;</span><span class="p">)</span> \
  <span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;kafka.bootstrap.servers&quot;</span><span class="p">,</span> <span class="s2">&quot;host1:port1,host2:port2&quot;</span><span class="p">)</span> \
  <span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;subscribePattern&quot;</span><span class="p">,</span> <span class="s2">&quot;topic.*&quot;</span><span class="p">)</span> \
  <span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;startingOffsets&quot;</span><span class="p">,</span> <span class="s2">&quot;earliest&quot;</span><span class="p">)</span> \
  <span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;endingOffsets&quot;</span><span class="p">,</span> <span class="s2">&quot;latest&quot;</span><span class="p">)</span> \
  <span class="o">.</span><span class="n">load</span><span class="p">()</span>
<span class="n">df</span><span class="o">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s2">&quot;CAST(key AS STRING)&quot;</span><span class="p">,</span> <span class="s2">&quot;CAST(value AS STRING)&quot;</span><span class="p">)</span></code></pre></figure>

  </div>
</div>

<p>源代码中的每一行都具有以下架构：</p>
<table class="table">
<tbody><tr><th>柱</th><th>类型</th></tr>
<tr>
  <td>键</td>
  <td>二元</td>
</tr>
<tr>
  <td>值</td>
  <td>二元</td>
</tr>
<tr>
  <td>话题</td>
  <td>串</td>
</tr>
<tr>
  <td>划分</td>
  <td>整型</td>
</tr>
<tr>
  <td>抵销</td>
  <td>长</td>
</tr>
<tr>
  <td>时间戳记</td>
  <td>时间戳记</td>
</tr>
<tr>
  <td>timestampType</td>
  <td>整型</td>
</tr>
<tr>
  <td>标头（可选）</td>
  <td>数组</td>
</tr>
</tbody></table>

<p>对于批量查询和流查询，必须为Kafka源设置以下选项。</p>

<table class="table">
<tbody><tr><th>选项</th><th>值</th><th>含义</th></tr>
<tr>
  <td>分配</td>
  <td>json字符串{“ topicA”：[0,1]，“ topicB”：[2,4]}</td>
  <td>要使用的特定TopicPartition。只能为Kafka来源指定“分配”，“订阅”或“ subscribePattern”选项之一。</td>
</tr>
<tr>
  <td>订阅</td>
  <td>以逗号分隔的主题列表</td>
  <td>要订阅的主题列表。只能为Kafka来源指定“分配”，“订阅”或“ subscribePattern”选项之一。</td>
</tr>
<tr>
  <td>subscriptionPattern</td>
  <td>Java正则表达式字符串</td>
  <td>用于订阅主题的模式。只能为Kafka源指定“分配”，“订阅”或“ subscribePattern”选项之一。</td>
</tr>
<tr>
  <td>kafka.bootstrap.servers</td>
  <td>以逗号分隔的host：port列表</td>
  <td>Kafka的“ bootstrap.servers”配置。</td>
</tr>
</tbody></table>

<p>以下配置是可选的：</p>

<table class="table">
<tbody><tr><th>选项</th><th>值</th><th>默认</th><th>查询类型</th><th>含义</th></tr>
<tr>
  <td>startingOffsetsByTimestamp</td>
  <td>json字符串“”“ {” topicA“：{” 0“：1000，” 1“：1000}，” topicB“：{” 0“：2000，” 1“：2000}}”“</td>
  <td>无（值<code>startingOffsets<code></code> will apply)</td></code></td><td>流和批处理</td>
  <td>启动查询时的时间戳记的起始点，一个json字符串，为每个TopicPartition指定起始时间戳记。每个分区返回的偏移量是最早的偏移量，其时间戳大于或等于相应分区中的给定时间戳记。如果不存在匹配的偏移量，查询将立即失败，以防止意外读取此类分区。（到目前为止，这是一种限制，并将在不久的将来解决。）<p></p>
  <p></p>Spark只是将时间戳信息传递给<code>KafkaConsumer.offsetsForTimes</code> ，并且不解释或解释该值。<p></p>有关更多详细信息<code>KafkaConsumer.offsetsForTimes</code> ，请参考<a href="https://kafka.apache.org/21/javadoc/org/apache/kafka/clients/consumer/KafkaConsumer.html#offsetsForTimes-java.util.Map-">javadoc</a>以获得详细信息。<p></p>还有意思<code>timestamp</code>这可以根据Kafka的配置而有所不同（ <code>log.message.timestamp.type</code> ）：有关更多详细信息，请参阅<a href="https://kafka.apache.org/documentation/">Kafka文档</a> 。<p></p>注意：此选项需要Kafka 0.10.1.0或更高版本。<p></p>笔记2： <code>startingOffsetsByTimestamp</code>优先于<code>startingOffsets</code> 。<p></p>注意3：对于流查询，仅在启动新查询时适用，并且恢复将始终从查询中断的地方开始。查询期间新发现的分区最早将开始。</td>
</tr>
<tr>
  <td>startingOffsets</td>
  <td>“最早”，“最新”（仅流）或json字符串““” {“ topicA”：{“ 0”：23，“ 1”：-1}，“ topicB”：{“ 0”：-2} }“”“</td>
  <td>“最新”用于流式传输，“最早”用于流式传输</td>
  <td>流和批处理</td>
  <td>查询开始的起点，可以是“最早”（来自最早的偏移量），“最新”（仅来自最新的偏移量），或者是为每个TopicPartition指定起始偏移量的json字符串。在json中，可使用-2作为偏移量来指代最早的，-1到最新的。注意：对于批查询，不允许最新（隐式或在json中使用-1）。对于流查询，这仅在启动新查询时适用，并且恢复将始终从查询中断的地方开始。查询期间新发现的分区最早将开始。</td>
</tr>
<tr>
  <td>EndingOffsetsByTimestamp</td>
  <td>json字符串“”“ {” topicA“：{” 0“：1000，” 1“：1000}，” topicB“：{” 0“：2000，” 1“：2000}}”“</td>
  <td>最新</td>
  <td>批量查询</td>
  <td>批处理查询结束的终点，一个json字符串，为每个TopicPartition指定结束时间戳。每个分区返回的偏移量是最早的偏移量，其时间戳大于或等于相应分区中的给定时间戳记。如果不存在匹配的偏移量，则该偏移量将设置为最新。<p></p>
  <p></p>Spark只是将时间戳信息传递给<code>KafkaConsumer.offsetsForTimes</code> ，并且不解释或解释该值。<p></p>有关更多详细信息<code>KafkaConsumer.offsetsForTimes</code> ，请参考<a href="https://kafka.apache.org/21/javadoc/org/apache/kafka/clients/consumer/KafkaConsumer.html#offsetsForTimes-java.util.Map-">javadoc</a>以获得详细信息。<p></p>还有意思<code>timestamp</code>这可以根据Kafka的配置而有所不同（ <code>log.message.timestamp.type</code> ）：有关更多详细信息，请参阅<a href="https://kafka.apache.org/documentation/">Kafka文档</a> 。<p></p>注意：此选项需要Kafka 0.10.1.0或更高版本。<p></p>笔记2： <code>endingOffsetsByTimestamp</code>优先于<code>endingOffsets</code> 。
  </td>
</tr>
<tr>
  <td>结尾偏移</td>
  <td>最新或json字符串{“ topicA”：{“ 0”：23，“ 1”：-1}，“ topicB”：{“ 0”：-1}}</td>
  <td>最新</td>
  <td>批量查询</td>
  <td>批处理查询结束的终点，可以是“最新”（仅指最新），也可以是json字符串，它为每个TopicPartition指定了结束偏移量。在json中，可以使用-1作为偏移量来引用最新，而-2（最早）则不能用作偏移量。</td>
</tr>
<tr>
  <td>failOnDataLoss</td>
  <td>对或错</td>
  <td>真正</td>
  <td>流和批处理</td>
  <td>是否在数据丢失（例如，主题被删除或偏移量超出范围）时使查询失败。这可能是一个错误的警报。当它无法正常工作时，可以将其禁用。</td>
</tr>
<tr>
  <td>kafkaConsumer.pollTimeoutMs</td>
  <td>长</td>
  <td>512</td>
  <td>流和批处理</td>
  <td>执行程序中从Kafka轮询数据的超时时间（以毫秒为单位）。</td>
</tr>
<tr>
  <td>fetchOffset.numRetries</td>
  <td>整型</td>
  <td>3</td>
  <td>流和批处理</td>
  <td>放弃获取Kafka偏移前重试的次数。</td>
</tr>
<tr>
  <td>fetchOffset.retryIntervalMs</td>
  <td>长</td>
  <td>10</td>
  <td>流和批处理</td>
  <td>重试获取Kafka偏移之前要等待的毫秒数</td>
</tr>
<tr>
  <td>maxOffsetsPerTrigger</td>
  <td>长</td>
  <td>没有</td>
  <td>流和批处理</td>
  <td>每个触发间隔处理的最大偏移量的速率限制。指定的偏移总数将在不同卷的topicPartitions中按比例分配。</td>
</tr>
<tr>
  <td>minPartitions</td>
  <td>整型</td>
  <td>没有</td>
  <td>流和批处理</td>
  <td>希望从Kafka读取的最小分区数。默认情况下，Spark具有1-1的topicPartitions映射到从Kafka使用的Spark分区。如果将此选项设置为大于topicPartitions的值，Spark会将大的Kafka分区分成较小的部分。请注意，此配置就像<code>hint</code> ：Spark任务的数量将<strong>约为</strong> <code>minPartitions</code> 。根据取整错误或未接收到任何新数据的Kafka分区，它可能更少或更多。</td>
</tr>
<tr>
  <td>groupIdPrefix</td>
  <td>串</td>
  <td>spark-kafka源</td>
  <td>流和批处理</td>
  <td>消费者组标识符的前缀（ <code>group.id</code> ）由结构化流查询生成。如果设置了“ kafka.group.id”，则该选项将被忽略。</td>
</tr>
<tr>
  <td>kafka.group.id</td>
  <td>串</td>
  <td>没有</td>
  <td>流和批处理</td>
  <td>从Kafka读取时在Kafka消费者中使用的Kafka组ID。请谨慎使用。默认情况下，每个查询都会生成一个唯一的组ID以读取数据。这样可以确保每个Kafka来源都有自己的使用者组，不会受到任何其他使用者的干扰，因此可以读取其订阅主题的所有分区。在某些情况下（例如，基于Kafka组的授权），您可能希望使用特定的授权组ID来读取数据。您可以选择设置组ID。但是，请格外小心，因为这可能会导致意外行为。同时运行的查询（批处理和流处理）或具有相同组ID的源很可能会互相干扰，导致每个查询仅读取部分数据。快速连续启动/重新启动查询时，也可能会发生这种情况。为了最大程度地减少此类问题，请将Kafka使用者会话超时设置为非常小（通过设置选项“ kafka.session.timeout.ms”）。设置此选项后，选项“ groupIdPrefix”将被忽略。</td>
</tr>
<tr>
  <td>includeHeaders</td>
  <td>布尔值</td>
  <td>假</td>
  <td>流和批处理</td>
  <td>是否在行中包含Kafka标头。</td>
</tr>
</tbody></table>消费者缓存初始化Kafka消费者非常耗时，尤其是在处理时间是关键因素的流媒体场景中。因此，Spark通过利用Apache Commons Pool在执行者上汇集了Kafka使用者。高速缓存密钥是根据以下信息构建的：*主题名称*主题分区*组ID以下属性可用于配置使用者池：<table class="table">
<tbody><tr><th>物业名称</th><th>默认</th><th>含义</th></tr>
<tr>
  <td>spark.kafka.consumer.cache.capacity</td>
  <td>缓存的使用者的最大数量。请注意，这是一个软限制。</td>
  <td>64</td>
</tr>
<tr>
  <td>spark.kafka.consumer.cache.timeout</td>
  <td>消费者在有资格被驱逐者驱逐之前可能闲置在游泳池中的最短时间。</td>
  <td>5m（5分钟）</td>
</tr>
<tr>
  <td>spark.kafka.consumer.cache.evictorThreadRunInterval</td>
  <td>消费者池的空闲驱逐线程运行之间的时间间隔。当为非肯定时，将不运行任何空闲的退出线程。</td>
  <td>1m（1分钟）</td>
</tr>
<tr>
  <td>spark.kafka.consumer.cache.jmx.enable</td>
  <td>为使用此配置实例创建的池启用或禁用JMX。池的统计信息可通过JMX实例获得。JMX名称的前缀设置为“ kafka010-cached-simple-kafka-consumer-pool”。
  </td>
  <td>假</td>
</tr>
</tbody></table>游泳池的大小受到以下因素的限制<code>spark.kafka.consumer.cache.capacity</code> ，但它用作“软限制”以不阻止Spark任务。空闲驱逐线程会定期删除使用时间不超过给定超时的使用者。如果在借用时达到此阈值，它将尝试删除当前未使用的最少使用的条目。如果无法将其删除，则池将继续增长。在最坏的情况下，池将增长到可以在执行程序中运行的最大并发任务数（即任务插槽数）。如果任务由于任何原因失败，出于安全原因，将使用新创建的Kafka使用者执行新任务。同时，我们使池中具有相同缓存密钥的所有使用者失效，以删除执行失败时使用的使用者。正在使用其他任务的使用者将不会关闭，但是当他们返回到池中时，它们也会失效。与消费者一起，Spark会分别合并从Kafka获取的记录，从而使Kafka消费者从Spark的角度来看是无国籍的，并最大程度地提高了合并效率。它利用与Kafka使用者池相同的缓存密钥。请注意，由于特性差异，它没有利用Apache Commons Pool。以下属性可用于配置获取的数据池：<table class="table">
<tbody><tr><th>物业名称</th><th>默认</th><th>含义</th></tr>
<tr>
  <td>spark.kafka.consumer.fetchedData.cache.timeout</td>
  <td>取出的数据在有资格被逐出者驱逐之前，可能在池中处于空闲状态的最短时间。</td>
  <td>5m（5分钟）</td>
</tr>
<tr>
  <td>spark.kafka.consumer.fetchedData.cache.evictorThreadRunInterval</td>
  <td>提取数据池的空闲驱逐线程运行之间的时间间隔。当为非肯定时，将不运行任何空闲的退出线程。</td>
  <td>1m（1分钟）</td>
</tr>
</tbody></table>##将数据写入Kafka在这里，我们描述了将流查询和批处理查询写入Apache Kafka的支持。请注意，Apache Kafka仅支持至少一次写入语义。因此，在向Kafka写入流式查询或批处理查询时，某些记录可能会重复。例如，如果Kafka需要重试经纪人未确认的消息（即使该经纪人接收并写入了消息记录），就会发生这种情况。由于这些Kafka写语义，结构化流无法阻止此类重复发生。但是，如果编写查询成功，则可以假定查询输出至少写入了一次。在读取写入的数据时删除重复项的一种可能的解决方案可能是引入一个主键（唯一），该键可用于在读取时执行重复数据删除。写入Kafka的Dataframe在架构中应包含以下几列：<table class="table">
<tbody><tr><th>柱</th><th>类型</th></tr>
<tr>
  <td>键（可选）</td>
  <td>字符串或二进制</td>
</tr>
<tr>
  <td>值（必填）</td>
  <td>字符串或二进制</td>
</tr>
<tr>
  <td>标头（可选）</td>
  <td>数组</td>
</tr>
<tr>
  <td>主题（*可选）</td>
  <td>串</td>
</tr>
<tr>
  <td>分区（可选）</td>
  <td>整型</td>
</tr>
</tbody></table>\ *如果未指定“主题”配置选项，则主题列为必填项。<br>值列是唯一必需的选项。如果未指定键列，则将自动添加“ null”值的键列（请参阅有关如何处理“ null”值的键值的Kafka语义）。如果存在主题列，则在将给定行写入Kafka时将其值用作主题，除非设置了“ topic”配置选项，即，“ topic”配置选项会覆盖主题列。如果未指定“ partition”列（或其值为“ null”），则由Kafka生产者计算分区。可以通过设置`kafka.partitioner.class`选项在Spark中指定Kafka分区程序。如果不存在，将使用Kafka默认分区程序。对于批量查询和流查询，必须为Kafka接收器设置以下选项。

<table class="table">
<tbody><tr><th>选项</th><th>值</th><th>含义</th></tr>
<tr>
  <td>kafka.bootstrap.servers</td>
  <td>以逗号分隔的host：port列表</td>
  <td>Kafka的“ bootstrap.servers”配置。</td>
</tr>
</tbody></table>以下配置是可选的：<table class="table">
<tbody><tr><th>选项</th><th>值</th><th>默认</th><th>查询类型</th><th>含义</th></tr>
<tr>
  <td>话题</td>
  <td>串</td>
  <td>没有</td>
  <td>流和批处理</td>
  <td>设置将所有行写入Kafka的主题。此选项将覆盖数据中可能存在的任何主题列。</td>
</tr>
<tr>
  <td>includeHeaders</td>
  <td>布尔值</td>
  <td>假</td>
  <td>流和批处理</td>
  <td>是否在行中包含Kafka标头。</td>
</tr>
</tbody></table>###为流式查询创建Kafka接收器<div class="codetabs">
<div data-lang="scala">

            <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span></span><span class="c1">// Write key-value data from a DataFrame to a specific Kafka topic specified in an option</span>
<span class="k">val</span> <span class="n">ds</span> <span class="k">=</span> <span class="n">df</span>
  <span class="o">.</span><span class="n">selectExpr</span><span class="o">(</span><span class="s">&quot;CAST(key AS STRING)&quot;</span><span class="o">,</span> <span class="s">&quot;CAST(value AS STRING)&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">writeStream</span>
  <span class="o">.</span><span class="n">format</span><span class="o">(</span><span class="s">&quot;kafka&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">option</span><span class="o">(</span><span class="s">&quot;kafka.bootstrap.servers&quot;</span><span class="o">,</span> <span class="s">&quot;host1:port1,host2:port2&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">option</span><span class="o">(</span><span class="s">&quot;topic&quot;</span><span class="o">,</span> <span class="s">&quot;topic1&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">start</span><span class="o">()</span>

<span class="c1">// Write key-value data from a DataFrame to Kafka using a topic specified in the data</span>
<span class="k">val</span> <span class="n">ds</span> <span class="k">=</span> <span class="n">df</span>
  <span class="o">.</span><span class="n">selectExpr</span><span class="o">(</span><span class="s">&quot;topic&quot;</span><span class="o">,</span> <span class="s">&quot;CAST(key AS STRING)&quot;</span><span class="o">,</span> <span class="s">&quot;CAST(value AS STRING)&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">writeStream</span>
  <span class="o">.</span><span class="n">format</span><span class="o">(</span><span class="s">&quot;kafka&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">option</span><span class="o">(</span><span class="s">&quot;kafka.bootstrap.servers&quot;</span><span class="o">,</span> <span class="s">&quot;host1:port1,host2:port2&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">start</span><span class="o">()</span></code></pre></figure>

          </div>
<div data-lang="java">

            <figure class="highlight"><pre><code class="language-java" data-lang="java"><span></span><span class="c1">// Write key-value data from a DataFrame to a specific Kafka topic specified in an option</span>
<span class="n">StreamingQuery</span> <span class="n">ds</span> <span class="o">=</span> <span class="n">df</span>
  <span class="o">.</span><span class="na">selectExpr</span><span class="o">(</span><span class="s">&quot;CAST(key AS STRING)&quot;</span><span class="o">,</span> <span class="s">&quot;CAST(value AS STRING)&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">writeStream</span><span class="o">()</span>
  <span class="o">.</span><span class="na">format</span><span class="o">(</span><span class="s">&quot;kafka&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">option</span><span class="o">(</span><span class="s">&quot;kafka.bootstrap.servers&quot;</span><span class="o">,</span> <span class="s">&quot;host1:port1,host2:port2&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">option</span><span class="o">(</span><span class="s">&quot;topic&quot;</span><span class="o">,</span> <span class="s">&quot;topic1&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">start</span><span class="o">();</span>

<span class="c1">// Write key-value data from a DataFrame to Kafka using a topic specified in the data</span>
<span class="n">StreamingQuery</span> <span class="n">ds</span> <span class="o">=</span> <span class="n">df</span>
  <span class="o">.</span><span class="na">selectExpr</span><span class="o">(</span><span class="s">&quot;topic&quot;</span><span class="o">,</span> <span class="s">&quot;CAST(key AS STRING)&quot;</span><span class="o">,</span> <span class="s">&quot;CAST(value AS STRING)&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">writeStream</span><span class="o">()</span>
  <span class="o">.</span><span class="na">format</span><span class="o">(</span><span class="s">&quot;kafka&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">option</span><span class="o">(</span><span class="s">&quot;kafka.bootstrap.servers&quot;</span><span class="o">,</span> <span class="s">&quot;host1:port1,host2:port2&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">start</span><span class="o">();</span></code></pre></figure>

          </div>
<div data-lang="python">

            <figure class="highlight"><pre><code class="language-python" data-lang="python"><span></span><span class="c1"># Write key-value data from a DataFrame to a specific Kafka topic specified in an option</span>
<span class="n">ds</span> <span class="o">=</span> <span class="n">df</span> \
  <span class="o">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s2">&quot;CAST(key AS STRING)&quot;</span><span class="p">,</span> <span class="s2">&quot;CAST(value AS STRING)&quot;</span><span class="p">)</span> \
  <span class="o">.</span><span class="n">writeStream</span> \
  <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot;kafka&quot;</span><span class="p">)</span> \
  <span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;kafka.bootstrap.servers&quot;</span><span class="p">,</span> <span class="s2">&quot;host1:port1,host2:port2&quot;</span><span class="p">)</span> \
  <span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;topic&quot;</span><span class="p">,</span> <span class="s2">&quot;topic1&quot;</span><span class="p">)</span> \
  <span class="o">.</span><span class="n">start</span><span class="p">()</span>

<span class="c1"># Write key-value data from a DataFrame to Kafka using a topic specified in the data</span>
<span class="n">ds</span> <span class="o">=</span> <span class="n">df</span> \
  <span class="o">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s2">&quot;topic&quot;</span><span class="p">,</span> <span class="s2">&quot;CAST(key AS STRING)&quot;</span><span class="p">,</span> <span class="s2">&quot;CAST(value AS STRING)&quot;</span><span class="p">)</span> \
  <span class="o">.</span><span class="n">writeStream</span> \
  <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot;kafka&quot;</span><span class="p">)</span> \
  <span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;kafka.bootstrap.servers&quot;</span><span class="p">,</span> <span class="s2">&quot;host1:port1,host2:port2&quot;</span><span class="p">)</span> \
  <span class="o">.</span><span class="n">start</span><span class="p">()</span></code></pre></figure>

          </div>
</div>###将批次查询的输出写入Kafka<div class="codetabs">
<div data-lang="scala">

            <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span></span><span class="c1">// Write key-value data from a DataFrame to a specific Kafka topic specified in an option</span>
<span class="n">df</span><span class="o">.</span><span class="n">selectExpr</span><span class="o">(</span><span class="s">&quot;CAST(key AS STRING)&quot;</span><span class="o">,</span> <span class="s">&quot;CAST(value AS STRING)&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">write</span>
  <span class="o">.</span><span class="n">format</span><span class="o">(</span><span class="s">&quot;kafka&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">option</span><span class="o">(</span><span class="s">&quot;kafka.bootstrap.servers&quot;</span><span class="o">,</span> <span class="s">&quot;host1:port1,host2:port2&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">option</span><span class="o">(</span><span class="s">&quot;topic&quot;</span><span class="o">,</span> <span class="s">&quot;topic1&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">save</span><span class="o">()</span>

<span class="c1">// Write key-value data from a DataFrame to Kafka using a topic specified in the data</span>
<span class="n">df</span><span class="o">.</span><span class="n">selectExpr</span><span class="o">(</span><span class="s">&quot;topic&quot;</span><span class="o">,</span> <span class="s">&quot;CAST(key AS STRING)&quot;</span><span class="o">,</span> <span class="s">&quot;CAST(value AS STRING)&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">write</span>
  <span class="o">.</span><span class="n">format</span><span class="o">(</span><span class="s">&quot;kafka&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">option</span><span class="o">(</span><span class="s">&quot;kafka.bootstrap.servers&quot;</span><span class="o">,</span> <span class="s">&quot;host1:port1,host2:port2&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">save</span><span class="o">()</span></code></pre></figure>

          </div>
<div data-lang="java">

            <figure class="highlight"><pre><code class="language-java" data-lang="java"><span></span><span class="c1">// Write key-value data from a DataFrame to a specific Kafka topic specified in an option</span>
<span class="n">df</span><span class="o">.</span><span class="na">selectExpr</span><span class="o">(</span><span class="s">&quot;CAST(key AS STRING)&quot;</span><span class="o">,</span> <span class="s">&quot;CAST(value AS STRING)&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">write</span><span class="o">()</span>
  <span class="o">.</span><span class="na">format</span><span class="o">(</span><span class="s">&quot;kafka&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">option</span><span class="o">(</span><span class="s">&quot;kafka.bootstrap.servers&quot;</span><span class="o">,</span> <span class="s">&quot;host1:port1,host2:port2&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">option</span><span class="o">(</span><span class="s">&quot;topic&quot;</span><span class="o">,</span> <span class="s">&quot;topic1&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">save</span><span class="o">();</span>

<span class="c1">// Write key-value data from a DataFrame to Kafka using a topic specified in the data</span>
<span class="n">df</span><span class="o">.</span><span class="na">selectExpr</span><span class="o">(</span><span class="s">&quot;topic&quot;</span><span class="o">,</span> <span class="s">&quot;CAST(key AS STRING)&quot;</span><span class="o">,</span> <span class="s">&quot;CAST(value AS STRING)&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">write</span><span class="o">()</span>
  <span class="o">.</span><span class="na">format</span><span class="o">(</span><span class="s">&quot;kafka&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">option</span><span class="o">(</span><span class="s">&quot;kafka.bootstrap.servers&quot;</span><span class="o">,</span> <span class="s">&quot;host1:port1,host2:port2&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">save</span><span class="o">();</span></code></pre></figure>

          </div>
<div data-lang="python">

            <figure class="highlight"><pre><code class="language-python" data-lang="python"><span></span><span class="c1"># Write key-value data from a DataFrame to a specific Kafka topic specified in an option</span>
<span class="n">df</span><span class="o">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s2">&quot;CAST(key AS STRING)&quot;</span><span class="p">,</span> <span class="s2">&quot;CAST(value AS STRING)&quot;</span><span class="p">)</span> \
  <span class="o">.</span><span class="n">write</span> \
  <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot;kafka&quot;</span><span class="p">)</span> \
  <span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;kafka.bootstrap.servers&quot;</span><span class="p">,</span> <span class="s2">&quot;host1:port1,host2:port2&quot;</span><span class="p">)</span> \
  <span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;topic&quot;</span><span class="p">,</span> <span class="s2">&quot;topic1&quot;</span><span class="p">)</span> \
  <span class="o">.</span><span class="n">save</span><span class="p">()</span>

<span class="c1"># Write key-value data from a DataFrame to Kafka using a topic specified in the data</span>
<span class="n">df</span><span class="o">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s2">&quot;topic&quot;</span><span class="p">,</span> <span class="s2">&quot;CAST(key AS STRING)&quot;</span><span class="p">,</span> <span class="s2">&quot;CAST(value AS STRING)&quot;</span><span class="p">)</span> \
  <span class="o">.</span><span class="n">write</span> \
  <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot;kafka&quot;</span><span class="p">)</span> \
  <span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;kafka.bootstrap.servers&quot;</span><span class="p">,</span> <span class="s2">&quot;host1:port1,host2:port2&quot;</span><span class="p">)</span> \
  <span class="o">.</span><span class="n">save</span><span class="p">()</span></code></pre></figure>

          </div>
</div>## Kafka特定的配置Kafka自己的配置可以通过带有前缀“ kafka。”的DataStreamReader.option来设置，例如，stream.option（“ kafka.bootstrap.servers”，“ host：port”）。有关可能的kafka参数，请参阅[Kafka使用者配置文档]（http://kafka.apache.org/documentation.html#newconsumerconfigs），以获取与读取数据相关的参数；以及[Kafka生产者配置文档]（http：// kafka。 apache.org/documentation/#producerconfigs）获取与写入数据相关的参数。请注意，以下Kafka参数无法设置，并且Kafka源或接收器将引发异常：-** group.id **：Kafka源将自动为每个查询创建唯一的组ID。用户可以通过可选的源选项“ groupIdPrefix”设置自动生成的group.id的前缀，默认值为“ spark-kafka-source”。您也可以设置“ kafka.group.id”以强制Spark使用特殊的组ID，但是，请阅读此选项的警告并谨慎使用。-** auto.offset.reset **：设置源选项“ startingOffsets”以指定从何处开始。结构化流管理在内部管理哪些偏移量，而不是依靠kafka使用者来执行此操作。这将确保在动态订阅新主题/分区时不会丢失任何数据。请注意，“ startingOffsets”仅在启动新的流查询时适用，并且恢复将始终从查询中断处开始。-** key.deserializer **：始终使用ByteArrayDeserializer将键反序列化为字节数组。使用DataFrame操作显式反序列化键。-** value.deserializer **：始终使用ByteArrayDeserializer将值反序列化为字节数组。使用DataFrame操作显式反序列化值。-** key.serializer **：密钥始终使用ByteArraySerializer或StringSerializer进行序列化。使用DataFrame操作可以将键显式序列化为字符串或字节数组。-** value.serializer **：值始终使用ByteArraySerializer或StringSerializer进行序列化。使用DataFrame操作可以将值显式序列化为字符串或字节数组。-** enable.auto.commit **：Kafka源不提交任何偏移量。-** interceptor.classes **：Kafka源始终将键和值读取为字节数组。使用ConsumerInterceptor是不安全的，因为它可能会中断查询。##部署与所有Spark应用程序一样，`spark-submit`用于启动您的应用程序。可以使用--packages（例如./bin/spark-submit --packages org.apache）将`spark-sql-kafka-0-10_2.12`及其依赖项直接添加到`spark-submit`中。 spark：spark-sql-kafka-0-10_2.12：3.0.0-preview ...为了试验“ spark-shell”，您还可以使用“ --packages”直接添加“ spark-sql-kafka-0-10_2.12”及其依赖项./bin/spark-shell --packages org。 apache.spark：spark-sql-kafka-0-10_2.12：3.0.0-preview ...有关提交具有外部依赖性的应用程序的更多详细信息，请参见[应用程序提交指南]（submitting-applications.html）。##安全性Kafka 0.9.0.0引入了一些增强集群安全性的功能。有关这些可能性的详细说明，请参见[Kafka安全文档]（http://kafka.apache.org/documentation.html#security）。值得注意的是，安全性是可选的，默认情况下已关闭。Spark支持以下方式对Kafka集群进行身份验证：-**委托令牌（在Kafka代理1.1.0中引入）**-** JAAS登录配置** ###委托令牌可以通过Spark参数配置应用程序并且可能不需要JAAS登录配置（Spark可以使用Kafka的动态JAAS配置功能）。有关委派令牌的更多信息，请参阅[Kafka委派令牌文档]（http://kafka.apache.org/documentation/#security_delegation_token）。该过程由Spark的Kafka委托令牌提供程序启动。设置`spark.kafka.clusters。$ {cluster} .auth.bootstrap.servers`时，Spark将按优先顺序考虑以下登录选项：-** JAAS登录配置**，请参见以下示例。-**密钥表文件**，例如./bin/spark-submit \ --keytab <keytab_file>\ --principal <principal>\ --conf spark.kafka.clusters。$ {cluster} .auth.bootstrap.servers = <kafka_servers>\ .. 。-** Kerberos凭证缓存**，例如./bin/spark-submit \ --conf spark.kafka.clusters。$ {cluster} .auth.bootstrap.servers = <kafka_servers>\ ...可以通过将“ spark.security.credentials.kafka.enabled”设置为“ false”（默认值：“ true”）来关闭Kafka委托令牌提供程序。可以将Spark配置为使用以下身份验证协议来获取令牌（必须与Kafka代理配置相匹配）：-** SASL SSL（默认）**-** SSL **-** SASL PLAINTEXT（用于测试）**成功获取委派令牌后，Spark将其分配到各个节点并相应地进行更新。委托令牌使用“ SCRAM”登录模块进行身份验证，因此必须配置相应的“ spark.kafka.clusters。$ {cluster} .sasl.token.mechanism”（默认值：“ SCRAM-SHA-512”）。另外，此参数必须与Kafka代理配置匹配。当执行者上可以使用委托令牌时，Spark将按优先顺序考虑以下登录选项：-** JAAS登录配置**，请参见以下示例。-**委托令牌**，请参阅<code>spark.kafka.clusters.${cluster}.target.bootstrap.servers.regex</code>参数以获取更多详细信息。如果以上都不适用，则假定不安全连接。####配置委托令牌可以从多个群集中获得，并且<code>${cluster}</code>是一个任意的唯一标识符，有助于对不同的配置进行分组。

<table class="table">
<tbody><tr><th>物业名称</th><th>默认</th><th>含义</th></tr>
  <tr>
    <td><code>spark.kafka.clusters.${cluster}.auth.bootstrap.servers</code></td>
    <td>没有</td>
    <td>逗号分隔的主机/端口对列表，用于建立与Kafka群集的初始连接。有关更多详细信息，请参阅Kafka文档。仅用于获取委托令牌。
    </td>
  </tr>
  <tr>
    <td><code>spark.kafka.clusters.${cluster}.target.bootstrap.servers.regex</code></td>
    <td>。*</td>
    <td>正则表达式匹配<code>bootstrap.servers</code>在应用程序中配置源和接收器。如果服务器地址与此正则表达式匹配，则在连接时将使用从各自的引导服务器获得的委托令牌。如果多个群集与地址匹配，则会引发异常，并且不会启动查询。Kafka的安全和不安全侦听器绑定到不同的端口。当两者都使用时，安全监听器端口必须是正则表达式的一部分。
    </td>
  </tr>
  <tr>
    <td><code>spark.kafka.clusters.${cluster}.security.protocol</code></td>
    <td>SASL_SSL</td>
    <td>与经纪人进行通信的协议。有关更多详细信息，请参阅Kafka文档。协议默认应用于所有源和接收器，其中<code>bootstrap.servers</code>配置匹配（有关更多详细信息，请参阅<code>spark.kafka.clusters.${cluster}.target.bootstrap.servers.regex</code> ），并且可以通过设置覆盖<code>kafka.security.protocol</code>在源或汇上。
    </td>
  </tr>
  <tr>
    <td><code>spark.kafka.clusters.${cluster}.sasl.kerberos.service.name</code></td>
    <td>卡夫卡</td>
    <td>Kafka运行时使用的Kerberos主体名称。这可以在Kafka的JAAS配置或Kafka的配置中定义。有关更多详细信息，请参阅Kafka文档。仅用于获取委托令牌。
    </td>
  </tr>
  <tr>
    <td><code>spark.kafka.clusters.${cluster}.ssl.truststore.location</code></td>
    <td>没有</td>
    <td>信任库文件的位置。有关更多详细信息，请参阅Kafka文档。仅用于获取委托令牌。
    </td>
  </tr>
  <tr>
    <td><code>spark.kafka.clusters.${cluster}.ssl.truststore.password</code></td>
    <td>没有</td>
    <td>信任存储文件的存储密码。这是可选的，仅在以下情况下才需要<code>spark.kafka.clusters.${cluster}.ssl.truststore.location</code>已配置。有关更多详细信息，请参阅Kafka文档。仅用于获取委托令牌。
    </td>
  </tr>
  <tr>
    <td><code>spark.kafka.clusters.${cluster}.ssl.keystore.location</code></td>
    <td>没有</td>
    <td>密钥库文件的位置。这对于客户端是可选的，并且可以用于客户端的双向身份验证。有关更多详细信息，请参阅Kafka文档。仅用于获取委托令牌。
    </td>
  </tr>
  <tr>
    <td><code>spark.kafka.clusters.${cluster}.ssl.keystore.password</code></td>
    <td>没有</td>
    <td>密钥存储文件的存储密码。这是可选的，仅在以下情况下才需要<code>spark.kafka.clusters.${cluster}.ssl.keystore.location</code>已配置。有关更多详细信息，请参阅Kafka文档。仅用于获取委托令牌。
    </td>
  </tr>
  <tr>
    <td><code>spark.kafka.clusters.${cluster}.ssl.key.password</code></td>
    <td>没有</td>
    <td>密钥存储文件中私钥的密码。这对于客户端是可选的。有关更多详细信息，请参阅Kafka文档。仅用于获取委托令牌。
    </td>
  </tr>
  <tr>
    <td><code>spark.kafka.clusters.${cluster}.sasl.token.mechanism</code></td>
    <td>SCRAM-SHA-512</td>
    <td>SASL机制用于具有委托令牌的客户端连接。因为用于身份验证的SCRAM登录模块必须在此处设置兼容机制。有关更多详细信息，请参阅Kafka文档（ <code>sasl.mechanism</code> ）。仅用于使用授权令牌对Kafka经纪人进行身份验证。
    </td>
  </tr>
</tbody></table>#### Kafka的特定配置Kafka自己的配置可以用`kafka.`前缀来设置，例如`--conf spark.kafka.clusters。$ {cluster} .kafka.retries = 1`。有关可能的Kafka参数，请参阅[Kafka adminclient config docs]（http://kafka.apache.org/documentation.html#adminclientconfigs）。 ####警告-尚不支持为代理用户获取委派令牌（[KAFKA-6945]（https://issues.apache.org/jira/browse/KAFKA-6945））。 ### JAAS登录配置JAAS登录配置必须放置在Spark尝试访问Kafka集群的所有节点上。这提供了以更高的维护成本应用任何定制身份验证逻辑的可能性。这可以通过几种方法完成。一种可能性是提供其他JVM参数，例如./bin/spark-submit \ --driver-java-options“ -Djava.security.auth.login.config = / path / to / custom_jaas.conf” \- -conf spark.executor.extraJavaOptions = -Djava.security.auth.login.config = / path / to / custom_jaas.conf \ ...
</kafka_servers></kafka_servers></principal></keytab_file>


                </div>
            
             <!-- /container -->
        </div>

        <script src="js/vendor/jquery-3.4.1.min.js"></script>
        <script src="js/vendor/bootstrap.min.js"></script>
        <script src="js/vendor/anchor.min.js"></script>
        <script src="js/main.js"></script>

        <!-- MathJax Section -->
        <script type="text/x-mathjax-config">
            MathJax.Hub.Config({
                TeX: { equationNumbers: { autoNumber: "AMS" } }
            });
        </script>
        <script>
            // Note that we load MathJax this way to work with local file (file://), HTTP and HTTPS.
            // We could use "//cdn.mathjax...", but that won't support "file://".
            (function(d, script) {
                script = d.createElement('script');
                script.type = 'text/javascript';
                script.async = true;
                script.onload = function(){
                    MathJax.Hub.Config({
                        tex2jax: {
                            inlineMath: [ ["$", "$"], ["\\\\(","\\\\)"] ],
                            displayMath: [ ["$$","$$"], ["\\[", "\\]"] ],
                            processEscapes: true,
                            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre']
                        }
                    });
                };
                script.src = ('https:' == document.location.protocol ? 'https://' : 'http://') +
                    'cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js' +
                    '?config=TeX-AMS-MML_HTMLorMML';
                d.getElementsByTagName('head')[0].appendChild(script);
            }(document));
        </script>
    

</body></html>