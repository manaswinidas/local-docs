<html class="no-js" ><!--<![endif]--><head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
        <title>监视和仪表-Spark 3.0.0-预览文档</title>
        
          <meta name="description" content="Monitoring, metrics, and instrumentation guide for Spark 3.0.0-preview">
        

        

        <link rel="stylesheet" href="css/bootstrap.min.css">
        <style>
            body {
                padding-top: 60px;
                padding-bottom: 40px;
            }
        </style>
        <meta name="viewport" content="width=device-width">
        <link rel="stylesheet" href="css/bootstrap-responsive.min.css">
        <link rel="stylesheet" href="css/main.css">

        <script src="js/vendor/modernizr-2.6.1-respond-1.1.0.min.js"></script>

        <link rel="stylesheet" href="css/pygments-default.css">

        
        <!-- Google analytics script -->
        <script type="text/javascript">
          var _gaq = _gaq || [];
          _gaq.push(['_setAccount', 'UA-32518208-2']);
          _gaq.push(['_trackPageview']);

          (function() {
            var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
            ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
            var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
          })();
        </script>
        

    </head>
    <body >
        <!--[if lt IE 7]>
            <p class="chromeframe">You are using an outdated browser. <a href="https://browsehappy.com/">Upgrade your browser today</a> or <a href="http://www.google.com/chromeframe/?redirect=true">install Google Chrome Frame</a> to better experience this site.</p>
        <![endif]-->

        <!-- This code is taken from http://twitter.github.com/bootstrap/examples/hero.html -->

        <div class="navbar navbar-fixed-top" id="topbar">
            <div class="navbar-inner">
                <div class="container">
                    <div class="brand"><a href="index.html"><img src="img/spark-logo-hd.png" style="height:50px"></a> <span class="version">3.0.0预览版</span>
                    </div>
                    <ul class="nav">
                        <!--TODO(andyk): Add class="active" attribute to li some how.-->
                        <li><a href="index.html">总览</a></li>

                        <li class="dropdown">
                            <a href="#" class="dropdown-toggle" data-toggle="dropdown">编程指南<b class="caret"></b></a>
                            <ul class="dropdown-menu">
                                <li><a href="quick-start.html">快速开始</a></li>
                                <li><a href="rdd-programming-guide.html">RDD，累加器，广播变量</a></li>
                                <li><a href="sql-programming-guide.html">SQL，数据框和数据集</a></li>
                                <li><a href="structured-streaming-programming-guide.html">结构化流</a></li>
                                <li><a href="streaming-programming-guide.html">火花流（DStreams）</a></li>
                                <li><a href="ml-guide.html">MLlib（机器学习）</a></li>
                                <li><a href="graphx-programming-guide.html">GraphX（图形处理）</a></li>
                                <li><a href="sparkr.html">SparkR（Spark上的R）</a></li>
                            </ul>
                        </li>

                        <li class="dropdown">
                            <a href="#" class="dropdown-toggle" data-toggle="dropdown">API文件<b class="caret"></b></a>
                            <ul class="dropdown-menu">
                                <li><a href="api/scala/index.html#org.apache.spark.package">斯卡拉</a></li>
                                <li><a href="api/java/index.html">爪哇</a></li>
                                <li><a href="api/python/index.html">蟒蛇</a></li>
                                <li><a href="api/R/index.html">[R</a></li>
                                <li><a href="api/sql/index.html">SQL，内置函数</a></li>
                            </ul>
                        </li>

                        <li class="dropdown">
                            <a href="#" class="dropdown-toggle" data-toggle="dropdown">部署中<b class="caret"></b></a>
                            <ul class="dropdown-menu">
                                <li><a href="cluster-overview.html">总览</a></li>
                                <li><a href="submitting-applications.html">提交申请</a></li>
                                <li class="divider"></li>
                                <li><a href="spark-standalone.html">Spark独立</a></li>
                                <li><a href="running-on-mesos.html">梅索斯</a></li>
                                <li><a href="running-on-yarn.html">纱</a></li>
                                <li><a href="running-on-kubernetes.html">Kubernetes</a></li>
                            </ul>
                        </li>

                        <li class="dropdown">
                            <a href="api.html" class="dropdown-toggle" data-toggle="dropdown">更多<b class="caret"></b></a>
                            <ul class="dropdown-menu">
                                <li><a href="configuration.html">组态</a></li>
                                <li><a href="monitoring.html">监控方式</a></li>
                                <li><a href="tuning.html">调音指南</a></li>
                                <li><a href="job-scheduling.html">作业调度</a></li>
                                <li><a href="security.html">安全</a></li>
                                <li><a href="hardware-provisioning.html">硬件配置</a></li>
                                <li><a href="migration-guide.html">迁移指南</a></li>
                                <li class="divider"></li>
                                <li><a href="building-spark.html">建筑火花</a></li>
                                <li><a href="https://spark.apache.org/contributing.html">为Spark贡献</a></li>
                                <li><a href="https://spark.apache.org/third-party-projects.html">第三方项目</a></li>
                            </ul>
                        </li>
                    </ul>
                    <!--<p class="navbar-text pull-right"><span class="version-text">v3.0.0-preview</span></p>-->
                </div>
            </div>
        </div>

        <div class="container-wrapper">

            
                <div class="content" id="content">
                    
                        <h1 class="title">监测与仪器</h1>
                    

                    <p>有几种方法可以监视Spark应用程序：Web UI，指标和外部工具。</p>

<h1 id="web-interfaces">Web界面</h1>

<p>默认情况下，每个SparkContext在端口4040上启动一个<a href="web-ui.html">Web UI</a> ，该<a href="web-ui.html">Web UI</a>显示有关该应用程序的有用信息。这包括：</p>

<ul>
  <li>调度程序阶段和任务列表</li>
  <li>RDD大小和内存使用情况摘要</li>
  <li>环境信息。</li>
  <li>有关正在运行的执行程序的信息</li>
</ul>

<p>您只需打开即可访问此界面<code>http://<driver-node>:4040</code>在网络浏览器中。如果多个SparkContext在同一主机上运行，它们将绑定到以4040（4041、4042等）开头的连续端口。</p>

<p>请注意，默认情况下，此信息仅在应用程序期间有效。要在事后查看Web UI，请设置<code>spark.eventLog.enabled</code>在启动应用程序之前为true。这会将Spark配置为记录Spark事件，这些事件将UI中显示的信息编码到持久存储中。</p>

<h2 id="viewing-after-the-fact">事后查看</h2>

<p>只要存在应用程序的事件日志，仍然可以通过Spark的历史记录服务器构造应用程序的UI。您可以通过执行以下命令来启动历史记录服务器：</p>

<pre><code>./sbin/start-history-server.sh
</code></pre>

<p>这将在以下位置创建一个Web界面<code>http://<server-url>:18080</code>默认情况下，列出未完成和已完成的应用程序和尝试。</p>

<p>使用文件系统提供程序类时（请参阅<code>spark.history.provider</code>下面），则必须在<code>spark.history.fs.logDirectory</code>配置选项，并且应包含每个代表应用程序事件日志的子目录。</p>

<p>Spark作业本身必须配置为记录事件，并将它们记录到相同的共享可写目录中。例如，如果服务器配置了日志目录为<code>hdfs://namenode/shared/spark-logs</code> ，那么客户端选项将是：</p>

<pre><code>spark.eventLog.enabled true
spark.eventLog.dir hdfs://namenode/shared/spark-logs
</code></pre>

<p>历史服务器可以配置如下：</p>

<h3 id="environment-variables">环境变量</h3>

<table class="table">
  <tbody><tr><th style="width:21%">环境变量</th><th>含义</th></tr>
  <tr>
    <td><code>SPARK_DAEMON_MEMORY</code></td>
    <td>分配给历史记录服务器的内存（默认值：1g）。</td>
  </tr>
  <tr>
    <td><code>SPARK_DAEMON_JAVA_OPTS</code></td>
    <td>历史记录服务器的JVM选项（默认值：无）。</td>
  </tr>
  <tr>
    <td><code>SPARK_DAEMON_CLASSPATH</code></td>
    <td>历史记录服务器的类路径（默认值：无）。</td>
  </tr>
  <tr>
    <td><code>SPARK_PUBLIC_DNS</code></td>
    <td>历史记录服务器的公共地址。如果未设置此选项，则指向应用程序历史记录的链接可能会使用服务器的内部地址，从而导致链接断开（默认值：无）。
    </td>
  </tr>
  <tr>
    <td><code>SPARK_HISTORY_OPTS</code></td>
    <td>
      <code>spark.history.*</code>历史记录服务器的配置选项（默认值：无）。
    </td>
  </tr>
</tbody></table>

<h3 id="spark-history-server-configuration-options">Spark History Server配置选项</h3>

<p>“ <a href="security.html#web-ui">安全性”</a>页面中更详细地介绍了Spark History Server的安全性选项。</p>

<table class="table">
  <tbody><tr><th>物业名称</th><th>默认</th><th>含义</th></tr>
  <tr>
    <td>spark.history.provider</td>
    <td><code>org.apache.spark.deploy.history.FsHistoryProvider</code></td>
    <td>实现应用程序历史记录后端的类的名称。目前，Spark仅提供一种实现，用于查找存储在文件系统中的应用程序日志。</td>
  </tr>
  <tr>
    <td>spark.history.fs.logDirectory</td>
    <td>文件：/ tmp / spark-events</td>
    <td>对于文件系统历史记录提供程序，指向要加载的包含应用程序事件日志的目录的URL。这可以是当地人<code>file://</code>路径，HDFS路径<code>hdfs://namenode/shared/spark-logs</code>或Hadoop API支持的替代文件系统。</td>
  </tr>
  <tr>
    <td>spark.history.fs.update.interval</td>
    <td>10秒</td>
    <td>文件系统历史记录提供程序检查日志目录中的新日志或更新日志的时间段。较短的时间间隔可以更快地检测到新应用程序，但要花更多的服务器负载来重新读取更新的应用程序。更新完成后，已完成和未完成的应用程序列表将反映更改。
    </td>
  </tr>
  <tr>
    <td>spark.history.retainedApplications</td>
    <td>50</td>
    <td>在高速缓存中保留UI数据的应用程序数。如果超过此上限，则最早的应用程序将从高速缓存中删除。如果应用程序不在高速缓存中，则如果要通过UI访问该应用程序，则必须从磁盘中加载该应用程序。</td>
  </tr>
  <tr>
    <td>spark.history.ui.maxApplications</td>
    <td>整数最大值</td>
    <td>历史记录摘要页面上显示的应用程序数。即使未在历史记录摘要页面上显示，也可以通过直接访问URL来访问应用程序UI。
    </td>
  </tr>
  <tr>
    <td>spark.history.ui.port</td>
    <td>18080</td>
    <td>历史服务器的Web界面绑定到的端口。
    </td>
  </tr>
  <tr>
    <td>spark.history.kerberos.enabled</td>
    <td>假</td>
    <td>指示历史记录服务器是否应使用kerberos登录。如果历史记录服务器正在访问安全的Hadoop群集上的HDFS文件，则这是必需的。如果是这样，它将使用配置<code>spark.history.kerberos.principal</code>和<code>spark.history.kerberos.keytab</code> 。
    </td>
  </tr>
  <tr>
    <td>spark.history.kerberos.principal</td>
    <td>（没有）</td>
    <td>历史记录服务器的Kerberos主体名称。
    </td>
  </tr>
  <tr>
    <td>spark.history.kerberos.keytab</td>
    <td>（没有）</td>
    <td>历史记录服务器的kerberos keytab文件的位置。
    </td>
  </tr>
  <tr>
    <td>spark.history.fs.cleaner.enabled</td>
    <td>假</td>
    <td>指定历史记录服务器是否应定期从存储中清除事件日志。
    </td>
  </tr>
  <tr>
    <td>spark.history.fs.cleaner.interval</td>
    <td>1天</td>
    <td>文件系统作业历史记录清除程序多久检查一次要删除的文件。如果两个条件中的至少一个成立，则删除文件。首先，如果它们早于<code>spark.history.fs.cleaner.maxAge</code> 。如果文件数量超过<code>spark.history.fs.cleaner.maxNum</code> ，Spark会尝试根据最旧的尝试时间顺序从应用程序中清除已完成的尝试。
    </td>
  </tr>
  <tr>
    <td>spark.history.fs.cleaner.maxAge</td>
    <td>7天</td>
    <td>文件系统历史记录清理程序运行时，早于此时间的工作历史记录文件将被删除。
    </td>
  </tr>
  <tr>
    <td>spark.history.fs.cleaner.maxNum</td>
    <td>整数最大值</td>
    <td>事件日志目录中的最大文件数。Spark尝试清除已完成的尝试日志，以将日志目录保持在此限制之下。这应该小于基础文件系统限制，例如HDFS中的“ dfs.namenode.fs-limits.max-directory-items”。</td>
  </tr>
  <tr>
    <td>spark.history.fs.endEventReparseChunkSize</td>
    <td>1m</td>
    <td>在日志文件末尾要解析多少字节以查找结束事件。通过跳过事件日志文件的不必要部分，此方法可用于加快应用程序列表的生成。可以通过将此配置设置为0来禁用它。
    </td>
  </tr>
  <tr>
    <td>spark.history.fs.inProgressOptimization.enabled</td>
    <td>真正</td>
    <td>启用对正在进行的日志的优化处理。此选项可能会使完成的应用程序无法重命名其正在进行的事件日志。
    </td>
  </tr>
  <tr>
    <td>spark.history.fs.driverlog.cleaner.enabled</td>
    <td><code>spark.history.fs.cleaner.enabled</code></td>
    <td>指定历史记录服务器是否应定期从存储中清除驱动程序日志。
    </td>
  </tr>
  <tr>
    <td>spark.history.fs.driverlog.cleaner.interval</td>
    <td><code>spark.history.fs.cleaner.interval</code></td>
    <td>文件系统驱动程序日志清除程序多久检查一次要删除的文件。只有文件早于<code>spark.history.fs.driverlog.cleaner.maxAge</code>
    </td>
  </tr>
  <tr>
    <td>spark.history.fs.driverlog.cleaner.maxAge</td>
    <td><code>spark.history.fs.cleaner.maxAge</code></td>
    <td>运行此驱动程序日志清除器时，早于此时间的驱动程序日志文件将被删除。
    </td>
  </tr>
  <tr>
    <td>spark.history.fs.numReplayThreads</td>
    <td>25％的可用核心</td>
    <td>历史记录服务器将用于处理事件日志的线程数。
    </td>
  </tr>
  <tr>
    <td>spark.history.store.maxDiskUsage</td>
    <td>10克</td>
    <td>存储缓存应用程序历史记录信息的本地目录的最大磁盘使用率。
    </td>
  </tr>
  <tr>
    <td>spark.history.store.path</td>
    <td>（没有）</td>
    <td>用于缓存应用程序历史记录数据的本地目录。如果设置，则历史记录服务器会将应用程序数据存储在磁盘上，而不是将其保留在内存中。历史服务器重新启动时，写入磁盘的数据将被重新使用。
    </td>
  </tr>
  <tr>
    <td>spark.history.custom.executor.log.url</td>
    <td>（没有）</td>
    <td>指定自定义spark执行程序日志URL，以支持外部日志服务，而不是在历史记录服务器中使用集群管理器的应用程序日志URL。Spark将通过可在集群管理器上变化的模式来支持某些路径变量。请查看集群管理器的文档，以了解支持哪些模式（如果有）。此配置对实时应用程序无效，仅影响历史记录服务器。
        <p></p>目前，仅YARN模式支持此配置</td>
  </tr>
  <tr>
    <td>spark.history.custom.executor.log.url.applyIncompleteApplication</td>
    <td>假</td>
    <td>指定是否还将自定义spark执行程序日志URL应用于不完整的应用程序。如果应该将运行中的应用程序的执行者日志作为原始日志URL提供，请将其设置为“ false”。请注意，不完整的应用程序可能包括未正常关闭的应用程序。即使将其设置为“ true”，此配置也对实时应用程序无效，仅影响历史记录服务器。
    </td>
  </tr>

</tbody></table>

<p>请注意，在所有这些用户界面中，通过单击表头即可对表进行排序，从而轻松识别慢任务，数据偏斜等。</p>

<p>注意</p>

<ol>
  <li>
    <p>历史记录服务器显示已完成和未完成的Spark作业。如果应用程序在失败后进行了多次尝试，则将显示失败的尝试以及任何正在进行的未完成尝试或最终成功的尝试。</p>
  </li>
  <li>
    <p>不完整的应用程序只会间歇更新。更新之间的时间由检查更改文件之间的间隔（ <code>spark.history.fs.update.interval</code> ）。在较大的群集上，可以将更新间隔设置为较大的值。查看正在运行的应用程序的方法实际上是查看其自己的Web UI。</p>
  </li>
  <li>
    <p>退出但未将其自身注册为已完成的应用程序将被列为未完成-即使它们不再运行。如果应用程序崩溃，可能会发生这种情况。</p>
  </li>
  <li>
    <p>发出Spark作业完成信号的一种方法是显式停止Spark Context（ <code>sc.stop()</code> ），或在Python中使用<code>with SparkContext() as sc:</code>处理Spark Context设置并拆除的构造。</p>
  </li>
</ol>

<h2 id="rest-api">REST API</h2>

<p>除了在UI中查看指标外，它们还可以作为JSON使用。这为开发人员提供了一种简便的方法来为Spark创建新的可视化和监视工具。JSON可用于正在运行的应用程序和历史记录服务器中。端点安装在<code>/api/v1</code> 。例如，对于历史记录服务器，通常可以在以下位置访问它们<code>http://<server-url>:18080/api/v1</code> ，对于正在运行的应用程序，位于<code>http://localhost:4040/api/v1</code> 。</p>

<p>在API中，应用程序通过其应用程序ID进行引用， <code>[app-id]</code> 。在YARN上运行时，每个应用程序可能会进行多次尝试，但是仅针对群集模式下的应用程序具有尝试ID，而客户端模式下的应用程序没有尝试ID。YARN集群模式下的应用程序可以通过它们的标识<code>[attempt-id]</code> 。在下面列出的API中，以YARN群集模式运行时， <code>[app-id]</code>实际上将是<code>[base-app-id]/[attempt-id]</code> ，在哪里<code>[base-app-id]</code>是YARN应用程序ID。</p>

<table class="table">
  <tbody><tr><th>终点</th><th>含义</th></tr>
  <tr>
    <td><code>/applications</code></td>
    <td>所有应用程序的列表。
    <br>
    <code>?status=[completed|running]</code>仅列出处于选定状态的应用程序。
    <br>
    <code>?minDate=[date]</code>最早列出的开始日期/时间。
    <br>
    <code>?maxDate=[date]</code>列出的最晚开始日期/时间。
    <br>
    <code>?minEndDate=[date]</code>列出的最早结束日期/时间。
    <br>
    <code>?maxEndDate=[date]</code>列出的最晚结束日期/时间。
    <br>
    <code>?limit=[limit]</code>限制列出的应用程序数量。
    <br>例子：<br><code>?minDate=2015-02-10</code>
    <br><code>?minDate=2015-02-03T16:42:40.000GMT</code>
    <br><code>?maxDate=2015-02-11T20:41:30.000GMT</code>
    <br><code>?minEndDate=2015-02-12</code>
    <br><code>?minEndDate=2015-02-12T09:15:10.000GMT</code>
    <br><code>?maxEndDate=2015-02-14T16:30:45.000GMT</code>
    <br><code>?limit=10</code></td>
  </tr>
  <tr>
    <td><code>/applications/[app-id]/jobs</code></td>
    <td>给定应用程序的所有作业的列表。
      <br><code>?status=[running|succeeded|failed|unknown]</code>仅列出处于特定状态的作业。
    </td>
  </tr>
  <tr>
    <td><code>/applications/[app-id]/jobs/[job-id]</code></td>
    <td>给定工作的详细信息。</td>
  </tr>
  <tr>
    <td><code>/applications/[app-id]/stages</code></td>
    <td>给定应用程序的所有阶段的列表。
      <br><code>?status=[active|complete|pending|failed]</code>仅列出该状态的阶段。
    </td>
  </tr>
  <tr>
    <td><code>/applications/[app-id]/stages/[stage-id]</code></td>
    <td>给定阶段的所有尝试的列表。
    </td>
  </tr>
  <tr>
    <td><code>/applications/[app-id]/stages/[stage-id]/[stage-attempt-id]</code></td>
    <td>给定阶段尝试的详细信息。</td>
  </tr>
  <tr>
    <td><code>/applications/[app-id]/stages/[stage-id]/[stage-attempt-id]/taskSummary</code></td>
    <td>给定阶段尝试中所有任务的摘要指标。
      <br><code>?quantiles</code>用给定的分位数总结指标。
      <br>例： <code>?quantiles=0.01,0.5,0.99</code>
    </td>
  </tr>
  <tr>
    <td><code>/applications/[app-id]/stages/[stage-id]/[stage-attempt-id]/taskList</code></td>
    <td>给定阶段尝试的所有任务的列表。
      <br><code>?offset=[offset]&length=[len]</code>列出给定范围内的任务。
      <br><code>?sortBy=[runtime|-runtime]</code>排序任务。
      <br>例： <code>?offset=10&length=50&sortBy=runtime</code>
    </td>
  </tr>
  <tr>
    <td><code>/applications/[app-id]/executors</code></td>
    <td>给定应用程序的所有活动执行者的列表。</td>
  </tr>
  <tr>
    <td><code>/applications/[app-id]/executors/[executor-id]/threads</code></td>
    <td>在给定的活动执行器中运行的所有线程的堆栈跟踪。无法通过历史记录服务器使用。
    </td>
  </tr>
  <tr>
    <td><code>/applications/[app-id]/allexecutors</code></td>
    <td>给定应用程序的所有（活动和无效）执行程序的列表。</td>
  </tr>
  <tr>
    <td><code>/applications/[app-id]/storage/rdd</code></td>
    <td>给定应用程序的已存储RDD列表。</td>
  </tr>
  <tr>
    <td><code>/applications/[app-id]/storage/rdd/[rdd-id]</code></td>
    <td>给定RDD的存储状态的详细信息。</td>
  </tr>
  <tr>
    <td><code>/applications/[base-app-id]/logs</code></td>
    <td>将给定应用程序所有尝试的事件日志下载为zip文件中的文件。
    </td>
  </tr>
  <tr>
    <td><code>/applications/[base-app-id]/[attempt-id]/logs</code></td>
    <td>下载特定应用程序尝试的事件日志为zip文件。</td>
  </tr>
  <tr>
    <td><code>/applications/[app-id]/streaming/statistics</code></td>
    <td>流上下文的统计信息。</td>
  </tr>
  <tr>
    <td><code>/applications/[app-id]/streaming/receivers</code></td>
    <td>所有流式接收器的列表。</td>
  </tr>
  <tr>
    <td><code>/applications/[app-id]/streaming/receivers/[stream-id]</code></td>
    <td>给定接收者的详细信息。</td>
  </tr>
  <tr>
    <td><code>/applications/[app-id]/streaming/batches</code></td>
    <td>所有保留批次的列表。</td>
  </tr>
  <tr>
    <td><code>/applications/[app-id]/streaming/batches/[batch-id]</code></td>
    <td>给定批次的详细信息。</td>
  </tr>
  <tr>
    <td><code>/applications/[app-id]/streaming/batches/[batch-id]/operations</code></td>
    <td>给定批次的所有输出操作的列表。</td>
  </tr>
  <tr>
    <td><code>/applications/[app-id]/streaming/batches/[batch-id]/operations/[outputOp-id]</code></td>
    <td>给定操作和给定批次的详细信息。</td>
  </tr>
  <tr>
    <td><code>/applications/[app-id]/environment</code></td>
    <td>给定应用程序的环境详细信息。</td>
  </tr>
  <tr>
    <td><code>/version</code></td>
    <td>获取当前的Spark版本。</td>
  </tr>
</tbody></table>

<p>可检索的作业和阶段数受独立的Spark UI的相同保留机制限制； <code>"spark.ui.retainedJobs"</code>定义触发作业垃圾收集的阈值，以及<code>spark.ui.retainedStages</code>对于阶段。请注意，垃圾回收是在回放时进行的：可以通过增加这些值并重新启动历史记录服务器来检索更多条目。</p>

<h3 id="executor-task-metrics">执行器任务指标</h3>

<p>REST API以任务执行的粒度公开Spark执行者收集的Task Metrics的值。这些指标可用于性能故障排除和工作负载表征。可用度量的列表，并带有简短说明：</p>

<table class="table">
  <tbody><tr><th>Spark执行器任务指标名称</th>
      <th>简短的介绍</th>
  </tr>
  <tr>
    <td>executorRunTime</td>
    <td>执行者花费在运行该任务上的时间。这包括获取随机数据的时间。该值以毫秒为单位。</td>
  </tr>
  <tr>
    <td>执行器CpuTime</td>
    <td>执行程序花费在执行此任务上的CPU时间。这包括获取随机数据的时间。该值以纳秒表示。</td>
  </tr>
  <tr>
    <td>executorDeserializeTime</td>
    <td>反序列化此任务所花费的时间。该值以毫秒为单位。</td>
  </tr>
  <tr>
    <td>executorDeserializeCpuTime</td>
    <td>执行程序反序列化此任务所花费的CPU时间。该值以纳秒表示。</td>
  </tr>
  <tr>
    <td>resultSize</td>
    <td>此任务作为TaskResult发送回驱动程序的字节数。</td>
  </tr>
  <tr>
    <td>jvmGCTime</td>
    <td>JVM在执行此任务时花费在垃圾回收上的时间。该值以毫秒为单位。</td>
  </tr>
  <tr>
    <td>resultSerializationTime</td>
    <td>序列化任务结果所花费的时间。该值以毫秒为单位。</td>
  </tr>
  <tr>
    <td>memoryBytesSpilled</td>
    <td>此任务溢出的内存中字节数。</td>
  </tr>
  <tr>
    <td>diskBytesSpilled</td>
    <td>此任务溢出的磁盘上字节数。</td>
  </tr>
  <tr>
    <td>peakExecutionMemory</td>
    <td>在混洗，聚合和联接期间创建的内部数据结构使用的峰值内存。该累加器的值应约为此任务中创建的所有此类数据结构的峰值大小的总和。对于SQL作业，这仅跟踪所有不安全的运算符和ExternalSort。</td>
  </tr>
  <tr>
    <td>inputMetrics。*</td>
    <td>与从[[org.apache.spark.rdd。HadoopRDD]]或来自持久数据。</td>
  </tr>
  <tr>
    <td>.bytesRead</td>
    <td>读取的总字节数。</td>
  </tr>
  <tr>
    <td>.recordsRead</td>
    <td>读取的记录总数。</td>
  </tr>
  <tr>
    <td>outputMetrics。*</td>
    <td>与外部写入数据（例如，到分布式文件系统）有关的度量标准，仅在具有输出的任务中定义。</td>            
  </tr>
  <tr>
    <td>.bytes书面</td>
    <td>写入的总字节数</td>
  </tr>
  <tr>
    <td>.records书面</td>
    <td>记录总数</td>
  </tr>
  <tr>
    <td>shuffleReadMetrics。*</td>
    <td>与随机读取操作有关的指标。</td>
  </tr>
  <tr>
    <td>.recordsRead</td>
    <td>随机操作读取的记录数</td>
  </tr>
  <tr>
    <td>.remoteBlocksFetched</td>
    <td>随机操作中获取的远程块数</td>
  </tr>
  <tr>
    <td>.localBlocksFetched</td>
    <td>随机操作中获取的本地（相对于从远程执行器读取的）块数</td>
  </tr>
  <tr>
    <td>.totalBlocksFetched</td>
    <td>随机操作中获取的块数（本地和远程）</td>
  </tr>
  <tr>
    <td>.remoteBytesRead</td>
    <td>随机操作读取的远程字节数</td>
  </tr>
  <tr>
    <td>.localBytesRead</td>
    <td>从本地磁盘进行随机播放操作读取的字节数（与从远程执行程序读取的字节数相反）</td>
  </tr>
  <tr>
    <td>.totalBytesRead</td>
    <td>在随机操作中读取的字节数（本地和远程）</td>
  </tr>
  <tr>
    <td>.remoteBytesReadToDisk</td>
    <td>随机操作读取到磁盘的远程字节数。大数据块在随机读取操作中被提取到磁盘，而不是被读取到内存中，这是默认行为。</td>
  </tr>
  <tr>
    <td>.fetchWaitTime</td>
    <td>任务花费在等待远程随机播放块上的时间。这仅包括对混洗输入数据的时间限制。例如，如果在任务仍未完成处理块A的情况下正在获取块B，则不认为它在块B上正在阻塞。该值以毫秒表示。</td>
  </tr>
  <tr>
    <td>shuffleWriteMetrics。*</td>
    <td>与写入随机数据的操作有关的指标。</td>
  </tr>
  <tr>
    <td>.bytes书面</td>
    <td>随机操作写入的字节数</td>
  </tr>
  <tr>
    <td>.records书面</td>
    <td>随机操作写入的记录数</td>
  </tr>
  <tr>
    <td>.writeTime</td>
    <td>阻止写入磁盘或缓冲区高速缓存所花费的时间。该值以纳秒表示。</td>
  </tr>
</tbody></table>

<h3 id="executor-metrics">执行器指标</h3>

<p>执行程序级别的度量标准作为心跳信号的一部分从每个执行程序发送到驱动程序，以描述执行程序本身的性能度量标准，例如JVM堆内存，GC信息。指标<code>peakExecutorMetrics.*</code>仅在以下情况下启用<code>spark.eventLog.logStageExecutorMetrics.enabled</code>是真的。可用度量的列表，并带有简短说明：</p>

<table class="table">
  <tbody><tr><th>执行者级别指标名称</th>
      <th>简短的介绍</th>
  </tr>
  <tr>
    <td>总GC时间</td>
    <td>在此执行程序中，JVM在垃圾回收上花费的时间总计。该值以毫秒为单位。</td>
  </tr>
  <tr>
    <td>totalInputBytes</td>
    <td>此执行程序求和的总输入字节数。</td>
  </tr>
  <tr>
    <td>totalShuffleRead</td>
    <td>此执行器求和器读取的字节总数。</td>
  </tr>
  <tr>
    <td>totalShuffleWrite</td>
    <td>此执行程序求和的总shuffer写字节数。</td>
  </tr>
  <tr>
    <td>最大内存</td>
    <td>可用于存储的内存总量，以字节为单位。</td>
  </tr>
  <tr>
    <td>memoryMetrics。*</td>
    <td>内存指标的当前值：</td>
  </tr>
  <tr>
    <td>.usedOnHeapStorageMemory</td>
    <td>在当前用于存储的堆内存上使用，以字节为单位。</td>
  </tr>
  <tr>
    <td>.usedOffHeapStorageMemory</td>
    <td>当前用于存储的堆外内存，以字节为单位。</td>
  </tr>
  <tr>
    <td>.totalOnHeapStorageMemory</td>
    <td>堆内存上可用于存储的总计（以字节为单位）。在MemoryManager实现上，此数量可能会随时间变化。</td>
  </tr>
  <tr>
    <td>.totalOffHeapStorageMemory</td>
    <td>堆外可用于存储的内存总量，以字节为单位。此数量可能会随时间变化，具体取决于MemoryManager的实现。</td>
  </tr>
  <tr>
    <td>peakMemoryMetrics。*</td>
    <td>内存（和GC）指标的峰值：</td>
  </tr>
  <tr>
    <td>。JVM堆内存</td>
    <td>用于对象分配的堆的峰值内存使用率。堆由一个或多个内存池组成。返回的内存使用量的已用和已提交大小是所有堆内存池的那些值的总和，而返回的内存使用量的init和max size表示堆内存的设置，该值可能不是所有堆的总和。内存池。返回的内存使用量中的已用内存量是未收集的活动对象和垃圾对象所占用的内存量（如果有）。</td>
  </tr>
  <tr>
    <td>。JVMOffHeapMemory</td>
    <td>Java虚拟机使用的非堆内存的峰值内存使用率。非堆内存由一个或多个内存池组成。返回的内存使用量的已用和已提交大小是所有非堆内存池的这些值的总和，而返回的内存使用量的init和max size表示的是非堆内存的设置，该设置可能不等于所有非堆内存池的内存。</td>
  </tr>
  <tr>
    <td>。OnHeapExecutionMemory</td>
    <td>正在使用的堆执行内存的峰值，以字节为单位。</td>
  </tr>
  <tr>
    <td>。OffHeapExecutionMemory</td>
    <td>峰值正在使用的堆执行内存，以字节为单位。</td>
  </tr>
  <tr>
    <td>。OnHeapStorageMemory</td>
    <td>正在使用的堆存储内存的峰值，以字节为单位。</td>
  </tr>
  <tr>
    <td>。堆外存储内存</td>
    <td>峰值正在使用的堆存储内存，以字节为单位。</td>
  </tr>
  <tr>
    <td>。OnHeapUnifiedMemory</td>
    <td>堆内存（执行和存储）上的峰值。</td>
  </tr>
  <tr>
    <td>。堆外统一内存</td>
    <td>减少堆内存（执行和存储）。</td>
  </tr>
  <tr>
    <td>。DirectPool内存</td>
    <td>JVM用于直接缓冲池的峰值内存（[[java.lang.management。BufferPoolMXBean]]）</td>
  </tr>
  <tr>
    <td>。映射池内存</td>
    <td>JVM用于映射缓冲池的峰值内存（[[java.lang.management。BufferPoolMXBean]]）</td>
  </tr>
  <tr>
    <td>。ProcessTreeJVMV内存</td>
    <td>虚拟内存大小（以字节为单位）。如果spark.eventLog.logStageExecutorProcessTreeMetrics.enabled为true，则启用。</td>
  </tr>
  <tr>
    <td>。ProcessTreeJVMRSSMemory</td>
    <td>常驻集大小：进程在实际内存中的页数。这只是计入文本，数据或堆栈空间的页面。这不包括尚未按需加载或换出的页面。如果spark.eventLog.logStageExecutorProcessTreeMetrics.enabled为true，则启用。</td>
  </tr>
  <tr>
    <td>。ProcessTreePythonVMemory</td>
    <td>Python的虚拟内存大小（以字节为单位）。如果spark.eventLog.logStageExecutorProcessTreeMetrics.enabled为true，则启用。</td>
  </tr>
  <tr>
    <td>。ProcessTreePythonRSSMemory</td>
    <td>Python的常驻集大小。如果spark.eventLog.logStageExecutorProcessTreeMetrics.enabled为true，则启用。</td>
  </tr>
  <tr>
    <td>。ProcessTreeOtherVMemory</td>
    <td>其他类型进程的虚拟内存大小（以字节为单位）。如果spark.eventLog.logStageExecutorProcessTreeMetrics.enabled为true，则启用。</td>
  </tr>
  <tr>
    <td>。ProcessTreeOtherRSS内存</td>
    <td>其他类型过程的居民集大小。如果spark.eventLog.logStageExecutorProcessTreeMetrics.enabled为true，则启用。</td>
  </tr>
    <tr>
    <td>。MinorGCCount</td>
    <td>次要GC总数。例如，垃圾收集器是Copy，PS Scavenge，ParNew，G1 Young Generation等之一。</td>
  </tr>
  <tr>
    <td>。MinorGCTime</td>
    <td>总的次要GC时间已过去。该值以毫秒为单位。</td>
  </tr>
  <tr>
    <td>。专业GC计数</td>
    <td>主要GC总计数。例如，垃圾收集器是MarkSweepCompact，PS MarkSweep，ConcurrentMarkSweep，G1 Old Generation等之一。</td>
  </tr>
  <tr>
    <td>。GCGC专业</td>
    <td>主要GC总时间已用。该值以毫秒为单位。</td>
  </tr>
</tbody></table>
<p>RSS和Vmem的计算基于<a href="http://man7.org/linux/man-pages/man5/proc.5.html">proc（5）</a></p>

<h3 id="api-versioning-policy">API版本政策</h3>

<p>这些端点已经过严格版本控制，可以更轻松地在顶部开发应用程序。特别是，Spark保证：</p>

<ul>
  <li>端点永远不会从一个版本中删除</li>
  <li>对于任何给定的端点，永远不会删除单个字段</li>
  <li>可以添加新的端点</li>
  <li>可以将新字段添加到现有端点</li>
  <li>以后可能会添加新版本的api作为单独的端点（例如， <code>api/v2</code> ）。新版本<em>不</em>要求是向后兼容。</li>
  <li>可能会删除Api版本，但只有在与新api版本共存的至少一个次要版本中，才能删除Api版本。</li>
</ul>

<p>请注意，即使检查正在运行的应用程序的用户界面， <code>applications/[app-id]</code>尽管只有一个应用程序可用，但仍需要保留一部分。例如。要查看正在运行的应用程序的作业列表，请转到<code>http://localhost:4040/api/v1/applications/[app-id]/jobs</code> 。这是为了使两种模式下的路径保持一致。</p>

<h1 id="metrics">指标</h1>

<p>Spark拥有一个基于<a href="http://metrics.dropwizard.io/">Dropwizard指标库</a>的可配置指标系统。这使用户可以将Spark指标报告给各种接收器，包括HTTP，JMX和CSV文件。指标由Spark代码库中嵌入的源生成。它们为特定活动和Spark组件提供工具。度量标准系统是通过Spark预期存在的配置文件配置的<code>$SPARK_HOME/conf/metrics.properties</code> 。可以通过<code>spark.metrics.conf</code> <a href="configuration.html#spark-properties">配置属性</a> 。代替使用配置文件，而是使用带有前缀的一组配置参数<code>spark.metrics.conf.</code>可以使用。默认情况下，用于驱动程序或执行程序指标的根名称空间是<code>spark.app.id</code> 。但是，通常情况下，用户希望能够针对驱动程序和执行程序跨应用程序跟踪指标，而使用应用程序ID很难做到这一点（即<code>spark.app.id</code> ），因为它随应用程序的每次调用而变化。对于此类用例，可以使用以下方法为指标报告指定自定义名称空间： <code>spark.metrics.namespace</code>配置属性。例如，如果用户希望将指标名称空间设置为应用程序的名称，则可以设置<code>spark.metrics.namespace</code>属性值<code>${spark.app.name}</code> 。然后，Spark会适当扩展此值，并将其用作度量标准系统的根名称空间。非驱动程序和执行程序指标永远不会被前缀<code>spark.app.id</code> ， <code>spark.metrics.namespace</code>属性会对此类指标产生任何此类影响。</p>

<p>Spark的度量标准解耦到与Spark组件相对应的不同<em>实例中</em> 。在每个实例中，您可以配置一组接收器，向其报告指标。当前支持以下实例：</p>

<ul>
  <li><code>master</code> ：Spark独立主进程。</li>
  <li><code>applications</code> ：母版中用于报告各种应用程序的组件。</li>
  <li><code>worker</code> ：一个Spark独立工作进程。</li>
  <li><code>executor</code> ：Spark执行器。</li>
  <li><code>driver</code> ：Spark驱动程序进程（创建SparkContext的进程）。</li>
  <li><code>shuffleService</code> ：Spark shuffle服务。</li>
  <li><code>applicationMaster</code> ：在YARN上运行时，Spark ApplicationMaster。</li>
  <li><code>mesos_cluster</code> ：在Mesos上运行时，Spark群集调度程序。</li>
</ul>

<p>每个实例可以报告零个或多个<em>接收器</em> 。水槽包含在<code>org.apache.spark.metrics.sink</code>包：</p>

<ul>
  <li><code>ConsoleSink</code> ：将指标信息记录到控制台。</li>
  <li><code>CSVSink</code> ：定期将指标数据导出到CSV文件。</li>
  <li><code>JmxSink</code> ：注册指标以在JMX控制台中查看。</li>
  <li><code>MetricsServlet</code> ：在现有的Spark UI中添加一个Servlet，以将指标数据作为JSON数据提供。</li>
  <li><code>PrometheusServlet</code> ：在现有的Spark UI中添加一个servlet，以Prometheus格式提供指标数据。</li>
  <li><code>GraphiteSink</code> ：将指标发送到Graphite节点。</li>
  <li><code>Slf4jSink</code> ：将指标作为日志条目发送到slf4j。</li>
  <li><code>StatsdSink</code> ：将指标发送到StatsD节点。</li>
</ul>

<p>由于许可限制，Spark还支持在默认版本中不包含的Ganglia接收器：</p>

<ul>
  <li><code>GangliaSink</code> ：将指标发送到Ganglia节点或多播组。</li>
</ul>

<p>要安装<code>GangliaSink</code>您需要执行Spark的自定义构建。<em><strong>请注意，通过嵌入此库，您将在Spark软件包中包含<a href="http://www.gnu.org/copyleft/lesser.html">LGPL</a>许可的代码</strong></em> 。对于sbt用户，请设置<code>SPARK_GANGLIA_LGPL</code>构建之前的环境变量。对于Maven用户，启用<code>-Pspark-ganglia-lgpl</code>轮廓。除了修改集群的Spark构建，用户应用程序还需要链接到<code>spark-ganglia-lgpl</code>神器。</p>

<p>指标配置文件的语法和每个接收器可用的参数在示例配置文件中定义， <code>$SPARK_HOME/conf/metrics.properties.template</code> 。</p>

<p>使用Spark配置参数而不是指标配置文件时，相关参数名称由前缀组成<code>spark.metrics.conf.</code>然后是配置详细信息，即参数采用以下形式： <code>spark.metrics.conf.[instance|*].sink.[sink_name].[parameter_name]</code> 。此示例显示了Graphite接收器的Spark配置参数列表：</p>
<pre><code>"spark.metrics.conf.*.sink.graphite.class"="org.apache.spark.metrics.sink.GraphiteSink"
"spark.metrics.conf.*.sink.graphite.host"="graphiteEndPoint_hostName&gt;"
"spark.metrics.conf.*.sink.graphite.port"=&lt;graphite_listening_port&gt;
"spark.metrics.conf.*.sink.graphite.period"=10
"spark.metrics.conf.*.sink.graphite.unit"=seconds
"spark.metrics.conf.*.sink.graphite.prefix"="optional_prefix"
"spark.metrics.conf.*.sink.graphite.regex"="optional_regex_to_send_matching_metrics"
</code></pre>

<p>Spark指标配置的默认值如下：</p>
<pre><code>"*.sink.servlet.class" = "org.apache.spark.metrics.sink.MetricsServlet"
"*.sink.servlet.path" = "/metrics/json"
"master.sink.servlet.path" = "/metrics/master/json"
"applications.sink.servlet.path" = "/metrics/applications/json"
</code></pre>

<p>可以使用度量配置文件或配置参数来配置其他源<code>spark.metrics.conf.[component_name].source.jvm.class=[source_name]</code> 。当前，JVM源是唯一可用的可选源。例如，以下配置参数激活JVM源：<code>"spark.metrics.conf.*.source.jvm.class"="org.apache.spark.metrics.source.JvmSource"</code></p>

<h2 id="list-of-available-metrics-providers">可用指标提供商列表</h2>

<p>Spark使用的度量标准有多种类型：仪表，计数器，直方图，仪表和计时器， <a href="https://metrics.dropwizard.io/3.1.0/getting-started/">有关详细信息</a> ，请参阅<a href="https://metrics.dropwizard.io/3.1.0/getting-started/">Dropwizard库文档</a> 。以下组件和指标列表列出了名称和有关可用指标的详细信息（按组件实例和源名称空间分组）。Spark仪表中最常用的度量标准时间是仪表和计数器。计数器可以被识别，因为它们具有<code>.count</code>后缀。计时器，仪表和直方图在列表中标注，其余列表元素是类型表的度量。绝大多数度量标准在配置其父组件实例后即处于活动状态，某些度量标准也需要通过附加配置参数启用，详细信息会在列表中报告。</p>

<h3 id="component-instance--driver">组件实例=驱动程序</h3>
<p>这是最大量度指标的组件</p>

<ul>
  <li>namespace = BlockManager<ul>
      <li>disk.diskSpaceUsed_MB</li>
      <li>memory.maxMem_MB</li>
      <li>memory.maxOffHeapMem_MB</li>
      <li>memory.maxOnHeapMem_MB</li>
      <li>memory.memUsed_MB</li>
      <li>memory.offHeapMemUsed_MB</li>
      <li>memory.onHeapMemUsed_MB</li>
      <li>memory.remainingMem_MB</li>
      <li>memory.remainingOffHeapMem_MB</li>
      <li>memory.remainingOnHeapMem_MB</li>
    </ul>
  </li>
  <li>namespace = HiveExternalCatalog<ul>
      <li>fileCacheHits.count</li>
      <li>filesDiscovered.count</li>
      <li>hiveClientCalls.count</li>
      <li>parallelListingJobCount.count</li>
      <li>partitionsFetched.count</li>
    </ul>
  </li>
  <li>namespace = CodeGenerator<ul>
      <li>编译时间（直方图）</li>
      <li>generateClassSize（直方图）</li>
      <li>generateMethodSize（直方图）</li>
      <li>hiveClientCalls.count</li>
      <li>sourceCodeSize（直方图）</li>
    </ul>
  </li>
  <li>名称空间= DAGScheduler<ul>
      <li>job.activeJobs</li>
      <li>job.allJobs</li>
      <li>messageProcessingTime（计时器）</li>
      <li>失败阶段</li>
      <li>阶段运行阶段</li>
      <li>阶段等待阶段</li>
    </ul>
  </li>
  <li>namespace = LiveListenerBus<ul>
      <li>listenerProcessingTime.org.apache.spark。心跳接收器（计时器）</li>
      <li>listenerProcessingTime.org.apache.spark.scheduler。EventLoggingListener（计时器）</li>
      <li>listenerProcessingTime.org.apache.spark.status。AppStatusListener（计时器）</li>
      <li>numEventsPosted.count</li>
      <li>queue.appStatus.listenerProcessingTime（计时器）</li>
      <li>queue.appStatus.numDroppedEvents.count</li>
      <li>queue.appStatus.size</li>
      <li>queue.eventLog.listenerProcessingTime（计时器）</li>
      <li>queue.eventLog.numDroppedEvents.count</li>
      <li>queue.eventLog.size</li>
      <li>queue.executorManagement.listenerProcessingTime（计时器）</li>
    </ul>
  </li>
  <li>namespace = appStatus（类型为计数器的所有指标）<ul>
      <li><strong>注意：</strong>在Spark 3.0中引入。视配置参数而定：<br>
 <code>spark.app.status.metrics.enabled=true</code> （默认为false）</li>
      <li>stage.failedStages.count</li>
      <li>stage.skippedStages.count</li>
      <li>stage.completedStages.count</li>
      <li>task.blackListedExecutors.count</li>
      <li>task.completedTasks.count</li>
      <li>task.failedTasks.count</li>
      <li>task.killedTasks.count</li>
      <li>task.skippedTasks.count</li>
      <li>task.unblackListedExecutors.count</li>
      <li>Jobs.succeededJobs</li>
      <li>Jobs.failedJobs</li>
      <li>jobDuration</li>
    </ul>
  </li>
  <li>namespace = AccumulatorSource<ul>
      <li><strong>注意：</strong>用户可配置的源，用于将累加器连接到公制</li>
      <li>DoubleAccumulatorSource</li>
      <li>LongAccumulatorSource</li>
    </ul>
  </li>
  <li>namespace = spark.streaming<ul>
      <li><strong>注意：</strong>这仅适用于Spark结构化流。以配置参数为条件： <code>spark.sql.streaming.metricsEnabled=true</code> （默认为false）</li>
      <li>事件时间水印</li>
      <li>inputRate-total</li>
      <li>潜伏</li>
      <li>处理率总计</li>
      <li>状态行总计</li>
      <li>状态字节</li>
    </ul>
  </li>
  <li>名称空间= JVMCPU<ul>
      <li>jvmCpuTime</li>
    </ul>
  </li>
</ul>

<h3 id="component-instance--executor">组件实例=执行器</h3>
<p>这些指标由Spark执行者公开。请注意，当前在本地模式下运行时它们不可用。</p>

<ul>
  <li>namespace = executor（指标的类型为counter或gauge）<ul>
      <li>bytesRead.count</li>
      <li>bytesWritten.count</li>
      <li>cpuTime.count</li>
      <li>deserializeCpuTime.count</li>
      <li>deserializeTime.count</li>
      <li>diskBytesSpilled.count</li>
      <li>filesystem.file.largeRead_ops</li>
      <li>filesystem.file.read_bytes</li>
      <li>filesystem.file.read_ops</li>
      <li>filesystem.file.write_bytes</li>
      <li>filesystem.file.write_ops</li>
      <li>filesystem.hdfs.largeRead_ops</li>
      <li>filesystem.hdfs.read_bytes</li>
      <li>filesystem.hdfs.read_ops</li>
      <li>filesystem.hdfs.write_bytes</li>
      <li>filesystem.hdfs.write_ops</li>
      <li>jvmGCTime.count</li>
      <li>memoryBytesSpilled.count</li>
      <li>recordsRead.count</li>
      <li>recordsWritten.count</li>
      <li>resultSerializationTime.count</li>
      <li>resultSize.count</li>
      <li>runTime.count</li>
      <li>shuffleBytesWritten.count</li>
      <li>shuffleFetchWaitTime.count</li>
      <li>shuffleLocalBlocksFetched.count</li>
      <li>shuffleLocalBytesRead.count</li>
      <li>shuffleRecordsRead.count</li>
      <li>shuffleRecordsWritten.count</li>
      <li>shuffleRemoteBlocksFetched.count</li>
      <li>shuffleRemoteBytesRead.count</li>
      <li>shuffleRemoteBytesReadToDisk.count</li>
      <li>shuffleTotalBytesRead.count</li>
      <li>shuffleWriteTime.count</li>
      <li>successedTasks.count</li>
      <li>threadpool.activeTasks</li>
      <li>threadpool.completeTasks</li>
      <li>threadpool.currentPool_size</li>
      <li>threadpool.maxPool_size</li>
      <li>threadpool.startedTasks</li>
    </ul>
  </li>
  <li>名称空间= JVMCPU<ul>
      <li>jvmCpuTime</li>
    </ul>
  </li>
  <li>namespace = NettyBlockTransfer<ul>
      <li>shuffle-client.usedDirectMemory</li>
      <li>shuffle-client.usedHeapMemory</li>
      <li>shuffle-server.usedDirectMemory</li>
      <li>shuffle-server.usedHeapMemory</li>
    </ul>
  </li>
  <li>namespace = HiveExternalCatalog<ul>
      <li>fileCacheHits.count</li>
      <li>filesDiscovered.count</li>
      <li>hiveClientCalls.count</li>
      <li>parallelListingJobCount.count</li>
      <li>partitionsFetched.count</li>
    </ul>
  </li>
  <li>namespace = CodeGenerator<ul>
      <li>编译时间（直方图）</li>
      <li>generateClassSize（直方图）</li>
      <li>generateMethodSize（直方图）</li>
      <li>hiveClientCalls.count</li>
      <li>sourceCodeSize（直方图）</li>
    </ul>
  </li>
  <li>名称空间= <executor class="" name="" plugin="">
</executor>    <ul>
      <li>可选名称空间。此名称空间中的指标由用户提供的代码定义，并使用Spark executor插件基础结构进行配置。另请参阅配置参数<code>spark.executor.plugins</code></li>
    </ul>
  </li>
</ul>

<h3 id="source--jvm-source">源= JVM源</h3>
<p>笔记：</p>
<ul>
  <li>通过设置相关内容激活此来源<code>metrics.properties</code>文件条目或配置参数：<code>spark.metrics.conf.*.source.jvm.class=org.apache.spark.metrics.source.JvmSource</code></li>
  <li>此源可用于驱动程序和执行程序实例，也可用于其他实例。</li>
  <li>此源使用<a href="https://metrics.dropwizard.io/3.1.0/manual/jvm/">用于JVM仪器</a>的<a href="https://metrics.dropwizard.io/3.1.0/manual/jvm/">Dropwizard / Codahale度量</a>标准集（尤其是度量标准集BufferPoolMetricSet，GarbageCollectorMetricSet和MemoryUsageGaugeSet）提供有关JVM度量标准的信息。</li>
</ul>

<h3 id="component-instance--applicationmaster">组件实例= applicationMaster</h3>
<p>注意：在YARN上运行时适用</p>

<ul>
  <li>numContainersPendingAllocate</li>
  <li>numExecutorsFailed</li>
  <li>numExecutorsRunning</li>
  <li>numLocalityAwareTasks</li>
  <li>numReleasedContainers</li>
</ul>

<h3 id="component-instance--mesos_cluster">组件实例= mesos_cluster</h3>
<p>注意：在mesos上运行时适用</p>

<ul>
  <li>等待司机</li>
  <li>launchDrivers</li>
  <li>retryDrivers</li>
</ul>

<h3 id="component-instance--master">组件实例=主</h3>
<p>注意：在Spark独立运行时适用</p>

<ul>
  <li>工作人员</li>
  <li>活着的工人</li>
  <li>应用</li>
  <li>等待应用</li>
</ul>

<h3 id="component-instance--applicationsource">组件实例= ApplicationSource</h3>
<p>注意：在Spark独立运行时适用</p>

<ul>
  <li>状态</li>
  <li>runtime_ms</li>
  <li>核心</li>
</ul>

<h3 id="component-instance--worker">组件实例=工人</h3>
<p>注意：在Spark独立运行时作为工人适用</p>

<ul>
  <li>执行者</li>
  <li>核心数</li>
  <li>memUsed_MB</li>
  <li>核心免费</li>
  <li>memFree_MB</li>
</ul>

<h3 id="component-instance--shuffleservice">组件实例= shuffleService</h3>
<p>注意：适用于随机播放服务</p>

<ul>
  <li>blockTransferRateBytes（米）</li>
  <li>numActiveConnections.count</li>
  <li>numRegisteredConnections.count</li>
  <li>numCaughtExceptions.count</li>
  <li>openBlockRequestLatencyMillis（直方图）</li>
  <li>registerExecutorRequestLatencyMillis（直方图）</li>
  <li>注册执行者人数</li>
  <li>shuffle-server.usedDirectMemory</li>
  <li>shuffle-server.usedHeapMemory</li>
</ul>

<h1 id="advanced-instrumentation">先进仪器</h1>

<p>可以使用几种外部工具来帮助分析Spark作业的性能：</p>

<ul>
  <li>集群范围内的监视工具（例如<a href="http://ganglia.sourceforge.net/">Ganglia</a> ）可以洞悉集群的总体利用率和资源瓶颈。例如，Ganglia仪表板可以快速显示特定工作负载是磁盘绑定，网络绑定还是CPU绑定。</li>
  <li>诸如<a href="http://dag.wieers.com/home-made/dstat/">dstat</a> ， <a href="http://linux.die.net/man/1/iostat">iostat</a>和<a href="http://linux.die.net/man/1/iotop">iotop之</a>类的OS分析工具可以在单个节点上提供细粒度的分析。</li>
  <li>JVM实用程序，例如<code>jstack</code>用于提供堆栈跟踪， <code>jmap</code>用于创建堆转储， <code>jstat</code>用于报告时间序列统计信息，以及<code>jconsole</code>对于视觉上探索各种JVM属性的人来说，对于熟悉JVM内部知识的人很有用。</li>
</ul>


                </div>
            
             <!-- /container -->
        </div>

        <script src="js/vendor/jquery-3.4.1.min.js"></script>
        <script src="js/vendor/bootstrap.min.js"></script>
        <script src="js/vendor/anchor.min.js"></script>
        <script src="js/main.js"></script>

        <!-- MathJax Section -->
        <script type="text/x-mathjax-config">
            MathJax.Hub.Config({
                TeX: { equationNumbers: { autoNumber: "AMS" } }
            });
        </script>
        <script>
            // Note that we load MathJax this way to work with local file (file://), HTTP and HTTPS.
            // We could use "//cdn.mathjax...", but that won't support "file://".
            (function(d, script) {
                script = d.createElement('script');
                script.type = 'text/javascript';
                script.async = true;
                script.onload = function(){
                    MathJax.Hub.Config({
                        tex2jax: {
                            inlineMath: [ ["$", "$"], ["\\\\(","\\\\)"] ],
                            displayMath: [ ["$$","$$"], ["\\[", "\\]"] ],
                            processEscapes: true,
                            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre']
                        }
                    });
                };
                script.src = ('https:' == document.location.protocol ? 'https://' : 'http://') +
                    'cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js' +
                    '?config=TeX-AMS-MML_HTMLorMML';
                d.getElementsByTagName('head')[0].appendChild(script);
            }(document));
        </script>
    

</body></html>