<html class="no-js" ><!--<![endif]--><head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
        <title>优化-基于RDD的API-Spark 2.4.4文档</title>
        

        

        <link rel="stylesheet" href="css/bootstrap.min.css">
        <style>
            body {
                padding-top: 60px;
                padding-bottom: 40px;
            }
        </style>
        <meta name="viewport" content="width=device-width">
        <link rel="stylesheet" href="css/bootstrap-responsive.min.css">
        <link rel="stylesheet" href="css/main.css">

        <script src="js/vendor/modernizr-2.6.1-respond-1.1.0.min.js"></script>

        <link rel="stylesheet" href="css/pygments-default.css">

        
        <!-- Google analytics script -->
        <script type="text/javascript">
          var _gaq = _gaq || [];
          _gaq.push(['_setAccount', 'UA-32518208-2']);
          _gaq.push(['_trackPageview']);

          (function() {
            var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
            ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
            var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
          })();
        </script>
        

    </head>
    <body >
        <!--[if lt IE 7]>
            <p class="chromeframe">You are using an outdated browser. <a href="https://browsehappy.com/">Upgrade your browser today</a> or <a href="http://www.google.com/chromeframe/?redirect=true">install Google Chrome Frame</a> to better experience this site.</p>
        <![endif]-->

        <!-- This code is taken from http://twitter.github.com/bootstrap/examples/hero.html -->

        <div class="navbar navbar-fixed-top" id="topbar">
            <div class="navbar-inner">
                <div class="container">
                    <div class="brand"><a href="index.html"><img src="img/spark-logo-hd.png" style="height:50px"></a> <span class="version">2.4.4</span>
                    </div>
                    <ul class="nav">
                        <!--TODO(andyk): Add class="active" attribute to li some how.-->
                        <li><a href="index.html">总览</a></li>

                        <li class="dropdown">
                            <a href="#" class="dropdown-toggle" data-toggle="dropdown">编程指南<b class="caret"></b></a>
                            <ul class="dropdown-menu">
                                <li><a href="quick-start.html">快速开始</a></li>
                                <li><a href="rdd-programming-guide.html">RDD，累加器，广播变量</a></li>
                                <li><a href="sql-programming-guide.html">SQL，数据框和数据集</a></li>
                                <li><a href="structured-streaming-programming-guide.html">结构化流</a></li>
                                <li><a href="streaming-programming-guide.html">火花流（DStreams）</a></li>
                                <li><a href="ml-guide.html">MLlib（机器学习）</a></li>
                                <li><a href="graphx-programming-guide.html">GraphX（图形处理）</a></li>
                                <li><a href="sparkr.html">SparkR（Spark上的R）</a></li>
                            </ul>
                        </li>

                        <li class="dropdown">
                            <a href="#" class="dropdown-toggle" data-toggle="dropdown">API文件<b class="caret"></b></a>
                            <ul class="dropdown-menu">
                                <li><a href="api/scala/index.html#org.apache.spark.package">斯卡拉</a></li>
                                <li><a href="api/java/index.html">爪哇</a></li>
                                <li><a href="api/python/index.html">蟒蛇</a></li>
                                <li><a href="api/R/index.html">[R</a></li>
                                <li><a href="api/sql/index.html">SQL，内置函数</a></li>
                            </ul>
                        </li>

                        <li class="dropdown">
                            <a href="#" class="dropdown-toggle" data-toggle="dropdown">部署中<b class="caret"></b></a>
                            <ul class="dropdown-menu">
                                <li><a href="cluster-overview.html">总览</a></li>
                                <li><a href="submitting-applications.html">提交申请</a></li>
                                <li class="divider"></li>
                                <li><a href="spark-standalone.html">Spark独立</a></li>
                                <li><a href="running-on-mesos.html">梅索斯</a></li>
                                <li><a href="running-on-yarn.html">纱</a></li>
                                <li><a href="running-on-kubernetes.html">Kubernetes</a></li>
                            </ul>
                        </li>

                        <li class="dropdown">
                            <a href="api.html" class="dropdown-toggle" data-toggle="dropdown">更多<b class="caret"></b></a>
                            <ul class="dropdown-menu">
                                <li><a href="configuration.html">组态</a></li>
                                <li><a href="monitoring.html">监控方式</a></li>
                                <li><a href="tuning.html">调音指南</a></li>
                                <li><a href="job-scheduling.html">作业调度</a></li>
                                <li><a href="security.html">安全</a></li>
                                <li><a href="hardware-provisioning.html">硬件配置</a></li>
                                <li class="divider"></li>
                                <li><a href="building-spark.html">建筑火花</a></li>
                                <li><a href="https://spark.apache.org/contributing.html">为Spark贡献</a></li>
                                <li><a href="https://spark.apache.org/third-party-projects.html">第三方项目</a></li>
                            </ul>
                        </li>
                    </ul>
                    <!--<p class="navbar-text pull-right"><span class="version-text">v2.4.4</span></p>-->
                </div>
            </div>
        </div>

        <div class="container-wrapper">

            
                
                    <div class="left-menu-wrapper">
    <div class="left-menu">
        <h3><a href="ml-guide.html">MLlib：主要指南</a></h3>
        
<ul>

    <li>
        <a href="ml-statistics.html">基本统计</a>
    </li>
    
    

    <li>
        <a href="ml-datasource">数据源</a>
    </li>
    
    

    <li>
        <a href="ml-pipeline.html">流水线</a>
    </li>
    
    

    <li>
        <a href="ml-features.html">提取，转换和选择特征</a>
    </li>
    
    

    <li>
        <a href="ml-classification-regression.html">分类与回归</a>
    </li>
    
    

    <li>
        <a href="ml-clustering.html">聚类</a>
    </li>
    
    

    <li>
        <a href="ml-collaborative-filtering.html">协同过滤</a>
    </li>
    
    

    <li>
        <a href="ml-frequent-pattern-mining.html">频繁模式挖掘</a>
    </li>
    
    

    <li>
        <a href="ml-tuning.html">模型选择和调整</a>
    </li>
    
    

    <li>
        <a href="ml-advanced.html">进阶主题</a>
    </li>
    
    

</ul>

        <h3><a href="mllib-guide.html">MLlib：基于RDD的API指南</a></h3>
        
<ul>

    <li>
        <a href="mllib-data-types.html">资料类型</a>
    </li>
    
    

    <li>
        <a href="mllib-statistics.html">基本统计</a>
    </li>
    
    

    <li>
        <a href="mllib-classification-regression.html">分类与回归</a>
    </li>
    
    

    <li>
        <a href="mllib-collaborative-filtering.html">协同过滤</a>
    </li>
    
    

    <li>
        <a href="mllib-clustering.html">聚类</a>
    </li>
    
    

    <li>
        <a href="mllib-dimensionality-reduction.html">降维</a>
    </li>
    
    

    <li>
        <a href="mllib-feature-extraction.html">特征提取和转换</a>
    </li>
    
    

    <li>
        <a href="mllib-frequent-pattern-mining.html">频繁模式挖掘</a>
    </li>
    
    

    <li>
        <a href="mllib-evaluation-metrics.html">评估指标</a>
    </li>
    
    

    <li>
        <a href="mllib-pmml-model-export.html">PMML模型导出</a>
    </li>
    
    

    <li>
        <a href="mllib-optimization.html">
            
                <b>优化（开发人员）</b>
            
        </a>
    </li>
    
    
        
<ul>

    <li>
        <a href="mllib-optimization.html#stochastic-gradient-descent-sgd">随机梯度下降</a>
    </li>
    
    

    <li>
        <a href="mllib-optimization.html#limited-memory-bfgs-l-bfgs">有限内存BFGS（L-BFGS）</a>
    </li>
    
    

</ul>

    

</ul>

    </div>
</div>
                
                <input id="nav-trigger" class="nav-trigger" type="checkbox" checked>
                <label for="nav-trigger"></label>
                <div class="content-with-sidebar" id="content">
                    
                        <h1 class="title">优化-基于RDD的API</h1>
                    

                    <ul id="markdown-toc">
  <li><a href="#mathematical-description" id="markdown-toc-mathematical-description">数学描述</a>    <ul>
      <li><a href="#gradient-descent" id="markdown-toc-gradient-descent">梯度下降</a></li>
      <li><a href="#stochastic-gradient-descent-sgd" id="markdown-toc-stochastic-gradient-descent-sgd">随机梯度下降（SGD）</a></li>
      <li><a href="#update-schemes-for-distributed-sgd" id="markdown-toc-update-schemes-for-distributed-sgd">分布式SGD的更新方案</a></li>
      <li><a href="#limited-memory-bfgs-l-bfgs" id="markdown-toc-limited-memory-bfgs-l-bfgs">内存有限的BFGS（L-BFGS）</a></li>
      <li><a href="#choosing-an-optimization-method" id="markdown-toc-choosing-an-optimization-method">选择一种优化方法</a></li>
    </ul>
  </li>
  <li><a href="#implementation-in-mllib" id="markdown-toc-implementation-in-mllib">MLlib中的实现</a>    <ul>
      <li><a href="#gradient-descent-and-stochastic-gradient-descent" id="markdown-toc-gradient-descent-and-stochastic-gradient-descent">梯度下降和随机梯度下降</a></li>
      <li><a href="#l-bfgs" id="markdown-toc-l-bfgs">BFGS</a></li>
    </ul>
  </li>
  <li><a href="#developers-notes" id="markdown-toc-developers-notes">开发人员说明</a></li>
</ul>

<p><code>\[ \newcommand{\R}{\mathbb{R}} \newcommand{\E}{\mathbb{E}} \newcommand{\x}{\mathbf{x}} \newcommand{\y}{\mathbf{y}} \newcommand{\wv}{\mathbf{w}} \newcommand{\av}{\mathbf{\alpha}} \newcommand{\bv}{\mathbf{b}} \newcommand{\N}{\mathbb{N}} \newcommand{\id}{\mathbf{I}} \newcommand{\ind}{\mathbf{1}} \newcommand{\0}{\mathbf{0}} \newcommand{\unit}{\mathbf{e}} \newcommand{\one}{\mathbf{1}} \newcommand{\zero}{\mathbf{0}} \]</code></p>

<h2 id="mathematical-description">数学描述</h2>

<h3 id="gradient-descent">梯度下降</h3>
<p>解决表单优化问题的最简单方法<code>$\min_{\wv \in\R^d} \; f(\wv)$</code>是<a href="http://en.wikipedia.org/wiki/Gradient_descent">梯度下降</a> 。这样的一阶优化方法（包括梯度下降及其随机变型）非常适合于大规模和分布式计算。</p>

<p>梯度下降法的目的是通过在最陡下降方向上迭代采取步骤来找到函数的局部最小值，该<a href="http://en.wikipedia.org/wiki/Gradient">梯度</a>是当前点（即当前参数值）上函数的导数（称为<a href="http://en.wikipedia.org/wiki/Gradient">梯度</a> ）的负数。如果目标函数<code>$f$</code>并非所有参数都可微，而是凸的，则<em>次梯度</em>是<em>梯度</em>的自然泛化，并承担了阶跃方向的作用。无论如何，计算的梯度或子梯度<code>$f$</code>成本很高-为了计算所有损失项的贡献，需要完整遍历整个数据集。</p>

<h3 id="stochastic-gradient-descent-sgd">随机梯度下降（SGD）</h3>
<p>目标函数的优化问题<code>$f$</code>作为和被写成是特别适合于使用<em>随机梯度下降（SGD）</em>来求解的。在我们的案例中，对于有<a href="mllib-classification-regression.html">监督的机器学习中</a>常用的优化公式， <code>\begin{equation} f(\wv) := \lambda\, R(\wv) + \frac1n \sum_{i=1}^n L(\wv;\x_i,y_i) \label{eq:regPrimal} \ . \end{equation}</code>这是特别自然的，因为损耗被写为来自每个数据点的单个损耗的平均值。</p>

<p>随机次梯度是对向量的随机选择，因此在期望中，我们可以获得原始目标函数的真实次梯度。选择一个数据点<code>$i\in[1..n]$</code>随机地均匀地得到<code>$\eqref{eq:regPrimal}$</code> ， 关于<code>$\wv$</code>如下： <code>\[ f'_{\wv,i} := L'_{\wv,i} + \lambda\, R'_\wv \ , \]</code>哪里<code>$L'_{\wv,i} \in \R^d$</code>是损失函数部分的次梯度，由<code>$i$</code> -th数据点，即<code>$L'_{\wv,i} \in \frac{\partial}{\partial \wv} L(\wv;\x_i,y_i)$</code> 。此外， <code>$R'_\wv$</code>是正则化器的子梯度<code>$R(\wv)$</code> ，即<code>$R'_\wv \in \frac{\partial}{\partial \wv} R(\wv)$</code> 。术语<code>$R'_\wv$</code>不依赖于选择哪个随机数据点。显然，期望随机选择<code>$i\in[1..n]$</code> ，我们有<code>$f'_{\wv,i}$</code>是原始目标的次要特征<code>$f$</code> ， 意思是<code>$\E\left[f'_{\wv,i}\right] \in \frac{\partial}{\partial \wv} f(\wv)$</code> 。</p>

<p>现在，运行SGD只是朝负随机次梯度的方向走<code>$f'_{\wv,i}$</code> ， 那是<code>\begin{equation}\label{eq:SGDupdate} \wv^{(t+1)} := \wv^{(t)} - \gamma \; f'_{\wv,i} \ . \end{equation}</code> <strong>步长。</strong>参数<code>$\gamma$</code>是步长，在默认实现中，步长选择为随迭代计数器的平方根减小，即<code>$\gamma := \frac{s}{\sqrt{t}}$</code>在里面<code>$t$</code>迭代，使用输入参数<code>$s=$ stepSize</code> 。注意，为SGD方法选择最佳步长通常在实践中会很困难，并且是积极研究的主题。</p>

<p><strong>渐变色。</strong>表格中实现的机器学习方法的（子）梯度<code>spark.mllib</code>在<a href="mllib-classification-regression.html">分类和回归</a>部分中可用。</p>

<p><strong>最近更新。</strong>作为仅使用次梯度的替代方法<code>$R'(\wv)$</code>在步长方向上调整正则表达式，可以通过使用近端运算符代替某些情况下获得改进的更新。对于L1 <a href="api/scala/index.html#org.apache.spark.mllib.optimization.L1Updater">调节器</a> ，近端算子由软阈值确定，如<a href="api/scala/index.html#org.apache.spark.mllib.optimization.L1Updater">L1Updater中</a>所实现。</p>

<h3 id="update-schemes-for-distributed-sgd">分布式SGD的更新方案</h3>
<p><a href="api/scala/index.html#org.apache.spark.mllib.optimization.GradientDescent">GradientDescent中</a>的SGD实现使用数据示例的简单（分布式）采样。我们记得优化问题的损失部分<code>$\eqref{eq:regPrimal}$</code>是<code>$\frac1n \sum_{i=1}^n L(\wv;\x_i,y_i)$</code> ，因此<code>$\frac1n \sum_{i=1}^n L'_{\wv,i}$</code>将是真正的（子）渐变。由于这需要访问完整的数据集，因此参数<code>miniBatchFraction</code>指定要使用的完整数据的哪一部分。该子集上梯度的平均值，即<code>\[ \frac1{|S|} \sum_{i\in S} L'_{\wv,i} \ , \]</code>是随机梯度。这里<code>$S$</code>是大小的采样子集<code>$|S|=$ miniBatchFraction $\cdot n$</code> 。</p>

<p>在每次迭代中，通过标准火花例程执行对分布式数据集（ <a href="rdd-programming-guide.html#resilient-distributed-datasets-rdds">RDD</a> ）的采样以及对每个工作机的部分结果之和的计算。</p>

<p>如果分数的分数<code>miniBatchFraction</code>如果将其设置为1（默认值），则每次迭代中得到的步骤都是精确的（子）梯度下降。在这种情况下，所使用的步长方向没有随机性，也没有方差。另一方面，如果<code>miniBatchFraction</code>选择很小，因此仅采样一个点，即<code>$|S|=$ miniBatchFraction $\cdot n = 1$</code> ，则该算法等效于标准SGD。在这种情况下，步进方向取决于该点的均匀随机采样。</p>

<h3 id="limited-memory-bfgs-l-bfgs">内存有限的BFGS（L-BFGS）</h3>
<p><a href="http://en.wikipedia.org/wiki/Limited-memory_BFGS">L-BFGS</a>是拟牛顿方法族中的一种优化算法，用于解决形式的优化问题<code>$\min_{\wv \in\R^d} \; f(\wv)$</code> 。L-BFGS方法在不评估目标函数的二阶导数以构造Hessian矩阵的情况下，将目标函数局部近似为二次方。Hessian矩阵可通过以前的梯度评估来近似，因此在以牛顿方法显式计算Hessian矩阵时，不存在垂直可伸缩性问题（训练特征的数量）。结果，与其他一阶优化相比，L-BFGS通常可以实现更快的收敛。</p>

<h3 id="choosing-an-optimization-method">选择一种优化方法</h3>

<p><a href="mllib-linear-methods.html">线性方法在</a>内部使用优化，有些线性方法在内部<code>spark.mllib</code>同时支持SGD和L-BFGS。根据目标函数的性质，不同的优化方法可以具有不同的收敛性保证，因此我们在此不涉及任何文献。通常，当L-BFGS可用时，我们建议使用它而不是SGD，因为L-BFGS趋向于收敛更快（迭代次数更少）。</p>

<h2 id="implementation-in-mllib">MLlib中的实现</h2>

<h3 id="gradient-descent-and-stochastic-gradient-descent">梯度下降和随机梯度下降</h3>
<p>梯度下降方法，包括作为随机基本梯度下降（SGD）的低级基元<code>MLlib</code> ，在其上开发了各种ML算法，例如，请参见<a href="mllib-linear-methods.html">线性方法</a>部分。</p>

<p>SGD类<a href="api/scala/index.html#org.apache.spark.mllib.optimization.GradientDescent">GradientDescent</a>设置以下参数：</p>

<ul>
  <li><code>Gradient</code>是一类，用于在当前参数值下计算要优化的函数的随机梯度，即相对于单个训练示例。MLlib包括用于常见损失函数的梯度类，例如铰链，逻辑，最小二乘。梯度类将训练示例，其标签和当前参数值作为输入。</li>
  <li><code>Updater</code>是执行实际梯度下降步骤的类，即针对损耗部分的给定梯度在每次迭代中更新权重。更新程序还负责从正则化部分执行更新。MLlib包括针对没有正则化的情况的更新程序，以及L1和L2正则化器。</li>
  <li><code>stepSize</code>是表示梯度下降的初始步长的标量值。MLlib中的所有更新程序在第t步使用的步长等于<code>stepSize $/ \sqrt{t}$</code> 。</li>
  <li><code>numIterations</code>是要运行的迭代次数。</li>
  <li><code>regParam</code>是使用L1或L2正则化时的正则化参数。</li>
  <li><code>miniBatchFraction</code>是每次迭代中采样的总数据的一部分，用于计算梯度方向。
    <ul>
      <li>采样仍然需要遍历整个RDD，因此减少了<code>miniBatchFraction</code>可能不会加快优化速度。当梯度的计算成本很高时，用户将看到最大的加速，因为只有选定的样本才用于计算梯度。</li>
    </ul>
  </li>
</ul>

<h3 id="l-bfgs">BFGS</h3>
<p>L-BFGS目前仅是低阶优化原语<code>MLlib</code> 。如果要在各种ML算法（例如线性回归和Logistic回归）中使用L-BFGS，则必须传递目标函数的梯度，然后将updater自己传递给优化器，而不是使用<a href="api/scala/index.html#org.apache.spark.mllib.classification.LogisticRegressionWithSGD">LogisticRegressionWithSGD之</a>类的训练API。请参见下面的示例。它将在下一版本中解决。</p>

<p>由于<a href="api/scala/index.html#org.apache.spark.mllib.optimization.L1Updater">L1Updater中</a>的软阈值逻辑设计用于梯度下降，因此无法使用<a href="api/scala/index.html#org.apache.spark.mllib.optimization.L1Updater">L1Updater进行</a> L1正则化。请参阅开发者说明。</p>

<p>L-BFGS方法<a href="api/scala/index.html#org.apache.spark.mllib.optimization.LBFGS">LBFGS.runLBFGS</a>具有以下参数：</p>

<ul>
  <li><code>Gradient</code>是一个类，用于在当前参数值下计算要优化的目标函数（即，相对于单个训练示例）的梯度。MLlib包括用于常见损失函数的梯度类，例如铰链，逻辑，最小二乘。梯度类将训练示例，其标签和当前参数值作为输入。</li>
  <li><code>Updater</code>是计算L-BFGS正则化部分的目标函数的梯度和损失的类。 MLlib包括针对没有正则化的情况的更新程序，以及L2正则化器。</li>
  <li><code>numCorrections</code>是L-BFGS更新中使用的更正数。建议10。</li>
  <li><code>maxNumIterations</code>是L-BFGS可以运行的最大迭代次数。</li>
  <li><code>regParam</code>是使用正则化时的正则化参数。</li>
  <li><code>convergenceTol</code>控制当L-BFGS被认为收敛时仍然允许多少相对变化。这必须是非负的。较低的值容忍度较低，因此通常会导致运行更多的迭代。此值同时考虑了<a href="https://github.com/scalanlp/breeze/blob/master/math/src/main/scala/breeze/optimize/LBFGS.scala">Breeze LBFGS</a>内部的平均改进和梯度范数。</li>
</ul>

<p>的<code>return</code>是一个包含两个元素的元组。第一个元素是一个包含每个要素权重的列矩阵，第二个元素是一个包含针对每次迭代计算的损耗的数组。</p>

<p>这是一个使用L-BFGS优化器通过L2正则训练二进制logistic回归的示例。</p>

<div class="codetabs">

<div data-lang="scala">
    <p>请参阅<a href="api/scala/index.html#org.apache.spark.mllib.optimization.LBFGS"><code>LBFGS</code> Scala文档</a>和<a href="api/scala/index.html#org.apache.spark.mllib.optimization.SquaredL2Updater"><code>SquaredL2Updater</code></a>有关API的详细信息，请参见<a href="api/scala/index.html#org.apache.spark.mllib.optimization.SquaredL2Updater">Scala文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">org.apache.spark.mllib.classification.LogisticRegressionModel</span>
<span class="k">import</span> <span class="nn">org.apache.spark.mllib.evaluation.BinaryClassificationMetrics</span>
<span class="k">import</span> <span class="nn">org.apache.spark.mllib.linalg.Vectors</span>
<span class="k">import</span> <span class="nn">org.apache.spark.mllib.optimization.</span><span class="o">{</span><span class="nc">LBFGS</span><span class="o">,</span> <span class="nc">LogisticGradient</span><span class="o">,</span> <span class="nc">SquaredL2Updater</span><span class="o">}</span>
<span class="k">import</span> <span class="nn">org.apache.spark.mllib.util.MLUtils</span>

<span class="k">val</span> <span class="n">data</span> <span class="k">=</span> <span class="nc">MLUtils</span><span class="o">.</span><span class="n">loadLibSVMFile</span><span class="o">(</span><span class="n">sc</span><span class="o">,</span> <span class="s">&quot;data/mllib/sample_libsvm_data.txt&quot;</span><span class="o">)</span>
<span class="k">val</span> <span class="n">numFeatures</span> <span class="k">=</span> <span class="n">data</span><span class="o">.</span><span class="n">take</span><span class="o">(</span><span class="mi">1</span><span class="o">)(</span><span class="mi">0</span><span class="o">).</span><span class="n">features</span><span class="o">.</span><span class="n">size</span>

<span class="c1">// Split data into training (60%) and test (40%).</span>
<span class="k">val</span> <span class="n">splits</span> <span class="k">=</span> <span class="n">data</span><span class="o">.</span><span class="n">randomSplit</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="mf">0.6</span><span class="o">,</span> <span class="mf">0.4</span><span class="o">),</span> <span class="n">seed</span> <span class="k">=</span> <span class="mi">11L</span><span class="o">)</span>

<span class="c1">// Append 1 into the training data as intercept.</span>
<span class="k">val</span> <span class="n">training</span> <span class="k">=</span> <span class="n">splits</span><span class="o">(</span><span class="mi">0</span><span class="o">).</span><span class="n">map</span><span class="o">(</span><span class="n">x</span> <span class="k">=&gt;</span> <span class="o">(</span><span class="n">x</span><span class="o">.</span><span class="n">label</span><span class="o">,</span> <span class="nc">MLUtils</span><span class="o">.</span><span class="n">appendBias</span><span class="o">(</span><span class="n">x</span><span class="o">.</span><span class="n">features</span><span class="o">))).</span><span class="n">cache</span><span class="o">()</span>

<span class="k">val</span> <span class="n">test</span> <span class="k">=</span> <span class="n">splits</span><span class="o">(</span><span class="mi">1</span><span class="o">)</span>

<span class="c1">// Run training algorithm to build the model</span>
<span class="k">val</span> <span class="n">numCorrections</span> <span class="k">=</span> <span class="mi">10</span>
<span class="k">val</span> <span class="n">convergenceTol</span> <span class="k">=</span> <span class="mi">1</span><span class="n">e</span><span class="o">-</span><span class="mi">4</span>
<span class="k">val</span> <span class="n">maxNumIterations</span> <span class="k">=</span> <span class="mi">20</span>
<span class="k">val</span> <span class="n">regParam</span> <span class="k">=</span> <span class="mf">0.1</span>
<span class="k">val</span> <span class="n">initialWeightsWithIntercept</span> <span class="k">=</span> <span class="nc">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="o">(</span><span class="k">new</span> <span class="nc">Array</span><span class="o">[</span><span class="kt">Double</span><span class="o">](</span><span class="n">numFeatures</span> <span class="o">+</span> <span class="mi">1</span><span class="o">))</span>

<span class="k">val</span> <span class="o">(</span><span class="n">weightsWithIntercept</span><span class="o">,</span> <span class="n">loss</span><span class="o">)</span> <span class="k">=</span> <span class="nc">LBFGS</span><span class="o">.</span><span class="n">runLBFGS</span><span class="o">(</span>
  <span class="n">training</span><span class="o">,</span>
  <span class="k">new</span> <span class="nc">LogisticGradient</span><span class="o">(),</span>
  <span class="k">new</span> <span class="nc">SquaredL2Updater</span><span class="o">(),</span>
  <span class="n">numCorrections</span><span class="o">,</span>
  <span class="n">convergenceTol</span><span class="o">,</span>
  <span class="n">maxNumIterations</span><span class="o">,</span>
  <span class="n">regParam</span><span class="o">,</span>
  <span class="n">initialWeightsWithIntercept</span><span class="o">)</span>

<span class="k">val</span> <span class="n">model</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">LogisticRegressionModel</span><span class="o">(</span>
  <span class="nc">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="o">(</span><span class="n">weightsWithIntercept</span><span class="o">.</span><span class="n">toArray</span><span class="o">.</span><span class="n">slice</span><span class="o">(</span><span class="mi">0</span><span class="o">,</span> <span class="n">weightsWithIntercept</span><span class="o">.</span><span class="n">size</span> <span class="o">-</span> <span class="mi">1</span><span class="o">)),</span>
  <span class="n">weightsWithIntercept</span><span class="o">(</span><span class="n">weightsWithIntercept</span><span class="o">.</span><span class="n">size</span> <span class="o">-</span> <span class="mi">1</span><span class="o">))</span>

<span class="c1">// Clear the default threshold.</span>
<span class="n">model</span><span class="o">.</span><span class="n">clearThreshold</span><span class="o">()</span>

<span class="c1">// Compute raw scores on the test set.</span>
<span class="k">val</span> <span class="n">scoreAndLabels</span> <span class="k">=</span> <span class="n">test</span><span class="o">.</span><span class="n">map</span> <span class="o">{</span> <span class="n">point</span> <span class="k">=&gt;</span>
  <span class="k">val</span> <span class="n">score</span> <span class="k">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="o">(</span><span class="n">point</span><span class="o">.</span><span class="n">features</span><span class="o">)</span>
  <span class="o">(</span><span class="n">score</span><span class="o">,</span> <span class="n">point</span><span class="o">.</span><span class="n">label</span><span class="o">)</span>
<span class="o">}</span>

<span class="c1">// Get evaluation metrics.</span>
<span class="k">val</span> <span class="n">metrics</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">BinaryClassificationMetrics</span><span class="o">(</span><span class="n">scoreAndLabels</span><span class="o">)</span>
<span class="k">val</span> <span class="n">auROC</span> <span class="k">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">areaUnderROC</span><span class="o">()</span>

<span class="n">println</span><span class="o">(</span><span class="s">&quot;Loss of each step in training process&quot;</span><span class="o">)</span>
<span class="n">loss</span><span class="o">.</span><span class="n">foreach</span><span class="o">(</span><span class="n">println</span><span class="o">)</span>
<span class="n">println</span><span class="o">(</span><span class="s">s&quot;Area under ROC = </span><span class="si">$auROC</span><span class="s">&quot;</span><span class="o">)</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / scala / org / apache / spark / examples / mllib / LBFGSExample.scala”中找到完整的示例代码。</small></div>
  </div>

<div data-lang="java">
    <p>请参阅<a href="api/java/org/apache/spark/mllib/optimization/LBFGS.html"><code>LBFGS</code> Java文档</a>和<a href="api/java/org/apache/spark/mllib/optimization/SquaredL2Updater.html"><code>SquaredL2Updater</code></a>有关该API的详细信息的<a href="api/java/org/apache/spark/mllib/optimization/SquaredL2Updater.html">Java文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">java.util.Arrays</span><span class="o">;</span>

<span class="kn">import</span> <span class="nn">scala.Tuple2</span><span class="o">;</span>

<span class="kn">import</span> <span class="nn">org.apache.spark.api.java.*</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.mllib.classification.LogisticRegressionModel</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.mllib.evaluation.BinaryClassificationMetrics</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.mllib.linalg.Vector</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.mllib.linalg.Vectors</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.mllib.optimization.*</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.mllib.regression.LabeledPoint</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.mllib.util.MLUtils</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.SparkConf</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.SparkContext</span><span class="o">;</span>

<span class="n">String</span> <span class="n">path</span> <span class="o">=</span> <span class="s">&quot;data/mllib/sample_libsvm_data.txt&quot;</span><span class="o">;</span>
<span class="n">JavaRDD</span><span class="o">&lt;</span><span class="n">LabeledPoint</span><span class="o">&gt;</span> <span class="n">data</span> <span class="o">=</span> <span class="n">MLUtils</span><span class="o">.</span><span class="na">loadLibSVMFile</span><span class="o">(</span><span class="n">sc</span><span class="o">,</span> <span class="n">path</span><span class="o">).</span><span class="na">toJavaRDD</span><span class="o">();</span>
<span class="kt">int</span> <span class="n">numFeatures</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="na">take</span><span class="o">(</span><span class="mi">1</span><span class="o">).</span><span class="na">get</span><span class="o">(</span><span class="mi">0</span><span class="o">).</span><span class="na">features</span><span class="o">().</span><span class="na">size</span><span class="o">();</span>

<span class="c1">// Split initial RDD into two... [60% training data, 40% testing data].</span>
<span class="n">JavaRDD</span><span class="o">&lt;</span><span class="n">LabeledPoint</span><span class="o">&gt;</span> <span class="n">trainingInit</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="na">sample</span><span class="o">(</span><span class="kc">false</span><span class="o">,</span> <span class="mf">0.6</span><span class="o">,</span> <span class="mi">11L</span><span class="o">);</span>
<span class="n">JavaRDD</span><span class="o">&lt;</span><span class="n">LabeledPoint</span><span class="o">&gt;</span> <span class="n">test</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="na">subtract</span><span class="o">(</span><span class="n">trainingInit</span><span class="o">);</span>

<span class="c1">// Append 1 into the training data as intercept.</span>
<span class="n">JavaPairRDD</span><span class="o">&lt;</span><span class="n">Object</span><span class="o">,</span> <span class="n">Vector</span><span class="o">&gt;</span> <span class="n">training</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="na">mapToPair</span><span class="o">(</span><span class="n">p</span> <span class="o">-&gt;</span>
  <span class="k">new</span> <span class="n">Tuple2</span><span class="o">&lt;&gt;(</span><span class="n">p</span><span class="o">.</span><span class="na">label</span><span class="o">(),</span> <span class="n">MLUtils</span><span class="o">.</span><span class="na">appendBias</span><span class="o">(</span><span class="n">p</span><span class="o">.</span><span class="na">features</span><span class="o">())));</span>
<span class="n">training</span><span class="o">.</span><span class="na">cache</span><span class="o">();</span>

<span class="c1">// Run training algorithm to build the model.</span>
<span class="kt">int</span> <span class="n">numCorrections</span> <span class="o">=</span> <span class="mi">10</span><span class="o">;</span>
<span class="kt">double</span> <span class="n">convergenceTol</span> <span class="o">=</span> <span class="mf">1e-4</span><span class="o">;</span>
<span class="kt">int</span> <span class="n">maxNumIterations</span> <span class="o">=</span> <span class="mi">20</span><span class="o">;</span>
<span class="kt">double</span> <span class="n">regParam</span> <span class="o">=</span> <span class="mf">0.1</span><span class="o">;</span>
<span class="n">Vector</span> <span class="n">initialWeightsWithIntercept</span> <span class="o">=</span> <span class="n">Vectors</span><span class="o">.</span><span class="na">dense</span><span class="o">(</span><span class="k">new</span> <span class="kt">double</span><span class="o">[</span><span class="n">numFeatures</span> <span class="o">+</span> <span class="mi">1</span><span class="o">]);</span>

<span class="n">Tuple2</span><span class="o">&lt;</span><span class="n">Vector</span><span class="o">,</span> <span class="kt">double</span><span class="o">[]&gt;</span> <span class="n">result</span> <span class="o">=</span> <span class="n">LBFGS</span><span class="o">.</span><span class="na">runLBFGS</span><span class="o">(</span>
  <span class="n">training</span><span class="o">.</span><span class="na">rdd</span><span class="o">(),</span>
  <span class="k">new</span> <span class="n">LogisticGradient</span><span class="o">(),</span>
  <span class="k">new</span> <span class="n">SquaredL2Updater</span><span class="o">(),</span>
  <span class="n">numCorrections</span><span class="o">,</span>
  <span class="n">convergenceTol</span><span class="o">,</span>
  <span class="n">maxNumIterations</span><span class="o">,</span>
  <span class="n">regParam</span><span class="o">,</span>
  <span class="n">initialWeightsWithIntercept</span><span class="o">);</span>
<span class="n">Vector</span> <span class="n">weightsWithIntercept</span> <span class="o">=</span> <span class="n">result</span><span class="o">.</span><span class="na">_1</span><span class="o">();</span>
<span class="kt">double</span><span class="o">[]</span> <span class="n">loss</span> <span class="o">=</span> <span class="n">result</span><span class="o">.</span><span class="na">_2</span><span class="o">();</span>

<span class="n">LogisticRegressionModel</span> <span class="n">model</span> <span class="o">=</span> <span class="k">new</span> <span class="n">LogisticRegressionModel</span><span class="o">(</span>
  <span class="n">Vectors</span><span class="o">.</span><span class="na">dense</span><span class="o">(</span><span class="n">Arrays</span><span class="o">.</span><span class="na">copyOf</span><span class="o">(</span><span class="n">weightsWithIntercept</span><span class="o">.</span><span class="na">toArray</span><span class="o">(),</span> <span class="n">weightsWithIntercept</span><span class="o">.</span><span class="na">size</span><span class="o">()</span> <span class="o">-</span> <span class="mi">1</span><span class="o">)),</span>
  <span class="o">(</span><span class="n">weightsWithIntercept</span><span class="o">.</span><span class="na">toArray</span><span class="o">())[</span><span class="n">weightsWithIntercept</span><span class="o">.</span><span class="na">size</span><span class="o">()</span> <span class="o">-</span> <span class="mi">1</span><span class="o">]);</span>

<span class="c1">// Clear the default threshold.</span>
<span class="n">model</span><span class="o">.</span><span class="na">clearThreshold</span><span class="o">();</span>

<span class="c1">// Compute raw scores on the test set.</span>
<span class="n">JavaPairRDD</span><span class="o">&lt;</span><span class="n">Object</span><span class="o">,</span> <span class="n">Object</span><span class="o">&gt;</span> <span class="n">scoreAndLabels</span> <span class="o">=</span> <span class="n">test</span><span class="o">.</span><span class="na">mapToPair</span><span class="o">(</span><span class="n">p</span> <span class="o">-&gt;</span>
  <span class="k">new</span> <span class="n">Tuple2</span><span class="o">&lt;&gt;(</span><span class="n">model</span><span class="o">.</span><span class="na">predict</span><span class="o">(</span><span class="n">p</span><span class="o">.</span><span class="na">features</span><span class="o">()),</span> <span class="n">p</span><span class="o">.</span><span class="na">label</span><span class="o">()));</span>

<span class="c1">// Get evaluation metrics.</span>
<span class="n">BinaryClassificationMetrics</span> <span class="n">metrics</span> <span class="o">=</span>
  <span class="k">new</span> <span class="n">BinaryClassificationMetrics</span><span class="o">(</span><span class="n">scoreAndLabels</span><span class="o">.</span><span class="na">rdd</span><span class="o">());</span>
<span class="kt">double</span> <span class="n">auROC</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="na">areaUnderROC</span><span class="o">();</span>

<span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">&quot;Loss of each step in training process&quot;</span><span class="o">);</span>
<span class="k">for</span> <span class="o">(</span><span class="kt">double</span> <span class="n">l</span> <span class="o">:</span> <span class="n">loss</span><span class="o">)</span> <span class="o">{</span>
  <span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="n">l</span><span class="o">);</span>
<span class="o">}</span>
<span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">&quot;Area under ROC = &quot;</span> <span class="o">+</span> <span class="n">auROC</span><span class="o">);</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / java / org / apache / spark / examples / mllib / JavaLBFGSExample.java”中找到完整的示例代码。</small></div>
  </div>
</div>

<h2 id="developers-notes">开发人员说明</h2>

<p>由于Hessian近似于先前的梯度求值，因此在优化过程中无法更改目标函数。结果，仅使用miniBatch不能随机地运行L-BFGS。因此，除非我们有更好的了解，否则我们不会提供此服务。</p>

<p><code>Updater</code>是最初为体面设计的一类，它计算实际的梯度下降步长。但是，通过忽略仅适用于梯度体面的逻辑部分（例如自适应步长素材），我们能够针对L-BFGS进行正则化的目标函数的梯度和损失。我们将其重构为正则化器，以替换更新器，以将正则化和后续步骤更新之间的逻辑分开。</p>


                </div>
            
             <!-- /container -->
        </div>

        <script src="js/vendor/jquery-1.12.4.min.js"></script>
        <script src="js/vendor/bootstrap.min.js"></script>
        <script src="js/vendor/anchor.min.js"></script>
        <script src="js/main.js"></script>

        <!-- MathJax Section -->
        <script type="text/x-mathjax-config">
            MathJax.Hub.Config({
                TeX: { equationNumbers: { autoNumber: "AMS" } }
            });
        </script>
        <script>
            // Note that we load MathJax this way to work with local file (file://), HTTP and HTTPS.
            // We could use "//cdn.mathjax...", but that won't support "file://".
            (function(d, script) {
                script = d.createElement('script');
                script.type = 'text/javascript';
                script.async = true;
                script.onload = function(){
                    MathJax.Hub.Config({
                        tex2jax: {
                            inlineMath: [ ["$", "$"], ["\\\\(","\\\\)"] ],
                            displayMath: [ ["$$","$$"], ["\\[", "\\]"] ],
                            processEscapes: true,
                            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre']
                        }
                    });
                };
                script.src = ('https:' == document.location.protocol ? 'https://' : 'http://') +
                    'cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js' +
                    '?config=TeX-AMS-MML_HTMLorMML';
                d.getElementsByTagName('head')[0].appendChild(script);
            }(document));
        </script>
    

</body></html>