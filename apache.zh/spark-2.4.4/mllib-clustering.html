<html class="no-js" ><!--<![endif]--><head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
        <title>群集-基于RDD的API-Spark 2.4.4文档</title>
        

        

        <link rel="stylesheet" href="css/bootstrap.min.css">
        <style>
            body {
                padding-top: 60px;
                padding-bottom: 40px;
            }
        </style>
        <meta name="viewport" content="width=device-width">
        <link rel="stylesheet" href="css/bootstrap-responsive.min.css">
        <link rel="stylesheet" href="css/main.css">

        <script src="js/vendor/modernizr-2.6.1-respond-1.1.0.min.js"></script>

        <link rel="stylesheet" href="css/pygments-default.css">

        
        <!-- Google analytics script -->
        <script type="text/javascript">
          var _gaq = _gaq || [];
          _gaq.push(['_setAccount', 'UA-32518208-2']);
          _gaq.push(['_trackPageview']);

          (function() {
            var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
            ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
            var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
          })();
        </script>
        

    </head>
    <body >
        <!--[if lt IE 7]>
            <p class="chromeframe">You are using an outdated browser. <a href="https://browsehappy.com/">Upgrade your browser today</a> or <a href="http://www.google.com/chromeframe/?redirect=true">install Google Chrome Frame</a> to better experience this site.</p>
        <![endif]-->

        <!-- This code is taken from http://twitter.github.com/bootstrap/examples/hero.html -->

        <div class="navbar navbar-fixed-top" id="topbar">
            <div class="navbar-inner">
                <div class="container">
                    <div class="brand"><a href="index.html"><img src="img/spark-logo-hd.png" style="height:50px"></a> <span class="version">2.4.4</span>
                    </div>
                    <ul class="nav">
                        <!--TODO(andyk): Add class="active" attribute to li some how.-->
                        <li><a href="index.html">总览</a></li>

                        <li class="dropdown">
                            <a href="#" class="dropdown-toggle" data-toggle="dropdown">编程指南<b class="caret"></b></a>
                            <ul class="dropdown-menu">
                                <li><a href="quick-start.html">快速开始</a></li>
                                <li><a href="rdd-programming-guide.html">RDD，累加器，广播变量</a></li>
                                <li><a href="sql-programming-guide.html">SQL，数据框和数据集</a></li>
                                <li><a href="structured-streaming-programming-guide.html">结构化流</a></li>
                                <li><a href="streaming-programming-guide.html">火花流（DStreams）</a></li>
                                <li><a href="ml-guide.html">MLlib（机器学习）</a></li>
                                <li><a href="graphx-programming-guide.html">GraphX（图形处理）</a></li>
                                <li><a href="sparkr.html">SparkR（Spark上的R）</a></li>
                            </ul>
                        </li>

                        <li class="dropdown">
                            <a href="#" class="dropdown-toggle" data-toggle="dropdown">API文件<b class="caret"></b></a>
                            <ul class="dropdown-menu">
                                <li><a href="api/scala/index.html#org.apache.spark.package">斯卡拉</a></li>
                                <li><a href="api/java/index.html">爪哇</a></li>
                                <li><a href="api/python/index.html">蟒蛇</a></li>
                                <li><a href="api/R/index.html">[R</a></li>
                                <li><a href="api/sql/index.html">SQL，内置函数</a></li>
                            </ul>
                        </li>

                        <li class="dropdown">
                            <a href="#" class="dropdown-toggle" data-toggle="dropdown">部署中<b class="caret"></b></a>
                            <ul class="dropdown-menu">
                                <li><a href="cluster-overview.html">总览</a></li>
                                <li><a href="submitting-applications.html">提交申请</a></li>
                                <li class="divider"></li>
                                <li><a href="spark-standalone.html">Spark独立</a></li>
                                <li><a href="running-on-mesos.html">梅索斯</a></li>
                                <li><a href="running-on-yarn.html">纱</a></li>
                                <li><a href="running-on-kubernetes.html">Kubernetes</a></li>
                            </ul>
                        </li>

                        <li class="dropdown">
                            <a href="api.html" class="dropdown-toggle" data-toggle="dropdown">更多<b class="caret"></b></a>
                            <ul class="dropdown-menu">
                                <li><a href="configuration.html">组态</a></li>
                                <li><a href="monitoring.html">监控方式</a></li>
                                <li><a href="tuning.html">调音指南</a></li>
                                <li><a href="job-scheduling.html">作业调度</a></li>
                                <li><a href="security.html">安全</a></li>
                                <li><a href="hardware-provisioning.html">硬件配置</a></li>
                                <li class="divider"></li>
                                <li><a href="building-spark.html">建筑火花</a></li>
                                <li><a href="https://spark.apache.org/contributing.html">为Spark贡献</a></li>
                                <li><a href="https://spark.apache.org/third-party-projects.html">第三方项目</a></li>
                            </ul>
                        </li>
                    </ul>
                    <!--<p class="navbar-text pull-right"><span class="version-text">v2.4.4</span></p>-->
                </div>
            </div>
        </div>

        <div class="container-wrapper">

            
                
                    <div class="left-menu-wrapper">
    <div class="left-menu">
        <h3><a href="ml-guide.html">MLlib：主要指南</a></h3>
        
<ul>

    <li>
        <a href="ml-statistics.html">基本统计</a>
    </li>
    
    

    <li>
        <a href="ml-datasource">数据源</a>
    </li>
    
    

    <li>
        <a href="ml-pipeline.html">流水线</a>
    </li>
    
    

    <li>
        <a href="ml-features.html">提取，转换和选择特征</a>
    </li>
    
    

    <li>
        <a href="ml-classification-regression.html">分类与回归</a>
    </li>
    
    

    <li>
        <a href="ml-clustering.html">聚类</a>
    </li>
    
    

    <li>
        <a href="ml-collaborative-filtering.html">协同过滤</a>
    </li>
    
    

    <li>
        <a href="ml-frequent-pattern-mining.html">频繁模式挖掘</a>
    </li>
    
    

    <li>
        <a href="ml-tuning.html">模型选择和调整</a>
    </li>
    
    

    <li>
        <a href="ml-advanced.html">进阶主题</a>
    </li>
    
    

</ul>

        <h3><a href="mllib-guide.html">MLlib：基于RDD的API指南</a></h3>
        
<ul>

    <li>
        <a href="mllib-data-types.html">资料类型</a>
    </li>
    
    

    <li>
        <a href="mllib-statistics.html">基本统计</a>
    </li>
    
    

    <li>
        <a href="mllib-classification-regression.html">分类与回归</a>
    </li>
    
    

    <li>
        <a href="mllib-collaborative-filtering.html">协同过滤</a>
    </li>
    
    

    <li>
        <a href="mllib-clustering.html">
            
                <b>聚类</b>
            
        </a>
    </li>
    
    
        
<ul>

    <li>
        <a href="mllib-clustering.html#k-means">k均值</a>
    </li>
    
    

    <li>
        <a href="mllib-clustering.html#gaussian-mixture">高斯混合</a>
    </li>
    
    

    <li>
        <a href="mllib-clustering.html#power-iteration-clustering-pic">功率迭代聚类（PIC）</a>
    </li>
    
    

    <li>
        <a href="mllib-clustering.html#latent-dirichlet-allocation-lda">潜在狄利克雷分配（LDA）</a>
    </li>
    
    

    <li>
        <a href="mllib-clustering.html#streaming-k-means">流式均值</a>
    </li>
    
    

</ul>

    

    <li>
        <a href="mllib-dimensionality-reduction.html">降维</a>
    </li>
    
    

    <li>
        <a href="mllib-feature-extraction.html">特征提取和转换</a>
    </li>
    
    

    <li>
        <a href="mllib-frequent-pattern-mining.html">频繁模式挖掘</a>
    </li>
    
    

    <li>
        <a href="mllib-evaluation-metrics.html">评估指标</a>
    </li>
    
    

    <li>
        <a href="mllib-pmml-model-export.html">PMML模型导出</a>
    </li>
    
    

    <li>
        <a href="mllib-optimization.html">优化（开发人员）</a>
    </li>
    
    

</ul>

    </div>
</div>
                
                <input id="nav-trigger" class="nav-trigger" type="checkbox" checked>
                <label for="nav-trigger"></label>
                <div class="content-with-sidebar" id="content">
                    
                        <h1 class="title">群集-基于RDD的API</h1>
                    

                    <p><a href="https://en.wikipedia.org/wiki/Cluster_analysis">聚类</a>是一个无监督的学习问题，因此我们旨在基于某种相似性概念将实体的子集彼此分组。聚类通常用于探索性分析和/或作为分层<a href="https://en.wikipedia.org/wiki/Supervised_learning">监督学习</a>管道的组成部分（在该<a href="https://en.wikipedia.org/wiki/Supervised_learning">学习</a>管道中，针对每个聚类训练不同的分类器或回归模型）。</p>

<p>的<code>spark.mllib</code>程序包支持以下模型：</p>

<ul id="markdown-toc">
  <li><a href="#k-means" id="markdown-toc-k-means">K均值</a></li>
  <li><a href="#gaussian-mixture" id="markdown-toc-gaussian-mixture">高斯混合</a></li>
  <li><a href="#power-iteration-clustering-pic" id="markdown-toc-power-iteration-clustering-pic">功率迭代聚类（PIC）</a></li>
  <li><a href="#latent-dirichlet-allocation-lda" id="markdown-toc-latent-dirichlet-allocation-lda">潜在狄利克雷分配（LDA）</a></li>
  <li><a href="#bisecting-k-means" id="markdown-toc-bisecting-k-means">均分k均值</a></li>
  <li><a href="#streaming-k-means" id="markdown-toc-streaming-k-means">流式均值</a></li>
</ul>

<h2 id="k-means">K均值</h2>

<p><a href="http://en.wikipedia.org/wiki/K-means_clustering">K均值</a>是最常用的聚类算法之一，它将数据点聚集成预定数量的聚类。的<code>spark.mllib</code>实现包括称为<a href="http://theory.stanford.edu/~sergei/papers/vldb12-kmpar.pdf">kmeans ||</a>的<a href="http://en.wikipedia.org/wiki/K-means%2B%2B">k-means ++</a>方法的并行变体。 。在执行<code>spark.mllib</code>具有以下参数：</p>

<ul>
  <li><em>k</em>是所需群集的数量。请注意，有可能返回少于k个聚类，例如，如果要聚类的独特点少于k个。</li>
  <li><em>maxIterations</em>是要运行的最大迭代数。</li>
  <li><em>initializeMode</em>指定随机初始化或通过k-means ||初始化。</li>
  <li><em>运行</em>此PARAM从此星火2.0.0没有影响。</li>
  <li><em>initializeSteps</em>确定k均值的步数||算法。</li>
  <li><em>epsilon</em>确定了我们认为k均值收敛的距离阈值。</li>
  <li><em>initialModel</em>是用于初始化的一组可选的群集中心。如果提供此参数，则仅执行一次运行。</li>
</ul>

<p><strong>例子</strong></p>

<div class="codetabs">
<div data-lang="scala">
    <p>可以在以下代码段中执行以下代码段<code>spark-shell</code> 。</p>

    <p>在以下示例中，加载和解析数据后，我们使用<a href="api/scala/index.html#org.apache.spark.mllib.clustering.KMeans"><code>KMeans</code></a>对象将数据分为两个群集。所需聚类的数量传递给算法。然后，我们计算平方误差的集合和内（WSSSE）。您可以通过增加<em>k</em>来减少此错误度量。实际上，最优<em>k</em>通常是WSSSE图中存在“肘”的那个。</p>

    <p>请参阅<a href="api/scala/index.html#org.apache.spark.mllib.clustering.KMeans"><code>KMeans</code> Scala文档</a>和<a href="api/scala/index.html#org.apache.spark.mllib.clustering.KMeansModel"><code>KMeansModel</code></a>有关API的详细信息，请参见<a href="api/scala/index.html#org.apache.spark.mllib.clustering.KMeansModel">Scala文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">org.apache.spark.mllib.clustering.</span><span class="o">{</span><span class="nc">KMeans</span><span class="o">,</span> <span class="nc">KMeansModel</span><span class="o">}</span>
<span class="k">import</span> <span class="nn">org.apache.spark.mllib.linalg.Vectors</span>

<span class="c1">// Load and parse the data</span>
<span class="k">val</span> <span class="n">data</span> <span class="k">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">textFile</span><span class="o">(</span><span class="s">&quot;data/mllib/kmeans_data.txt&quot;</span><span class="o">)</span>
<span class="k">val</span> <span class="n">parsedData</span> <span class="k">=</span> <span class="n">data</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="n">s</span> <span class="k">=&gt;</span> <span class="nc">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="o">(</span><span class="n">s</span><span class="o">.</span><span class="n">split</span><span class="o">(</span><span class="sc">&#39; &#39;</span><span class="o">).</span><span class="n">map</span><span class="o">(</span><span class="k">_</span><span class="o">.</span><span class="n">toDouble</span><span class="o">))).</span><span class="n">cache</span><span class="o">()</span>

<span class="c1">// Cluster the data into two classes using KMeans</span>
<span class="k">val</span> <span class="n">numClusters</span> <span class="k">=</span> <span class="mi">2</span>
<span class="k">val</span> <span class="n">numIterations</span> <span class="k">=</span> <span class="mi">20</span>
<span class="k">val</span> <span class="n">clusters</span> <span class="k">=</span> <span class="nc">KMeans</span><span class="o">.</span><span class="n">train</span><span class="o">(</span><span class="n">parsedData</span><span class="o">,</span> <span class="n">numClusters</span><span class="o">,</span> <span class="n">numIterations</span><span class="o">)</span>

<span class="c1">// Evaluate clustering by computing Within Set Sum of Squared Errors</span>
<span class="k">val</span> <span class="nc">WSSSE</span> <span class="k">=</span> <span class="n">clusters</span><span class="o">.</span><span class="n">computeCost</span><span class="o">(</span><span class="n">parsedData</span><span class="o">)</span>
<span class="n">println</span><span class="o">(</span><span class="s">s&quot;Within Set Sum of Squared Errors = </span><span class="si">$WSSSE</span><span class="s">&quot;</span><span class="o">)</span>

<span class="c1">// Save and load model</span>
<span class="n">clusters</span><span class="o">.</span><span class="n">save</span><span class="o">(</span><span class="n">sc</span><span class="o">,</span> <span class="s">&quot;target/org/apache/spark/KMeansExample/KMeansModel&quot;</span><span class="o">)</span>
<span class="k">val</span> <span class="n">sameModel</span> <span class="k">=</span> <span class="nc">KMeansModel</span><span class="o">.</span><span class="n">load</span><span class="o">(</span><span class="n">sc</span><span class="o">,</span> <span class="s">&quot;target/org/apache/spark/KMeansExample/KMeansModel&quot;</span><span class="o">)</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / scala / org / apache / spark / examples / mllib / KMeansExample.scala”中找到完整的示例代码。</small></div>
  </div>

<div data-lang="java">
    <p>MLlib的所有方法都使用Java友好类型，因此您可以像在Scala中一样导入和调用它们。唯一需要注意的是，这些方法采用Scala RDD对象，而Spark Java API使用单独的<code>JavaRDD</code>类。您可以通过调用将Java RDD转换为Scala <code>.rdd()</code>在你的<code>JavaRDD</code>宾语。下面给出了一个与Scala中提供的示例等效的独立应用程序示例：</p>

    <p>请参阅<a href="api/java/org/apache/spark/mllib/clustering/KMeans.html"><code>KMeans</code> Java文档</a>和<a href="api/java/org/apache/spark/mllib/clustering/KMeansModel.html"><code>KMeansModel</code></a>有关该API的详细信息的<a href="api/java/org/apache/spark/mllib/clustering/KMeansModel.html">Java文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">org.apache.spark.api.java.JavaRDD</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.mllib.clustering.KMeans</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.mllib.clustering.KMeansModel</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.mllib.linalg.Vector</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.mllib.linalg.Vectors</span><span class="o">;</span>

<span class="c1">// Load and parse data</span>
<span class="n">String</span> <span class="n">path</span> <span class="o">=</span> <span class="s">&quot;data/mllib/kmeans_data.txt&quot;</span><span class="o">;</span>
<span class="n">JavaRDD</span><span class="o">&lt;</span><span class="n">String</span><span class="o">&gt;</span> <span class="n">data</span> <span class="o">=</span> <span class="n">jsc</span><span class="o">.</span><span class="na">textFile</span><span class="o">(</span><span class="n">path</span><span class="o">);</span>
<span class="n">JavaRDD</span><span class="o">&lt;</span><span class="n">Vector</span><span class="o">&gt;</span> <span class="n">parsedData</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="na">map</span><span class="o">(</span><span class="n">s</span> <span class="o">-&gt;</span> <span class="o">{</span>
  <span class="n">String</span><span class="o">[]</span> <span class="n">sarray</span> <span class="o">=</span> <span class="n">s</span><span class="o">.</span><span class="na">split</span><span class="o">(</span><span class="s">&quot; &quot;</span><span class="o">);</span>
  <span class="kt">double</span><span class="o">[]</span> <span class="n">values</span> <span class="o">=</span> <span class="k">new</span> <span class="kt">double</span><span class="o">[</span><span class="n">sarray</span><span class="o">.</span><span class="na">length</span><span class="o">];</span>
  <span class="k">for</span> <span class="o">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="o">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">sarray</span><span class="o">.</span><span class="na">length</span><span class="o">;</span> <span class="n">i</span><span class="o">++)</span> <span class="o">{</span>
    <span class="n">values</span><span class="o">[</span><span class="n">i</span><span class="o">]</span> <span class="o">=</span> <span class="n">Double</span><span class="o">.</span><span class="na">parseDouble</span><span class="o">(</span><span class="n">sarray</span><span class="o">[</span><span class="n">i</span><span class="o">]);</span>
  <span class="o">}</span>
  <span class="k">return</span> <span class="n">Vectors</span><span class="o">.</span><span class="na">dense</span><span class="o">(</span><span class="n">values</span><span class="o">);</span>
<span class="o">});</span>
<span class="n">parsedData</span><span class="o">.</span><span class="na">cache</span><span class="o">();</span>

<span class="c1">// Cluster the data into two classes using KMeans</span>
<span class="kt">int</span> <span class="n">numClusters</span> <span class="o">=</span> <span class="mi">2</span><span class="o">;</span>
<span class="kt">int</span> <span class="n">numIterations</span> <span class="o">=</span> <span class="mi">20</span><span class="o">;</span>
<span class="n">KMeansModel</span> <span class="n">clusters</span> <span class="o">=</span> <span class="n">KMeans</span><span class="o">.</span><span class="na">train</span><span class="o">(</span><span class="n">parsedData</span><span class="o">.</span><span class="na">rdd</span><span class="o">(),</span> <span class="n">numClusters</span><span class="o">,</span> <span class="n">numIterations</span><span class="o">);</span>

<span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">&quot;Cluster centers:&quot;</span><span class="o">);</span>
<span class="k">for</span> <span class="o">(</span><span class="n">Vector</span> <span class="n">center</span><span class="o">:</span> <span class="n">clusters</span><span class="o">.</span><span class="na">clusterCenters</span><span class="o">())</span> <span class="o">{</span>
  <span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">&quot; &quot;</span> <span class="o">+</span> <span class="n">center</span><span class="o">);</span>
<span class="o">}</span>
<span class="kt">double</span> <span class="n">cost</span> <span class="o">=</span> <span class="n">clusters</span><span class="o">.</span><span class="na">computeCost</span><span class="o">(</span><span class="n">parsedData</span><span class="o">.</span><span class="na">rdd</span><span class="o">());</span>
<span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">&quot;Cost: &quot;</span> <span class="o">+</span> <span class="n">cost</span><span class="o">);</span>

<span class="c1">// Evaluate clustering by computing Within Set Sum of Squared Errors</span>
<span class="kt">double</span> <span class="n">WSSSE</span> <span class="o">=</span> <span class="n">clusters</span><span class="o">.</span><span class="na">computeCost</span><span class="o">(</span><span class="n">parsedData</span><span class="o">.</span><span class="na">rdd</span><span class="o">());</span>
<span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">&quot;Within Set Sum of Squared Errors = &quot;</span> <span class="o">+</span> <span class="n">WSSSE</span><span class="o">);</span>

<span class="c1">// Save and load model</span>
<span class="n">clusters</span><span class="o">.</span><span class="na">save</span><span class="o">(</span><span class="n">jsc</span><span class="o">.</span><span class="na">sc</span><span class="o">(),</span> <span class="s">&quot;target/org/apache/spark/JavaKMeansExample/KMeansModel&quot;</span><span class="o">);</span>
<span class="n">KMeansModel</span> <span class="n">sameModel</span> <span class="o">=</span> <span class="n">KMeansModel</span><span class="o">.</span><span class="na">load</span><span class="o">(</span><span class="n">jsc</span><span class="o">.</span><span class="na">sc</span><span class="o">(),</span>
  <span class="s">&quot;target/org/apache/spark/JavaKMeansExample/KMeansModel&quot;</span><span class="o">);</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / java / org / apache / spark / examples / mllib / JavaKMeansExample.java”中找到完整的示例代码。</small></div>
  </div>

<div data-lang="python">
    <p>以下示例可以在PySpark shell中进行测试。</p>

    <p>在下面的示例中，在加载和解析数据之后，我们使用KMeans对象将数据分为两个集群。所需聚类的数量传递给算法。然后，我们计算平方误差的集合和内（WSSSE）。您可以通过增加<em>k</em>来减少此错误度量。实际上，最佳<em>k</em>通常是WSSSE图中有“肘”的那个。</p>

    <p>请参阅<a href="api/python/pyspark.mllib.html#pyspark.mllib.clustering.KMeans"><code>KMeans</code> Python文档</a>和<a href="api/python/pyspark.mllib.html#pyspark.mllib.clustering.KMeansModel"><code>KMeansModel</code></a>有关该API的更多详细信息的<a href="api/python/pyspark.mllib.html#pyspark.mllib.clustering.KMeansModel">Python文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">numpy</span> <span class="kn">import</span> <span class="n">array</span>
<span class="kn">from</span> <span class="nn">math</span> <span class="kn">import</span> <span class="n">sqrt</span>

<span class="kn">from</span> <span class="nn">pyspark.mllib.clustering</span> <span class="kn">import</span> <span class="n">KMeans</span><span class="p">,</span> <span class="n">KMeansModel</span>

<span class="c1"># Load and parse the data</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">textFile</span><span class="p">(</span><span class="s2">&quot;data/mllib/kmeans_data.txt&quot;</span><span class="p">)</span>
<span class="n">parsedData</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">line</span><span class="p">:</span> <span class="n">array</span><span class="p">([</span><span class="nb">float</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">line</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39; &#39;</span><span class="p">)]))</span>

<span class="c1"># Build the model (cluster the data)</span>
<span class="n">clusters</span> <span class="o">=</span> <span class="n">KMeans</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">parsedData</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">maxIterations</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">initializationMode</span><span class="o">=</span><span class="s2">&quot;random&quot;</span><span class="p">)</span>

<span class="c1"># Evaluate clustering by computing Within Set Sum of Squared Errors</span>
<span class="k">def</span> <span class="nf">error</span><span class="p">(</span><span class="n">point</span><span class="p">):</span>
    <span class="n">center</span> <span class="o">=</span> <span class="n">clusters</span><span class="o">.</span><span class="n">centers</span><span class="p">[</span><span class="n">clusters</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">point</span><span class="p">)]</span>
    <span class="k">return</span> <span class="n">sqrt</span><span class="p">(</span><span class="nb">sum</span><span class="p">([</span><span class="n">x</span><span class="o">**</span><span class="mi">2</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="p">(</span><span class="n">point</span> <span class="o">-</span> <span class="n">center</span><span class="p">)]))</span>

<span class="n">WSSSE</span> <span class="o">=</span> <span class="n">parsedData</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">point</span><span class="p">:</span> <span class="n">error</span><span class="p">(</span><span class="n">point</span><span class="p">))</span><span class="o">.</span><span class="n">reduce</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">x</span> <span class="o">+</span> <span class="n">y</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&quot;Within Set Sum of Squared Error = &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">WSSSE</span><span class="p">))</span>

<span class="c1"># Save and load model</span>
<span class="n">clusters</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">sc</span><span class="p">,</span> <span class="s2">&quot;target/org/apache/spark/PythonKMeansExample/KMeansModel&quot;</span><span class="p">)</span>
<span class="n">sameModel</span> <span class="o">=</span> <span class="n">KMeansModel</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">sc</span><span class="p">,</span> <span class="s2">&quot;target/org/apache/spark/PythonKMeansExample/KMeansModel&quot;</span><span class="p">)</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / python / mllib / k_means_example.py”中找到完整的示例代码。</small></div>
  </div>

</div>

<h2 id="gaussian-mixture">高斯混合</h2>

<p><a href="http://en.wikipedia.org/wiki/Mixture_model#Multivariate_Gaussian_mixture_model">高斯混合模型</a>表示一种复合分布，其中从<em>k个</em>高斯子分布之一中抽取点，每个子分布都有自己的概率。的<code>spark.mllib</code>在给定一组样本的情况下，实现使用<a href="http://en.wikipedia.org/wiki/Expectation%E2%80%93maximization_algorithm">期望最大化</a>算法来推导最大似然模型。该实现具有以下参数：</p>

<ul>
  <li><em>k</em>是所需群集的数量。</li>
  <li><em>ConvergenceTol</em>是对数似然率的最大变化，在此我们认为已实现收敛。</li>
  <li><em>maxIterations</em>是要达到收敛而要执行的最大迭代次数。</li>
  <li><em>initialModel</em>是启动EM算法的可选起点。如果省略此参数，将从数据中构造一个随机起点。</li>
</ul>

<p><strong>例子</strong></p>

<div class="codetabs">
<div data-lang="scala">
    <p>在下面的示例中，在加载和解析数据之后，我们使用<a href="api/scala/index.html#org.apache.spark.mllib.clustering.GaussianMixture">GaussianMixture</a>对象将数据分为两个集群。所需聚类的数量传递给算法。然后，我们输出混合模型的参数。</p>

    <p>请参阅<a href="api/scala/index.html#org.apache.spark.mllib.clustering.GaussianMixture"><code>GaussianMixture</code> Scala文档</a>和<a href="api/scala/index.html#org.apache.spark.mllib.clustering.GaussianMixtureModel"><code>GaussianMixtureModel</code></a>有关API的详细信息，请参见<a href="api/scala/index.html#org.apache.spark.mllib.clustering.GaussianMixtureModel">Scala文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">org.apache.spark.mllib.clustering.</span><span class="o">{</span><span class="nc">GaussianMixture</span><span class="o">,</span> <span class="nc">GaussianMixtureModel</span><span class="o">}</span>
<span class="k">import</span> <span class="nn">org.apache.spark.mllib.linalg.Vectors</span>

<span class="c1">// Load and parse the data</span>
<span class="k">val</span> <span class="n">data</span> <span class="k">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">textFile</span><span class="o">(</span><span class="s">&quot;data/mllib/gmm_data.txt&quot;</span><span class="o">)</span>
<span class="k">val</span> <span class="n">parsedData</span> <span class="k">=</span> <span class="n">data</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="n">s</span> <span class="k">=&gt;</span> <span class="nc">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="o">(</span><span class="n">s</span><span class="o">.</span><span class="n">trim</span><span class="o">.</span><span class="n">split</span><span class="o">(</span><span class="sc">&#39; &#39;</span><span class="o">).</span><span class="n">map</span><span class="o">(</span><span class="k">_</span><span class="o">.</span><span class="n">toDouble</span><span class="o">))).</span><span class="n">cache</span><span class="o">()</span>

<span class="c1">// Cluster the data into two classes using GaussianMixture</span>
<span class="k">val</span> <span class="n">gmm</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">GaussianMixture</span><span class="o">().</span><span class="n">setK</span><span class="o">(</span><span class="mi">2</span><span class="o">).</span><span class="n">run</span><span class="o">(</span><span class="n">parsedData</span><span class="o">)</span>

<span class="c1">// Save and load model</span>
<span class="n">gmm</span><span class="o">.</span><span class="n">save</span><span class="o">(</span><span class="n">sc</span><span class="o">,</span> <span class="s">&quot;target/org/apache/spark/GaussianMixtureExample/GaussianMixtureModel&quot;</span><span class="o">)</span>
<span class="k">val</span> <span class="n">sameModel</span> <span class="k">=</span> <span class="nc">GaussianMixtureModel</span><span class="o">.</span><span class="n">load</span><span class="o">(</span><span class="n">sc</span><span class="o">,</span>
  <span class="s">&quot;target/org/apache/spark/GaussianMixtureExample/GaussianMixtureModel&quot;</span><span class="o">)</span>

<span class="c1">// output parameters of max-likelihood model</span>
<span class="k">for</span> <span class="o">(</span><span class="n">i</span> <span class="k">&lt;-</span> <span class="mi">0</span> <span class="n">until</span> <span class="n">gmm</span><span class="o">.</span><span class="n">k</span><span class="o">)</span> <span class="o">{</span>
  <span class="n">println</span><span class="o">(</span><span class="s">&quot;weight=%f\nmu=%s\nsigma=\n%s\n&quot;</span> <span class="n">format</span>
    <span class="o">(</span><span class="n">gmm</span><span class="o">.</span><span class="n">weights</span><span class="o">(</span><span class="n">i</span><span class="o">),</span> <span class="n">gmm</span><span class="o">.</span><span class="n">gaussians</span><span class="o">(</span><span class="n">i</span><span class="o">).</span><span class="n">mu</span><span class="o">,</span> <span class="n">gmm</span><span class="o">.</span><span class="n">gaussians</span><span class="o">(</span><span class="n">i</span><span class="o">).</span><span class="n">sigma</span><span class="o">))</span>
<span class="o">}</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / scala / org / apache / spark / examples / mllib / GaussianMixtureExample.scala”中找到完整的示例代码。</small></div>
  </div>

<div data-lang="java">
    <p>MLlib的所有方法都使用Java友好类型，因此您可以像在Scala中一样导入和调用它们。唯一需要注意的是，这些方法采用Scala RDD对象，而Spark Java API使用单独的<code>JavaRDD</code>类。您可以通过调用将Java RDD转换为Scala <code>.rdd()</code>在你的<code>JavaRDD</code>宾语。下面给出了一个与Scala中提供的示例等效的独立应用程序示例：</p>

    <p>请参阅<a href="api/java/org/apache/spark/mllib/clustering/GaussianMixture.html"><code>GaussianMixture</code> Java文档</a>和<a href="api/java/org/apache/spark/mllib/clustering/GaussianMixtureModel.html"><code>GaussianMixtureModel</code></a>有关该API的详细信息的<a href="api/java/org/apache/spark/mllib/clustering/GaussianMixtureModel.html">Java文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">org.apache.spark.api.java.JavaRDD</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.mllib.clustering.GaussianMixture</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.mllib.clustering.GaussianMixtureModel</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.mllib.linalg.Vector</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.mllib.linalg.Vectors</span><span class="o">;</span>

<span class="c1">// Load and parse data</span>
<span class="n">String</span> <span class="n">path</span> <span class="o">=</span> <span class="s">&quot;data/mllib/gmm_data.txt&quot;</span><span class="o">;</span>
<span class="n">JavaRDD</span><span class="o">&lt;</span><span class="n">String</span><span class="o">&gt;</span> <span class="n">data</span> <span class="o">=</span> <span class="n">jsc</span><span class="o">.</span><span class="na">textFile</span><span class="o">(</span><span class="n">path</span><span class="o">);</span>
<span class="n">JavaRDD</span><span class="o">&lt;</span><span class="n">Vector</span><span class="o">&gt;</span> <span class="n">parsedData</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="na">map</span><span class="o">(</span><span class="n">s</span> <span class="o">-&gt;</span> <span class="o">{</span>
  <span class="n">String</span><span class="o">[]</span> <span class="n">sarray</span> <span class="o">=</span> <span class="n">s</span><span class="o">.</span><span class="na">trim</span><span class="o">().</span><span class="na">split</span><span class="o">(</span><span class="s">&quot; &quot;</span><span class="o">);</span>
  <span class="kt">double</span><span class="o">[]</span> <span class="n">values</span> <span class="o">=</span> <span class="k">new</span> <span class="kt">double</span><span class="o">[</span><span class="n">sarray</span><span class="o">.</span><span class="na">length</span><span class="o">];</span>
  <span class="k">for</span> <span class="o">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="o">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">sarray</span><span class="o">.</span><span class="na">length</span><span class="o">;</span> <span class="n">i</span><span class="o">++)</span> <span class="o">{</span>
    <span class="n">values</span><span class="o">[</span><span class="n">i</span><span class="o">]</span> <span class="o">=</span> <span class="n">Double</span><span class="o">.</span><span class="na">parseDouble</span><span class="o">(</span><span class="n">sarray</span><span class="o">[</span><span class="n">i</span><span class="o">]);</span>
  <span class="o">}</span>
  <span class="k">return</span> <span class="n">Vectors</span><span class="o">.</span><span class="na">dense</span><span class="o">(</span><span class="n">values</span><span class="o">);</span>
<span class="o">});</span>
<span class="n">parsedData</span><span class="o">.</span><span class="na">cache</span><span class="o">();</span>

<span class="c1">// Cluster the data into two classes using GaussianMixture</span>
<span class="n">GaussianMixtureModel</span> <span class="n">gmm</span> <span class="o">=</span> <span class="k">new</span> <span class="n">GaussianMixture</span><span class="o">().</span><span class="na">setK</span><span class="o">(</span><span class="mi">2</span><span class="o">).</span><span class="na">run</span><span class="o">(</span><span class="n">parsedData</span><span class="o">.</span><span class="na">rdd</span><span class="o">());</span>

<span class="c1">// Save and load GaussianMixtureModel</span>
<span class="n">gmm</span><span class="o">.</span><span class="na">save</span><span class="o">(</span><span class="n">jsc</span><span class="o">.</span><span class="na">sc</span><span class="o">(),</span> <span class="s">&quot;target/org/apache/spark/JavaGaussianMixtureExample/GaussianMixtureModel&quot;</span><span class="o">);</span>
<span class="n">GaussianMixtureModel</span> <span class="n">sameModel</span> <span class="o">=</span> <span class="n">GaussianMixtureModel</span><span class="o">.</span><span class="na">load</span><span class="o">(</span><span class="n">jsc</span><span class="o">.</span><span class="na">sc</span><span class="o">(),</span>
  <span class="s">&quot;target/org.apache.spark.JavaGaussianMixtureExample/GaussianMixtureModel&quot;</span><span class="o">);</span>

<span class="c1">// Output the parameters of the mixture model</span>
<span class="k">for</span> <span class="o">(</span><span class="kt">int</span> <span class="n">j</span> <span class="o">=</span> <span class="mi">0</span><span class="o">;</span> <span class="n">j</span> <span class="o">&lt;</span> <span class="n">gmm</span><span class="o">.</span><span class="na">k</span><span class="o">();</span> <span class="n">j</span><span class="o">++)</span> <span class="o">{</span>
  <span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">printf</span><span class="o">(</span><span class="s">&quot;weight=%f\nmu=%s\nsigma=\n%s\n&quot;</span><span class="o">,</span>
    <span class="n">gmm</span><span class="o">.</span><span class="na">weights</span><span class="o">()[</span><span class="n">j</span><span class="o">],</span> <span class="n">gmm</span><span class="o">.</span><span class="na">gaussians</span><span class="o">()[</span><span class="n">j</span><span class="o">].</span><span class="na">mu</span><span class="o">(),</span> <span class="n">gmm</span><span class="o">.</span><span class="na">gaussians</span><span class="o">()[</span><span class="n">j</span><span class="o">].</span><span class="na">sigma</span><span class="o">());</span>
<span class="o">}</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / java / org / apache / spark / examples / mllib / JavaGaussianMixtureExample.java”中找到完整的示例代码。</small></div>
  </div>

<div data-lang="python">
    <p>在下面的示例中，在加载和解析数据之后，我们使用<a href="api/python/pyspark.mllib.html#pyspark.mllib.clustering.GaussianMixture">GaussianMixture</a>对象将数据分为两个集群。所需聚类的数量传递给算法。然后，我们输出混合模型的参数。</p>

    <p>请参阅<a href="api/python/pyspark.mllib.html#pyspark.mllib.clustering.GaussianMixture"><code>GaussianMixture</code> Python文档</a>和<a href="api/python/pyspark.mllib.html#pyspark.mllib.clustering.GaussianMixtureModel"><code>GaussianMixtureModel</code></a>有关该API的更多详细信息的<a href="api/python/pyspark.mllib.html#pyspark.mllib.clustering.GaussianMixtureModel">Python文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">numpy</span> <span class="kn">import</span> <span class="n">array</span>

<span class="kn">from</span> <span class="nn">pyspark.mllib.clustering</span> <span class="kn">import</span> <span class="n">GaussianMixture</span><span class="p">,</span> <span class="n">GaussianMixtureModel</span>

<span class="c1"># Load and parse the data</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">textFile</span><span class="p">(</span><span class="s2">&quot;data/mllib/gmm_data.txt&quot;</span><span class="p">)</span>
<span class="n">parsedData</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">line</span><span class="p">:</span> <span class="n">array</span><span class="p">([</span><span class="nb">float</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">line</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39; &#39;</span><span class="p">)]))</span>

<span class="c1"># Build the model (cluster the data)</span>
<span class="n">gmm</span> <span class="o">=</span> <span class="n">GaussianMixture</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">parsedData</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

<span class="c1"># Save and load model</span>
<span class="n">gmm</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">sc</span><span class="p">,</span> <span class="s2">&quot;target/org/apache/spark/PythonGaussianMixtureExample/GaussianMixtureModel&quot;</span><span class="p">)</span>
<span class="n">sameModel</span> <span class="o">=</span> <span class="n">GaussianMixtureModel</span>\
    <span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">sc</span><span class="p">,</span> <span class="s2">&quot;target/org/apache/spark/PythonGaussianMixtureExample/GaussianMixtureModel&quot;</span><span class="p">)</span>

<span class="c1"># output parameters of model</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">):</span>
    <span class="k">print</span><span class="p">(</span><span class="s2">&quot;weight = &quot;</span><span class="p">,</span> <span class="n">gmm</span><span class="o">.</span><span class="n">weights</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="s2">&quot;mu = &quot;</span><span class="p">,</span> <span class="n">gmm</span><span class="o">.</span><span class="n">gaussians</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">mu</span><span class="p">,</span>
          <span class="s2">&quot;sigma = &quot;</span><span class="p">,</span> <span class="n">gmm</span><span class="o">.</span><span class="n">gaussians</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">sigma</span><span class="o">.</span><span class="n">toArray</span><span class="p">())</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / python / mllib / gaussian_mixture_example.py”中找到完整的示例代码。</small></div>
  </div>

</div>

<h2 id="power-iteration-clustering-pic">功率迭代聚类（PIC）</h2>

<p>幂迭代聚类（PIC）是一种可扩展且高效的算法，用于将图的顶点聚类成对的相似性作为边缘属性，如<a href="http://www.cs.cmu.edu/~frank/papers/icml2010-pic-final.pdf">Lin和Cohen的Power Iteration Clustering中所述</a> 。它通过<a href="http://en.wikipedia.org/wiki/Power_iteration">幂迭代计算</a>图的归一化亲和矩阵的伪特征向量，并将其用于对顶点进行聚类。
<code>spark.mllib</code>包括使用GraphX作为后端的PIC实现。需要一个<code>RDD</code>的<code>(srcId, dstId, similarity)</code>元组并输出带有聚类分配的模型。相似性必须是非负的。PIC假设相似性度量是对称的。一双<code>(srcId, dstId)</code>无论排序如何，输入数据中最多只能出现一次。如果输入中缺少一对，则将它们的相似性视为零。
<code>spark.mllib</code>的PIC实现采用以下（超）参数：</p>

<ul>
  <li><code>k</code> ：集群数</li>
  <li><code>maxIterations</code> ：最大功率迭代次数</li>
  <li><code>initializationMode</code> ：初始化模型。这可以是默认值“随机”（使用随机向量作为顶点属性），也可以是“度数”（使用标准化的和相似度）。</li>
</ul>

<p><strong>例子</strong></p>

<p>在下面的代码中，我们显示了代码片段，以演示如何在<code>spark.mllib</code> 。</p>

<div class="codetabs">
<div data-lang="scala">

    <p><a href="api/scala/index.html#org.apache.spark.mllib.clustering.PowerIterationClustering"><code>PowerIterationClustering</code></a>实现PIC算法。需要一个<code>RDD</code>的<code>(srcId: Long, dstId: Long, similarity: Double)</code>表示亲和度矩阵的元组。呼唤<code>PowerIterationClustering.run</code>返回一个<a href="api/scala/index.html#org.apache.spark.mllib.clustering.PowerIterationClusteringModel"><code>PowerIterationClusteringModel</code></a> ，其中包含计算出的聚类分配。</p>

    <p>请参阅<a href="api/scala/index.html#org.apache.spark.mllib.clustering.PowerIterationClustering"><code>PowerIterationClustering</code> Scala文档</a>和<a href="api/scala/index.html#org.apache.spark.mllib.clustering.PowerIterationClusteringModel"><code>PowerIterationClusteringModel</code></a>有关API的详细信息，请参见<a href="api/scala/index.html#org.apache.spark.mllib.clustering.PowerIterationClusteringModel">Scala文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">org.apache.spark.mllib.clustering.PowerIterationClustering</span>

<span class="k">val</span> <span class="n">circlesRdd</span> <span class="k">=</span> <span class="n">generateCirclesRdd</span><span class="o">(</span><span class="n">sc</span><span class="o">,</span> <span class="n">params</span><span class="o">.</span><span class="n">k</span><span class="o">,</span> <span class="n">params</span><span class="o">.</span><span class="n">numPoints</span><span class="o">)</span>
<span class="k">val</span> <span class="n">model</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">PowerIterationClustering</span><span class="o">()</span>
  <span class="o">.</span><span class="n">setK</span><span class="o">(</span><span class="n">params</span><span class="o">.</span><span class="n">k</span><span class="o">)</span>
  <span class="o">.</span><span class="n">setMaxIterations</span><span class="o">(</span><span class="n">params</span><span class="o">.</span><span class="n">maxIterations</span><span class="o">)</span>
  <span class="o">.</span><span class="n">setInitializationMode</span><span class="o">(</span><span class="s">&quot;degree&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">run</span><span class="o">(</span><span class="n">circlesRdd</span><span class="o">)</span>

<span class="k">val</span> <span class="n">clusters</span> <span class="k">=</span> <span class="n">model</span><span class="o">.</span><span class="n">assignments</span><span class="o">.</span><span class="n">collect</span><span class="o">().</span><span class="n">groupBy</span><span class="o">(</span><span class="k">_</span><span class="o">.</span><span class="n">cluster</span><span class="o">).</span><span class="n">mapValues</span><span class="o">(</span><span class="k">_</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="k">_</span><span class="o">.</span><span class="n">id</span><span class="o">))</span>
<span class="k">val</span> <span class="n">assignments</span> <span class="k">=</span> <span class="n">clusters</span><span class="o">.</span><span class="n">toList</span><span class="o">.</span><span class="n">sortBy</span> <span class="o">{</span> <span class="k">case</span> <span class="o">(</span><span class="n">k</span><span class="o">,</span> <span class="n">v</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="n">v</span><span class="o">.</span><span class="n">length</span> <span class="o">}</span>
<span class="k">val</span> <span class="n">assignmentsStr</span> <span class="k">=</span> <span class="n">assignments</span>
  <span class="o">.</span><span class="n">map</span> <span class="o">{</span> <span class="k">case</span> <span class="o">(</span><span class="n">k</span><span class="o">,</span> <span class="n">v</span><span class="o">)</span> <span class="k">=&gt;</span>
    <span class="s">s&quot;</span><span class="si">$k</span><span class="s"> -&gt; </span><span class="si">${</span><span class="n">v</span><span class="o">.</span><span class="n">sorted</span><span class="o">.</span><span class="n">mkString</span><span class="o">(</span><span class="s">&quot;[&quot;</span><span class="o">,</span> <span class="s">&quot;,&quot;</span><span class="o">,</span> <span class="s">&quot;]&quot;</span><span class="o">)</span><span class="si">}</span><span class="s">&quot;</span>
  <span class="o">}.</span><span class="n">mkString</span><span class="o">(</span><span class="s">&quot;, &quot;</span><span class="o">)</span>
<span class="k">val</span> <span class="n">sizesStr</span> <span class="k">=</span> <span class="n">assignments</span><span class="o">.</span><span class="n">map</span> <span class="o">{</span>
  <span class="k">_</span><span class="o">.</span><span class="n">_2</span><span class="o">.</span><span class="n">length</span>
<span class="o">}.</span><span class="n">sorted</span><span class="o">.</span><span class="n">mkString</span><span class="o">(</span><span class="s">&quot;(&quot;</span><span class="o">,</span> <span class="s">&quot;,&quot;</span><span class="o">,</span> <span class="s">&quot;)&quot;</span><span class="o">)</span>
<span class="n">println</span><span class="o">(</span><span class="s">s&quot;Cluster assignments: </span><span class="si">$assignmentsStr</span><span class="s">\ncluster sizes: </span><span class="si">$sizesStr</span><span class="s">&quot;</span><span class="o">)</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / scala / org / apache / spark / examples / mllib / PowerIterationClusteringExample.scala”中找到完整的示例代码。</small></div>
  </div>

<div data-lang="java">

    <p><a href="api/java/org/apache/spark/mllib/clustering/PowerIterationClustering.html"><code>PowerIterationClustering</code></a>实现PIC算法。需要一个<code>JavaRDD</code>的<code>(srcId: Long, dstId: Long, similarity: Double)</code>表示亲和度矩阵的元组。呼唤<code>PowerIterationClustering.run</code>返回一个<a href="api/java/org/apache/spark/mllib/clustering/PowerIterationClusteringModel.html"><code>PowerIterationClusteringModel</code></a>其中包含计算出的聚类分配。</p>

    <p>请参阅<a href="api/java/org/apache/spark/mllib/clustering/PowerIterationClustering.html"><code>PowerIterationClustering</code> Java文档</a>和<a href="api/java/org/apache/spark/mllib/clustering/PowerIterationClusteringModel.html"><code>PowerIterationClusteringModel</code></a>有关该API的详细信息的<a href="api/java/org/apache/spark/mllib/clustering/PowerIterationClusteringModel.html">Java文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">org.apache.spark.mllib.clustering.PowerIterationClustering</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.mllib.clustering.PowerIterationClusteringModel</span><span class="o">;</span>

<span class="n">JavaRDD</span><span class="o">&lt;</span><span class="n">Tuple3</span><span class="o">&lt;</span><span class="n">Long</span><span class="o">,</span> <span class="n">Long</span><span class="o">,</span> <span class="n">Double</span><span class="o">&gt;&gt;</span> <span class="n">similarities</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="na">parallelize</span><span class="o">(</span><span class="n">Arrays</span><span class="o">.</span><span class="na">asList</span><span class="o">(</span>
  <span class="k">new</span> <span class="n">Tuple3</span><span class="o">&lt;&gt;(</span><span class="mi">0</span><span class="n">L</span><span class="o">,</span> <span class="mi">1L</span><span class="o">,</span> <span class="mf">0.9</span><span class="o">),</span>
  <span class="k">new</span> <span class="n">Tuple3</span><span class="o">&lt;&gt;(</span><span class="mi">1L</span><span class="o">,</span> <span class="mi">2L</span><span class="o">,</span> <span class="mf">0.9</span><span class="o">),</span>
  <span class="k">new</span> <span class="n">Tuple3</span><span class="o">&lt;&gt;(</span><span class="mi">2L</span><span class="o">,</span> <span class="mi">3L</span><span class="o">,</span> <span class="mf">0.9</span><span class="o">),</span>
  <span class="k">new</span> <span class="n">Tuple3</span><span class="o">&lt;&gt;(</span><span class="mi">3L</span><span class="o">,</span> <span class="mi">4L</span><span class="o">,</span> <span class="mf">0.1</span><span class="o">),</span>
  <span class="k">new</span> <span class="n">Tuple3</span><span class="o">&lt;&gt;(</span><span class="mi">4L</span><span class="o">,</span> <span class="mi">5L</span><span class="o">,</span> <span class="mf">0.9</span><span class="o">)));</span>

<span class="n">PowerIterationClustering</span> <span class="n">pic</span> <span class="o">=</span> <span class="k">new</span> <span class="n">PowerIterationClustering</span><span class="o">()</span>
  <span class="o">.</span><span class="na">setK</span><span class="o">(</span><span class="mi">2</span><span class="o">)</span>
  <span class="o">.</span><span class="na">setMaxIterations</span><span class="o">(</span><span class="mi">10</span><span class="o">);</span>
<span class="n">PowerIterationClusteringModel</span> <span class="n">model</span> <span class="o">=</span> <span class="n">pic</span><span class="o">.</span><span class="na">run</span><span class="o">(</span><span class="n">similarities</span><span class="o">);</span>

<span class="k">for</span> <span class="o">(</span><span class="n">PowerIterationClustering</span><span class="o">.</span><span class="na">Assignment</span> <span class="n">a</span><span class="o">:</span> <span class="n">model</span><span class="o">.</span><span class="na">assignments</span><span class="o">().</span><span class="na">toJavaRDD</span><span class="o">().</span><span class="na">collect</span><span class="o">())</span> <span class="o">{</span>
  <span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="n">a</span><span class="o">.</span><span class="na">id</span><span class="o">()</span> <span class="o">+</span> <span class="s">&quot; -&gt; &quot;</span> <span class="o">+</span> <span class="n">a</span><span class="o">.</span><span class="na">cluster</span><span class="o">());</span>
<span class="o">}</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / java / org / apache / spark / examples / mllib / JavaPowerIterationClusteringExample.java”中找到完整的示例代码。</small></div>
  </div>

<div data-lang="python">

    <p><a href="api/python/pyspark.mllib.html#pyspark.mllib.clustering.PowerIterationClustering"><code>PowerIterationClustering</code></a>实现PIC算法。需要一个<code>RDD</code>的<code>(srcId: Long, dstId: Long, similarity: Double)</code>表示亲和度矩阵的元组。呼唤<code>PowerIterationClustering.run</code>返回一个<a href="api/python/pyspark.mllib.html#pyspark.mllib.clustering.PowerIterationClustering"><code>PowerIterationClusteringModel</code></a> ，其中包含计算出的聚类分配。</p>

    <p>请参阅<a href="api/python/pyspark.mllib.html#pyspark.mllib.clustering.PowerIterationClustering"><code>PowerIterationClustering</code> Python文档</a>和<a href="api/python/pyspark.mllib.html#pyspark.mllib.clustering.PowerIterationClusteringModel"><code>PowerIterationClusteringModel</code></a>有关该API的更多详细信息的<a href="api/python/pyspark.mllib.html#pyspark.mllib.clustering.PowerIterationClusteringModel">Python文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pyspark.mllib.clustering</span> <span class="kn">import</span> <span class="n">PowerIterationClustering</span><span class="p">,</span> <span class="n">PowerIterationClusteringModel</span>

<span class="c1"># Load and parse the data</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">textFile</span><span class="p">(</span><span class="s2">&quot;data/mllib/pic_data.txt&quot;</span><span class="p">)</span>
<span class="n">similarities</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">line</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">([</span><span class="nb">float</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">line</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39; &#39;</span><span class="p">)]))</span>

<span class="c1"># Cluster the data into two classes using PowerIterationClustering</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">PowerIterationClustering</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">similarities</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>

<span class="n">model</span><span class="o">.</span><span class="n">assignments</span><span class="p">()</span><span class="o">.</span><span class="n">foreach</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="k">print</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">id</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot; -&gt; &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">cluster</span><span class="p">)))</span>

<span class="c1"># Save and load model</span>
<span class="n">model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">sc</span><span class="p">,</span> <span class="s2">&quot;target/org/apache/spark/PythonPowerIterationClusteringExample/PICModel&quot;</span><span class="p">)</span>
<span class="n">sameModel</span> <span class="o">=</span> <span class="n">PowerIterationClusteringModel</span>\
    <span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">sc</span><span class="p">,</span> <span class="s2">&quot;target/org/apache/spark/PythonPowerIterationClusteringExample/PICModel&quot;</span><span class="p">)</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / python / mllib / power_iteration_clustering_example.py”中找到完整的示例代码。</small></div>
  </div>

</div>

<h2 id="latent-dirichlet-allocation-lda">潜在狄利克雷分配（LDA）</h2>

<p><a href="http://en.wikipedia.org/wiki/Latent_Dirichlet_allocation">潜在狄利克雷分配（LDA）</a>是一种主题模型，可以从文本文档集合中推断出主题。可以将LDA视为聚类算法，如下所示：</p>

<ul>
  <li>主题对应于聚类中心，文档对应于数据集中的示例（行）。</li>
  <li>主题和文档都存在于特征空间中，其中特征向量是字数（词袋）的向量。</li>
  <li>LDA不会使用传统的距离来估计聚类，而是使用基于文本文档生成方式的统计模型的功能。</li>
</ul>

<p>LDA通过以下方式支持不同的推理算法<code>setOptimizer</code>功能。
<code>EMLDAOptimizer</code>使用似然函数的<a href="http://en.wikipedia.org/wiki/Expectation%E2%80%93maximization_algorithm">期望最大化</a>学习聚类并产生综合结果，而<code>OnlineLDAOptimizer</code>使用迭代小批量采样进行<a href="https://www.cs.princeton.edu/~blei/papers/HoffmanBleiBach2010b.pdf">在线变分推理</a> ，并且通常对内存友好。</p>

<p>LDA接收文档集合作为单词计数和以下参数的向量（使用构建器模式设置）：</p>

<ul>
  <li><code>k</code> ：主题数（即群集中心）</li>
  <li><code>optimizer</code> ：用于学习LDA模型的优化程序<code>EMLDAOptimizer</code>要么<code>OnlineLDAOptimizer</code></li>
  <li><code>docConcentration</code> ：Dirichlet参数，用于优先于主题的文档分布。较大的值鼓励更平滑的推断分布。</li>
  <li><code>topicConcentration</code> ：Dirichlet参数，用于表示优先项在主题（词）上的分布。较大的值鼓励更平滑的推断分布。</li>
  <li><code>maxIterations</code> ：限制迭代次数。</li>
  <li><code>checkpointInterval</code> ：如果使用检查点（在Spark配置中设置），则此参数指定创建检查点的频率。如果<code>maxIterations</code>很大，使用检查点可以帮助减少磁盘上的随机文件大小并有助于故障恢复。</li>
</ul>

<p>所有的<code>spark.mllib</code>的LDA模型支持：</p>

<ul>
  <li><code>describeTopics</code> ：以最重要的术语和术语权重的数组形式返回主题</li>
  <li><code>topicsMatrix</code> ：返回一个<code>vocabSize</code>通过<code>k</code>每个列都是主题的矩阵</li>
</ul>

<p><em>注意</em> ：LDA仍处于积极开发中的实验功能。结果，某些功能仅在优化器生成的两个优化器/模型之一中可用。当前，可以将分布式模型转换为本地模型，但反之则不能。</p>

<p>以下讨论将分别描述每个优化器/模型对。</p>

<p><strong>期望最大化</strong></p>

<p>实施于<a href="api/scala/index.html#org.apache.spark.mllib.clustering.EMLDAOptimizer"><code>EMLDAOptimizer</code></a>和<a href="api/scala/index.html#org.apache.spark.mllib.clustering.DistributedLDAModel"><code>DistributedLDAModel</code></a> 。</p>

<p>对于提供给的参数<code>LDA</code> ：</p>

<ul>
  <li><code>docConcentration</code> ：仅支持对称先验，因此提供的所有值<code>k</code>维向量必须相同。所有值还必须为$> 1.0 $。提供<code>Vector(-1)</code>导致默认行为（统一<code>k</code>值$（50 / k）+ 1 $的维向量</li>
  <li><code>topicConcentration</code> ：仅支持对称先验。值必须为$> 1.0 $。提供<code>-1</code>导致默认值为$ 0.1 + 1 $。</li>
  <li><code>maxIterations</code> ：最大EM迭代次数。</li>
</ul>

<p><em>注意</em> ：进行足够的迭代很重要。在早期迭代中，EM通常没有用的主题，但是经过更多迭代后，这些主题会显着改善。根据您的数据集，通常至少合理使用20次甚至50-100次迭代。</p>

<p><code>EMLDAOptimizer</code>产生一个<code>DistributedLDAModel</code> ，它不仅存储推断出的主题，还存储训练语料库中每个文档的完整训练语料库和主题分布。一种<code>DistributedLDAModel</code>支持：</p>

<ul>
  <li><code>topTopicsPerDocument</code> ：训练语料库中每个文档的主要主题及其权重</li>
  <li><code>topDocumentsPerTopic</code> ：每个主题的重要文档以及相应主题在文档中的权重。</li>
  <li><code>logPrior</code> ：在给定超参数的情况下，估计主题和文档主题分布的对数概率<code>docConcentration</code>和<code>topicConcentration</code></li>
  <li><code>logLikelihood</code> ：根据推断的主题和文档主题的分布，记录训练语料库的可能性</li>
</ul>

<p><strong>在线变分贝叶斯</strong></p>

<p>实施于<a href="api/scala/org/apache/spark/mllib/clustering/OnlineLDAOptimizer.html"><code>OnlineLDAOptimizer</code></a>和<a href="api/scala/org/apache/spark/mllib/clustering/LocalLDAModel.html"><code>LocalLDAModel</code></a> 。</p>

<p>对于提供给的参数<code>LDA</code> ：</p>

<ul>
  <li><code>docConcentration</code> ：通过在每个参数中传递等于Dirichlet参数的值的向量，可以使用非对称先验<code>k</code>尺寸。值应为$> = 0 $。提供<code>Vector(-1)</code>导致默认行为（统一<code>k</code>值$（1.0 / k）$）的维向量</li>
  <li><code>topicConcentration</code> ：仅支持对称先验。值必须为$> = 0 $。提供<code>-1</code>结果默认为$（1.0 / k）$。</li>
  <li><code>maxIterations</code> ：要提交的迷你批的最大数量。</li>
</ul>

<p>此外， <code>OnlineLDAOptimizer</code>接受以下参数：</p>

<ul>
  <li><code>miniBatchFraction</code> ：语料库分数在每次迭代中采样和使用</li>
  <li><code>optimizeDocConcentration</code> ：如果设置为true，则执行超参数的最大似然估计<code>docConcentration</code> （又名<code>alpha</code> ）在每个小批量之后，并设置优化<code>docConcentration</code>在返回<code>LocalLDAModel</code></li>
  <li><code>tau0</code>和<code>kappa</code> ：用于学习率衰减，由$（\ tau_0 + iter）^ {-\ kappa} $计算得出，其中$ iter $是当前迭代次数。</li>
</ul>

<p><code>OnlineLDAOptimizer</code>产生一个<code>LocalLDAModel</code> ，仅存储推断出的主题。一种<code>LocalLDAModel</code>支持：</p>

<ul>
  <li><code>logLikelihood(documents)</code> ：计算提供的下限<code>documents</code>给定推断的主题。</li>
  <li><code>logPerplexity(documents)</code> ：计算所提供的困惑度的上限<code>documents</code>给定推断的主题。</li>
</ul>

<p><strong>例子</strong></p>

<p>在以下示例中，我们加载代表文档语料库的单词计数向量。然后，我们使用<a href="api/scala/index.html#org.apache.spark.mllib.clustering.LDA">LDA</a>从文档中推断出三个主题。所需聚类的数量传递给算法。然后，我们输出主题，表示为单词上的概率分布。</p>

<div class="codetabs">
<div data-lang="scala">
    <p>请参阅<a href="api/scala/index.html#org.apache.spark.mllib.clustering.LDA"><code>LDA</code> Scala文档</a>和<a href="api/scala/index.html#org.apache.spark.mllib.clustering.DistributedLDAModel"><code>DistributedLDAModel</code></a>有关API的详细信息，请参见<a href="api/scala/index.html#org.apache.spark.mllib.clustering.DistributedLDAModel">Scala文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">org.apache.spark.mllib.clustering.</span><span class="o">{</span><span class="nc">DistributedLDAModel</span><span class="o">,</span> <span class="nc">LDA</span><span class="o">}</span>
<span class="k">import</span> <span class="nn">org.apache.spark.mllib.linalg.Vectors</span>

<span class="c1">// Load and parse the data</span>
<span class="k">val</span> <span class="n">data</span> <span class="k">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">textFile</span><span class="o">(</span><span class="s">&quot;data/mllib/sample_lda_data.txt&quot;</span><span class="o">)</span>
<span class="k">val</span> <span class="n">parsedData</span> <span class="k">=</span> <span class="n">data</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="n">s</span> <span class="k">=&gt;</span> <span class="nc">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="o">(</span><span class="n">s</span><span class="o">.</span><span class="n">trim</span><span class="o">.</span><span class="n">split</span><span class="o">(</span><span class="sc">&#39; &#39;</span><span class="o">).</span><span class="n">map</span><span class="o">(</span><span class="k">_</span><span class="o">.</span><span class="n">toDouble</span><span class="o">)))</span>
<span class="c1">// Index documents with unique IDs</span>
<span class="k">val</span> <span class="n">corpus</span> <span class="k">=</span> <span class="n">parsedData</span><span class="o">.</span><span class="n">zipWithIndex</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="k">_</span><span class="o">.</span><span class="n">swap</span><span class="o">).</span><span class="n">cache</span><span class="o">()</span>

<span class="c1">// Cluster the documents into three topics using LDA</span>
<span class="k">val</span> <span class="n">ldaModel</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">LDA</span><span class="o">().</span><span class="n">setK</span><span class="o">(</span><span class="mi">3</span><span class="o">).</span><span class="n">run</span><span class="o">(</span><span class="n">corpus</span><span class="o">)</span>

<span class="c1">// Output topics. Each is a distribution over words (matching word count vectors)</span>
<span class="n">println</span><span class="o">(</span><span class="s">s&quot;Learned topics (as distributions over vocab of </span><span class="si">${</span><span class="n">ldaModel</span><span class="o">.</span><span class="n">vocabSize</span><span class="si">}</span><span class="s"> words):&quot;</span><span class="o">)</span>
<span class="k">val</span> <span class="n">topics</span> <span class="k">=</span> <span class="n">ldaModel</span><span class="o">.</span><span class="n">topicsMatrix</span>
<span class="k">for</span> <span class="o">(</span><span class="n">topic</span> <span class="k">&lt;-</span> <span class="nc">Range</span><span class="o">(</span><span class="mi">0</span><span class="o">,</span> <span class="mi">3</span><span class="o">))</span> <span class="o">{</span>
  <span class="n">print</span><span class="o">(</span><span class="s">s&quot;Topic </span><span class="si">$topic</span><span class="s"> :&quot;</span><span class="o">)</span>
  <span class="k">for</span> <span class="o">(</span><span class="n">word</span> <span class="k">&lt;-</span> <span class="nc">Range</span><span class="o">(</span><span class="mi">0</span><span class="o">,</span> <span class="n">ldaModel</span><span class="o">.</span><span class="n">vocabSize</span><span class="o">))</span> <span class="o">{</span>
    <span class="n">print</span><span class="o">(</span><span class="s">s&quot;</span><span class="si">${</span><span class="n">topics</span><span class="o">(</span><span class="n">word</span><span class="o">,</span> <span class="n">topic</span><span class="o">)</span><span class="si">}</span><span class="s">&quot;</span><span class="o">)</span>
  <span class="o">}</span>
  <span class="n">println</span><span class="o">()</span>
<span class="o">}</span>

<span class="c1">// Save and load model.</span>
<span class="n">ldaModel</span><span class="o">.</span><span class="n">save</span><span class="o">(</span><span class="n">sc</span><span class="o">,</span> <span class="s">&quot;target/org/apache/spark/LatentDirichletAllocationExample/LDAModel&quot;</span><span class="o">)</span>
<span class="k">val</span> <span class="n">sameModel</span> <span class="k">=</span> <span class="nc">DistributedLDAModel</span><span class="o">.</span><span class="n">load</span><span class="o">(</span><span class="n">sc</span><span class="o">,</span>
  <span class="s">&quot;target/org/apache/spark/LatentDirichletAllocationExample/LDAModel&quot;</span><span class="o">)</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / scala / org / apache / spark / examples / mllib / LatentDirichletAllocationExample.scala”中找到完整的示例代码。</small></div>
  </div>

<div data-lang="java">
    <p>请参阅<a href="api/java/org/apache/spark/mllib/clustering/LDA.html"><code>LDA</code> Java文档</a>和<a href="api/java/org/apache/spark/mllib/clustering/DistributedLDAModel.html"><code>DistributedLDAModel</code></a>有关该API的详细信息的<a href="api/java/org/apache/spark/mllib/clustering/DistributedLDAModel.html">Java文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">scala.Tuple2</span><span class="o">;</span>

<span class="kn">import</span> <span class="nn">org.apache.spark.api.java.JavaPairRDD</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.api.java.JavaRDD</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.mllib.clustering.DistributedLDAModel</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.mllib.clustering.LDA</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.mllib.clustering.LDAModel</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.mllib.linalg.Matrix</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.mllib.linalg.Vector</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.mllib.linalg.Vectors</span><span class="o">;</span>

<span class="c1">// Load and parse the data</span>
<span class="n">String</span> <span class="n">path</span> <span class="o">=</span> <span class="s">&quot;data/mllib/sample_lda_data.txt&quot;</span><span class="o">;</span>
<span class="n">JavaRDD</span><span class="o">&lt;</span><span class="n">String</span><span class="o">&gt;</span> <span class="n">data</span> <span class="o">=</span> <span class="n">jsc</span><span class="o">.</span><span class="na">textFile</span><span class="o">(</span><span class="n">path</span><span class="o">);</span>
<span class="n">JavaRDD</span><span class="o">&lt;</span><span class="n">Vector</span><span class="o">&gt;</span> <span class="n">parsedData</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="na">map</span><span class="o">(</span><span class="n">s</span> <span class="o">-&gt;</span> <span class="o">{</span>
  <span class="n">String</span><span class="o">[]</span> <span class="n">sarray</span> <span class="o">=</span> <span class="n">s</span><span class="o">.</span><span class="na">trim</span><span class="o">().</span><span class="na">split</span><span class="o">(</span><span class="s">&quot; &quot;</span><span class="o">);</span>
  <span class="kt">double</span><span class="o">[]</span> <span class="n">values</span> <span class="o">=</span> <span class="k">new</span> <span class="kt">double</span><span class="o">[</span><span class="n">sarray</span><span class="o">.</span><span class="na">length</span><span class="o">];</span>
  <span class="k">for</span> <span class="o">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="o">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">sarray</span><span class="o">.</span><span class="na">length</span><span class="o">;</span> <span class="n">i</span><span class="o">++)</span> <span class="o">{</span>
    <span class="n">values</span><span class="o">[</span><span class="n">i</span><span class="o">]</span> <span class="o">=</span> <span class="n">Double</span><span class="o">.</span><span class="na">parseDouble</span><span class="o">(</span><span class="n">sarray</span><span class="o">[</span><span class="n">i</span><span class="o">]);</span>
  <span class="o">}</span>
  <span class="k">return</span> <span class="n">Vectors</span><span class="o">.</span><span class="na">dense</span><span class="o">(</span><span class="n">values</span><span class="o">);</span>
<span class="o">});</span>
<span class="c1">// Index documents with unique IDs</span>
<span class="n">JavaPairRDD</span><span class="o">&lt;</span><span class="n">Long</span><span class="o">,</span> <span class="n">Vector</span><span class="o">&gt;</span> <span class="n">corpus</span> <span class="o">=</span>
  <span class="n">JavaPairRDD</span><span class="o">.</span><span class="na">fromJavaRDD</span><span class="o">(</span><span class="n">parsedData</span><span class="o">.</span><span class="na">zipWithIndex</span><span class="o">().</span><span class="na">map</span><span class="o">(</span><span class="n">Tuple2</span><span class="o">::</span><span class="n">swap</span><span class="o">));</span>
<span class="n">corpus</span><span class="o">.</span><span class="na">cache</span><span class="o">();</span>

<span class="c1">// Cluster the documents into three topics using LDA</span>
<span class="n">LDAModel</span> <span class="n">ldaModel</span> <span class="o">=</span> <span class="k">new</span> <span class="n">LDA</span><span class="o">().</span><span class="na">setK</span><span class="o">(</span><span class="mi">3</span><span class="o">).</span><span class="na">run</span><span class="o">(</span><span class="n">corpus</span><span class="o">);</span>

<span class="c1">// Output topics. Each is a distribution over words (matching word count vectors)</span>
<span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">&quot;Learned topics (as distributions over vocab of &quot;</span> <span class="o">+</span> <span class="n">ldaModel</span><span class="o">.</span><span class="na">vocabSize</span><span class="o">()</span>
  <span class="o">+</span> <span class="s">&quot; words):&quot;</span><span class="o">);</span>
<span class="n">Matrix</span> <span class="n">topics</span> <span class="o">=</span> <span class="n">ldaModel</span><span class="o">.</span><span class="na">topicsMatrix</span><span class="o">();</span>
<span class="k">for</span> <span class="o">(</span><span class="kt">int</span> <span class="n">topic</span> <span class="o">=</span> <span class="mi">0</span><span class="o">;</span> <span class="n">topic</span> <span class="o">&lt;</span> <span class="mi">3</span><span class="o">;</span> <span class="n">topic</span><span class="o">++)</span> <span class="o">{</span>
  <span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">print</span><span class="o">(</span><span class="s">&quot;Topic &quot;</span> <span class="o">+</span> <span class="n">topic</span> <span class="o">+</span> <span class="s">&quot;:&quot;</span><span class="o">);</span>
  <span class="k">for</span> <span class="o">(</span><span class="kt">int</span> <span class="n">word</span> <span class="o">=</span> <span class="mi">0</span><span class="o">;</span> <span class="n">word</span> <span class="o">&lt;</span> <span class="n">ldaModel</span><span class="o">.</span><span class="na">vocabSize</span><span class="o">();</span> <span class="n">word</span><span class="o">++)</span> <span class="o">{</span>
    <span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">print</span><span class="o">(</span><span class="s">&quot; &quot;</span> <span class="o">+</span> <span class="n">topics</span><span class="o">.</span><span class="na">apply</span><span class="o">(</span><span class="n">word</span><span class="o">,</span> <span class="n">topic</span><span class="o">));</span>
  <span class="o">}</span>
  <span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">();</span>
<span class="o">}</span>

<span class="n">ldaModel</span><span class="o">.</span><span class="na">save</span><span class="o">(</span><span class="n">jsc</span><span class="o">.</span><span class="na">sc</span><span class="o">(),</span>
  <span class="s">&quot;target/org/apache/spark/JavaLatentDirichletAllocationExample/LDAModel&quot;</span><span class="o">);</span>
<span class="n">DistributedLDAModel</span> <span class="n">sameModel</span> <span class="o">=</span> <span class="n">DistributedLDAModel</span><span class="o">.</span><span class="na">load</span><span class="o">(</span><span class="n">jsc</span><span class="o">.</span><span class="na">sc</span><span class="o">(),</span>
  <span class="s">&quot;target/org/apache/spark/JavaLatentDirichletAllocationExample/LDAModel&quot;</span><span class="o">);</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / java / org / apache / spark / examples / mllib / JavaLatentDirichletAllocationExample.java”中找到完整的示例代码。</small></div>
  </div>

<div data-lang="python">
    <p>请参阅<a href="api/python/pyspark.mllib.html#pyspark.mllib.clustering.LDA"><code>LDA</code> Python文档</a>和<a href="api/python/pyspark.mllib.html#pyspark.mllib.clustering.LDAModel"><code>LDAModel</code></a>有关该API的更多详细信息的<a href="api/python/pyspark.mllib.html#pyspark.mllib.clustering.LDAModel">Python文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pyspark.mllib.clustering</span> <span class="kn">import</span> <span class="n">LDA</span><span class="p">,</span> <span class="n">LDAModel</span>
<span class="kn">from</span> <span class="nn">pyspark.mllib.linalg</span> <span class="kn">import</span> <span class="n">Vectors</span>

<span class="c1"># Load and parse the data</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">textFile</span><span class="p">(</span><span class="s2">&quot;data/mllib/sample_lda_data.txt&quot;</span><span class="p">)</span>
<span class="n">parsedData</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">line</span><span class="p">:</span> <span class="n">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="p">([</span><span class="nb">float</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">line</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39; &#39;</span><span class="p">)]))</span>
<span class="c1"># Index documents with unique IDs</span>
<span class="n">corpus</span> <span class="o">=</span> <span class="n">parsedData</span><span class="o">.</span><span class="n">zipWithIndex</span><span class="p">()</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="p">[</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]])</span><span class="o">.</span><span class="n">cache</span><span class="p">()</span>

<span class="c1"># Cluster the documents into three topics using LDA</span>
<span class="n">ldaModel</span> <span class="o">=</span> <span class="n">LDA</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">corpus</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>

<span class="c1"># Output topics. Each is a distribution over words (matching word count vectors)</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&quot;Learned topics (as distributions over vocab of &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">ldaModel</span><span class="o">.</span><span class="n">vocabSize</span><span class="p">())</span>
      <span class="o">+</span> <span class="s2">&quot; words):&quot;</span><span class="p">)</span>
<span class="n">topics</span> <span class="o">=</span> <span class="n">ldaModel</span><span class="o">.</span><span class="n">topicsMatrix</span><span class="p">()</span>
<span class="k">for</span> <span class="n">topic</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">):</span>
    <span class="k">print</span><span class="p">(</span><span class="s2">&quot;Topic &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">topic</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;:&quot;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">ldaModel</span><span class="o">.</span><span class="n">vocabSize</span><span class="p">()):</span>
        <span class="k">print</span><span class="p">(</span><span class="s2">&quot; &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">topics</span><span class="p">[</span><span class="n">word</span><span class="p">][</span><span class="n">topic</span><span class="p">]))</span>

<span class="c1"># Save and load model</span>
<span class="n">ldaModel</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">sc</span><span class="p">,</span> <span class="s2">&quot;target/org/apache/spark/PythonLatentDirichletAllocationExample/LDAModel&quot;</span><span class="p">)</span>
<span class="n">sameModel</span> <span class="o">=</span> <span class="n">LDAModel</span>\
    <span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">sc</span><span class="p">,</span> <span class="s2">&quot;target/org/apache/spark/PythonLatentDirichletAllocationExample/LDAModel&quot;</span><span class="p">)</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / python / mllib / latent_dirichlet_allocation_example.py”中找到完整的示例代码。</small></div>
  </div>

</div>

<h2 id="bisecting-k-means">均分k均值</h2>

<p>平分K均值通常会比常规K均值快得多，但通常会产生不同的聚类。</p>

<p>均分k均值是一种<a href="https://en.wikipedia.org/wiki/Hierarchical_clustering">层次聚类</a> 。层次聚类是寻求建立聚类层次的最常用聚类分析方法之一。层次集群的策略通常分为两种：</p>

<ul>
  <li>集结：这是一种“自下而上”的方法：每个观察都在其自己的群集中开始，并且随着一个群集在层次结构中的向上移动，合并成对的群集。</li>
  <li>分歧：这是一种“自上而下”的方法：所有观察都从一个簇开始，并且随着一个人向下移动到层次结构而递归执行拆分。</li>
</ul>

<p>二等分k均值算法是一种分裂算法。MLlib中的实现具有以下参数：</p>

<ul>
  <li><em>k</em> ：所需的叶簇数量（默认值：4）。如果没有可分割的叶簇，则实际数目可能会更小。</li>
  <li><em>maxIterations</em> ：拆分集群的k均值迭代的最大次数（默认值：20）</li>
  <li><em>minDivisibleClusterSize</em> ：可整除群集的最小点数（如果> = 1.0）或最小点数比例（如果<1.0）（默认值：1）</li>
  <li><em>seed</em> ：随机种子（默认值：类名称的哈希值）</li>
</ul>

<p><strong>例子</strong></p>

<div class="codetabs">
<div data-lang="scala">
    <p>请参阅<a href="api/scala/index.html#org.apache.spark.mllib.clustering.BisectingKMeans"><code>BisectingKMeans</code> Scala文档</a>和<a href="api/scala/index.html#org.apache.spark.mllib.clustering.BisectingKMeansModel"><code>BisectingKMeansModel</code></a>有关API的详细信息，请参见<a href="api/scala/index.html#org.apache.spark.mllib.clustering.BisectingKMeansModel">Scala文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">org.apache.spark.mllib.clustering.BisectingKMeans</span>
<span class="k">import</span> <span class="nn">org.apache.spark.mllib.linalg.</span><span class="o">{</span><span class="nc">Vector</span><span class="o">,</span> <span class="nc">Vectors</span><span class="o">}</span>

<span class="c1">// Loads and parses data</span>
<span class="k">def</span> <span class="n">parse</span><span class="o">(</span><span class="n">line</span><span class="k">:</span> <span class="kt">String</span><span class="o">)</span><span class="k">:</span> <span class="kt">Vector</span> <span class="o">=</span> <span class="nc">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="o">(</span><span class="n">line</span><span class="o">.</span><span class="n">split</span><span class="o">(</span><span class="s">&quot; &quot;</span><span class="o">).</span><span class="n">map</span><span class="o">(</span><span class="k">_</span><span class="o">.</span><span class="n">toDouble</span><span class="o">))</span>
<span class="k">val</span> <span class="n">data</span> <span class="k">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">textFile</span><span class="o">(</span><span class="s">&quot;data/mllib/kmeans_data.txt&quot;</span><span class="o">).</span><span class="n">map</span><span class="o">(</span><span class="n">parse</span><span class="o">).</span><span class="n">cache</span><span class="o">()</span>

<span class="c1">// Clustering the data into 6 clusters by BisectingKMeans.</span>
<span class="k">val</span> <span class="n">bkm</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">BisectingKMeans</span><span class="o">().</span><span class="n">setK</span><span class="o">(</span><span class="mi">6</span><span class="o">)</span>
<span class="k">val</span> <span class="n">model</span> <span class="k">=</span> <span class="n">bkm</span><span class="o">.</span><span class="n">run</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="c1">// Show the compute cost and the cluster centers</span>
<span class="n">println</span><span class="o">(</span><span class="s">s&quot;Compute Cost: </span><span class="si">${</span><span class="n">model</span><span class="o">.</span><span class="n">computeCost</span><span class="o">(</span><span class="n">data</span><span class="o">)</span><span class="si">}</span><span class="s">&quot;</span><span class="o">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">clusterCenters</span><span class="o">.</span><span class="n">zipWithIndex</span><span class="o">.</span><span class="n">foreach</span> <span class="o">{</span> <span class="k">case</span> <span class="o">(</span><span class="n">center</span><span class="o">,</span> <span class="n">idx</span><span class="o">)</span> <span class="k">=&gt;</span>
  <span class="n">println</span><span class="o">(</span><span class="s">s&quot;Cluster Center </span><span class="si">${</span><span class="n">idx</span><span class="si">}</span><span class="s">: </span><span class="si">${</span><span class="n">center</span><span class="si">}</span><span class="s">&quot;</span><span class="o">)</span>
<span class="o">}</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / scala / org / apache / spark / examples / mllib / BisectingKMeansExample.scala”中找到完整的示例代码。</small></div>
  </div>

<div data-lang="java">
    <p>请参阅<a href="api/java/org/apache/spark/mllib/clustering/BisectingKMeans.html"><code>BisectingKMeans</code> Java文档</a>和<a href="api/java/org/apache/spark/mllib/clustering/BisectingKMeansModel.html"><code>BisectingKMeansModel</code></a>有关该API的详细信息的<a href="api/java/org/apache/spark/mllib/clustering/BisectingKMeansModel.html">Java文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">java.util.Arrays</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">java.util.List</span><span class="o">;</span>

<span class="kn">import</span> <span class="nn">org.apache.spark.api.java.JavaRDD</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.mllib.clustering.BisectingKMeans</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.mllib.clustering.BisectingKMeansModel</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.mllib.linalg.Vector</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.mllib.linalg.Vectors</span><span class="o">;</span>

<span class="n">List</span><span class="o">&lt;</span><span class="n">Vector</span><span class="o">&gt;</span> <span class="n">localData</span> <span class="o">=</span> <span class="n">Arrays</span><span class="o">.</span><span class="na">asList</span><span class="o">(</span>
  <span class="n">Vectors</span><span class="o">.</span><span class="na">dense</span><span class="o">(</span><span class="mf">0.1</span><span class="o">,</span> <span class="mf">0.1</span><span class="o">),</span>   <span class="n">Vectors</span><span class="o">.</span><span class="na">dense</span><span class="o">(</span><span class="mf">0.3</span><span class="o">,</span> <span class="mf">0.3</span><span class="o">),</span>
  <span class="n">Vectors</span><span class="o">.</span><span class="na">dense</span><span class="o">(</span><span class="mf">10.1</span><span class="o">,</span> <span class="mf">10.1</span><span class="o">),</span> <span class="n">Vectors</span><span class="o">.</span><span class="na">dense</span><span class="o">(</span><span class="mf">10.3</span><span class="o">,</span> <span class="mf">10.3</span><span class="o">),</span>
  <span class="n">Vectors</span><span class="o">.</span><span class="na">dense</span><span class="o">(</span><span class="mf">20.1</span><span class="o">,</span> <span class="mf">20.1</span><span class="o">),</span> <span class="n">Vectors</span><span class="o">.</span><span class="na">dense</span><span class="o">(</span><span class="mf">20.3</span><span class="o">,</span> <span class="mf">20.3</span><span class="o">),</span>
  <span class="n">Vectors</span><span class="o">.</span><span class="na">dense</span><span class="o">(</span><span class="mf">30.1</span><span class="o">,</span> <span class="mf">30.1</span><span class="o">),</span> <span class="n">Vectors</span><span class="o">.</span><span class="na">dense</span><span class="o">(</span><span class="mf">30.3</span><span class="o">,</span> <span class="mf">30.3</span><span class="o">)</span>
<span class="o">);</span>
<span class="n">JavaRDD</span><span class="o">&lt;</span><span class="n">Vector</span><span class="o">&gt;</span> <span class="n">data</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="na">parallelize</span><span class="o">(</span><span class="n">localData</span><span class="o">,</span> <span class="mi">2</span><span class="o">);</span>

<span class="n">BisectingKMeans</span> <span class="n">bkm</span> <span class="o">=</span> <span class="k">new</span> <span class="n">BisectingKMeans</span><span class="o">()</span>
  <span class="o">.</span><span class="na">setK</span><span class="o">(</span><span class="mi">4</span><span class="o">);</span>
<span class="n">BisectingKMeansModel</span> <span class="n">model</span> <span class="o">=</span> <span class="n">bkm</span><span class="o">.</span><span class="na">run</span><span class="o">(</span><span class="n">data</span><span class="o">);</span>

<span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">&quot;Compute Cost: &quot;</span> <span class="o">+</span> <span class="n">model</span><span class="o">.</span><span class="na">computeCost</span><span class="o">(</span><span class="n">data</span><span class="o">));</span>

<span class="n">Vector</span><span class="o">[]</span> <span class="n">clusterCenters</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="na">clusterCenters</span><span class="o">();</span>
<span class="k">for</span> <span class="o">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="o">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">clusterCenters</span><span class="o">.</span><span class="na">length</span><span class="o">;</span> <span class="n">i</span><span class="o">++)</span> <span class="o">{</span>
  <span class="n">Vector</span> <span class="n">clusterCenter</span> <span class="o">=</span> <span class="n">clusterCenters</span><span class="o">[</span><span class="n">i</span><span class="o">];</span>
  <span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">&quot;Cluster Center &quot;</span> <span class="o">+</span> <span class="n">i</span> <span class="o">+</span> <span class="s">&quot;: &quot;</span> <span class="o">+</span> <span class="n">clusterCenter</span><span class="o">);</span>
<span class="o">}</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / java / org / apache / spark / examples / mllib / JavaBisectingKMeansExample.java”中找到完整的示例代码。</small></div>
  </div>

<div data-lang="python">
    <p>请参阅<a href="api/python/pyspark.mllib.html#pyspark.mllib.clustering.BisectingKMeans"><code>BisectingKMeans</code> Python文档</a>和<a href="api/python/pyspark.mllib.html#pyspark.mllib.clustering.BisectingKMeansModel"><code>BisectingKMeansModel</code></a>有关该API的更多详细信息的<a href="api/python/pyspark.mllib.html#pyspark.mllib.clustering.BisectingKMeansModel">Python文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">numpy</span> <span class="kn">import</span> <span class="n">array</span>

<span class="kn">from</span> <span class="nn">pyspark.mllib.clustering</span> <span class="kn">import</span> <span class="n">BisectingKMeans</span><span class="p">,</span> <span class="n">BisectingKMeansModel</span>

<span class="c1"># Load and parse the data</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">textFile</span><span class="p">(</span><span class="s2">&quot;data/mllib/kmeans_data.txt&quot;</span><span class="p">)</span>
<span class="n">parsedData</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">line</span><span class="p">:</span> <span class="n">array</span><span class="p">([</span><span class="nb">float</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">line</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39; &#39;</span><span class="p">)]))</span>

<span class="c1"># Build the model (cluster the data)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">BisectingKMeans</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">parsedData</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">maxIterations</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>

<span class="c1"># Evaluate clustering</span>
<span class="n">cost</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">computeCost</span><span class="p">(</span><span class="n">parsedData</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&quot;Bisecting K-means Cost = &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">cost</span><span class="p">))</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / python / mllib / bisecting_k_means_example.py”中找到完整的示例代码。</small></div>
  </div>
</div>

<h2 id="streaming-k-means">流式均值</h2>

<p>当数据到达流中时，我们可能希望动态估计群集，并在新数据到达时对其进行更新。 <code>spark.mllib</code>为流式k均值聚类提供支持，并提供参数以控制估计值的衰减（或“健忘”）。该算法使用了小批量k均值更新规则的概括。对于每一批数据，我们将所有点分配给它们最近的聚类，计算新的聚类中心，然后使用以下方法更新每个聚类：</p>

<p><code>\begin{equation} c_{t+1} = \frac{c_tn_t\alpha + x_tm_t}{n_t\alpha+m_t} \end{equation}</code>
<code>\begin{equation} n_{t+1} = n_t + m_t \end{equation}</code></p>

<p>哪里<code>$c_t$</code>是该集群的上一个中心， <code>$n_t$</code>是到目前为止分配给集群的点数， <code>$x_t$</code>是当前批次中的新群集中心，并且<code>$m_t$</code>是在当前批次中添加到群集的点数。衰减系数<code>$\alpha$</code>可以用来忽略过去：with <code>$\alpha$=1</code>从一开始就将使用所有数据；与<code>$\alpha$=0</code>仅使用最新数据。这类似于指数加权移动平均值。</p>

<p>衰减可以使用<code>halfLife</code>参数，它确定正确的衰减因子<code>a</code>这样，对于当时获取的数据<code>t</code> ，其按时间的贡献<code>t + halfLife</code>将下降到0.5。时间单位可以指定为<code>batches</code>要么<code>points</code>并且更新规则将进行相应调整。</p>

<p><strong>例子</strong></p>

<p>此示例显示了如何估计流数据上的群集。</p>

<div class="codetabs">

<div data-lang="scala">
    <p>请参阅<a href="api/scala/index.html#org.apache.spark.mllib.clustering.StreamingKMeans"><code>StreamingKMeans</code></a>有关API的详细信息，请参见<a href="api/scala/index.html#org.apache.spark.mllib.clustering.StreamingKMeans">Scala文档</a> 。有关StreamingContext的详细信息，请参阅《 <a href="streaming-programming-guide.html#initializing">Spark Streaming编程指南》</a> 。</p>

    <div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">org.apache.spark.mllib.clustering.StreamingKMeans</span>
<span class="k">import</span> <span class="nn">org.apache.spark.mllib.linalg.Vectors</span>
<span class="k">import</span> <span class="nn">org.apache.spark.mllib.regression.LabeledPoint</span>
<span class="k">import</span> <span class="nn">org.apache.spark.streaming.</span><span class="o">{</span><span class="nc">Seconds</span><span class="o">,</span> <span class="nc">StreamingContext</span><span class="o">}</span>

<span class="k">val</span> <span class="n">conf</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SparkConf</span><span class="o">().</span><span class="n">setAppName</span><span class="o">(</span><span class="s">&quot;StreamingKMeansExample&quot;</span><span class="o">)</span>
<span class="k">val</span> <span class="n">ssc</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">StreamingContext</span><span class="o">(</span><span class="n">conf</span><span class="o">,</span> <span class="nc">Seconds</span><span class="o">(</span><span class="n">args</span><span class="o">(</span><span class="mi">2</span><span class="o">).</span><span class="n">toLong</span><span class="o">))</span>

<span class="k">val</span> <span class="n">trainingData</span> <span class="k">=</span> <span class="n">ssc</span><span class="o">.</span><span class="n">textFileStream</span><span class="o">(</span><span class="n">args</span><span class="o">(</span><span class="mi">0</span><span class="o">)).</span><span class="n">map</span><span class="o">(</span><span class="nc">Vectors</span><span class="o">.</span><span class="n">parse</span><span class="o">)</span>
<span class="k">val</span> <span class="n">testData</span> <span class="k">=</span> <span class="n">ssc</span><span class="o">.</span><span class="n">textFileStream</span><span class="o">(</span><span class="n">args</span><span class="o">(</span><span class="mi">1</span><span class="o">)).</span><span class="n">map</span><span class="o">(</span><span class="nc">LabeledPoint</span><span class="o">.</span><span class="n">parse</span><span class="o">)</span>

<span class="k">val</span> <span class="n">model</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">StreamingKMeans</span><span class="o">()</span>
  <span class="o">.</span><span class="n">setK</span><span class="o">(</span><span class="n">args</span><span class="o">(</span><span class="mi">3</span><span class="o">).</span><span class="n">toInt</span><span class="o">)</span>
  <span class="o">.</span><span class="n">setDecayFactor</span><span class="o">(</span><span class="mf">1.0</span><span class="o">)</span>
  <span class="o">.</span><span class="n">setRandomCenters</span><span class="o">(</span><span class="n">args</span><span class="o">(</span><span class="mi">4</span><span class="o">).</span><span class="n">toInt</span><span class="o">,</span> <span class="mf">0.0</span><span class="o">)</span>

<span class="n">model</span><span class="o">.</span><span class="n">trainOn</span><span class="o">(</span><span class="n">trainingData</span><span class="o">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">predictOnValues</span><span class="o">(</span><span class="n">testData</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="n">lp</span> <span class="k">=&gt;</span> <span class="o">(</span><span class="n">lp</span><span class="o">.</span><span class="n">label</span><span class="o">,</span> <span class="n">lp</span><span class="o">.</span><span class="n">features</span><span class="o">))).</span><span class="n">print</span><span class="o">()</span>

<span class="n">ssc</span><span class="o">.</span><span class="n">start</span><span class="o">()</span>
<span class="n">ssc</span><span class="o">.</span><span class="n">awaitTermination</span><span class="o">()</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / scala / org / apache / spark / examples / mllib / StreamingKMeansExample.scala”中找到完整的示例代码。</small></div>
  </div>

<div data-lang="python">
    <p>请参阅<a href="api/python/pyspark.mllib.html#pyspark.mllib.clustering.StreamingKMeans"><code>StreamingKMeans</code></a>有关该API的更多详细信息的<a href="api/python/pyspark.mllib.html#pyspark.mllib.clustering.StreamingKMeans">Python文档</a> 。有关StreamingContext的详细信息，请参阅《 <a href="streaming-programming-guide.html#initializing">Spark Streaming编程指南》</a> 。</p>

    <div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pyspark.mllib.linalg</span> <span class="kn">import</span> <span class="n">Vectors</span>
<span class="kn">from</span> <span class="nn">pyspark.mllib.regression</span> <span class="kn">import</span> <span class="n">LabeledPoint</span>
<span class="kn">from</span> <span class="nn">pyspark.mllib.clustering</span> <span class="kn">import</span> <span class="n">StreamingKMeans</span>

<span class="c1"># we make an input stream of vectors for training,</span>
<span class="c1"># as well as a stream of vectors for testing</span>
<span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="n">lp</span><span class="p">):</span>
    <span class="n">label</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">lp</span><span class="p">[</span><span class="n">lp</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s1">&#39;(&#39;</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">:</span> <span class="n">lp</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s1">&#39;)&#39;</span><span class="p">)])</span>
    <span class="n">vec</span> <span class="o">=</span> <span class="n">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="p">(</span><span class="n">lp</span><span class="p">[</span><span class="n">lp</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s1">&#39;[&#39;</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">:</span> <span class="n">lp</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s1">&#39;]&#39;</span><span class="p">)]</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;,&#39;</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">LabeledPoint</span><span class="p">(</span><span class="n">label</span><span class="p">,</span> <span class="n">vec</span><span class="p">)</span>

<span class="n">trainingData</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">textFile</span><span class="p">(</span><span class="s2">&quot;data/mllib/kmeans_data.txt&quot;</span><span class="p">)</span>\
    <span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">line</span><span class="p">:</span> <span class="n">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="p">([</span><span class="nb">float</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">line</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39; &#39;</span><span class="p">)]))</span>

<span class="n">testingData</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">textFile</span><span class="p">(</span><span class="s2">&quot;data/mllib/streaming_kmeans_data_test.txt&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">parse</span><span class="p">)</span>

<span class="n">trainingQueue</span> <span class="o">=</span> <span class="p">[</span><span class="n">trainingData</span><span class="p">]</span>
<span class="n">testingQueue</span> <span class="o">=</span> <span class="p">[</span><span class="n">testingData</span><span class="p">]</span>

<span class="n">trainingStream</span> <span class="o">=</span> <span class="n">ssc</span><span class="o">.</span><span class="n">queueStream</span><span class="p">(</span><span class="n">trainingQueue</span><span class="p">)</span>
<span class="n">testingStream</span> <span class="o">=</span> <span class="n">ssc</span><span class="o">.</span><span class="n">queueStream</span><span class="p">(</span><span class="n">testingQueue</span><span class="p">)</span>

<span class="c1"># We create a model with random clusters and specify the number of clusters to find</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">StreamingKMeans</span><span class="p">(</span><span class="n">k</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">decayFactor</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span><span class="o">.</span><span class="n">setRandomCenters</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>

<span class="c1"># Now register the streams for training and testing and start the job,</span>
<span class="c1"># printing the predicted cluster assignments on new data points as they arrive.</span>
<span class="n">model</span><span class="o">.</span><span class="n">trainOn</span><span class="p">(</span><span class="n">trainingStream</span><span class="p">)</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predictOnValues</span><span class="p">(</span><span class="n">testingStream</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">lp</span><span class="p">:</span> <span class="p">(</span><span class="n">lp</span><span class="o">.</span><span class="n">label</span><span class="p">,</span> <span class="n">lp</span><span class="o">.</span><span class="n">features</span><span class="p">)))</span>
<span class="n">result</span><span class="o">.</span><span class="n">pprint</span><span class="p">()</span>

<span class="n">ssc</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>
<span class="n">ssc</span><span class="o">.</span><span class="n">stop</span><span class="p">(</span><span class="n">stopSparkContext</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">stopGraceFully</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / python / mllib / streaming_k_means_example.py”中找到完整的示例代码。</small></div>
  </div>

</div>

<p>在添加带有数据的新文本文件时，群集中心将更新。每个培训点的格式应为<code>[x1, x2, x3]</code> ，并且每个测试数据点的格式应为<code>(y, [x1, x2, x3])</code> ，在哪里<code>y</code>是一些有用的标签或标识符（例如，真实的类别分配）。任何时候放置文本文件<code>/training/data/dir</code>模型将更新。任何时候放置文本文件<code>/testing/data/dir</code>您将看到预测。有了新数据，集群中心将发生变化！</p>


                </div>
            
             <!-- /container -->
        </div>

        <script src="js/vendor/jquery-1.12.4.min.js"></script>
        <script src="js/vendor/bootstrap.min.js"></script>
        <script src="js/vendor/anchor.min.js"></script>
        <script src="js/main.js"></script>

        <!-- MathJax Section -->
        <script type="text/x-mathjax-config">
            MathJax.Hub.Config({
                TeX: { equationNumbers: { autoNumber: "AMS" } }
            });
        </script>
        <script>
            // Note that we load MathJax this way to work with local file (file://), HTTP and HTTPS.
            // We could use "//cdn.mathjax...", but that won't support "file://".
            (function(d, script) {
                script = d.createElement('script');
                script.type = 'text/javascript';
                script.async = true;
                script.onload = function(){
                    MathJax.Hub.Config({
                        tex2jax: {
                            inlineMath: [ ["$", "$"], ["\\\\(","\\\\)"] ],
                            displayMath: [ ["$$","$$"], ["\\[", "\\]"] ],
                            processEscapes: true,
                            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre']
                        }
                    });
                };
                script.src = ('https:' == document.location.protocol ? 'https://' : 'http://') +
                    'cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js' +
                    '?config=TeX-AMS-MML_HTMLorMML';
                d.getElementsByTagName('head')[0].appendChild(script);
            }(document));
        </script>
    

</body></html>