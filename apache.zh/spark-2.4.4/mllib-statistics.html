<html class="no-js" ><!--<![endif]--><head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
        <title>基本统计信息-基于RDD的API-Spark 2.4.4文档</title>
        

        

        <link rel="stylesheet" href="css/bootstrap.min.css">
        <style>
            body {
                padding-top: 60px;
                padding-bottom: 40px;
            }
        </style>
        <meta name="viewport" content="width=device-width">
        <link rel="stylesheet" href="css/bootstrap-responsive.min.css">
        <link rel="stylesheet" href="css/main.css">

        <script src="js/vendor/modernizr-2.6.1-respond-1.1.0.min.js"></script>

        <link rel="stylesheet" href="css/pygments-default.css">

        
        <!-- Google analytics script -->
        <script type="text/javascript">
          var _gaq = _gaq || [];
          _gaq.push(['_setAccount', 'UA-32518208-2']);
          _gaq.push(['_trackPageview']);

          (function() {
            var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
            ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
            var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
          })();
        </script>
        

    </head>
    <body >
        <!--[if lt IE 7]>
            <p class="chromeframe">You are using an outdated browser. <a href="https://browsehappy.com/">Upgrade your browser today</a> or <a href="http://www.google.com/chromeframe/?redirect=true">install Google Chrome Frame</a> to better experience this site.</p>
        <![endif]-->

        <!-- This code is taken from http://twitter.github.com/bootstrap/examples/hero.html -->

        <div class="navbar navbar-fixed-top" id="topbar">
            <div class="navbar-inner">
                <div class="container">
                    <div class="brand"><a href="index.html"><img src="img/spark-logo-hd.png" style="height:50px"></a> <span class="version">2.4.4</span>
                    </div>
                    <ul class="nav">
                        <!--TODO(andyk): Add class="active" attribute to li some how.-->
                        <li><a href="index.html">总览</a></li>

                        <li class="dropdown">
                            <a href="#" class="dropdown-toggle" data-toggle="dropdown">编程指南<b class="caret"></b></a>
                            <ul class="dropdown-menu">
                                <li><a href="quick-start.html">快速开始</a></li>
                                <li><a href="rdd-programming-guide.html">RDD，累加器，广播变量</a></li>
                                <li><a href="sql-programming-guide.html">SQL，数据框和数据集</a></li>
                                <li><a href="structured-streaming-programming-guide.html">结构化流</a></li>
                                <li><a href="streaming-programming-guide.html">火花流（DStreams）</a></li>
                                <li><a href="ml-guide.html">MLlib（机器学习）</a></li>
                                <li><a href="graphx-programming-guide.html">GraphX（图形处理）</a></li>
                                <li><a href="sparkr.html">SparkR（Spark上的R）</a></li>
                            </ul>
                        </li>

                        <li class="dropdown">
                            <a href="#" class="dropdown-toggle" data-toggle="dropdown">API文件<b class="caret"></b></a>
                            <ul class="dropdown-menu">
                                <li><a href="api/scala/index.html#org.apache.spark.package">斯卡拉</a></li>
                                <li><a href="api/java/index.html">爪哇</a></li>
                                <li><a href="api/python/index.html">蟒蛇</a></li>
                                <li><a href="api/R/index.html">[R</a></li>
                                <li><a href="api/sql/index.html">SQL，内置函数</a></li>
                            </ul>
                        </li>

                        <li class="dropdown">
                            <a href="#" class="dropdown-toggle" data-toggle="dropdown">部署中<b class="caret"></b></a>
                            <ul class="dropdown-menu">
                                <li><a href="cluster-overview.html">总览</a></li>
                                <li><a href="submitting-applications.html">提交申请</a></li>
                                <li class="divider"></li>
                                <li><a href="spark-standalone.html">Spark独立</a></li>
                                <li><a href="running-on-mesos.html">梅索斯</a></li>
                                <li><a href="running-on-yarn.html">纱</a></li>
                                <li><a href="running-on-kubernetes.html">Kubernetes</a></li>
                            </ul>
                        </li>

                        <li class="dropdown">
                            <a href="api.html" class="dropdown-toggle" data-toggle="dropdown">更多<b class="caret"></b></a>
                            <ul class="dropdown-menu">
                                <li><a href="configuration.html">组态</a></li>
                                <li><a href="monitoring.html">监控方式</a></li>
                                <li><a href="tuning.html">调音指南</a></li>
                                <li><a href="job-scheduling.html">作业调度</a></li>
                                <li><a href="security.html">安全</a></li>
                                <li><a href="hardware-provisioning.html">硬件配置</a></li>
                                <li class="divider"></li>
                                <li><a href="building-spark.html">建筑火花</a></li>
                                <li><a href="https://spark.apache.org/contributing.html">为Spark贡献</a></li>
                                <li><a href="https://spark.apache.org/third-party-projects.html">第三方项目</a></li>
                            </ul>
                        </li>
                    </ul>
                    <!--<p class="navbar-text pull-right"><span class="version-text">v2.4.4</span></p>-->
                </div>
            </div>
        </div>

        <div class="container-wrapper">

            
                
                    <div class="left-menu-wrapper">
    <div class="left-menu">
        <h3><a href="ml-guide.html">MLlib：主要指南</a></h3>
        
<ul>

    <li>
        <a href="ml-statistics.html">基本统计</a>
    </li>
    
    

    <li>
        <a href="ml-datasource">数据源</a>
    </li>
    
    

    <li>
        <a href="ml-pipeline.html">流水线</a>
    </li>
    
    

    <li>
        <a href="ml-features.html">提取，转换和选择特征</a>
    </li>
    
    

    <li>
        <a href="ml-classification-regression.html">分类与回归</a>
    </li>
    
    

    <li>
        <a href="ml-clustering.html">聚类</a>
    </li>
    
    

    <li>
        <a href="ml-collaborative-filtering.html">协同过滤</a>
    </li>
    
    

    <li>
        <a href="ml-frequent-pattern-mining.html">频繁模式挖掘</a>
    </li>
    
    

    <li>
        <a href="ml-tuning.html">模型选择和调整</a>
    </li>
    
    

    <li>
        <a href="ml-advanced.html">进阶主题</a>
    </li>
    
    

</ul>

        <h3><a href="mllib-guide.html">MLlib：基于RDD的API指南</a></h3>
        
<ul>

    <li>
        <a href="mllib-data-types.html">资料类型</a>
    </li>
    
    

    <li>
        <a href="mllib-statistics.html">
            
                <b>基本统计</b>
            
        </a>
    </li>
    
    
        
<ul>

    <li>
        <a href="mllib-statistics.html#summary-statistics">统计摘要</a>
    </li>
    
    

    <li>
        <a href="mllib-statistics.html#correlations">相关性</a>
    </li>
    
    

    <li>
        <a href="mllib-statistics.html#stratified-sampling">分层抽样</a>
    </li>
    
    

    <li>
        <a href="mllib-statistics.html#hypothesis-testing">假设检验</a>
    </li>
    
    

    <li>
        <a href="mllib-statistics.html#random-data-generation">随机数据生成</a>
    </li>
    
    

</ul>

    

    <li>
        <a href="mllib-classification-regression.html">分类与回归</a>
    </li>
    
    

    <li>
        <a href="mllib-collaborative-filtering.html">协同过滤</a>
    </li>
    
    

    <li>
        <a href="mllib-clustering.html">聚类</a>
    </li>
    
    

    <li>
        <a href="mllib-dimensionality-reduction.html">降维</a>
    </li>
    
    

    <li>
        <a href="mllib-feature-extraction.html">特征提取和转换</a>
    </li>
    
    

    <li>
        <a href="mllib-frequent-pattern-mining.html">频繁模式挖掘</a>
    </li>
    
    

    <li>
        <a href="mllib-evaluation-metrics.html">评估指标</a>
    </li>
    
    

    <li>
        <a href="mllib-pmml-model-export.html">PMML模型导出</a>
    </li>
    
    

    <li>
        <a href="mllib-optimization.html">优化（开发人员）</a>
    </li>
    
    

</ul>

    </div>
</div>
                
                <input id="nav-trigger" class="nav-trigger" type="checkbox" checked>
                <label for="nav-trigger"></label>
                <div class="content-with-sidebar" id="content">
                    
                        <h1 class="title">基本统计信息-基于RDD的API</h1>
                    

                    <ul id="markdown-toc">
  <li><a href="#summary-statistics" id="markdown-toc-summary-statistics">统计摘要</a></li>
  <li><a href="#correlations" id="markdown-toc-correlations">相关性</a></li>
  <li><a href="#stratified-sampling" id="markdown-toc-stratified-sampling">分层抽样</a></li>
  <li><a href="#hypothesis-testing" id="markdown-toc-hypothesis-testing">假设检验</a>    <ul>
      <li><a href="#streaming-significance-testing" id="markdown-toc-streaming-significance-testing">流重要性测试</a></li>
    </ul>
  </li>
  <li><a href="#random-data-generation" id="markdown-toc-random-data-generation">随机数据生成</a></li>
  <li><a href="#kernel-density-estimation" id="markdown-toc-kernel-density-estimation">内核密度估计</a></li>
</ul>

<p><code>\[ \newcommand{\R}{\mathbb{R}} \newcommand{\E}{\mathbb{E}} \newcommand{\x}{\mathbf{x}} \newcommand{\y}{\mathbf{y}} \newcommand{\wv}{\mathbf{w}} \newcommand{\av}{\mathbf{\alpha}} \newcommand{\bv}{\mathbf{b}} \newcommand{\N}{\mathbb{N}} \newcommand{\id}{\mathbf{I}} \newcommand{\ind}{\mathbf{1}} \newcommand{\0}{\mathbf{0}} \newcommand{\unit}{\mathbf{e}} \newcommand{\one}{\mathbf{1}} \newcommand{\zero}{\mathbf{0}} \]</code></p>

<h2 id="summary-statistics">统计摘要</h2>

<p>我们提供以下内容的列摘要统计信息： <code>RDD[Vector]</code>通过功能<code>colStats</code>可在<code>Statistics</code> 。</p>

<div class="codetabs">
<div data-lang="scala">

    <p><a href="api/scala/index.html#org.apache.spark.mllib.stat.Statistics$"><code>colStats()</code></a>返回的实例<a href="api/scala/index.html#org.apache.spark.mllib.stat.MultivariateStatisticalSummary"><code>MultivariateStatisticalSummary</code></a> ，其中包含按列的最大值，最小值，平均值，方差和非零数，以及总数。</p>

    <p>请参阅<a href="api/scala/index.html#org.apache.spark.mllib.stat.MultivariateStatisticalSummary"><code>MultivariateStatisticalSummary</code></a>有关API的详细信息，请参见<a href="api/scala/index.html#org.apache.spark.mllib.stat.MultivariateStatisticalSummary">Scala文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">org.apache.spark.mllib.linalg.Vectors</span>
<span class="k">import</span> <span class="nn">org.apache.spark.mllib.stat.</span><span class="o">{</span><span class="nc">MultivariateStatisticalSummary</span><span class="o">,</span> <span class="nc">Statistics</span><span class="o">}</span>

<span class="k">val</span> <span class="n">observations</span> <span class="k">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">parallelize</span><span class="o">(</span>
  <span class="nc">Seq</span><span class="o">(</span>
    <span class="nc">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="o">(</span><span class="mf">1.0</span><span class="o">,</span> <span class="mf">10.0</span><span class="o">,</span> <span class="mf">100.0</span><span class="o">),</span>
    <span class="nc">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="o">(</span><span class="mf">2.0</span><span class="o">,</span> <span class="mf">20.0</span><span class="o">,</span> <span class="mf">200.0</span><span class="o">),</span>
    <span class="nc">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="o">(</span><span class="mf">3.0</span><span class="o">,</span> <span class="mf">30.0</span><span class="o">,</span> <span class="mf">300.0</span><span class="o">)</span>
  <span class="o">)</span>
<span class="o">)</span>

<span class="c1">// Compute column summary statistics.</span>
<span class="k">val</span> <span class="n">summary</span><span class="k">:</span> <span class="kt">MultivariateStatisticalSummary</span> <span class="o">=</span> <span class="nc">Statistics</span><span class="o">.</span><span class="n">colStats</span><span class="o">(</span><span class="n">observations</span><span class="o">)</span>
<span class="n">println</span><span class="o">(</span><span class="n">summary</span><span class="o">.</span><span class="n">mean</span><span class="o">)</span>  <span class="c1">// a dense vector containing the mean value for each column</span>
<span class="n">println</span><span class="o">(</span><span class="n">summary</span><span class="o">.</span><span class="n">variance</span><span class="o">)</span>  <span class="c1">// column-wise variance</span>
<span class="n">println</span><span class="o">(</span><span class="n">summary</span><span class="o">.</span><span class="n">numNonzeros</span><span class="o">)</span>  <span class="c1">// number of nonzeros in each column</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / scala / org / apache / spark / examples / mllib / SummaryStatisticsExample.scala”中找到完整的示例代码。</small></div>
  </div>

<div data-lang="java">

    <p><a href="api/java/org/apache/spark/mllib/stat/Statistics.html"><code>colStats()</code></a>返回的实例<a href="api/java/org/apache/spark/mllib/stat/MultivariateStatisticalSummary.html"><code>MultivariateStatisticalSummary</code></a> ，其中包含按列的最大值，最小值，平均值，方差和非零数，以及总数。</p>

    <p>请参阅<a href="api/java/org/apache/spark/mllib/stat/MultivariateStatisticalSummary.html"><code>MultivariateStatisticalSummary</code></a>有关该API的详细信息的<a href="api/java/org/apache/spark/mllib/stat/MultivariateStatisticalSummary.html">Java文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">java.util.Arrays</span><span class="o">;</span>

<span class="kn">import</span> <span class="nn">org.apache.spark.api.java.JavaRDD</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.mllib.linalg.Vector</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.mllib.linalg.Vectors</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.mllib.stat.MultivariateStatisticalSummary</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.mllib.stat.Statistics</span><span class="o">;</span>

<span class="n">JavaRDD</span><span class="o">&lt;</span><span class="n">Vector</span><span class="o">&gt;</span> <span class="n">mat</span> <span class="o">=</span> <span class="n">jsc</span><span class="o">.</span><span class="na">parallelize</span><span class="o">(</span>
  <span class="n">Arrays</span><span class="o">.</span><span class="na">asList</span><span class="o">(</span>
    <span class="n">Vectors</span><span class="o">.</span><span class="na">dense</span><span class="o">(</span><span class="mf">1.0</span><span class="o">,</span> <span class="mf">10.0</span><span class="o">,</span> <span class="mf">100.0</span><span class="o">),</span>
    <span class="n">Vectors</span><span class="o">.</span><span class="na">dense</span><span class="o">(</span><span class="mf">2.0</span><span class="o">,</span> <span class="mf">20.0</span><span class="o">,</span> <span class="mf">200.0</span><span class="o">),</span>
    <span class="n">Vectors</span><span class="o">.</span><span class="na">dense</span><span class="o">(</span><span class="mf">3.0</span><span class="o">,</span> <span class="mf">30.0</span><span class="o">,</span> <span class="mf">300.0</span><span class="o">)</span>
  <span class="o">)</span>
<span class="o">);</span> <span class="c1">// an RDD of Vectors</span>

<span class="c1">// Compute column summary statistics.</span>
<span class="n">MultivariateStatisticalSummary</span> <span class="n">summary</span> <span class="o">=</span> <span class="n">Statistics</span><span class="o">.</span><span class="na">colStats</span><span class="o">(</span><span class="n">mat</span><span class="o">.</span><span class="na">rdd</span><span class="o">());</span>
<span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="n">summary</span><span class="o">.</span><span class="na">mean</span><span class="o">());</span>  <span class="c1">// a dense vector containing the mean value for each column</span>
<span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="n">summary</span><span class="o">.</span><span class="na">variance</span><span class="o">());</span>  <span class="c1">// column-wise variance</span>
<span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="n">summary</span><span class="o">.</span><span class="na">numNonzeros</span><span class="o">());</span>  <span class="c1">// number of nonzeros in each column</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / java / org / apache / spark / examples / mllib / JavaSummaryStatisticsExample.java”中找到完整的示例代码。</small></div>
  </div>

<div data-lang="python">
    <p><a href="api/python/pyspark.mllib.html#pyspark.mllib.stat.Statistics.colStats"><code>colStats()</code></a>返回的实例<a href="api/python/pyspark.mllib.html#pyspark.mllib.stat.MultivariateStatisticalSummary"><code>MultivariateStatisticalSummary</code></a> ，其中包含按列的最大值，最小值，平均值，方差和非零数，以及总数。</p>

    <p>请参阅<a href="api/python/pyspark.mllib.html#pyspark.mllib.stat.MultivariateStatisticalSummary"><code>MultivariateStatisticalSummary</code></a>有关该API的更多详细信息的<a href="api/python/pyspark.mllib.html#pyspark.mllib.stat.MultivariateStatisticalSummary">Python文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>

<span class="kn">from</span> <span class="nn">pyspark.mllib.stat</span> <span class="kn">import</span> <span class="n">Statistics</span>

<span class="n">mat</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">parallelize</span><span class="p">(</span>
    <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">10.0</span><span class="p">,</span> <span class="mf">100.0</span><span class="p">]),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">2.0</span><span class="p">,</span> <span class="mf">20.0</span><span class="p">,</span> <span class="mf">200.0</span><span class="p">]),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">3.0</span><span class="p">,</span> <span class="mf">30.0</span><span class="p">,</span> <span class="mf">300.0</span><span class="p">])]</span>
<span class="p">)</span>  <span class="c1"># an RDD of Vectors</span>

<span class="c1"># Compute column summary statistics.</span>
<span class="n">summary</span> <span class="o">=</span> <span class="n">Statistics</span><span class="o">.</span><span class="n">colStats</span><span class="p">(</span><span class="n">mat</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">summary</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>  <span class="c1"># a dense vector containing the mean value for each column</span>
<span class="k">print</span><span class="p">(</span><span class="n">summary</span><span class="o">.</span><span class="n">variance</span><span class="p">())</span>  <span class="c1"># column-wise variance</span>
<span class="k">print</span><span class="p">(</span><span class="n">summary</span><span class="o">.</span><span class="n">numNonzeros</span><span class="p">())</span>  <span class="c1"># number of nonzeros in each column</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / python / mllib / summary_statistics_example.py”中找到完整的示例代码。</small></div>
  </div>

</div>

<h2 id="correlations">相关性</h2>

<p>计算两个系列数据之间的相关性是“统计”中的常见操作。在<code>spark.mllib</code>我们提供了灵活性，可以计算多个序列之间的成对相关性。目前支持的相关方法是Pearson和Spearman的相关。</p>

<div class="codetabs">
<div data-lang="scala">
    <p><a href="api/scala/index.html#org.apache.spark.mllib.stat.Statistics$"><code>Statistics</code></a>提供了计算序列之间相关性的方法。根据输入的类型，两个<code>RDD[Double]</code>或<code>RDD[Vector]</code> ，输出将是<code>Double</code>或相关<code>Matrix</code>分别。</p>

    <p>请参阅<a href="api/scala/index.html#org.apache.spark.mllib.stat.Statistics$"><code>Statistics</code></a>有关API的详细信息，请参见<a href="api/scala/index.html#org.apache.spark.mllib.stat.Statistics$">Scala文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">org.apache.spark.mllib.linalg._</span>
<span class="k">import</span> <span class="nn">org.apache.spark.mllib.stat.Statistics</span>
<span class="k">import</span> <span class="nn">org.apache.spark.rdd.RDD</span>

<span class="k">val</span> <span class="n">seriesX</span><span class="k">:</span> <span class="kt">RDD</span><span class="o">[</span><span class="kt">Double</span><span class="o">]</span> <span class="k">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">parallelize</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="mi">2</span><span class="o">,</span> <span class="mi">3</span><span class="o">,</span> <span class="mi">3</span><span class="o">,</span> <span class="mi">5</span><span class="o">))</span>  <span class="c1">// a series</span>
<span class="c1">// must have the same number of partitions and cardinality as seriesX</span>
<span class="k">val</span> <span class="n">seriesY</span><span class="k">:</span> <span class="kt">RDD</span><span class="o">[</span><span class="kt">Double</span><span class="o">]</span> <span class="k">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">parallelize</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="mi">11</span><span class="o">,</span> <span class="mi">22</span><span class="o">,</span> <span class="mi">33</span><span class="o">,</span> <span class="mi">33</span><span class="o">,</span> <span class="mi">555</span><span class="o">))</span>

<span class="c1">// compute the correlation using Pearson&#39;s method. Enter &quot;spearman&quot; for Spearman&#39;s method. If a</span>
<span class="c1">// method is not specified, Pearson&#39;s method will be used by default.</span>
<span class="k">val</span> <span class="n">correlation</span><span class="k">:</span> <span class="kt">Double</span> <span class="o">=</span> <span class="nc">Statistics</span><span class="o">.</span><span class="n">corr</span><span class="o">(</span><span class="n">seriesX</span><span class="o">,</span> <span class="n">seriesY</span><span class="o">,</span> <span class="s">&quot;pearson&quot;</span><span class="o">)</span>
<span class="n">println</span><span class="o">(</span><span class="s">s&quot;Correlation is: </span><span class="si">$correlation</span><span class="s">&quot;</span><span class="o">)</span>

<span class="k">val</span> <span class="n">data</span><span class="k">:</span> <span class="kt">RDD</span><span class="o">[</span><span class="kt">Vector</span><span class="o">]</span> <span class="k">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">parallelize</span><span class="o">(</span>
  <span class="nc">Seq</span><span class="o">(</span>
    <span class="nc">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="o">(</span><span class="mf">1.0</span><span class="o">,</span> <span class="mf">10.0</span><span class="o">,</span> <span class="mf">100.0</span><span class="o">),</span>
    <span class="nc">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="o">(</span><span class="mf">2.0</span><span class="o">,</span> <span class="mf">20.0</span><span class="o">,</span> <span class="mf">200.0</span><span class="o">),</span>
    <span class="nc">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="o">(</span><span class="mf">5.0</span><span class="o">,</span> <span class="mf">33.0</span><span class="o">,</span> <span class="mf">366.0</span><span class="o">))</span>
<span class="o">)</span>  <span class="c1">// note that each Vector is a row and not a column</span>

<span class="c1">// calculate the correlation matrix using Pearson&#39;s method. Use &quot;spearman&quot; for Spearman&#39;s method</span>
<span class="c1">// If a method is not specified, Pearson&#39;s method will be used by default.</span>
<span class="k">val</span> <span class="n">correlMatrix</span><span class="k">:</span> <span class="kt">Matrix</span> <span class="o">=</span> <span class="nc">Statistics</span><span class="o">.</span><span class="n">corr</span><span class="o">(</span><span class="n">data</span><span class="o">,</span> <span class="s">&quot;pearson&quot;</span><span class="o">)</span>
<span class="n">println</span><span class="o">(</span><span class="n">correlMatrix</span><span class="o">.</span><span class="n">toString</span><span class="o">)</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / scala / org / apache / spark / examples / mllib / CorrelationsExample.scala”中找到完整的示例代码。</small></div>
  </div>

<div data-lang="java">
    <p><a href="api/java/org/apache/spark/mllib/stat/Statistics.html"><code>Statistics</code></a>提供了计算序列之间相关性的方法。根据输入的类型，两个<code>JavaDoubleRDD</code> s或a <code>JavaRDD<Vector></code> ，输出将是<code>Double</code>或相关<code>Matrix</code>分别。</p>

    <p>请参阅<a href="api/java/org/apache/spark/mllib/stat/Statistics.html"><code>Statistics</code></a>有关该API的详细信息的<a href="api/java/org/apache/spark/mllib/stat/Statistics.html">Java文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">java.util.Arrays</span><span class="o">;</span>

<span class="kn">import</span> <span class="nn">org.apache.spark.api.java.JavaDoubleRDD</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.api.java.JavaRDD</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.mllib.linalg.Matrix</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.mllib.linalg.Vector</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.mllib.linalg.Vectors</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.mllib.stat.Statistics</span><span class="o">;</span>

<span class="n">JavaDoubleRDD</span> <span class="n">seriesX</span> <span class="o">=</span> <span class="n">jsc</span><span class="o">.</span><span class="na">parallelizeDoubles</span><span class="o">(</span>
  <span class="n">Arrays</span><span class="o">.</span><span class="na">asList</span><span class="o">(</span><span class="mf">1.0</span><span class="o">,</span> <span class="mf">2.0</span><span class="o">,</span> <span class="mf">3.0</span><span class="o">,</span> <span class="mf">3.0</span><span class="o">,</span> <span class="mf">5.0</span><span class="o">));</span>  <span class="c1">// a series</span>

<span class="c1">// must have the same number of partitions and cardinality as seriesX</span>
<span class="n">JavaDoubleRDD</span> <span class="n">seriesY</span> <span class="o">=</span> <span class="n">jsc</span><span class="o">.</span><span class="na">parallelizeDoubles</span><span class="o">(</span>
  <span class="n">Arrays</span><span class="o">.</span><span class="na">asList</span><span class="o">(</span><span class="mf">11.0</span><span class="o">,</span> <span class="mf">22.0</span><span class="o">,</span> <span class="mf">33.0</span><span class="o">,</span> <span class="mf">33.0</span><span class="o">,</span> <span class="mf">555.0</span><span class="o">));</span>

<span class="c1">// compute the correlation using Pearson&#39;s method. Enter &quot;spearman&quot; for Spearman&#39;s method.</span>
<span class="c1">// If a method is not specified, Pearson&#39;s method will be used by default.</span>
<span class="n">Double</span> <span class="n">correlation</span> <span class="o">=</span> <span class="n">Statistics</span><span class="o">.</span><span class="na">corr</span><span class="o">(</span><span class="n">seriesX</span><span class="o">.</span><span class="na">srdd</span><span class="o">(),</span> <span class="n">seriesY</span><span class="o">.</span><span class="na">srdd</span><span class="o">(),</span> <span class="s">&quot;pearson&quot;</span><span class="o">);</span>
<span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">&quot;Correlation is: &quot;</span> <span class="o">+</span> <span class="n">correlation</span><span class="o">);</span>

<span class="c1">// note that each Vector is a row and not a column</span>
<span class="n">JavaRDD</span><span class="o">&lt;</span><span class="n">Vector</span><span class="o">&gt;</span> <span class="n">data</span> <span class="o">=</span> <span class="n">jsc</span><span class="o">.</span><span class="na">parallelize</span><span class="o">(</span>
  <span class="n">Arrays</span><span class="o">.</span><span class="na">asList</span><span class="o">(</span>
    <span class="n">Vectors</span><span class="o">.</span><span class="na">dense</span><span class="o">(</span><span class="mf">1.0</span><span class="o">,</span> <span class="mf">10.0</span><span class="o">,</span> <span class="mf">100.0</span><span class="o">),</span>
    <span class="n">Vectors</span><span class="o">.</span><span class="na">dense</span><span class="o">(</span><span class="mf">2.0</span><span class="o">,</span> <span class="mf">20.0</span><span class="o">,</span> <span class="mf">200.0</span><span class="o">),</span>
    <span class="n">Vectors</span><span class="o">.</span><span class="na">dense</span><span class="o">(</span><span class="mf">5.0</span><span class="o">,</span> <span class="mf">33.0</span><span class="o">,</span> <span class="mf">366.0</span><span class="o">)</span>
  <span class="o">)</span>
<span class="o">);</span>

<span class="c1">// calculate the correlation matrix using Pearson&#39;s method.</span>
<span class="c1">// Use &quot;spearman&quot; for Spearman&#39;s method.</span>
<span class="c1">// If a method is not specified, Pearson&#39;s method will be used by default.</span>
<span class="n">Matrix</span> <span class="n">correlMatrix</span> <span class="o">=</span> <span class="n">Statistics</span><span class="o">.</span><span class="na">corr</span><span class="o">(</span><span class="n">data</span><span class="o">.</span><span class="na">rdd</span><span class="o">(),</span> <span class="s">&quot;pearson&quot;</span><span class="o">);</span>
<span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="n">correlMatrix</span><span class="o">.</span><span class="na">toString</span><span class="o">());</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / java / org / apache / spark / examples / mllib / JavaCorrelationsExample.java”中找到完整的示例代码。</small></div>
  </div>

<div data-lang="python">
    <p><a href="api/python/pyspark.mllib.html#pyspark.mllib.stat.Statistics"><code>Statistics</code></a>提供了计算序列之间相关性的方法。根据输入的类型，两个<code>RDD[Double]</code>或<code>RDD[Vector]</code> ，输出将是<code>Double</code>或相关<code>Matrix</code>分别。</p>

    <p>请参阅<a href="api/python/pyspark.mllib.html#pyspark.mllib.stat.Statistics"><code>Statistics</code></a>有关该API的更多详细信息的<a href="api/python/pyspark.mllib.html#pyspark.mllib.stat.Statistics">Python文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pyspark.mllib.stat</span> <span class="kn">import</span> <span class="n">Statistics</span>

<span class="n">seriesX</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">parallelize</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">,</span> <span class="mf">5.0</span><span class="p">])</span>  <span class="c1"># a series</span>
<span class="c1"># seriesY must have the same number of partitions and cardinality as seriesX</span>
<span class="n">seriesY</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">parallelize</span><span class="p">([</span><span class="mf">11.0</span><span class="p">,</span> <span class="mf">22.0</span><span class="p">,</span> <span class="mf">33.0</span><span class="p">,</span> <span class="mf">33.0</span><span class="p">,</span> <span class="mf">555.0</span><span class="p">])</span>

<span class="c1"># Compute the correlation using Pearson&#39;s method. Enter &quot;spearman&quot; for Spearman&#39;s method.</span>
<span class="c1"># If a method is not specified, Pearson&#39;s method will be used by default.</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&quot;Correlation is: &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">Statistics</span><span class="o">.</span><span class="n">corr</span><span class="p">(</span><span class="n">seriesX</span><span class="p">,</span> <span class="n">seriesY</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s2">&quot;pearson&quot;</span><span class="p">)))</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">parallelize</span><span class="p">(</span>
    <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">10.0</span><span class="p">,</span> <span class="mf">100.0</span><span class="p">]),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">2.0</span><span class="p">,</span> <span class="mf">20.0</span><span class="p">,</span> <span class="mf">200.0</span><span class="p">]),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">5.0</span><span class="p">,</span> <span class="mf">33.0</span><span class="p">,</span> <span class="mf">366.0</span><span class="p">])]</span>
<span class="p">)</span>  <span class="c1"># an RDD of Vectors</span>

<span class="c1"># calculate the correlation matrix using Pearson&#39;s method. Use &quot;spearman&quot; for Spearman&#39;s method.</span>
<span class="c1"># If a method is not specified, Pearson&#39;s method will be used by default.</span>
<span class="k">print</span><span class="p">(</span><span class="n">Statistics</span><span class="o">.</span><span class="n">corr</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s2">&quot;pearson&quot;</span><span class="p">))</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / python / mllib / correlations_example.py”中找到完整的示例代码。</small></div>
  </div>

</div>

<h2 id="stratified-sampling">分层抽样</h2>

<p>与其他统计功能不同，后者位于<code>spark.mllib</code> ，分层抽样方法， <code>sampleByKey</code>和<code>sampleByKeyExact</code> ，可以对键/值对的RDD执行。对于分层采样，可以将键视为标签，将值视为特定属性。例如，键可以是男人或女人，或者是文档ID，并且相应的值可以是人口中人群的年龄列表或文档中的单词列表。的<code>sampleByKey</code>该方法将掷硬币来决定是否对观察结果进行采样，因此需要对数据进行一次传递，并提供<em>预期的</em>样本量。 <code>sampleByKeyExact</code>与用于<code>sampleByKey</code> ，但将以99.99％的置信度提供准确的抽样数量。 <code>sampleByKeyExact</code>目前不支援python。</p>

<div class="codetabs">
<div data-lang="scala">
    <p><a href="api/scala/index.html#org.apache.spark.rdd.PairRDDFunctions"><code>sampleByKeyExact()</code></a>允许用户精确采样$ \ lceil f_k \ cdot n_k \ rceil \，\ forall k \ in K $项目，其中$ f_k $是键$ k $的期望分数，$ n_k $是键值对的数量键$ k $，而$ K $是键集。无需替换的采样需要在RDD上再进行一次通过以确保样本量，而使用替换的采样则需要进行另外两次通过。</p>

    <div class="highlight"><pre><span></span><span class="c1">// an RDD[(K, V)] of any key value pairs</span>
<span class="k">val</span> <span class="n">data</span> <span class="k">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">parallelize</span><span class="o">(</span>
  <span class="nc">Seq</span><span class="o">((</span><span class="mi">1</span><span class="o">,</span> <span class="sc">&#39;a&#39;</span><span class="o">),</span> <span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="sc">&#39;b&#39;</span><span class="o">),</span> <span class="o">(</span><span class="mi">2</span><span class="o">,</span> <span class="sc">&#39;c&#39;</span><span class="o">),</span> <span class="o">(</span><span class="mi">2</span><span class="o">,</span> <span class="sc">&#39;d&#39;</span><span class="o">),</span> <span class="o">(</span><span class="mi">2</span><span class="o">,</span> <span class="sc">&#39;e&#39;</span><span class="o">),</span> <span class="o">(</span><span class="mi">3</span><span class="o">,</span> <span class="sc">&#39;f&#39;</span><span class="o">)))</span>

<span class="c1">// specify the exact fraction desired from each key</span>
<span class="k">val</span> <span class="n">fractions</span> <span class="k">=</span> <span class="nc">Map</span><span class="o">(</span><span class="mi">1</span> <span class="o">-&gt;</span> <span class="mf">0.1</span><span class="o">,</span> <span class="mi">2</span> <span class="o">-&gt;</span> <span class="mf">0.6</span><span class="o">,</span> <span class="mi">3</span> <span class="o">-&gt;</span> <span class="mf">0.3</span><span class="o">)</span>

<span class="c1">// Get an approximate sample from each stratum</span>
<span class="k">val</span> <span class="n">approxSample</span> <span class="k">=</span> <span class="n">data</span><span class="o">.</span><span class="n">sampleByKey</span><span class="o">(</span><span class="n">withReplacement</span> <span class="k">=</span> <span class="kc">false</span><span class="o">,</span> <span class="n">fractions</span> <span class="k">=</span> <span class="n">fractions</span><span class="o">)</span>
<span class="c1">// Get an exact sample from each stratum</span>
<span class="k">val</span> <span class="n">exactSample</span> <span class="k">=</span> <span class="n">data</span><span class="o">.</span><span class="n">sampleByKeyExact</span><span class="o">(</span><span class="n">withReplacement</span> <span class="k">=</span> <span class="kc">false</span><span class="o">,</span> <span class="n">fractions</span> <span class="k">=</span> <span class="n">fractions</span><span class="o">)</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / scala / org / apache / spark / examples / mllib / StratifiedSamplingExample.scala”中找到完整的示例代码。</small></div>
  </div>

<div data-lang="java">
    <p><a href="api/java/org/apache/spark/api/java/JavaPairRDD.html"><code>sampleByKeyExact()</code></a>允许用户精确采样$ \ lceil f_k \ cdot n_k \ rceil \，\ forall k \ in K $项目，其中$ f_k $是键$ k $的期望分数，$ n_k $是键值对的数量键$ k $，而$ K $是键集。无需替换的采样需要在RDD上再进行一次通过以确保样本量，而使用替换的采样则需要进行另外两次通过。</p>

    <div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">java.util.*</span><span class="o">;</span>

<span class="kn">import</span> <span class="nn">scala.Tuple2</span><span class="o">;</span>

<span class="kn">import</span> <span class="nn">org.apache.spark.api.java.JavaPairRDD</span><span class="o">;</span>

<span class="n">List</span><span class="o">&lt;</span><span class="n">Tuple2</span><span class="o">&lt;</span><span class="n">Integer</span><span class="o">,</span> <span class="n">Character</span><span class="o">&gt;&gt;</span> <span class="n">list</span> <span class="o">=</span> <span class="n">Arrays</span><span class="o">.</span><span class="na">asList</span><span class="o">(</span>
    <span class="k">new</span> <span class="n">Tuple2</span><span class="o">&lt;&gt;(</span><span class="mi">1</span><span class="o">,</span> <span class="sc">&#39;a&#39;</span><span class="o">),</span>
    <span class="k">new</span> <span class="n">Tuple2</span><span class="o">&lt;&gt;(</span><span class="mi">1</span><span class="o">,</span> <span class="sc">&#39;b&#39;</span><span class="o">),</span>
    <span class="k">new</span> <span class="n">Tuple2</span><span class="o">&lt;&gt;(</span><span class="mi">2</span><span class="o">,</span> <span class="sc">&#39;c&#39;</span><span class="o">),</span>
    <span class="k">new</span> <span class="n">Tuple2</span><span class="o">&lt;&gt;(</span><span class="mi">2</span><span class="o">,</span> <span class="sc">&#39;d&#39;</span><span class="o">),</span>
    <span class="k">new</span> <span class="n">Tuple2</span><span class="o">&lt;&gt;(</span><span class="mi">2</span><span class="o">,</span> <span class="sc">&#39;e&#39;</span><span class="o">),</span>
    <span class="k">new</span> <span class="n">Tuple2</span><span class="o">&lt;&gt;(</span><span class="mi">3</span><span class="o">,</span> <span class="sc">&#39;f&#39;</span><span class="o">)</span>
<span class="o">);</span>

<span class="n">JavaPairRDD</span><span class="o">&lt;</span><span class="n">Integer</span><span class="o">,</span> <span class="n">Character</span><span class="o">&gt;</span> <span class="n">data</span> <span class="o">=</span> <span class="n">jsc</span><span class="o">.</span><span class="na">parallelizePairs</span><span class="o">(</span><span class="n">list</span><span class="o">);</span>

<span class="c1">// specify the exact fraction desired from each key Map&lt;K, Double&gt;</span>
<span class="n">ImmutableMap</span><span class="o">&lt;</span><span class="n">Integer</span><span class="o">,</span> <span class="n">Double</span><span class="o">&gt;</span> <span class="n">fractions</span> <span class="o">=</span> <span class="n">ImmutableMap</span><span class="o">.</span><span class="na">of</span><span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="mf">0.1</span><span class="o">,</span> <span class="mi">2</span><span class="o">,</span> <span class="mf">0.6</span><span class="o">,</span> <span class="mi">3</span><span class="o">,</span> <span class="mf">0.3</span><span class="o">);</span>

<span class="c1">// Get an approximate sample from each stratum</span>
<span class="n">JavaPairRDD</span><span class="o">&lt;</span><span class="n">Integer</span><span class="o">,</span> <span class="n">Character</span><span class="o">&gt;</span> <span class="n">approxSample</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="na">sampleByKey</span><span class="o">(</span><span class="kc">false</span><span class="o">,</span> <span class="n">fractions</span><span class="o">);</span>
<span class="c1">// Get an exact sample from each stratum</span>
<span class="n">JavaPairRDD</span><span class="o">&lt;</span><span class="n">Integer</span><span class="o">,</span> <span class="n">Character</span><span class="o">&gt;</span> <span class="n">exactSample</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="na">sampleByKeyExact</span><span class="o">(</span><span class="kc">false</span><span class="o">,</span> <span class="n">fractions</span><span class="o">);</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / java / org / apache / spark / examples / mllib / JavaStratifiedSamplingExample.java”中找到完整的示例代码。</small></div>
  </div>
<div data-lang="python">
    <p><a href="api/python/pyspark.html#pyspark.RDD.sampleByKey"><code>sampleByKey()</code></a>允许用户采样大约$ \ lceil f_k \ cdot n_k \ rceil \，\ forall k \ in K $项目，其中$ f_k $是键$ k $的期望分数，$ n_k $是键值对的数量键$ k $，而$ K $是键集。</p>

    <p><em>注意：</em> <code>sampleByKeyExact()</code>目前不支持Python。</p>

    <div class="highlight"><pre><span></span><span class="c1"># an RDD of any key value pairs</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">parallelize</span><span class="p">([(</span><span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;a&#39;</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="s1">&#39;c&#39;</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="s1">&#39;d&#39;</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="s1">&#39;e&#39;</span><span class="p">),</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="s1">&#39;f&#39;</span><span class="p">)])</span>

<span class="c1"># specify the exact fraction desired from each key as a dictionary</span>
<span class="n">fractions</span> <span class="o">=</span> <span class="p">{</span><span class="mi">1</span><span class="p">:</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mi">2</span><span class="p">:</span> <span class="mf">0.6</span><span class="p">,</span> <span class="mi">3</span><span class="p">:</span> <span class="mf">0.3</span><span class="p">}</span>

<span class="n">approxSample</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">sampleByKey</span><span class="p">(</span><span class="bp">False</span><span class="p">,</span> <span class="n">fractions</span><span class="p">)</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / python / mllib / stratified_sampling_example.py”中找到完整的示例代码。</small></div>
  </div>

</div>

<h2 id="hypothesis-testing">假设检验</h2>

<p>假设检验是一种强大的统计工具，可用来确定结果是否具有统计学意义，以及该结果是否偶然发生。 <code>spark.mllib</code>目前支持皮尔逊（Pearson）的卡方（$ \ chi ^ 2 $）测试，以证明其适合性和独立性。输入数据类型确定是否进行拟合优度或独立性测试。拟合优度检验要求输入类型为<code>Vector</code> ，而独立性测试则需要<code>Matrix</code>作为输入。</p>

<p><code>spark.mllib</code>也支持输入类型<code>RDD[LabeledPoint]</code>通过卡方独立性测试启用特征选择。</p>

<div class="codetabs">
<div data-lang="scala">
    <p><a href="api/scala/index.html#org.apache.spark.mllib.stat.Statistics$"><code>Statistics</code></a>提供了运行Pearson卡方检验的方法。以下示例演示了如何运行和解释假设检验。</p>

    <div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">org.apache.spark.mllib.linalg._</span>
<span class="k">import</span> <span class="nn">org.apache.spark.mllib.regression.LabeledPoint</span>
<span class="k">import</span> <span class="nn">org.apache.spark.mllib.stat.Statistics</span>
<span class="k">import</span> <span class="nn">org.apache.spark.mllib.stat.test.ChiSqTestResult</span>
<span class="k">import</span> <span class="nn">org.apache.spark.rdd.RDD</span>

<span class="c1">// a vector composed of the frequencies of events</span>
<span class="k">val</span> <span class="n">vec</span><span class="k">:</span> <span class="kt">Vector</span> <span class="o">=</span> <span class="nc">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="o">(</span><span class="mf">0.1</span><span class="o">,</span> <span class="mf">0.15</span><span class="o">,</span> <span class="mf">0.2</span><span class="o">,</span> <span class="mf">0.3</span><span class="o">,</span> <span class="mf">0.25</span><span class="o">)</span>

<span class="c1">// compute the goodness of fit. If a second vector to test against is not supplied</span>
<span class="c1">// as a parameter, the test runs against a uniform distribution.</span>
<span class="k">val</span> <span class="n">goodnessOfFitTestResult</span> <span class="k">=</span> <span class="nc">Statistics</span><span class="o">.</span><span class="n">chiSqTest</span><span class="o">(</span><span class="n">vec</span><span class="o">)</span>
<span class="c1">// summary of the test including the p-value, degrees of freedom, test statistic, the method</span>
<span class="c1">// used, and the null hypothesis.</span>
<span class="n">println</span><span class="o">(</span><span class="s">s&quot;</span><span class="si">$goodnessOfFitTestResult</span><span class="s">\n&quot;</span><span class="o">)</span>

<span class="c1">// a contingency matrix. Create a dense matrix ((1.0, 2.0), (3.0, 4.0), (5.0, 6.0))</span>
<span class="k">val</span> <span class="n">mat</span><span class="k">:</span> <span class="kt">Matrix</span> <span class="o">=</span> <span class="nc">Matrices</span><span class="o">.</span><span class="n">dense</span><span class="o">(</span><span class="mi">3</span><span class="o">,</span> <span class="mi">2</span><span class="o">,</span> <span class="nc">Array</span><span class="o">(</span><span class="mf">1.0</span><span class="o">,</span> <span class="mf">3.0</span><span class="o">,</span> <span class="mf">5.0</span><span class="o">,</span> <span class="mf">2.0</span><span class="o">,</span> <span class="mf">4.0</span><span class="o">,</span> <span class="mf">6.0</span><span class="o">))</span>

<span class="c1">// conduct Pearson&#39;s independence test on the input contingency matrix</span>
<span class="k">val</span> <span class="n">independenceTestResult</span> <span class="k">=</span> <span class="nc">Statistics</span><span class="o">.</span><span class="n">chiSqTest</span><span class="o">(</span><span class="n">mat</span><span class="o">)</span>
<span class="c1">// summary of the test including the p-value, degrees of freedom</span>
<span class="n">println</span><span class="o">(</span><span class="s">s&quot;</span><span class="si">$independenceTestResult</span><span class="s">\n&quot;</span><span class="o">)</span>

<span class="k">val</span> <span class="n">obs</span><span class="k">:</span> <span class="kt">RDD</span><span class="o">[</span><span class="kt">LabeledPoint</span><span class="o">]</span> <span class="k">=</span>
  <span class="n">sc</span><span class="o">.</span><span class="n">parallelize</span><span class="o">(</span>
    <span class="nc">Seq</span><span class="o">(</span>
      <span class="nc">LabeledPoint</span><span class="o">(</span><span class="mf">1.0</span><span class="o">,</span> <span class="nc">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="o">(</span><span class="mf">1.0</span><span class="o">,</span> <span class="mf">0.0</span><span class="o">,</span> <span class="mf">3.0</span><span class="o">)),</span>
      <span class="nc">LabeledPoint</span><span class="o">(</span><span class="mf">1.0</span><span class="o">,</span> <span class="nc">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="o">(</span><span class="mf">1.0</span><span class="o">,</span> <span class="mf">2.0</span><span class="o">,</span> <span class="mf">0.0</span><span class="o">)),</span>
      <span class="nc">LabeledPoint</span><span class="o">(-</span><span class="mf">1.0</span><span class="o">,</span> <span class="nc">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="o">(-</span><span class="mf">1.0</span><span class="o">,</span> <span class="mf">0.0</span><span class="o">,</span> <span class="o">-</span><span class="mf">0.5</span><span class="o">)</span>
      <span class="o">)</span>
    <span class="o">)</span>
  <span class="o">)</span> <span class="c1">// (label, feature) pairs.</span>

<span class="c1">// The contingency table is constructed from the raw (label, feature) pairs and used to conduct</span>
<span class="c1">// the independence test. Returns an array containing the ChiSquaredTestResult for every feature</span>
<span class="c1">// against the label.</span>
<span class="k">val</span> <span class="n">featureTestResults</span><span class="k">:</span> <span class="kt">Array</span><span class="o">[</span><span class="kt">ChiSqTestResult</span><span class="o">]</span> <span class="k">=</span> <span class="nc">Statistics</span><span class="o">.</span><span class="n">chiSqTest</span><span class="o">(</span><span class="n">obs</span><span class="o">)</span>
<span class="n">featureTestResults</span><span class="o">.</span><span class="n">zipWithIndex</span><span class="o">.</span><span class="n">foreach</span> <span class="o">{</span> <span class="k">case</span> <span class="o">(</span><span class="n">k</span><span class="o">,</span> <span class="n">v</span><span class="o">)</span> <span class="k">=&gt;</span>
  <span class="n">println</span><span class="o">(</span><span class="s">s&quot;Column </span><span class="si">${</span><span class="o">(</span><span class="n">v</span> <span class="o">+</span> <span class="mi">1</span><span class="o">)</span><span class="si">}</span><span class="s"> :&quot;</span><span class="o">)</span>
  <span class="n">println</span><span class="o">(</span><span class="n">k</span><span class="o">)</span>
<span class="o">}</span>  <span class="c1">// summary of the test</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / scala / org / apache / spark / examples / mllib / HypothesisTestingExample.scala”中找到完整的示例代码。</small></div>
  </div>

<div data-lang="java">
    <p><a href="api/java/org/apache/spark/mllib/stat/Statistics.html"><code>Statistics</code></a>提供了运行Pearson卡方检验的方法。以下示例演示了如何运行和解释假设检验。</p>

    <p>请参阅<a href="api/java/org/apache/spark/mllib/stat/test/ChiSqTestResult.html"><code>ChiSqTestResult</code></a>有关该API的详细信息的<a href="api/java/org/apache/spark/mllib/stat/test/ChiSqTestResult.html">Java文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">java.util.Arrays</span><span class="o">;</span>

<span class="kn">import</span> <span class="nn">org.apache.spark.api.java.JavaRDD</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.mllib.linalg.Matrices</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.mllib.linalg.Matrix</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.mllib.linalg.Vector</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.mllib.linalg.Vectors</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.mllib.regression.LabeledPoint</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.mllib.stat.Statistics</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.mllib.stat.test.ChiSqTestResult</span><span class="o">;</span>

<span class="c1">// a vector composed of the frequencies of events</span>
<span class="n">Vector</span> <span class="n">vec</span> <span class="o">=</span> <span class="n">Vectors</span><span class="o">.</span><span class="na">dense</span><span class="o">(</span><span class="mf">0.1</span><span class="o">,</span> <span class="mf">0.15</span><span class="o">,</span> <span class="mf">0.2</span><span class="o">,</span> <span class="mf">0.3</span><span class="o">,</span> <span class="mf">0.25</span><span class="o">);</span>

<span class="c1">// compute the goodness of fit. If a second vector to test against is not supplied</span>
<span class="c1">// as a parameter, the test runs against a uniform distribution.</span>
<span class="n">ChiSqTestResult</span> <span class="n">goodnessOfFitTestResult</span> <span class="o">=</span> <span class="n">Statistics</span><span class="o">.</span><span class="na">chiSqTest</span><span class="o">(</span><span class="n">vec</span><span class="o">);</span>
<span class="c1">// summary of the test including the p-value, degrees of freedom, test statistic,</span>
<span class="c1">// the method used, and the null hypothesis.</span>
<span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="n">goodnessOfFitTestResult</span> <span class="o">+</span> <span class="s">&quot;\n&quot;</span><span class="o">);</span>

<span class="c1">// Create a contingency matrix ((1.0, 2.0), (3.0, 4.0), (5.0, 6.0))</span>
<span class="n">Matrix</span> <span class="n">mat</span> <span class="o">=</span> <span class="n">Matrices</span><span class="o">.</span><span class="na">dense</span><span class="o">(</span><span class="mi">3</span><span class="o">,</span> <span class="mi">2</span><span class="o">,</span> <span class="k">new</span> <span class="kt">double</span><span class="o">[]{</span><span class="mf">1.0</span><span class="o">,</span> <span class="mf">3.0</span><span class="o">,</span> <span class="mf">5.0</span><span class="o">,</span> <span class="mf">2.0</span><span class="o">,</span> <span class="mf">4.0</span><span class="o">,</span> <span class="mf">6.0</span><span class="o">});</span>

<span class="c1">// conduct Pearson&#39;s independence test on the input contingency matrix</span>
<span class="n">ChiSqTestResult</span> <span class="n">independenceTestResult</span> <span class="o">=</span> <span class="n">Statistics</span><span class="o">.</span><span class="na">chiSqTest</span><span class="o">(</span><span class="n">mat</span><span class="o">);</span>
<span class="c1">// summary of the test including the p-value, degrees of freedom...</span>
<span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="n">independenceTestResult</span> <span class="o">+</span> <span class="s">&quot;\n&quot;</span><span class="o">);</span>

<span class="c1">// an RDD of labeled points</span>
<span class="n">JavaRDD</span><span class="o">&lt;</span><span class="n">LabeledPoint</span><span class="o">&gt;</span> <span class="n">obs</span> <span class="o">=</span> <span class="n">jsc</span><span class="o">.</span><span class="na">parallelize</span><span class="o">(</span>
  <span class="n">Arrays</span><span class="o">.</span><span class="na">asList</span><span class="o">(</span>
    <span class="k">new</span> <span class="n">LabeledPoint</span><span class="o">(</span><span class="mf">1.0</span><span class="o">,</span> <span class="n">Vectors</span><span class="o">.</span><span class="na">dense</span><span class="o">(</span><span class="mf">1.0</span><span class="o">,</span> <span class="mf">0.0</span><span class="o">,</span> <span class="mf">3.0</span><span class="o">)),</span>
    <span class="k">new</span> <span class="n">LabeledPoint</span><span class="o">(</span><span class="mf">1.0</span><span class="o">,</span> <span class="n">Vectors</span><span class="o">.</span><span class="na">dense</span><span class="o">(</span><span class="mf">1.0</span><span class="o">,</span> <span class="mf">2.0</span><span class="o">,</span> <span class="mf">0.0</span><span class="o">)),</span>
    <span class="k">new</span> <span class="n">LabeledPoint</span><span class="o">(-</span><span class="mf">1.0</span><span class="o">,</span> <span class="n">Vectors</span><span class="o">.</span><span class="na">dense</span><span class="o">(-</span><span class="mf">1.0</span><span class="o">,</span> <span class="mf">0.0</span><span class="o">,</span> <span class="o">-</span><span class="mf">0.5</span><span class="o">))</span>
  <span class="o">)</span>
<span class="o">);</span>

<span class="c1">// The contingency table is constructed from the raw (label, feature) pairs and used to conduct</span>
<span class="c1">// the independence test. Returns an array containing the ChiSquaredTestResult for every feature</span>
<span class="c1">// against the label.</span>
<span class="n">ChiSqTestResult</span><span class="o">[]</span> <span class="n">featureTestResults</span> <span class="o">=</span> <span class="n">Statistics</span><span class="o">.</span><span class="na">chiSqTest</span><span class="o">(</span><span class="n">obs</span><span class="o">.</span><span class="na">rdd</span><span class="o">());</span>
<span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">1</span><span class="o">;</span>
<span class="k">for</span> <span class="o">(</span><span class="n">ChiSqTestResult</span> <span class="n">result</span> <span class="o">:</span> <span class="n">featureTestResults</span><span class="o">)</span> <span class="o">{</span>
  <span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">&quot;Column &quot;</span> <span class="o">+</span> <span class="n">i</span> <span class="o">+</span> <span class="s">&quot;:&quot;</span><span class="o">);</span>
  <span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="n">result</span> <span class="o">+</span> <span class="s">&quot;\n&quot;</span><span class="o">);</span>  <span class="c1">// summary of the test</span>
  <span class="n">i</span><span class="o">++;</span>
<span class="o">}</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / java / org / apache / spark / examples / mllib / JavaHypothesisTestingExample.java”中找到完整的示例代码。</small></div>
  </div>

<div data-lang="python">
    <p><a href="api/python/index.html#pyspark.mllib.stat.Statistics$"><code>Statistics</code></a>提供了运行Pearson卡方检验的方法。以下示例演示了如何运行和解释假设检验。</p>

    <p>请参阅<a href="api/python/pyspark.mllib.html#pyspark.mllib.stat.Statistics"><code>Statistics</code></a>有关该API的更多详细信息的<a href="api/python/pyspark.mllib.html#pyspark.mllib.stat.Statistics">Python文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pyspark.mllib.linalg</span> <span class="kn">import</span> <span class="n">Matrices</span><span class="p">,</span> <span class="n">Vectors</span>
<span class="kn">from</span> <span class="nn">pyspark.mllib.regression</span> <span class="kn">import</span> <span class="n">LabeledPoint</span>
<span class="kn">from</span> <span class="nn">pyspark.mllib.stat</span> <span class="kn">import</span> <span class="n">Statistics</span>

<span class="n">vec</span> <span class="o">=</span> <span class="n">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.15</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">)</span>  <span class="c1"># a vector composed of the frequencies of events</span>

<span class="c1"># compute the goodness of fit. If a second vector to test against</span>
<span class="c1"># is not supplied as a parameter, the test runs against a uniform distribution.</span>
<span class="n">goodnessOfFitTestResult</span> <span class="o">=</span> <span class="n">Statistics</span><span class="o">.</span><span class="n">chiSqTest</span><span class="p">(</span><span class="n">vec</span><span class="p">)</span>

<span class="c1"># summary of the test including the p-value, degrees of freedom,</span>
<span class="c1"># test statistic, the method used, and the null hypothesis.</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">%s</span><span class="se">\n</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">goodnessOfFitTestResult</span><span class="p">)</span>

<span class="n">mat</span> <span class="o">=</span> <span class="n">Matrices</span><span class="o">.</span><span class="n">dense</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="p">[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">,</span> <span class="mf">5.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mf">4.0</span><span class="p">,</span> <span class="mf">6.0</span><span class="p">])</span>  <span class="c1"># a contingency matrix</span>

<span class="c1"># conduct Pearson&#39;s independence test on the input contingency matrix</span>
<span class="n">independenceTestResult</span> <span class="o">=</span> <span class="n">Statistics</span><span class="o">.</span><span class="n">chiSqTest</span><span class="p">(</span><span class="n">mat</span><span class="p">)</span>

<span class="c1"># summary of the test including the p-value, degrees of freedom,</span>
<span class="c1"># test statistic, the method used, and the null hypothesis.</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">%s</span><span class="se">\n</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">independenceTestResult</span><span class="p">)</span>

<span class="n">obs</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">parallelize</span><span class="p">(</span>
    <span class="p">[</span><span class="n">LabeledPoint</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="p">[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">]),</span>
     <span class="n">LabeledPoint</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="p">[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">]),</span>
     <span class="n">LabeledPoint</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5</span><span class="p">])]</span>
<span class="p">)</span>  <span class="c1"># LabeledPoint(label, feature)</span>

<span class="c1"># The contingency table is constructed from an RDD of LabeledPoint and used to conduct</span>
<span class="c1"># the independence test. Returns an array containing the ChiSquaredTestResult for every feature</span>
<span class="c1"># against the label.</span>
<span class="n">featureTestResults</span> <span class="o">=</span> <span class="n">Statistics</span><span class="o">.</span><span class="n">chiSqTest</span><span class="p">(</span><span class="n">obs</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">result</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">featureTestResults</span><span class="p">):</span>
    <span class="k">print</span><span class="p">(</span><span class="s2">&quot;Column </span><span class="si">%d</span><span class="s2">:</span><span class="se">\n</span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">result</span><span class="p">))</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / python / mllib / hypothesis_testing_example.py”中找到完整的示例代码。</small></div>
  </div>

</div>

<p>另外， <code>spark.mllib</code>提供了Kolmogorov-Smirnov（KS）测试的1-样本，两面实现，以实现概率分布的相等性。通过提供理论分布的名称（当前仅支持正态分布）及其参数，或提供根据给定的理论分布计算累积分布的函数，用户可以检验零假设，即从该假设中抽取样本分配。如果用户针对正态分布进行测试（ <code>distName="norm"</code> ）（但不提供分发参数），则测试会初始化为标准正态分布并记录一条适当的消息。</p>

<div class="codetabs">
<div data-lang="scala">
    <p><a href="api/scala/index.html#org.apache.spark.mllib.stat.Statistics$"><code>Statistics</code></a>提供了运行1样本，2面Kolmogorov-Smirnov测试的方法。以下示例演示了如何运行和解释假设检验。</p>

    <p>请参阅<a href="api/scala/index.html#org.apache.spark.mllib.stat.Statistics$"><code>Statistics</code></a>有关API的详细信息，请参见<a href="api/scala/index.html#org.apache.spark.mllib.stat.Statistics$">Scala文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">org.apache.spark.mllib.stat.Statistics</span>
<span class="k">import</span> <span class="nn">org.apache.spark.rdd.RDD</span>

<span class="k">val</span> <span class="n">data</span><span class="k">:</span> <span class="kt">RDD</span><span class="o">[</span><span class="kt">Double</span><span class="o">]</span> <span class="k">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">parallelize</span><span class="o">(</span><span class="nc">Seq</span><span class="o">(</span><span class="mf">0.1</span><span class="o">,</span> <span class="mf">0.15</span><span class="o">,</span> <span class="mf">0.2</span><span class="o">,</span> <span class="mf">0.3</span><span class="o">,</span> <span class="mf">0.25</span><span class="o">))</span>  <span class="c1">// an RDD of sample data</span>

<span class="c1">// run a KS test for the sample versus a standard normal distribution</span>
<span class="k">val</span> <span class="n">testResult</span> <span class="k">=</span> <span class="nc">Statistics</span><span class="o">.</span><span class="n">kolmogorovSmirnovTest</span><span class="o">(</span><span class="n">data</span><span class="o">,</span> <span class="s">&quot;norm&quot;</span><span class="o">,</span> <span class="mi">0</span><span class="o">,</span> <span class="mi">1</span><span class="o">)</span>
<span class="c1">// summary of the test including the p-value, test statistic, and null hypothesis if our p-value</span>
<span class="c1">// indicates significance, we can reject the null hypothesis.</span>
<span class="n">println</span><span class="o">(</span><span class="n">testResult</span><span class="o">)</span>
<span class="n">println</span><span class="o">()</span>

<span class="c1">// perform a KS test using a cumulative distribution function of our making</span>
<span class="k">val</span> <span class="n">myCDF</span> <span class="k">=</span> <span class="nc">Map</span><span class="o">(</span><span class="mf">0.1</span> <span class="o">-&gt;</span> <span class="mf">0.2</span><span class="o">,</span> <span class="mf">0.15</span> <span class="o">-&gt;</span> <span class="mf">0.6</span><span class="o">,</span> <span class="mf">0.2</span> <span class="o">-&gt;</span> <span class="mf">0.05</span><span class="o">,</span> <span class="mf">0.3</span> <span class="o">-&gt;</span> <span class="mf">0.05</span><span class="o">,</span> <span class="mf">0.25</span> <span class="o">-&gt;</span> <span class="mf">0.1</span><span class="o">)</span>
<span class="k">val</span> <span class="n">testResult2</span> <span class="k">=</span> <span class="nc">Statistics</span><span class="o">.</span><span class="n">kolmogorovSmirnovTest</span><span class="o">(</span><span class="n">data</span><span class="o">,</span> <span class="n">myCDF</span><span class="o">)</span>
<span class="n">println</span><span class="o">(</span><span class="n">testResult2</span><span class="o">)</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / scala / org / apache / spark / examples / mllib / HypothesisTestingKolmogorovSmirnovTestExample.scala”中找到完整的示例代码。</small></div>
  </div>

<div data-lang="java">
    <p><a href="api/java/org/apache/spark/mllib/stat/Statistics.html"><code>Statistics</code></a>提供了运行1样本，2面Kolmogorov-Smirnov测试的方法。以下示例演示了如何运行和解释假设检验。</p>

    <p>请参阅<a href="api/java/org/apache/spark/mllib/stat/Statistics.html"><code>Statistics</code></a>有关该API的详细信息的<a href="api/java/org/apache/spark/mllib/stat/Statistics.html">Java文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">java.util.Arrays</span><span class="o">;</span>

<span class="kn">import</span> <span class="nn">org.apache.spark.api.java.JavaDoubleRDD</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.mllib.stat.Statistics</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.mllib.stat.test.KolmogorovSmirnovTestResult</span><span class="o">;</span>

<span class="n">JavaDoubleRDD</span> <span class="n">data</span> <span class="o">=</span> <span class="n">jsc</span><span class="o">.</span><span class="na">parallelizeDoubles</span><span class="o">(</span><span class="n">Arrays</span><span class="o">.</span><span class="na">asList</span><span class="o">(</span><span class="mf">0.1</span><span class="o">,</span> <span class="mf">0.15</span><span class="o">,</span> <span class="mf">0.2</span><span class="o">,</span> <span class="mf">0.3</span><span class="o">,</span> <span class="mf">0.25</span><span class="o">));</span>
<span class="n">KolmogorovSmirnovTestResult</span> <span class="n">testResult</span> <span class="o">=</span>
  <span class="n">Statistics</span><span class="o">.</span><span class="na">kolmogorovSmirnovTest</span><span class="o">(</span><span class="n">data</span><span class="o">,</span> <span class="s">&quot;norm&quot;</span><span class="o">,</span> <span class="mf">0.0</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">);</span>
<span class="c1">// summary of the test including the p-value, test statistic, and null hypothesis</span>
<span class="c1">// if our p-value indicates significance, we can reject the null hypothesis</span>
<span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="n">testResult</span><span class="o">);</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / java / org / apache / spark / examples / mllib / JavaHypothesisTestingKolmogorovSmirnovTestExample.java”中找到完整的示例代码。</small></div>
  </div>

<div data-lang="python">
    <p><a href="api/python/pyspark.mllib.html#pyspark.mllib.stat.Statistics"><code>Statistics</code></a>提供了运行1样本，2面Kolmogorov-Smirnov测试的方法。以下示例演示了如何运行和解释假设检验。</p>

    <p>请参阅<a href="api/python/pyspark.mllib.html#pyspark.mllib.stat.Statistics"><code>Statistics</code></a>有关该API的更多详细信息的<a href="api/python/pyspark.mllib.html#pyspark.mllib.stat.Statistics">Python文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pyspark.mllib.stat</span> <span class="kn">import</span> <span class="n">Statistics</span>

<span class="n">parallelData</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">parallelize</span><span class="p">([</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.15</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">])</span>

<span class="c1"># run a KS test for the sample versus a standard normal distribution</span>
<span class="n">testResult</span> <span class="o">=</span> <span class="n">Statistics</span><span class="o">.</span><span class="n">kolmogorovSmirnovTest</span><span class="p">(</span><span class="n">parallelData</span><span class="p">,</span> <span class="s2">&quot;norm&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="c1"># summary of the test including the p-value, test statistic, and null hypothesis</span>
<span class="c1"># if our p-value indicates significance, we can reject the null hypothesis</span>
<span class="c1"># Note that the Scala functionality of calling Statistics.kolmogorovSmirnovTest with</span>
<span class="c1"># a lambda to calculate the CDF is not made available in the Python API</span>
<span class="k">print</span><span class="p">(</span><span class="n">testResult</span><span class="p">)</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / python / mllib / hypothesis_testing_kolmogorov_smirnov_test_example.py”中找到完整的示例代码。</small></div>
  </div>
</div>

<h3 id="streaming-significance-testing">流重要性测试</h3>
<p><code>spark.mllib</code>提供一些测试的在线实施以支持A / B测试等用例。这些测试可以在Spark Streaming上执行<code>DStream[(Boolean,Double)]</code>其中每个元组的第一个元素表示对照组（ <code>false</code> ）或治疗组（ <code>true</code> ），第二个元素是观察值。</p>

<p>流重要性测试支持以下参数：</p>

<ul>
  <li><code>peacePeriod</code> -流中要忽略的初始数据点的数量，用于减轻新颖性的影响。</li>
  <li><code>windowSize</code> -进行假设检验的过去批次的数量。设定为<code>0</code>将使用所有先前的批次执行累积处理。</li>
</ul>

<div class="codetabs">
<div data-lang="scala">
    <p><a href="api/scala/index.html#org.apache.spark.mllib.stat.test.StreamingTest"><code>StreamingTest</code></a>提供流假设检验。</p>

    <div class="highlight"><pre><span></span><span class="k">val</span> <span class="n">data</span> <span class="k">=</span> <span class="n">ssc</span><span class="o">.</span><span class="n">textFileStream</span><span class="o">(</span><span class="n">dataDir</span><span class="o">).</span><span class="n">map</span><span class="o">(</span><span class="n">line</span> <span class="k">=&gt;</span> <span class="n">line</span><span class="o">.</span><span class="n">split</span><span class="o">(</span><span class="s">&quot;,&quot;</span><span class="o">)</span> <span class="k">match</span> <span class="o">{</span>
  <span class="k">case</span> <span class="nc">Array</span><span class="o">(</span><span class="n">label</span><span class="o">,</span> <span class="n">value</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="nc">BinarySample</span><span class="o">(</span><span class="n">label</span><span class="o">.</span><span class="n">toBoolean</span><span class="o">,</span> <span class="n">value</span><span class="o">.</span><span class="n">toDouble</span><span class="o">)</span>
<span class="o">})</span>

<span class="k">val</span> <span class="n">streamingTest</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">StreamingTest</span><span class="o">()</span>
  <span class="o">.</span><span class="n">setPeacePeriod</span><span class="o">(</span><span class="mi">0</span><span class="o">)</span>
  <span class="o">.</span><span class="n">setWindowSize</span><span class="o">(</span><span class="mi">0</span><span class="o">)</span>
  <span class="o">.</span><span class="n">setTestMethod</span><span class="o">(</span><span class="s">&quot;welch&quot;</span><span class="o">)</span>

<span class="k">val</span> <span class="n">out</span> <span class="k">=</span> <span class="n">streamingTest</span><span class="o">.</span><span class="n">registerStream</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>
<span class="n">out</span><span class="o">.</span><span class="n">print</span><span class="o">()</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / scala / org / apache / spark / examples / mllib / StreamingTestExample.scala”中找到完整的示例代码。</small></div>
  </div>

<div data-lang="java">
    <p><a href="api/java/index.html#org.apache.spark.mllib.stat.test.StreamingTest"><code>StreamingTest</code></a>提供流假设检验。</p>

    <div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">org.apache.spark.mllib.stat.test.BinarySample</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.mllib.stat.test.StreamingTest</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.mllib.stat.test.StreamingTestResult</span><span class="o">;</span>

<span class="n">JavaDStream</span><span class="o">&lt;</span><span class="n">BinarySample</span><span class="o">&gt;</span> <span class="n">data</span> <span class="o">=</span> <span class="n">ssc</span><span class="o">.</span><span class="na">textFileStream</span><span class="o">(</span><span class="n">dataDir</span><span class="o">).</span><span class="na">map</span><span class="o">(</span><span class="n">line</span> <span class="o">-&gt;</span> <span class="o">{</span>
  <span class="n">String</span><span class="o">[]</span> <span class="n">ts</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="na">split</span><span class="o">(</span><span class="s">&quot;,&quot;</span><span class="o">);</span>
  <span class="kt">boolean</span> <span class="n">label</span> <span class="o">=</span> <span class="n">Boolean</span><span class="o">.</span><span class="na">parseBoolean</span><span class="o">(</span><span class="n">ts</span><span class="o">[</span><span class="mi">0</span><span class="o">]);</span>
  <span class="kt">double</span> <span class="n">value</span> <span class="o">=</span> <span class="n">Double</span><span class="o">.</span><span class="na">parseDouble</span><span class="o">(</span><span class="n">ts</span><span class="o">[</span><span class="mi">1</span><span class="o">]);</span>
  <span class="k">return</span> <span class="k">new</span> <span class="n">BinarySample</span><span class="o">(</span><span class="n">label</span><span class="o">,</span> <span class="n">value</span><span class="o">);</span>
<span class="o">});</span>

<span class="n">StreamingTest</span> <span class="n">streamingTest</span> <span class="o">=</span> <span class="k">new</span> <span class="n">StreamingTest</span><span class="o">()</span>
  <span class="o">.</span><span class="na">setPeacePeriod</span><span class="o">(</span><span class="mi">0</span><span class="o">)</span>
  <span class="o">.</span><span class="na">setWindowSize</span><span class="o">(</span><span class="mi">0</span><span class="o">)</span>
  <span class="o">.</span><span class="na">setTestMethod</span><span class="o">(</span><span class="s">&quot;welch&quot;</span><span class="o">);</span>

<span class="n">JavaDStream</span><span class="o">&lt;</span><span class="n">StreamingTestResult</span><span class="o">&gt;</span> <span class="n">out</span> <span class="o">=</span> <span class="n">streamingTest</span><span class="o">.</span><span class="na">registerStream</span><span class="o">(</span><span class="n">data</span><span class="o">);</span>
<span class="n">out</span><span class="o">.</span><span class="na">print</span><span class="o">();</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / java / org / apache / spark / examples / mllib / JavaStreamingTestExample.java”中找到完整的示例代码。</small></div>
  </div>
</div>

<h2 id="random-data-generation">随机数据生成</h2>

<p>随机数据生成对于随机算法，原型设计和性能测试很有用。
<code>spark.mllib</code>支持生成具有从给定分布（均一，标准正态或泊松）得出的iid值的随机RDD。</p>

<div class="codetabs">
<div data-lang="scala">
    <p><a href="api/scala/index.html#org.apache.spark.mllib.random.RandomRDDs$"><code>RandomRDDs</code></a>提供了用于生成随机双RDD或矢量RDD的工厂方法。以下示例生成一个随机双RDD，其值遵循标准正态分布<code>N(0, 1)</code> ，然后将其映射到<code>N(1, 4)</code> 。</p>

    <p>请参阅<a href="api/scala/index.html#org.apache.spark.mllib.random.RandomRDDs$"><code>RandomRDDs</code></a>有关API的详细信息，请参见<a href="api/scala/index.html#org.apache.spark.mllib.random.RandomRDDs$">Scala文档</a> 。</p>

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span></span><span class="k">import</span> <span class="nn">org.apache.spark.SparkContext</span>
<span class="k">import</span> <span class="nn">org.apache.spark.mllib.random.RandomRDDs._</span>

<span class="k">val</span> <span class="n">sc</span><span class="k">:</span> <span class="kt">SparkContext</span> <span class="o">=</span> <span class="o">...</span>

<span class="c1">// Generate a random double RDD that contains 1 million i.i.d. values drawn from the</span>
<span class="c1">// standard normal distribution `N(0, 1)`, evenly distributed in 10 partitions.</span>
<span class="k">val</span> <span class="n">u</span> <span class="k">=</span> <span class="n">normalRDD</span><span class="o">(</span><span class="n">sc</span><span class="o">,</span> <span class="mi">1000000L</span><span class="o">,</span> <span class="mi">10</span><span class="o">)</span>
<span class="c1">// Apply a transform to get a random double RDD following `N(1, 4)`.</span>
<span class="k">val</span> <span class="n">v</span> <span class="k">=</span> <span class="n">u</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="n">x</span> <span class="k">=&gt;</span> <span class="mf">1.0</span> <span class="o">+</span> <span class="mf">2.0</span> <span class="o">*</span> <span class="n">x</span><span class="o">)</span></code></pre></figure>

  </div>

<div data-lang="java">
    <p><a href="api/java/index.html#org.apache.spark.mllib.random.RandomRDDs"><code>RandomRDDs</code></a>提供了用于生成随机双RDD或矢量RDD的工厂方法。以下示例生成一个随机双RDD，其值遵循标准正态分布<code>N(0, 1)</code> ，然后将其映射到<code>N(1, 4)</code> 。</p>

    <p>请参阅<a href="api/java/org/apache/spark/mllib/random/RandomRDDs"><code>RandomRDDs</code></a>有关该API的详细信息的<a href="api/java/org/apache/spark/mllib/random/RandomRDDs">Java文档</a> 。</p>

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span></span><span class="kn">import</span> <span class="nn">org.apache.spark.SparkContext</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.api.JavaDoubleRDD</span><span class="o">;</span>
<span class="kn">import static</span> <span class="nn">org.apache.spark.mllib.random.RandomRDDs.*</span><span class="o">;</span>

<span class="n">JavaSparkContext</span> <span class="n">jsc</span> <span class="o">=</span> <span class="o">...</span>

<span class="c1">// Generate a random double RDD that contains 1 million i.i.d. values drawn from the</span>
<span class="c1">// standard normal distribution `N(0, 1)`, evenly distributed in 10 partitions.</span>
<span class="n">JavaDoubleRDD</span> <span class="n">u</span> <span class="o">=</span> <span class="n">normalJavaRDD</span><span class="o">(</span><span class="n">jsc</span><span class="o">,</span> <span class="mi">1000000L</span><span class="o">,</span> <span class="mi">10</span><span class="o">);</span>
<span class="c1">// Apply a transform to get a random double RDD following `N(1, 4)`.</span>
<span class="n">JavaDoubleRDD</span> <span class="n">v</span> <span class="o">=</span> <span class="n">u</span><span class="o">.</span><span class="na">mapToDouble</span><span class="o">(</span><span class="n">x</span> <span class="o">-&gt;</span> <span class="mf">1.0</span> <span class="o">+</span> <span class="mf">2.0</span> <span class="o">*</span> <span class="n">x</span><span class="o">);</span></code></pre></figure>

  </div>

<div data-lang="python">
    <p><a href="api/python/pyspark.mllib.html#pyspark.mllib.random.RandomRDDs"><code>RandomRDDs</code></a>提供了用于生成随机双RDD或矢量RDD的工厂方法。以下示例生成一个随机双RDD，其值遵循标准正态分布<code>N(0, 1)</code> ，然后将其映射到<code>N(1, 4)</code> 。</p>

    <p>请参阅<a href="api/python/pyspark.mllib.html#pyspark.mllib.random.RandomRDDs"><code>RandomRDDs</code></a>有关该API的更多详细信息的<a href="api/python/pyspark.mllib.html#pyspark.mllib.random.RandomRDDs">Python文档</a> 。</p>

    <figure class="highlight"><pre><code class="language-python" data-lang="python"><span></span><span class="kn">from</span> <span class="nn">pyspark.mllib.random</span> <span class="kn">import</span> <span class="n">RandomRDDs</span>

<span class="n">sc</span> <span class="o">=</span> <span class="o">...</span> <span class="c1"># SparkContext</span>

<span class="c1"># Generate a random double RDD that contains 1 million i.i.d. values drawn from the</span>
<span class="c1"># standard normal distribution `N(0, 1)`, evenly distributed in 10 partitions.</span>
<span class="n">u</span> <span class="o">=</span> <span class="n">RandomRDDs</span><span class="o">.</span><span class="n">normalRDD</span><span class="p">(</span><span class="n">sc</span><span class="p">,</span> <span class="il">1000000L</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="c1"># Apply a transform to get a random double RDD following `N(1, 4)`.</span>
<span class="n">v</span> <span class="o">=</span> <span class="n">u</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="mf">1.0</span> <span class="o">+</span> <span class="mf">2.0</span> <span class="o">*</span> <span class="n">x</span><span class="p">)</span></code></pre></figure>

  </div>
</div>

<h2 id="kernel-density-estimation">内核密度估计</h2>

<p><a href="https://en.wikipedia.org/wiki/Kernel_density_estimation">内核密度估计</a>是一种用于可视化经验概率分布的技术，无需假设要从中得出观察样本的特定分布。它计算在给定的一组点上评估的随机变量的概率密度函数的估计。它通过将特定点的经验分布的PDF表示为以每个样本为中心的正态分布PDF的平均值来实现此估计。</p>

<div class="codetabs">

<div data-lang="scala">
    <p><a href="api/scala/index.html#org.apache.spark.mllib.stat.KernelDensity"><code>KernelDensity</code></a>提供了根据样本的RDD计算内核密度估计值的方法。下面的示例演示了如何执行此操作。</p>

    <p>请参阅<a href="api/scala/index.html#org.apache.spark.mllib.stat.KernelDensity"><code>KernelDensity</code></a>有关API的详细信息，请参见<a href="api/scala/index.html#org.apache.spark.mllib.stat.KernelDensity">Scala文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">org.apache.spark.mllib.stat.KernelDensity</span>
<span class="k">import</span> <span class="nn">org.apache.spark.rdd.RDD</span>

<span class="c1">// an RDD of sample data</span>
<span class="k">val</span> <span class="n">data</span><span class="k">:</span> <span class="kt">RDD</span><span class="o">[</span><span class="kt">Double</span><span class="o">]</span> <span class="k">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">parallelize</span><span class="o">(</span><span class="nc">Seq</span><span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="mi">1</span><span class="o">,</span> <span class="mi">1</span><span class="o">,</span> <span class="mi">2</span><span class="o">,</span> <span class="mi">3</span><span class="o">,</span> <span class="mi">4</span><span class="o">,</span> <span class="mi">5</span><span class="o">,</span> <span class="mi">5</span><span class="o">,</span> <span class="mi">6</span><span class="o">,</span> <span class="mi">7</span><span class="o">,</span> <span class="mi">8</span><span class="o">,</span> <span class="mi">9</span><span class="o">,</span> <span class="mi">9</span><span class="o">))</span>

<span class="c1">// Construct the density estimator with the sample data and a standard deviation</span>
<span class="c1">// for the Gaussian kernels</span>
<span class="k">val</span> <span class="n">kd</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">KernelDensity</span><span class="o">()</span>
  <span class="o">.</span><span class="n">setSample</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>
  <span class="o">.</span><span class="n">setBandwidth</span><span class="o">(</span><span class="mf">3.0</span><span class="o">)</span>

<span class="c1">// Find density estimates for the given values</span>
<span class="k">val</span> <span class="n">densities</span> <span class="k">=</span> <span class="n">kd</span><span class="o">.</span><span class="n">estimate</span><span class="o">(</span><span class="nc">Array</span><span class="o">(-</span><span class="mf">1.0</span><span class="o">,</span> <span class="mf">2.0</span><span class="o">,</span> <span class="mf">5.0</span><span class="o">))</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / scala / org / apache / spark / examples / mllib / KernelDensityEstimationExample.scala”中找到完整的示例代码。</small></div>
  </div>

<div data-lang="java">
    <p><a href="api/java/index.html#org.apache.spark.mllib.stat.KernelDensity"><code>KernelDensity</code></a>提供了根据样本的RDD计算内核密度估计值的方法。下面的示例演示了如何执行此操作。</p>

    <p>请参阅<a href="api/java/org/apache/spark/mllib/stat/KernelDensity.html"><code>KernelDensity</code></a>有关该API的详细信息的<a href="api/java/org/apache/spark/mllib/stat/KernelDensity.html">Java文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">java.util.Arrays</span><span class="o">;</span>

<span class="kn">import</span> <span class="nn">org.apache.spark.api.java.JavaRDD</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.mllib.stat.KernelDensity</span><span class="o">;</span>

<span class="c1">// an RDD of sample data</span>
<span class="n">JavaRDD</span><span class="o">&lt;</span><span class="n">Double</span><span class="o">&gt;</span> <span class="n">data</span> <span class="o">=</span> <span class="n">jsc</span><span class="o">.</span><span class="na">parallelize</span><span class="o">(</span>
  <span class="n">Arrays</span><span class="o">.</span><span class="na">asList</span><span class="o">(</span><span class="mf">1.0</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">,</span> <span class="mf">2.0</span><span class="o">,</span> <span class="mf">3.0</span><span class="o">,</span> <span class="mf">4.0</span><span class="o">,</span> <span class="mf">5.0</span><span class="o">,</span> <span class="mf">5.0</span><span class="o">,</span> <span class="mf">6.0</span><span class="o">,</span> <span class="mf">7.0</span><span class="o">,</span> <span class="mf">8.0</span><span class="o">,</span> <span class="mf">9.0</span><span class="o">,</span> <span class="mf">9.0</span><span class="o">));</span>

<span class="c1">// Construct the density estimator with the sample data</span>
<span class="c1">// and a standard deviation for the Gaussian kernels</span>
<span class="n">KernelDensity</span> <span class="n">kd</span> <span class="o">=</span> <span class="k">new</span> <span class="n">KernelDensity</span><span class="o">().</span><span class="na">setSample</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="na">setBandwidth</span><span class="o">(</span><span class="mf">3.0</span><span class="o">);</span>

<span class="c1">// Find density estimates for the given values</span>
<span class="kt">double</span><span class="o">[]</span> <span class="n">densities</span> <span class="o">=</span> <span class="n">kd</span><span class="o">.</span><span class="na">estimate</span><span class="o">(</span><span class="k">new</span> <span class="kt">double</span><span class="o">[]{-</span><span class="mf">1.0</span><span class="o">,</span> <span class="mf">2.0</span><span class="o">,</span> <span class="mf">5.0</span><span class="o">});</span>

<span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="n">Arrays</span><span class="o">.</span><span class="na">toString</span><span class="o">(</span><span class="n">densities</span><span class="o">));</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / java / org / apache / spark / examples / mllib / JavaKernelDensityEstimationExample.java”中找到完整的示例代码。</small></div>
  </div>

<div data-lang="python">
    <p><a href="api/python/pyspark.mllib.html#pyspark.mllib.stat.KernelDensity"><code>KernelDensity</code></a>提供了根据样本的RDD计算内核密度估计值的方法。下面的示例演示了如何执行此操作。</p>

    <p>请参阅<a href="api/python/pyspark.mllib.html#pyspark.mllib.stat.KernelDensity"><code>KernelDensity</code></a>有关该API的更多详细信息的<a href="api/python/pyspark.mllib.html#pyspark.mllib.stat.KernelDensity">Python文档</a> 。</p>

    <div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pyspark.mllib.stat</span> <span class="kn">import</span> <span class="n">KernelDensity</span>

<span class="c1"># an RDD of sample data</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">parallelize</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">,</span> <span class="mf">4.0</span><span class="p">,</span> <span class="mf">5.0</span><span class="p">,</span> <span class="mf">5.0</span><span class="p">,</span> <span class="mf">6.0</span><span class="p">,</span> <span class="mf">7.0</span><span class="p">,</span> <span class="mf">8.0</span><span class="p">,</span> <span class="mf">9.0</span><span class="p">,</span> <span class="mf">9.0</span><span class="p">])</span>

<span class="c1"># Construct the density estimator with the sample data and a standard deviation for the Gaussian</span>
<span class="c1"># kernels</span>
<span class="n">kd</span> <span class="o">=</span> <span class="n">KernelDensity</span><span class="p">()</span>
<span class="n">kd</span><span class="o">.</span><span class="n">setSample</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">kd</span><span class="o">.</span><span class="n">setBandwidth</span><span class="p">(</span><span class="mf">3.0</span><span class="p">)</span>

<span class="c1"># Find density estimates for the given values</span>
<span class="n">densities</span> <span class="o">=</span> <span class="n">kd</span><span class="o">.</span><span class="n">estimate</span><span class="p">([</span><span class="o">-</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mf">5.0</span><span class="p">])</span>
</pre></div>
    <div><small>在Spark存储库中的“ examples / src / main / python / mllib / kernel_density_estimation_example.py”中找到完整的示例代码。</small></div>
  </div>

</div>


                </div>
            
             <!-- /container -->
        </div>

        <script src="js/vendor/jquery-1.12.4.min.js"></script>
        <script src="js/vendor/bootstrap.min.js"></script>
        <script src="js/vendor/anchor.min.js"></script>
        <script src="js/main.js"></script>

        <!-- MathJax Section -->
        <script type="text/x-mathjax-config">
            MathJax.Hub.Config({
                TeX: { equationNumbers: { autoNumber: "AMS" } }
            });
        </script>
        <script>
            // Note that we load MathJax this way to work with local file (file://), HTTP and HTTPS.
            // We could use "//cdn.mathjax...", but that won't support "file://".
            (function(d, script) {
                script = d.createElement('script');
                script.type = 'text/javascript';
                script.async = true;
                script.onload = function(){
                    MathJax.Hub.Config({
                        tex2jax: {
                            inlineMath: [ ["$", "$"], ["\\\\(","\\\\)"] ],
                            displayMath: [ ["$$","$$"], ["\\[", "\\]"] ],
                            processEscapes: true,
                            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre']
                        }
                    });
                };
                script.src = ('https:' == document.location.protocol ? 'https://' : 'http://') +
                    'cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js' +
                    '?config=TeX-AMS-MML_HTMLorMML';
                d.getElementsByTagName('head')[0].appendChild(script);
            }(document));
        </script>
    

</body></html>