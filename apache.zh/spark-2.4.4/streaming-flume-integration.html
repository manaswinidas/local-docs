<html class="no-js" ><!--<![endif]--><head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
        <title>Spark Streaming + Flume集成指南-Spark 2.4.4文档</title>
        

        

        <link rel="stylesheet" href="css/bootstrap.min.css">
        <style>
            body {
                padding-top: 60px;
                padding-bottom: 40px;
            }
        </style>
        <meta name="viewport" content="width=device-width">
        <link rel="stylesheet" href="css/bootstrap-responsive.min.css">
        <link rel="stylesheet" href="css/main.css">

        <script src="js/vendor/modernizr-2.6.1-respond-1.1.0.min.js"></script>

        <link rel="stylesheet" href="css/pygments-default.css">

        
        <!-- Google analytics script -->
        <script type="text/javascript">
          var _gaq = _gaq || [];
          _gaq.push(['_setAccount', 'UA-32518208-2']);
          _gaq.push(['_trackPageview']);

          (function() {
            var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
            ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
            var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
          })();
        </script>
        

    </head>
    <body >
        <!--[if lt IE 7]>
            <p class="chromeframe">You are using an outdated browser. <a href="https://browsehappy.com/">Upgrade your browser today</a> or <a href="http://www.google.com/chromeframe/?redirect=true">install Google Chrome Frame</a> to better experience this site.</p>
        <![endif]-->

        <!-- This code is taken from http://twitter.github.com/bootstrap/examples/hero.html -->

        <div class="navbar navbar-fixed-top" id="topbar">
            <div class="navbar-inner">
                <div class="container">
                    <div class="brand"><a href="index.html"><img src="img/spark-logo-hd.png" style="height:50px"></a> <span class="version">2.4.4</span>
                    </div>
                    <ul class="nav">
                        <!--TODO(andyk): Add class="active" attribute to li some how.-->
                        <li><a href="index.html">总览</a></li>

                        <li class="dropdown">
                            <a href="#" class="dropdown-toggle" data-toggle="dropdown">编程指南<b class="caret"></b></a>
                            <ul class="dropdown-menu">
                                <li><a href="quick-start.html">快速开始</a></li>
                                <li><a href="rdd-programming-guide.html">RDD，累加器，广播变量</a></li>
                                <li><a href="sql-programming-guide.html">SQL，数据框和数据集</a></li>
                                <li><a href="structured-streaming-programming-guide.html">结构化流</a></li>
                                <li><a href="streaming-programming-guide.html">火花流（DStreams）</a></li>
                                <li><a href="ml-guide.html">MLlib（机器学习）</a></li>
                                <li><a href="graphx-programming-guide.html">GraphX（图形处理）</a></li>
                                <li><a href="sparkr.html">SparkR（Spark上的R）</a></li>
                            </ul>
                        </li>

                        <li class="dropdown">
                            <a href="#" class="dropdown-toggle" data-toggle="dropdown">API文件<b class="caret"></b></a>
                            <ul class="dropdown-menu">
                                <li><a href="api/scala/index.html#org.apache.spark.package">斯卡拉</a></li>
                                <li><a href="api/java/index.html">爪哇</a></li>
                                <li><a href="api/python/index.html">蟒蛇</a></li>
                                <li><a href="api/R/index.html">[R</a></li>
                                <li><a href="api/sql/index.html">SQL，内置函数</a></li>
                            </ul>
                        </li>

                        <li class="dropdown">
                            <a href="#" class="dropdown-toggle" data-toggle="dropdown">部署中<b class="caret"></b></a>
                            <ul class="dropdown-menu">
                                <li><a href="cluster-overview.html">总览</a></li>
                                <li><a href="submitting-applications.html">提交申请</a></li>
                                <li class="divider"></li>
                                <li><a href="spark-standalone.html">Spark独立</a></li>
                                <li><a href="running-on-mesos.html">梅索斯</a></li>
                                <li><a href="running-on-yarn.html">纱</a></li>
                                <li><a href="running-on-kubernetes.html">Kubernetes</a></li>
                            </ul>
                        </li>

                        <li class="dropdown">
                            <a href="api.html" class="dropdown-toggle" data-toggle="dropdown">更多<b class="caret"></b></a>
                            <ul class="dropdown-menu">
                                <li><a href="configuration.html">组态</a></li>
                                <li><a href="monitoring.html">监控方式</a></li>
                                <li><a href="tuning.html">调音指南</a></li>
                                <li><a href="job-scheduling.html">作业调度</a></li>
                                <li><a href="security.html">安全</a></li>
                                <li><a href="hardware-provisioning.html">硬件配置</a></li>
                                <li class="divider"></li>
                                <li><a href="building-spark.html">建筑火花</a></li>
                                <li><a href="https://spark.apache.org/contributing.html">为Spark贡献</a></li>
                                <li><a href="https://spark.apache.org/third-party-projects.html">第三方项目</a></li>
                            </ul>
                        </li>
                    </ul>
                    <!--<p class="navbar-text pull-right"><span class="version-text">v2.4.4</span></p>-->
                </div>
            </div>
        </div>

        <div class="container-wrapper">

            
                <div class="content" id="content">
                    
                        <h1 class="title">Spark Streaming + Flume集成指南</h1>
                    

                    <p><a href="https://flume.apache.org/">Apache Flume</a>是一种分布式，可靠且可用的服务，用于有效地收集，聚合和移动大量日志数据。在这里，我们说明如何配置Flume和Spark Streaming以从Flume接收数据。有两种方法。</p>

<p><strong>注意：从Spark 2.3.0开始不建议使用Flume。</strong></p>

<h2 id="approach-1-flume-style-push-based-approach">方法1：Flume式基于推的方法</h2>
<p>Flume旨在在Flume代理之间推送数据。通过这种方法，Spark Streaming本质上设置了一个接收器，该接收器充当Flume的Avro代理，Flume可以将数据推送到该接收器。这是配置步骤。</p>

<h4 id="general-requirements">一般要求</h4>
<p>选择集群中的一台计算机，以便</p>

<ul>
  <li>
    <p>启动Flume + Spark Streaming应用程序时，其中一个Spark辅助程序必须在该计算机上运行。</p>
  </li>
  <li>
    <p>可以将Flume配置为将数据推送到该计算机上的端口。</p>
  </li>
</ul>

<p>由于采用了推送模型，因此流媒体应用程序需要启动，并安排接收器并在所选端口上侦听，以使Flume能够推送数据。</p>

<h4 id="configuring-flume">配置Flume</h4>
<p>通过在配置文件中包含以下内容，配置Flume代理以将数据发送到Avro接收器。</p>

<pre><code>agent.sinks = avroSink
agent.sinks.avroSink.type = avro
agent.sinks.avroSink.channel = memoryChannel
agent.sinks.avroSink.hostname = &lt;chosen machine's hostname&gt;
agent.sinks.avroSink.port = &lt;chosen port on the machine&gt;
</code></pre>

<p>有关配置Flume代理的更多信息，请参见<a href="https://flume.apache.org/documentation.html">Flume的文档</a> 。</p>

<h4 id="configuring-spark-streaming-application">配置Spark Streaming应用程序</h4>
<ol>
  <li>
    <p><strong>链接：</strong>在SBT / Maven项目定义中，将流应用程序链接到以下工件（有关更多信息，请参见主编程指南中的“ <a href="streaming-programming-guide.html#linking">链接”部分</a> ）。</p>

    <pre><code> groupId = org.apache.spark
 artifactId = spark-streaming-flume_2.12
 version = 2.4.4
</code></pre>
  </li>
  <li>
    <p><strong>编程：</strong>在流应用程序代码中，导入<code>FlumeUtils</code>并按如下所示创建输入DStream。</p>

    <div class="codetabs">
 <div data-lang="scala">
        <pre><code> import org.apache.spark.streaming.flume._

 val flumeStream = FlumeUtils.createStream(streamingContext, [chosen machine's hostname], [chosen port])
</code></pre>

        <p>请参阅<a href="api/scala/index.html#org.apache.spark.streaming.flume.FlumeUtils$">API文档</a> 。</p>
      </div>
 <div data-lang="java">
        <pre><code> import org.apache.spark.streaming.flume.*;

 JavaReceiverInputDStream&lt;SparkFlumeEvent&gt; flumeStream =
 	FlumeUtils.createStream(streamingContext, [chosen machine's hostname], [chosen port]);
</code></pre>

        <p>请参阅<a href="api/java/index.html?org/apache/spark/streaming/flume/FlumeUtils.html">API文档</a> 。</p>
      </div>
 <div data-lang="python">
        <pre><code> from pyspark.streaming.flume import FlumeUtils

 flumeStream = FlumeUtils.createStream(streamingContext, [chosen machine's hostname], [chosen port])
</code></pre>

        <p>默认情况下，Python API将Flume事件主体解码为UTF8编码的字符串。您可以指定自定义解码功能，以将Flume事件中的正文字节数组解码为任意数据类型。请参阅<a href="api/python/pyspark.streaming.html#pyspark.streaming.flume.FlumeUtils">API文档</a> 。</p>
      </div>
 </div>

    <p>请注意，主机名应与集群中的资源管理器（Mesos，YARN或Spark Standalone）使用的主机名相同，以便资源分配可以匹配名称并在正确的机器中启动接收器。</p>
  </li>
  <li>
    <p><strong>部署：</strong>与任何Spark应用程序一样， <code>spark-submit</code>用于启动您的应用程序。但是，Scala / Java应用程序和Python应用程序的详细信息略有不同。</p>

    <p>对于Scala和Java应用程序，如果您使用SBT或Maven进行项目管理，则打包<code>spark-streaming-flume_2.12</code>及其依赖关系到应用程序JAR中。确保<code>spark-core_2.12</code>和<code>spark-streaming_2.12</code>被标记为<code>provided</code>依赖关系，如Spark安装中已经存在的依赖关系。然后使用<code>spark-submit</code>以启动您的应用程序（请参阅主要编程指南中的“ <a href="streaming-programming-guide.html#deploying-applications">部署”部分</a> ）。</p>

    <p>对于缺少SBT / Maven项目管理的Python应用程序， <code>spark-streaming-flume_2.12</code>它的依赖关系可以直接添加到<code>spark-submit</code>使用<code>--packages</code> （请参阅<a href="submitting-applications.html">申请提交指南</a> ）。那是，</p>

    <pre><code> ./bin/spark-submit --packages org.apache.spark:spark-streaming-flume_2.12:2.4.4 ...
</code></pre>

    <p>或者，您也可以下载Maven工件的JAR <code>spark-streaming-flume-assembly</code>从<a href="http://search.maven.org/#search|ga|1|a%3A"spark-streaming-flume-assembly_2.12" AND v%3A"2.4.4"">Maven存储库</a>并将其添加到<code>spark-submit</code>与<code>--jars</code> 。</p>
  </li>
</ol>

<h2 id="approach-2-pull-based-approach-using-a-custom-sink">方法2：使用自定义接收器的基于拉的方法</h2>
<p>这种方法不是运行Flume将数据直接推送到Spark Streaming，而是运行自定义的Flume接收器，该接收器可以执行以下操作。</p>

<ul>
  <li>Flume将数据推入接收器，并且数据保持缓冲状态。</li>
  <li>Spark Streaming使用<a href="streaming-programming-guide.html#receiver-reliability">可靠的Flume接收器</a>和事务从<a href="streaming-programming-guide.html#receiver-reliability">接收器</a>中提取数据。只有在Spark Streaming接收并复制了数据之后，事务才能成功。</li>
</ul>

<p>与以前的方法相比，这确保了更强的可靠性和<a href="streaming-programming-guide.html#fault-tolerance-semantics">容错保证</a> 。但是，这需要将Flume配置为运行自定义接收器。这是配置步骤。</p>

<h4 id="general-requirements-1">一般要求</h4>
<p>选择将在Flume代理中运行自定义接收器的计算机。Flume管道的其余部分配置为将数据发送到该代理。Spark集群中的计算机应有权访问运行自定义接收器的所选计算机。</p>

<h4 id="configuring-flume-1">配置Flume</h4>
<p>在所选计算机上配置Flume需要执行以下两个步骤。</p>

<ol>
  <li>
    <p><strong>接收器JAR</strong> ：将以下JAR添加到指定用于运行自定义接收器的计算机中的Flume的类路径（请参阅<a href="https://flume.apache.org/documentation.html">Flume的文档</a>以了解操作方法）。</p>

    <p>（i） <em>自定义接收器JAR</em> ：下载与以下工件（或<a href="http://search.maven.org/remotecontent?filepath=org/apache/spark/spark-streaming-flume-sink_2.12/2.4.4/spark-streaming-flume-sink_2.12-2.4.4.jar">直接链接</a> ）相对应的JAR。</p>

    <pre><code> groupId = org.apache.spark
 artifactId = spark-streaming-flume-sink_2.12
 version = 2.4.4
</code></pre>

    <p>（ii） <em>Scala库JAR</em> ：下载适用于Scala 2.12.8的Scala库JAR。可以通过以下工件详细信息（或<a href="http://search.maven.org/remotecontent?filepath=org/scala-lang/scala-library/2.12.8/scala-library-2.12.8.jar">直接链接</a> ）找到它。</p>

    <pre><code> groupId = org.scala-lang
 artifactId = scala-library
 version = 2.12.8
</code></pre>

    <p>（iii） <em>Commons Lang 3 JAR</em> ：下载Commons Lang 3 JAR。可以通过以下工件详细信息（或<a href="http://search.maven.org/remotecontent?filepath=org/apache/commons/commons-lang3/3.5/commons-lang3-3.5.jar">直接链接</a> ）找到它。</p>

    <pre><code> groupId = org.apache.commons
 artifactId = commons-lang3
 version = 3.5
</code></pre>
  </li>
  <li>
    <p><strong>配置文件</strong> ：在该计算机上，通过在配置文件中包含以下内容，将Flume代理配置为将数据发送到Avro接收器。</p>

    <pre><code> agent.sinks = spark
 agent.sinks.spark.type = org.apache.spark.streaming.flume.sink.SparkSink
 agent.sinks.spark.hostname = &lt;hostname of the local machine&gt;
 agent.sinks.spark.port = &lt;port to listen on for connection from Spark&gt;
 agent.sinks.spark.channel = memoryChannel
</code></pre>

    <p>另外，请确保将上游Flume管道配置为将数据发送到运行此接收器的Flume代理。</p>
  </li>
</ol>

<p>有关配置Flume代理的更多信息，请参见<a href="https://flume.apache.org/documentation.html">Flume的文档</a> 。</p>

<h4 id="configuring-spark-streaming-application-1">配置Spark Streaming应用程序</h4>
<ol>
  <li>
    <p><strong>链接：</strong>在SBT / Maven项目定义中，将流应用程序链接到<code>spark-streaming-flume_2.12</code> （请参阅主编程指南中的“ <a href="streaming-programming-guide.html#linking">链接”部分</a> ）。</p>
  </li>
  <li>
    <p><strong>编程：</strong>在流应用程序代码中，导入<code>FlumeUtils</code>并按如下所示创建输入DStream。</p>

    <div class="codetabs">
 <div data-lang="scala">
        <pre><code> import org.apache.spark.streaming.flume._

 val flumeStream = FlumeUtils.createPollingStream(streamingContext, [sink machine hostname], [sink port])
</code></pre>
      </div>
 <div data-lang="java">
        <pre><code> import org.apache.spark.streaming.flume.*;

 JavaReceiverInputDStream&lt;SparkFlumeEvent&gt;flumeStream =
     FlumeUtils.createPollingStream(streamingContext, [sink machine hostname], [sink port]);
</code></pre>
      </div>
 <div data-lang="python">
        <pre><code> from pyspark.streaming.flume import FlumeUtils

 addresses = [([sink machine hostname 1], [sink port 1]), ([sink machine hostname 2], [sink port 2])]
 flumeStream = FlumeUtils.createPollingStream(streamingContext, addresses)
</code></pre>

        <p>默认情况下，Python API将Flume事件主体解码为UTF8编码的字符串。您可以指定自定义解码功能，以将Flume事件中的正文字节数组解码为任意数据类型。请参阅<a href="api/python/pyspark.streaming.html#pyspark.streaming.flume.FlumeUtils">API文档</a> 。</p>
      </div>
 </div>

    <p>请注意，每个输入DStream都可以配置为从多个接收器接收数据。</p>
  </li>
  <li>
    <p><strong>部署：</strong>与第一种方法相同。</p>
  </li>
</ol>



                </div>
            
             <!-- /container -->
        </div>

        <script src="js/vendor/jquery-1.12.4.min.js"></script>
        <script src="js/vendor/bootstrap.min.js"></script>
        <script src="js/vendor/anchor.min.js"></script>
        <script src="js/main.js"></script>

        <!-- MathJax Section -->
        <script type="text/x-mathjax-config">
            MathJax.Hub.Config({
                TeX: { equationNumbers: { autoNumber: "AMS" } }
            });
        </script>
        <script>
            // Note that we load MathJax this way to work with local file (file://), HTTP and HTTPS.
            // We could use "//cdn.mathjax...", but that won't support "file://".
            (function(d, script) {
                script = d.createElement('script');
                script.type = 'text/javascript';
                script.async = true;
                script.onload = function(){
                    MathJax.Hub.Config({
                        tex2jax: {
                            inlineMath: [ ["$", "$"], ["\\\\(","\\\\)"] ],
                            displayMath: [ ["$$","$$"], ["\\[", "\\]"] ],
                            processEscapes: true,
                            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre']
                        }
                    });
                };
                script.src = ('https:' == document.location.protocol ? 'https://' : 'http://') +
                    'cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js' +
                    '?config=TeX-AMS-MML_HTMLorMML';
                d.getElementsByTagName('head')[0].appendChild(script);
            }(document));
        </script>
    

</body></html>