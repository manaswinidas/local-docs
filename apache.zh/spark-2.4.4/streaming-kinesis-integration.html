<html class="no-js" ><!--<![endif]--><head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
        <title>Spark Streaming + Kinesis集成-Spark 2.4.4文档</title>
        

        

        <link rel="stylesheet" href="css/bootstrap.min.css">
        <style>
            body {
                padding-top: 60px;
                padding-bottom: 40px;
            }
        </style>
        <meta name="viewport" content="width=device-width">
        <link rel="stylesheet" href="css/bootstrap-responsive.min.css">
        <link rel="stylesheet" href="css/main.css">

        <script src="js/vendor/modernizr-2.6.1-respond-1.1.0.min.js"></script>

        <link rel="stylesheet" href="css/pygments-default.css">

        
        <!-- Google analytics script -->
        <script type="text/javascript">
          var _gaq = _gaq || [];
          _gaq.push(['_setAccount', 'UA-32518208-2']);
          _gaq.push(['_trackPageview']);

          (function() {
            var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
            ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
            var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
          })();
        </script>
        

    </head>
    <body >
        <!--[if lt IE 7]>
            <p class="chromeframe">You are using an outdated browser. <a href="https://browsehappy.com/">Upgrade your browser today</a> or <a href="http://www.google.com/chromeframe/?redirect=true">install Google Chrome Frame</a> to better experience this site.</p>
        <![endif]-->

        <!-- This code is taken from http://twitter.github.com/bootstrap/examples/hero.html -->

        <div class="navbar navbar-fixed-top" id="topbar">
            <div class="navbar-inner">
                <div class="container">
                    <div class="brand"><a href="index.html"><img src="img/spark-logo-hd.png" style="height:50px"></a> <span class="version">2.4.4</span>
                    </div>
                    <ul class="nav">
                        <!--TODO(andyk): Add class="active" attribute to li some how.-->
                        <li><a href="index.html">总览</a></li>

                        <li class="dropdown">
                            <a href="#" class="dropdown-toggle" data-toggle="dropdown">编程指南<b class="caret"></b></a>
                            <ul class="dropdown-menu">
                                <li><a href="quick-start.html">快速开始</a></li>
                                <li><a href="rdd-programming-guide.html">RDD，累加器，广播变量</a></li>
                                <li><a href="sql-programming-guide.html">SQL，数据框和数据集</a></li>
                                <li><a href="structured-streaming-programming-guide.html">结构化流</a></li>
                                <li><a href="streaming-programming-guide.html">火花流（DStreams）</a></li>
                                <li><a href="ml-guide.html">MLlib（机器学习）</a></li>
                                <li><a href="graphx-programming-guide.html">GraphX（图形处理）</a></li>
                                <li><a href="sparkr.html">SparkR（Spark上的R）</a></li>
                            </ul>
                        </li>

                        <li class="dropdown">
                            <a href="#" class="dropdown-toggle" data-toggle="dropdown">API文件<b class="caret"></b></a>
                            <ul class="dropdown-menu">
                                <li><a href="api/scala/index.html#org.apache.spark.package">斯卡拉</a></li>
                                <li><a href="api/java/index.html">爪哇</a></li>
                                <li><a href="api/python/index.html">蟒蛇</a></li>
                                <li><a href="api/R/index.html">[R</a></li>
                                <li><a href="api/sql/index.html">SQL，内置函数</a></li>
                            </ul>
                        </li>

                        <li class="dropdown">
                            <a href="#" class="dropdown-toggle" data-toggle="dropdown">部署中<b class="caret"></b></a>
                            <ul class="dropdown-menu">
                                <li><a href="cluster-overview.html">总览</a></li>
                                <li><a href="submitting-applications.html">提交申请</a></li>
                                <li class="divider"></li>
                                <li><a href="spark-standalone.html">Spark独立</a></li>
                                <li><a href="running-on-mesos.html">梅索斯</a></li>
                                <li><a href="running-on-yarn.html">纱</a></li>
                                <li><a href="running-on-kubernetes.html">Kubernetes</a></li>
                            </ul>
                        </li>

                        <li class="dropdown">
                            <a href="api.html" class="dropdown-toggle" data-toggle="dropdown">更多<b class="caret"></b></a>
                            <ul class="dropdown-menu">
                                <li><a href="configuration.html">组态</a></li>
                                <li><a href="monitoring.html">监控方式</a></li>
                                <li><a href="tuning.html">调音指南</a></li>
                                <li><a href="job-scheduling.html">作业调度</a></li>
                                <li><a href="security.html">安全</a></li>
                                <li><a href="hardware-provisioning.html">硬件配置</a></li>
                                <li class="divider"></li>
                                <li><a href="building-spark.html">建筑火花</a></li>
                                <li><a href="https://spark.apache.org/contributing.html">为Spark贡献</a></li>
                                <li><a href="https://spark.apache.org/third-party-projects.html">第三方项目</a></li>
                            </ul>
                        </li>
                    </ul>
                    <!--<p class="navbar-text pull-right"><span class="version-text">v2.4.4</span></p>-->
                </div>
            </div>
        </div>

        <div class="container-wrapper">

            
                <div class="content" id="content">
                    
                        <h1 class="title">Spark Streaming + Kinesis集成</h1>
                    

                    <p><a href="http://aws.amazon.com/kinesis/">Amazon Kinesis</a>是一项全面托管的服务，用于大规模实时处理流数据。Kinesis接收器使用Amazon根据Amazon软件许可（ASL）提供的Kinesis客户端库（KCL）创建输入DStream。KCL构建在Apache 2.0许可的AWS Java SDK之上，并通过Workers，Checkpoint和Shard Lease的概念提供负载平衡，容错，检查点。在这里，我们解释了如何配置Spark Streaming以从Kinesis接收数据。</p>

<h4 id="configuring-kinesis">配置Kinesis</h4>

<p>可以根据以下<a href="http://docs.aws.amazon.com/kinesis/latest/dev/step-one-create-stream.html">指南</a>在一个有效的Kinesis端点之一上设置Kinesis流，其中的分片数量为1个或更多。</p>

<h4 id="configuring-spark-streaming-application">配置Spark Streaming应用程序</h4>

<ol>
  <li>
    <p><strong>链接：</strong>对于使用SBT / Maven项目定义的Scala / Java应用程序，将流应用程序链接到以下工件（有关更多信息，请参见主编程指南中的“ <a href="streaming-programming-guide.html#linking">链接”部分</a> ）。</p>

    <pre><code> groupId = org.apache.spark
 artifactId = spark-streaming-kinesis-asl_2.12
 version = 2.4.4
</code></pre>

    <p>对于Python应用程序，在部署应用程序时必须添加上述库及其依赖项。请参阅下面的“ <em>部署”</em>小节。
 <strong>请注意，通过链接到此库，您将在应用程序中包含<a href="https://aws.amazon.com/asl/">ASL</a>许可的代码。</strong></p>
  </li>
  <li>
    <p><strong>编程：</strong>在流应用程序代码中，导入<code>KinesisInputDStream</code>并创建字节数组的输入DStream，如下所示：</p>

    <div class="codetabs">
 <div data-lang="scala">
        <pre><code>     import org.apache.spark.storage.StorageLevel
     import org.apache.spark.streaming.kinesis.KinesisInputDStream
     import org.apache.spark.streaming.{Seconds, StreamingContext}
     import com.amazonaws.services.kinesis.clientlibrary.lib.worker.InitialPositionInStream

     val kinesisStream = KinesisInputDStream.builder
         .streamingContext(streamingContext)
         .endpointUrl([endpoint URL])
         .regionName([region name])
         .streamName([streamName])
         .initialPositionInStream([initial position])
         .checkpointAppName([Kinesis app name])
         .checkpointInterval([checkpoint interval])
         .storageLevel(StorageLevel.MEMORY_AND_DISK_2)
         .build()
</code></pre>

        <p>请参阅<a href="api/scala/index.html#org.apache.spark.streaming.kinesis.KinesisInputDStream">API文档</a>和<a href="https://github.com/apache/spark/tree/master/external/kinesis-asl/src/main/scala/org/apache/spark/examples/streaming/KinesisWordCountASL.scala">示例</a> 。请参阅“ <a href="#running-the-example">运行示例”</a>小节，以获取有关如何运行示例的说明。</p>

      </div>
 <div data-lang="java">
        <pre><code>     import org.apache.spark.storage.StorageLevel
     import org.apache.spark.streaming.kinesis.KinesisInputDStream
     import org.apache.spark.streaming.Seconds
     import org.apache.spark.streaming.StreamingContext
     import com.amazonaws.services.kinesis.clientlibrary.lib.worker.InitialPositionInStream

     KinesisInputDStream&lt;byte[]&gt; kinesisStream = KinesisInputDStream.builder
         .streamingContext(streamingContext)
         .endpointUrl([endpoint URL])
         .regionName([region name])
         .streamName([streamName])
         .initialPositionInStream([initial position])
         .checkpointAppName([Kinesis app name])
         .checkpointInterval([checkpoint interval])
         .storageLevel(StorageLevel.MEMORY_AND_DISK_2)
         .build();
</code></pre>

        <p>请参阅<a href="api/java/index.html?org/apache/spark/streaming/kinesis/KinesisUtils.html">API文档</a>和<a href="https://github.com/apache/spark/tree/master/external/kinesis-asl/src/main/java/org/apache/spark/examples/streaming/JavaKinesisWordCountASL.java">示例</a> 。有关<a href="#running-the-example">运行示例</a>的说明，请参阅“ <a href="#running-the-example">运行示例”</a>小节。</p>

      </div>
 <div data-lang="python">
        <pre><code>     from pyspark.streaming.kinesis import KinesisUtils, InitialPositionInStream

     kinesisStream = KinesisUtils.createStream(
         streamingContext, [Kinesis app name], [Kinesis stream name], [endpoint URL],
         [region name], [initial position], [checkpoint interval], StorageLevel.MEMORY_AND_DISK_2)
</code></pre>

        <p>请参阅<a href="api/python/pyspark.streaming.html#pyspark.streaming.kinesis.KinesisUtils">API文档</a>和<a href="https://github.com/apache/spark/tree/master/external/kinesis-asl/src/main/python/examples/streaming/kinesis_wordcount_asl.py">示例</a> 。有关<a href="#running-the-example">运行示例</a>的说明，请参阅“ <a href="#running-the-example">运行示例”</a>小节。</p>

      </div>
 </div>

    <p>您还可以提供带Kinesis的“消息处理程序功能” <code>Record</code>并返回一个通用对象<code>T</code> ，以防您想使用<code>Record</code>例如分区键。目前仅Scala和Java支持此功能。</p>

    <div class="codetabs">
 <div data-lang="scala">
        <pre><code>         import org.apache.spark.storage.StorageLevel
         import org.apache.spark.streaming.kinesis.KinesisInputDStream
         import org.apache.spark.streaming.{Seconds, StreamingContext}
         import com.amazonaws.services.kinesis.clientlibrary.lib.worker.InitialPositionInStream

         val kinesisStream = KinesisInputDStream.builder
             .streamingContext(streamingContext)
             .endpointUrl([endpoint URL])
             .regionName([region name])
             .streamName([streamName])
             .initialPositionInStream([initial position])
             .checkpointAppName([Kinesis app name])
             .checkpointInterval([checkpoint interval])
             .storageLevel(StorageLevel.MEMORY_AND_DISK_2)
             .buildWithMessageHandler([message handler])
</code></pre>

      </div>
 <div data-lang="java">
        <pre><code>         import org.apache.spark.storage.StorageLevel
         import org.apache.spark.streaming.kinesis.KinesisInputDStream
         import org.apache.spark.streaming.Seconds
         import org.apache.spark.streaming.StreamingContext
         import com.amazonaws.services.kinesis.clientlibrary.lib.worker.InitialPositionInStream

         KinesisInputDStream&lt;byte[]&gt; kinesisStream = KinesisInputDStream.builder
             .streamingContext(streamingContext)
             .endpointUrl([endpoint URL])
             .regionName([region name])
             .streamName([streamName])
             .initialPositionInStream([initial position])
             .checkpointAppName([Kinesis app name])
             .checkpointInterval([checkpoint interval])
             .storageLevel(StorageLevel.MEMORY_AND_DISK_2)
             .buildWithMessageHandler([message handler]);
</code></pre>

      </div>
 </div>

    <ul>
      <li>
        <p><code>streamingContext</code> ：StreamingContext包含Kinesis使用的应用程序名称，以将该Kinesis应用程序绑定到Kinesis流</p>
      </li>
      <li><code>[Kinesis app name]</code> ：用于在DynamoDB表中检查点Kinesis序列号的应用程序名称。
        <ul>
          <li>对于给定的帐户和区域，应用程序名称必须唯一。</li>
          <li>如果该表存在但检查点信息不正确（针对其他流或旧的过期序列号），则可能存在临时错误。</li>
        </ul>
      </li>
      <li>
        <p><code>[Kinesis stream name]</code> ：此流应用程序将从中提取数据的Kinesis流。</p>
      </li>
      <li>
        <p><code>[endpoint URL]</code> ：有效的Kinesis端点URL可以在<a href="http://docs.aws.amazon.com/general/latest/gr/rande.html#ak_region">这里</a>找到。</p>
      </li>
      <li>
        <p><code>[region name]</code> ：有效的Kinesis区域名称可以在<a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-regions-availability-zones.html">这里</a>找到。</p>
      </li>
      <li>
        <p><code>[checkpoint interval]</code> ：Kinesis Client Library将其位置保存在流中的时间间隔（例如，Duration（2000）= 2秒）。对于初学者，请将其设置为与流应用程序的批处理间隔相同。</p>
      </li>
      <li>
        <p><code>[initial position]</code> ：可以是<code>InitialPositionInStream.TRIM_HORIZON</code>要么<code>InitialPositionInStream.LATEST</code> （看到<a href="#kinesis-checkpointing"><code>Kinesis Checkpointing</code></a>部分和<a href="http://docs.aws.amazon.com/streams/latest/dev/developing-consumers-with-sdk.html"><code>Amazon Kinesis API documentation</code></a>更多细节）。</p>
      </li>
      <li><code>[message handler]</code> ：需要运动的功能<code>Record</code>并输出通用<code>T</code> 。</li>
    </ul>

    <p>在其他版本的API中，您也可以直接指定AWS访问密钥和秘密密钥。</p>
  </li>
  <li>
    <p><strong>部署：</strong>与任何Spark应用程序一样， <code>spark-submit</code>用于启动您的应用程序。但是，Scala / Java应用程序和Python应用程序的详细信息略有不同。</p>

    <p>对于Scala和Java应用程序，如果您使用SBT或Maven进行项目管理，则打包<code>spark-streaming-kinesis-asl_2.12</code>及其依赖关系到应用程序JAR中。确保<code>spark-core_2.12</code>和<code>spark-streaming_2.12</code>被标记为<code>provided</code>依赖关系，如Spark安装中已经存在的依赖关系。然后使用<code>spark-submit</code>以启动您的应用程序（请参阅主要编程指南中的“ <a href="streaming-programming-guide.html#deploying-applications">部署”部分</a> ）。</p>

    <p>对于缺少SBT / Maven项目管理的Python应用程序， <code>spark-streaming-kinesis-asl_2.12</code>它的依赖关系可以直接添加到<code>spark-submit</code>使用<code>--packages</code> （请参阅<a href="submitting-applications.html">申请提交指南</a> ）。那是，</p>

    <pre><code> ./bin/spark-submit --packages org.apache.spark:spark-streaming-kinesis-asl_2.12:2.4.4 ...
</code></pre>

    <p>或者，您也可以下载Maven工件的JAR <code>spark-streaming-kinesis-asl-assembly</code>从<a href="http://search.maven.org/#search|ga|1|a%3A"spark-streaming-kinesis-asl-assembly_2.12" AND v%3A"2.4.4"">Maven存储库</a>并将其添加到<code>spark-submit</code>与<code>--jars</code> 。</p>

    <p style="text-align:center">
  		<img src="img/streaming-kinesis-arch.png" title="Spark Streaming Kinesis架构" alt="Spark Streaming Kinesis架构" width="60%">
   	<!-- Images are downsized intentionally to improve quality on retina displays -->
 </p>

    <p><em>运行时要记住的要点：</em></p>

    <ul>
      <li>
        <p>Kinesis数据处理按分区排序，每条消息至少进行一次。</p>
      </li>
      <li>
        <p>多个应用程序可以从同一Kinesis流中读取。Kinesis将在DynamoDB中维护特定于应用程序的分片和检查点信息。</p>
      </li>
      <li>
        <p>单个Kinesis流分片一次由一个输入DStream处理。</p>
      </li>
      <li>
        <p>通过创建多个KinesisRecordProcessor线程，单个Kinesis输入DStream可以从Kinesis流的多个碎片读取。</p>
      </li>
      <li>
        <p>可以从Kinesis流中读取在单独的进程/实例中运行的多个输入DStream。</p>
      </li>
      <li>
        <p>您所需要的Kinesis输入DStream数量永远不会超过Kinesis流分片的数量，因为每个输入DStream都会创建至少一个处理单个分片的KinesisRecordProcessor线程。</p>
      </li>
      <li>
        <p>通过添加/删除Kinesis输入DStream（在单个过程中或跨多个过程/实例）来实现水平缩放-达到每个先前点的Kinesis流分片总数。</p>
      </li>
      <li>
        <p>Kinesis输入DStream将平衡所有DStream之间的负载-甚至跨进程/实例。</p>
      </li>
      <li>
        <p>由于负载变化，在重新分片事件（合并和拆分）期间，Kinesis输入DStream将平衡负载。</p>
      </li>
      <li>
        <p>最佳做法是，建议您在可能的情况下通过过度配置来避免重新分片抖动。</p>
      </li>
      <li>
        <p>每个Kinesis输入DStream都维护自己的检查点信息。有关更多详细信息，请参见Kinesis Checkpointing部分。</p>
      </li>
      <li>
        <p>在输入DStream处理期间，Kinesis流分片的数量与在Spark集群中创建的RDD分区/分片的数量之间没有关联。这些是2个独立的分区方案。</p>
      </li>
    </ul>
  </li>
</ol>

<h4 id="running-the-example">运行示例</h4>
<p>要运行该示例，</p>

<ul>
  <li>
    <p>从<a href="https://spark.apache.org/downloads.html">下载站点</a>下载Spark二进制<a href="https://spark.apache.org/downloads.html">文件</a> 。</p>
  </li>
  <li>
    <p>在AWS内设置Kinesis流（请参阅前面的部分）。请注意Kinesis流的名称以及与创建流的区域相对应的终结点URL。</p>
  </li>
  <li>
    <p>设置环境变量<code>AWS_ACCESS_KEY_ID</code>和<code>AWS_SECRET_KEY</code>使用您的AWS凭证。</p>
  </li>
  <li>
    <p>在Spark根目录中，将示例运行为</p>

    <div class="codetabs">
  <div data-lang="scala">

        <pre><code>  bin/run-example --packages org.apache.spark:spark-streaming-kinesis-asl_2.12:2.4.4 streaming.KinesisWordCountASL [Kinesis app name] [Kinesis stream name] [endpoint URL]
</code></pre>

      </div>
  <div data-lang="java">

        <pre><code>  bin/run-example --packages org.apache.spark:spark-streaming-kinesis-asl_2.12:2.4.4 streaming.JavaKinesisWordCountASL [Kinesis app name] [Kinesis stream name] [endpoint URL]
</code></pre>

      </div>
  <div data-lang="python">

        <pre><code>  bin/spark-submit --jars external/kinesis-asl/target/scala-*/\
      spark-streaming-kinesis-asl-assembly_*.jar \
      external/kinesis-asl/src/main/python/examples/streaming/kinesis_wordcount_asl.py \
      [Kinesis app name] [Kinesis stream name] [endpoint URL] [region name]
</code></pre>

      </div>
  </div>

    <p>这将等待从Kinesis流接收数据。</p>
  </li>
  <li>
    <p>要生成随机字符串数据以放入Kinesis流中，请在另一个终端中，运行关联的Kinesis数据生成器。</p>

    <pre><code>  bin/run-example streaming.KinesisWordProducerASL [Kinesis stream name] [endpoint URL] 1000 10
</code></pre>

    <p>这将每秒将1000行（每行10个随机数）推入Kinesis流。然后，正在运行的示例应接收并处理此数据。</p>
  </li>
</ul>

<h4 id="record-de-aggregation">记录分解</h4>

<p>使用<a href="http://docs.aws.amazon.com/kinesis/latest/dev/developing-producers-with-kpl.html">Kinesis生产者库（KPL）</a>生成数据时，可以汇总消息以节省成本。Spark Streaming将在使用过程中自动取消聚合记录。</p>

<h4 id="kinesis-checkpointing">运动学检查点</h4>
<ul>
  <li>
    <p>每个Kinesis输入DStream定期将流的当前位置存储在支持DynamoDB表中。这使系统能够从故障中恢复并在DStream中断的地方继续进行处理。</p>
  </li>
  <li>
    <p>频繁进行检查点操作会在AWS检查点存储层上造成过多负载，并可能导致AWS节流。提供的示例使用随机退避重试策略来处理此限制。</p>
  </li>
  <li>
    <p>如果输入DStream启动时不存在Kinesis检查点信息，它将从最早的可用记录开始（ <code>InitialPositionInStream.TRIM_HORIZON</code> ）或最新提示（ <code>InitialPositionInStream.LATEST</code> ）。这是可配置的。</p>
    <ul>
      <li><code>InitialPositionInStream.LATEST</code>如果在没有输入DStreams运行的情况下（没有存储检查点信息）将数据添加到流中，则可能会导致丢失记录。</li>
      <li><code>InitialPositionInStream.TRIM_HORIZON</code>可能会导致重复处理记录，其影响取决于检查点的频率和处理的幂等性。</li>
    </ul>
  </li>
</ul>

<h4 id="kinesis-retry-configuration">Kinesis重试配置</h4>
<ul>
  <li><code>spark.streaming.kinesis.retry.waitTime</code> ：Kinesis重试之间的等待时间作为持续时间字符串。从Amazon Kinesis阅读时，用户可能会点击<code>ProvisionedThroughputExceededException</code>的速度超过每秒5个事务或超过2 MB /秒的最大读取速率。当获取未能减少这些异常时，可以调整此配置以增加获取之间的睡眠时间。默认值为“ 100ms”。</li>
  <li><code>spark.streaming.kinesis.retry.maxAttempts</code> ：Kinesis提取的最大重试次数。这个配置也可以用来解决Kinesis <code>ProvisionedThroughputExceededException</code>在上述方案中。可以增加它的数量，以增加Kinesis读取的重试次数。默认值为3。</li>
</ul>


                </div>
            
             <!-- /container -->
        </div>

        <script src="js/vendor/jquery-1.12.4.min.js"></script>
        <script src="js/vendor/bootstrap.min.js"></script>
        <script src="js/vendor/anchor.min.js"></script>
        <script src="js/main.js"></script>

        <!-- MathJax Section -->
        <script type="text/x-mathjax-config">
            MathJax.Hub.Config({
                TeX: { equationNumbers: { autoNumber: "AMS" } }
            });
        </script>
        <script>
            // Note that we load MathJax this way to work with local file (file://), HTTP and HTTPS.
            // We could use "//cdn.mathjax...", but that won't support "file://".
            (function(d, script) {
                script = d.createElement('script');
                script.type = 'text/javascript';
                script.async = true;
                script.onload = function(){
                    MathJax.Hub.Config({
                        tex2jax: {
                            inlineMath: [ ["$", "$"], ["\\\\(","\\\\)"] ],
                            displayMath: [ ["$$","$$"], ["\\[", "\\]"] ],
                            processEscapes: true,
                            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre']
                        }
                    });
                };
                script.src = ('https:' == document.location.protocol ? 'https://' : 'http://') +
                    'cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js' +
                    '?config=TeX-AMS-MML_HTMLorMML';
                d.getElementsByTagName('head')[0].appendChild(script);
            }(document));
        </script>
    

</body></html>