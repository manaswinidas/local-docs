<html class="no-js" ><!--<![endif]--><head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
        <title>旧版迁移指南-MLlib-Spark 2.4.4文档</title>
        
          <meta name="description" content="MLlib migration guides from before Spark 2.4.4">
        

        

        <link rel="stylesheet" href="css/bootstrap.min.css">
        <style>
            body {
                padding-top: 60px;
                padding-bottom: 40px;
            }
        </style>
        <meta name="viewport" content="width=device-width">
        <link rel="stylesheet" href="css/bootstrap-responsive.min.css">
        <link rel="stylesheet" href="css/main.css">

        <script src="js/vendor/modernizr-2.6.1-respond-1.1.0.min.js"></script>

        <link rel="stylesheet" href="css/pygments-default.css">

        
        <!-- Google analytics script -->
        <script type="text/javascript">
          var _gaq = _gaq || [];
          _gaq.push(['_setAccount', 'UA-32518208-2']);
          _gaq.push(['_trackPageview']);

          (function() {
            var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
            ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
            var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
          })();
        </script>
        

    </head>
    <body >
        <!--[if lt IE 7]>
            <p class="chromeframe">You are using an outdated browser. <a href="https://browsehappy.com/">Upgrade your browser today</a> or <a href="http://www.google.com/chromeframe/?redirect=true">install Google Chrome Frame</a> to better experience this site.</p>
        <![endif]-->

        <!-- This code is taken from http://twitter.github.com/bootstrap/examples/hero.html -->

        <div class="navbar navbar-fixed-top" id="topbar">
            <div class="navbar-inner">
                <div class="container">
                    <div class="brand"><a href="index.html"><img src="img/spark-logo-hd.png" style="height:50px"></a> <span class="version">2.4.4</span>
                    </div>
                    <ul class="nav">
                        <!--TODO(andyk): Add class="active" attribute to li some how.-->
                        <li><a href="index.html">总览</a></li>

                        <li class="dropdown">
                            <a href="#" class="dropdown-toggle" data-toggle="dropdown">编程指南<b class="caret"></b></a>
                            <ul class="dropdown-menu">
                                <li><a href="quick-start.html">快速开始</a></li>
                                <li><a href="rdd-programming-guide.html">RDD，累加器，广播变量</a></li>
                                <li><a href="sql-programming-guide.html">SQL，数据框和数据集</a></li>
                                <li><a href="structured-streaming-programming-guide.html">结构化流</a></li>
                                <li><a href="streaming-programming-guide.html">火花流（DStreams）</a></li>
                                <li><a href="ml-guide.html">MLlib（机器学习）</a></li>
                                <li><a href="graphx-programming-guide.html">GraphX（图形处理）</a></li>
                                <li><a href="sparkr.html">SparkR（Spark上的R）</a></li>
                            </ul>
                        </li>

                        <li class="dropdown">
                            <a href="#" class="dropdown-toggle" data-toggle="dropdown">API文件<b class="caret"></b></a>
                            <ul class="dropdown-menu">
                                <li><a href="api/scala/index.html#org.apache.spark.package">斯卡拉</a></li>
                                <li><a href="api/java/index.html">爪哇</a></li>
                                <li><a href="api/python/index.html">蟒蛇</a></li>
                                <li><a href="api/R/index.html">[R</a></li>
                                <li><a href="api/sql/index.html">SQL，内置函数</a></li>
                            </ul>
                        </li>

                        <li class="dropdown">
                            <a href="#" class="dropdown-toggle" data-toggle="dropdown">部署中<b class="caret"></b></a>
                            <ul class="dropdown-menu">
                                <li><a href="cluster-overview.html">总览</a></li>
                                <li><a href="submitting-applications.html">提交申请</a></li>
                                <li class="divider"></li>
                                <li><a href="spark-standalone.html">Spark独立</a></li>
                                <li><a href="running-on-mesos.html">梅索斯</a></li>
                                <li><a href="running-on-yarn.html">纱</a></li>
                                <li><a href="running-on-kubernetes.html">Kubernetes</a></li>
                            </ul>
                        </li>

                        <li class="dropdown">
                            <a href="api.html" class="dropdown-toggle" data-toggle="dropdown">更多<b class="caret"></b></a>
                            <ul class="dropdown-menu">
                                <li><a href="configuration.html">组态</a></li>
                                <li><a href="monitoring.html">监控方式</a></li>
                                <li><a href="tuning.html">调音指南</a></li>
                                <li><a href="job-scheduling.html">作业调度</a></li>
                                <li><a href="security.html">安全</a></li>
                                <li><a href="hardware-provisioning.html">硬件配置</a></li>
                                <li class="divider"></li>
                                <li><a href="building-spark.html">建筑火花</a></li>
                                <li><a href="https://spark.apache.org/contributing.html">为Spark贡献</a></li>
                                <li><a href="https://spark.apache.org/third-party-projects.html">第三方项目</a></li>
                            </ul>
                        </li>
                    </ul>
                    <!--<p class="navbar-text pull-right"><span class="version-text">v2.4.4</span></p>-->
                </div>
            </div>
        </div>

        <div class="container-wrapper">

            
                
                    <div class="left-menu-wrapper">
    <div class="left-menu">
        <h3><a href="ml-guide.html">MLlib：主要指南</a></h3>
        
<ul>

    <li>
        <a href="ml-statistics.html">基本统计</a>
    </li>
    
    

    <li>
        <a href="ml-datasource">数据源</a>
    </li>
    
    

    <li>
        <a href="ml-pipeline.html">流水线</a>
    </li>
    
    

    <li>
        <a href="ml-features.html">提取，转换和选择特征</a>
    </li>
    
    

    <li>
        <a href="ml-classification-regression.html">分类与回归</a>
    </li>
    
    

    <li>
        <a href="ml-clustering.html">聚类</a>
    </li>
    
    

    <li>
        <a href="ml-collaborative-filtering.html">协同过滤</a>
    </li>
    
    

    <li>
        <a href="ml-frequent-pattern-mining.html">频繁模式挖掘</a>
    </li>
    
    

    <li>
        <a href="ml-tuning.html">模型选择和调整</a>
    </li>
    
    

    <li>
        <a href="ml-advanced.html">进阶主题</a>
    </li>
    
    

</ul>

        <h3><a href="mllib-guide.html">MLlib：基于RDD的API指南</a></h3>
        
<ul>

    <li>
        <a href="mllib-data-types.html">资料类型</a>
    </li>
    
    

    <li>
        <a href="mllib-statistics.html">基本统计</a>
    </li>
    
    

    <li>
        <a href="mllib-classification-regression.html">分类与回归</a>
    </li>
    
    

    <li>
        <a href="mllib-collaborative-filtering.html">协同过滤</a>
    </li>
    
    

    <li>
        <a href="mllib-clustering.html">聚类</a>
    </li>
    
    

    <li>
        <a href="mllib-dimensionality-reduction.html">降维</a>
    </li>
    
    

    <li>
        <a href="mllib-feature-extraction.html">特征提取和转换</a>
    </li>
    
    

    <li>
        <a href="mllib-frequent-pattern-mining.html">频繁模式挖掘</a>
    </li>
    
    

    <li>
        <a href="mllib-evaluation-metrics.html">评估指标</a>
    </li>
    
    

    <li>
        <a href="mllib-pmml-model-export.html">PMML模型导出</a>
    </li>
    
    

    <li>
        <a href="mllib-optimization.html">优化（开发人员）</a>
    </li>
    
    

</ul>

    </div>
</div>
                
                <input id="nav-trigger" class="nav-trigger" type="checkbox" checked>
                <label for="nav-trigger"></label>
                <div class="content-with-sidebar" id="content">
                    
                        <h1 class="title">旧的迁移指南-MLlib</h1>
                    

                    <p>当前Spark版本的迁移指南位于<a href="ml-guide.html#migration-guide">MLlib指南主页上</a> 。</p>

<h2 id="from-21-to-22">从2.1到2.2</h2>

<h3 id="breaking-changes">重大变化</h3>

<p>没有重大变化。</p>

<h3 id="deprecations-and-changes-of-behavior">弃用和行为改变</h3>

<p><strong>弃用</strong></p>

<p>没有弃用。</p>

<p><strong>行为改变</strong></p>

<ul>
  <li><a href="https://issues.apache.org/jira/browse/SPARK-19787">SPARK-19787</a> ：的默认值<code>regParam</code>从<code>1.0</code>至<code>0.1</code>对于<code>ALS.train</code>方法（标记为<code>DeveloperApi</code> ）。
 <strong>请注意，</strong>这不会<em>影响</em> <code>ALS</code>估计器或模型，也不是MLlib的<code>ALS</code>类。</li>
  <li><a href="https://issues.apache.org/jira/browse/SPARK-14772">SPARK-14772</a> ：修复了Python和Scala API之间的不一致<code>Param.copy</code>方法。</li>
  <li><a href="https://issues.apache.org/jira/browse/SPARK-11569">SPARK-11569</a> ： <code>StringIndexer</code>现在处理<code>NULL</code>值与看不见的值相同。以前，无论<code>handleInvalid</code>参数。</li>
</ul>

<h2 id="from-20-to-21">从2.0到2.1</h2>

<h3 id="breaking-changes-1">重大变化</h3>

<p><strong>弃用的方法已删除</strong></p>

<ul>
  <li><code>setLabelCol</code>在<code>feature.ChiSqSelectorModel</code></li>
  <li><code>numTrees</code>在<code>classification.RandomForestClassificationModel</code> （现在指的是称为<code>numTrees</code> ）</li>
  <li><code>numTrees</code>在<code>regression.RandomForestRegressionModel</code> （现在指的是称为<code>numTrees</code> ）</li>
  <li><code>model</code>在<code>regression.LinearRegressionSummary</code></li>
  <li><code>validateParams</code>在<code>PipelineStage</code></li>
  <li><code>validateParams</code>在<code>Evaluator</code></li>
</ul>

<h3 id="deprecations-and-changes-of-behavior-1">弃用和行为改变</h3>

<p><strong>弃用</strong></p>

<ul>
  <li><a href="https://issues.apache.org/jira/browse/SPARK-18592">SPARK-18592</a> ：弃用所有参数设置器方法，但输入/输出列的参数<code>DecisionTreeClassificationModel</code> ， <code>GBTClassificationModel</code> ， <code>RandomForestClassificationModel</code> ， <code>DecisionTreeRegressionModel</code> ， <code>GBTRegressionModel</code>和<code>RandomForestRegressionModel</code></li>
</ul>

<p><strong>行为改变</strong></p>

<ul>
  <li><a href="https://issues.apache.org/jira/browse/SPARK-17870">SPARK-17870</a> ：修复了一个错误<code>ChiSqSelector</code>这很可能会改变其结果。现在<code>ChiSquareSelector</code>使用pValue而不是原始统计信息来选择固定数量的主要特征。</li>
  <li><a href="https://issues.apache.org/jira/browse/SPARK-3261">SPARK-3261</a> ： <code>KMeans</code>如果k个不同的质心不可用或未被选择，则返回的数量可能少于k个聚类中心。</li>
  <li><a href="https://issues.apache.org/jira/browse/SPARK-17389">SPARK-17389</a> ： <code>KMeans</code>将k均值||的默认步数从5减少到2初始化模式。</li>
</ul>

<h2 id="from-16-to-20">从1.6到2.0</h2>

<h3 id="breaking-changes-2">重大变化</h3>

<p>Spark 2.0中有几项重大更改，概述如下。</p>

<p><strong>基于DataFrame的API的线性代数类</strong></p>

<p>Spark的线性代数依存关系已移至新项目， <code>mllib-local</code> （请参阅<a href="https://issues.apache.org/jira/browse/SPARK-13944">SPARK-13944</a> ）。作为此更改的一部分，线性代数类被复制到新的程序包中， <code>spark.ml.linalg</code> 。中基于DataFrame的API <code>spark.ml</code>现在取决于<code>spark.ml.linalg</code>类，导致一些重大变化，主要是在各种模型类中（完整列表请参见<a href="https://issues.apache.org/jira/browse/SPARK-14810">SPARK-14810</a> ）。</p>

<p><strong>注意：中</strong>的基于RDD的API <code>spark.mllib</code>继续依赖以前的软件包<code>spark.mllib.linalg</code> 。</p>

<p><em>转换向量和矩阵</em></p>

<p>尽管大多数管道组件都支持向后兼容以进行加载，但某些现有组件<code>DataFrames</code>并且包含矢量列或矩阵列的2.0之前版本的Spark版本中的管道可能需要迁移到新<code>spark.ml</code>向量和矩阵类型。转换实用程序<code>DataFrame</code>来自的列<code>spark.mllib.linalg</code>至<code>spark.ml.linalg</code>类型（反之亦然）可以在<code>spark.mllib.util.MLUtils</code> 。</p>

<p>还有一些实用方法可用于转换向量和矩阵的单个实例。使用<code>asML</code>上的方法<code>mllib.linalg.Vector</code> / <code>mllib.linalg.Matrix</code>用于转换为<code>ml.linalg</code>类型和<code>mllib.linalg.Vectors.fromML</code> / <code>mllib.linalg.Matrices.fromML</code>用于转换为<code>mllib.linalg</code>类型。</p>

<div class="codetabs">
<div data-lang="scala">

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span></span><span class="k">import</span> <span class="nn">org.apache.spark.mllib.util.MLUtils</span>

<span class="c1">// convert DataFrame columns</span>
<span class="k">val</span> <span class="n">convertedVecDF</span> <span class="k">=</span> <span class="nc">MLUtils</span><span class="o">.</span><span class="n">convertVectorColumnsToML</span><span class="o">(</span><span class="n">vecDF</span><span class="o">)</span>
<span class="k">val</span> <span class="n">convertedMatrixDF</span> <span class="k">=</span> <span class="nc">MLUtils</span><span class="o">.</span><span class="n">convertMatrixColumnsToML</span><span class="o">(</span><span class="n">matrixDF</span><span class="o">)</span>
<span class="c1">// convert a single vector or matrix</span>
<span class="k">val</span> <span class="n">mlVec</span><span class="k">:</span> <span class="kt">org.apache.spark.ml.linalg.Vector</span> <span class="o">=</span> <span class="n">mllibVec</span><span class="o">.</span><span class="n">asML</span>
<span class="k">val</span> <span class="n">mlMat</span><span class="k">:</span> <span class="kt">org.apache.spark.ml.linalg.Matrix</span> <span class="o">=</span> <span class="n">mllibMat</span><span class="o">.</span><span class="n">asML</span></code></pre></figure>

    <p>请参阅<a href="api/scala/index.html#org.apache.spark.mllib.util.MLUtils$"><code>MLUtils</code> Scala文档</a>以获取更多详细信息。</p>
  </div>

<div data-lang="java">

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span></span><span class="kn">import</span> <span class="nn">org.apache.spark.mllib.util.MLUtils</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.Dataset</span><span class="o">;</span>

<span class="c1">// convert DataFrame columns</span>
<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">convertedVecDF</span> <span class="o">=</span> <span class="n">MLUtils</span><span class="o">.</span><span class="na">convertVectorColumnsToML</span><span class="o">(</span><span class="n">vecDF</span><span class="o">);</span>
<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">convertedMatrixDF</span> <span class="o">=</span> <span class="n">MLUtils</span><span class="o">.</span><span class="na">convertMatrixColumnsToML</span><span class="o">(</span><span class="n">matrixDF</span><span class="o">);</span>
<span class="c1">// convert a single vector or matrix</span>
<span class="n">org</span><span class="o">.</span><span class="na">apache</span><span class="o">.</span><span class="na">spark</span><span class="o">.</span><span class="na">ml</span><span class="o">.</span><span class="na">linalg</span><span class="o">.</span><span class="na">Vector</span> <span class="n">mlVec</span> <span class="o">=</span> <span class="n">mllibVec</span><span class="o">.</span><span class="na">asML</span><span class="o">();</span>
<span class="n">org</span><span class="o">.</span><span class="na">apache</span><span class="o">.</span><span class="na">spark</span><span class="o">.</span><span class="na">ml</span><span class="o">.</span><span class="na">linalg</span><span class="o">.</span><span class="na">Matrix</span> <span class="n">mlMat</span> <span class="o">=</span> <span class="n">mllibMat</span><span class="o">.</span><span class="na">asML</span><span class="o">();</span></code></pre></figure>

    <p>请参阅<a href="api/java/org/apache/spark/mllib/util/MLUtils.html"><code>MLUtils</code> Java文档</a>以获取更多详细信息。</p>
  </div>

<div data-lang="python">

    <figure class="highlight"><pre><code class="language-python" data-lang="python"><span></span><span class="kn">from</span> <span class="nn">pyspark.mllib.util</span> <span class="kn">import</span> <span class="n">MLUtils</span>

<span class="c1"># convert DataFrame columns</span>
<span class="n">convertedVecDF</span> <span class="o">=</span> <span class="n">MLUtils</span><span class="o">.</span><span class="n">convertVectorColumnsToML</span><span class="p">(</span><span class="n">vecDF</span><span class="p">)</span>
<span class="n">convertedMatrixDF</span> <span class="o">=</span> <span class="n">MLUtils</span><span class="o">.</span><span class="n">convertMatrixColumnsToML</span><span class="p">(</span><span class="n">matrixDF</span><span class="p">)</span>
<span class="c1"># convert a single vector or matrix</span>
<span class="n">mlVec</span> <span class="o">=</span> <span class="n">mllibVec</span><span class="o">.</span><span class="n">asML</span><span class="p">()</span>
<span class="n">mlMat</span> <span class="o">=</span> <span class="n">mllibMat</span><span class="o">.</span><span class="n">asML</span><span class="p">()</span></code></pre></figure>

    <p>请参阅<a href="api/python/pyspark.mllib.html#pyspark.mllib.util.MLUtils"><code>MLUtils</code> Python文档</a>提供了更多详细信息。</p>
  </div>
</div>

<p><strong>弃用的方法已删除</strong></p>

<p>几种不推荐使用的方法已在<code>spark.mllib</code>和<code>spark.ml</code>套餐：</p>

<ul>
  <li><code>setScoreCol</code>在<code>ml.evaluation.BinaryClassificationEvaluator</code></li>
  <li><code>weights</code>在<code>LinearRegression</code>和<code>LogisticRegression</code>在<code>spark.ml</code></li>
  <li><code>setMaxNumIterations</code>在<code>mllib.optimization.LBFGS</code> （标记为<code>DeveloperApi</code> ）</li>
  <li><code>treeReduce</code>和<code>treeAggregate</code>在<code>mllib.rdd.RDDFunctions</code> （这些功能在<code>RDD</code> ，直接被标记为<code>DeveloperApi</code> ）</li>
  <li><code>defaultStategy</code>在<code>mllib.tree.configuration.Strategy</code></li>
  <li><code>build</code>在<code>mllib.tree.Node</code></li>
  <li>libsvm加载程序，用于多类，并在其中加载/保存labeledData方法<code>mllib.util.MLUtils</code></li>
</ul>

<p>重大更改的完整列表可以在<a href="https://issues.apache.org/jira/browse/SPARK-14810">SPARK-14810中</a>找到。</p>

<h3 id="deprecations-and-changes-of-behavior-2">弃用和行为改变</h3>

<p><strong>弃用</strong></p>

<p>中的弃用<code>spark.mllib</code>和<code>spark.ml</code>套餐包括：</p>

<ul>
  <li><a href="https://issues.apache.org/jira/browse/SPARK-14984">SPARK-14984</a> ：在<code>spark.ml.regression.LinearRegressionSummary</code> ， <code>model</code>字段已弃用。</li>
  <li><a href="https://issues.apache.org/jira/browse/SPARK-13784">SPARK-13784</a> ：在<code>spark.ml.regression.RandomForestRegressionModel</code>和<code>spark.ml.classification.RandomForestClassificationModel</code> ， <code>numTrees</code>不推荐使用此参数<code>getNumTrees</code>方法。</li>
  <li><a href="https://issues.apache.org/jira/browse/SPARK-13761">SPARK-13761</a> ：在<code>spark.ml.param.Params</code> ， <code>validateParams</code>方法已弃用。我们将覆盖方法中的所有功能移至相应的<code>transformSchema</code> 。</li>
  <li><a href="https://issues.apache.org/jira/browse/SPARK-14829">SPARK-14829</a> ：在<code>spark.mllib</code>包， <code>LinearRegressionWithSGD</code> ， <code>LassoWithSGD</code> ， <code>RidgeRegressionWithSGD</code>和<code>LogisticRegressionWithSGD</code>已弃用。我们鼓励用户使用<code>spark.ml.regression.LinearRegresson</code>和<code>spark.ml.classification.LogisticRegresson</code> 。</li>
  <li><a href="https://issues.apache.org/jira/browse/SPARK-14900">SPARK-14900</a> ：在<code>spark.mllib.evaluation.MulticlassMetrics</code> ，参数<code>precision</code> ， <code>recall</code>和<code>fMeasure</code>不赞成使用<code>accuracy</code> 。</li>
  <li><a href="https://issues.apache.org/jira/browse/SPARK-15644">SPARK-15644</a> ：在<code>spark.ml.util.MLReader</code>和<code>spark.ml.util.MLWriter</code> ， <code>context</code>不赞成使用该方法<code>session</code> 。</li>
  <li>在<code>spark.ml.feature.ChiSqSelectorModel</code> ， <code>setLabelCol</code>方法已被弃用，因为该方法未被<code>ChiSqSelectorModel</code> 。</li>
</ul>

<p><strong>行为改变</strong></p>

<p>行为改变<code>spark.mllib</code>和<code>spark.ml</code>套餐包括：</p>

<ul>
  <li><a href="https://issues.apache.org/jira/browse/SPARK-7780">SPARK-7780</a> ： <code>spark.mllib.classification.LogisticRegressionWithLBFGS</code>直接呼叫<code>spark.ml.classification.LogisticRegresson</code>现在进行二进制分类。这将引入以下行为更改<code>spark.mllib.classification.LogisticRegressionWithLBFGS</code> ：<ul>
      <li>当使用L1 / L2 Updater训练二进制分类模型时，截距将不会正则化。</li>
      <li>如果用户设置时未进行正则化，则无论有无特征缩放训练都将以相同的收敛速度返回相同的解决方案。</li>
    </ul>
  </li>
  <li><a href="https://issues.apache.org/jira/browse/SPARK-13429">SPARK-13429</a> ：为了提供更好和一致的结果<code>spark.ml.classification.LogisticRegresson</code> ，默认值为<code>spark.mllib.classification.LogisticRegressionWithLBFGS</code> ： <code>convergenceTol</code>已从1E-4更改为1E-6。</li>
  <li><a href="https://issues.apache.org/jira/browse/SPARK-12363">SPARK-12363</a> ：修复了一个错误<code>PowerIterationClustering</code>这很可能会改变其结果。</li>
  <li><a href="https://issues.apache.org/jira/browse/SPARK-13048">SPARK-13048</a> ： <code>LDA</code>使用<code>EM</code>如果正在使用检查点，则优化器将默认保留最后一个检查点。</li>
  <li><a href="https://issues.apache.org/jira/browse/SPARK-12153">SPARK-12153</a> ： <code>Word2Vec</code>现在尊重句子边界。以前，它无法正确处理它们。</li>
  <li><a href="https://issues.apache.org/jira/browse/SPARK-10574">SPARK-10574</a> ： <code>HashingTF</code>用途<code>MurmurHash3</code>作为两者中的默认哈希算法<code>spark.ml</code>和<code>spark.mllib</code> 。</li>
  <li><a href="https://issues.apache.org/jira/browse/SPARK-14768">SPARK-14768</a> ： <code>expectedType</code> PySpark的论点<code>Param</code>去掉了。</li>
  <li><a href="https://issues.apache.org/jira/browse/SPARK-14931">SPARK-14931</a> ：一些默认值<code>Param</code> Scala和Python中的管道之间不匹配的值已更改。</li>
  <li><a href="https://issues.apache.org/jira/browse/SPARK-13600">SPARK-13600</a> ： <code>QuantileDiscretizer</code>现在使用<code>spark.sql.DataFrameStatFunctions.approxQuantile</code>查找拆分（以前使用的自定义采样逻辑）。对于相同的输入数据和参数，输出存储桶将有所不同。</li>
</ul>

<h2 id="from-15-to-16">从1.5到1.6</h2>

<p>API中没有重大的API更改<code>spark.mllib</code>要么<code>spark.ml</code>包，但存在弃用和行为更改。</p>

<p>不推荐使用：</p>

<ul>
  <li><a href="https://issues.apache.org/jira/browse/SPARK-11358">SPARK-11358</a> ：在<code>spark.mllib.clustering.KMeans</code> ， <code>runs</code>参数已弃用。</li>
  <li><a href="https://issues.apache.org/jira/browse/SPARK-10592">SPARK-10592</a> ：在<code>spark.ml.classification.LogisticRegressionModel</code>和<code>spark.ml.regression.LinearRegressionModel</code> ， <code>weights</code>已弃用该字段以使用新名称<code>coefficients</code> 。这有助于消除分配给算法的实例（行）“权重”。</li>
</ul>

<p>行为变化：</p>

<ul>
  <li><a href="https://issues.apache.org/jira/browse/SPARK-7770">SPARK-7770</a> ： <code>spark.mllib.tree.GradientBoostedTrees</code> ： <code>validationTol</code>在1.6中更改了语义。以前，这是绝对误差变化的阈值。现在，它类似于<code>GradientDescent</code>的<code>convergenceTol</code> ：对于大错误，它使用相对错误（相对于先前的错误）；对于小错误（ <code>< 0.01</code> ），则使用绝对错误。</li>
  <li><a href="https://issues.apache.org/jira/browse/SPARK-11069">SPARK-11069</a> ： <code>spark.ml.feature.RegexTokenizer</code> ：以前，在标记化之前，它不会将字符串转换为小写。现在，默认情况下它将转换为小写，并带有一个选项。这与简单的行为相匹配<code>Tokenizer</code>变压器。</li>
</ul>

<h2 id="from-14-to-15">从1.4到1.5</h2>

<p>在里面<code>spark.mllib</code>程序包，没有重大的API更改，但有一些行为更改：</p>

<ul>
  <li><a href="https://issues.apache.org/jira/browse/SPARK-9005">SPARK-9005</a> ： <code>RegressionMetrics.explainedVariance</code>返回平方的平均回归和。</li>
  <li><a href="https://issues.apache.org/jira/browse/SPARK-8600">SPARK-8600</a> ： <code>NaiveBayesModel.labels</code>变得排序。</li>
  <li><a href="https://issues.apache.org/jira/browse/SPARK-3382">SPARK-3382</a> ： <code>GradientDescent</code>具有默认的收敛容差<code>1e-3</code> ，因此迭代可能早于1.4结束。</li>
</ul>

<p>在里面<code>spark.ml</code>包中，存在一项重大的API更改和一项行为更改：</p>

<ul>
  <li><a href="https://issues.apache.org/jira/browse/SPARK-9268">SPARK-9268</a> ：从以下版本中删除了Java的varargs支持： <code>Params.setDefault</code>由于<a href="https://issues.scala-lang.org/browse/SI-9013">Scala编译器错误</a> 。</li>
  <li><a href="https://issues.apache.org/jira/browse/SPARK-10097">SPARK-10097</a> ： <code>Evaluator.isLargerBetter</code>添加以指示度量顺序。像RMSE这样的指标不再像1.4中那样翻转符号。</li>
</ul>

<h2 id="from-13-to-14">从1.3到1.4</h2>

<p>在里面<code>spark.mllib</code>包中有一些重大更改，但全部<code>DeveloperApi</code>要么<code>Experimental</code>蜜蜂：</p>

<ul>
  <li>梯度助推树<ul>
      <li><em>（重大更改）</em> <a href="api/scala/index.html#org.apache.spark.mllib.tree.loss.Loss"><code>Loss.gradient</code></a>方法已更改。对于仅写自己的GBT损失的用户而言，这只是一个问题。</li>
      <li><em>（巨变）</em> <code>apply</code>和<code>copy</code>案例类的方法<a href="api/scala/index.html#org.apache.spark.mllib.tree.configuration.BoostingStrategy"><code>BoostingStrategy</code></a>由于对案例类字段的修改而已更改。对于使用以下内容的用户，这可能是个问题<code>BoostingStrategy</code>设置GBT参数。</li>
    </ul>
  </li>
  <li><em>（突变）</em>的返回值<a href="api/scala/index.html#org.apache.spark.mllib.clustering.LDA"><code>LDA.run</code></a>已经改变。现在它返回一个抽象类<code>LDAModel</code>代替具体的课程<code>DistributedLDAModel</code> 。类型的对象<code>LDAModel</code>仍可以转换为适当的具体类型，具体取决于优化算法。</li>
</ul>

<p>在里面<code>spark.ml</code>软件包中，发生了一些主要的API更改，包括：</p>

<ul>
  <li><code>Param</code>和其他用于指定参数的API</li>
  <li><code>uid</code>管道组件的唯一ID</li>
  <li>重组某些班级</li>
</ul>

<p>自从<code>spark.ml</code> API是Spark 1.3中的Alpha组件，我们不在此列出所有更改。但是，从1.4开始<code>spark.ml</code>不再是Alpha组件，我们将提供有关将来版本的所有API更改的详细信息。</p>

<h2 id="from-12-to-13">从1.2到1.3</h2>

<p>在里面<code>spark.mllib</code>包装中有几个重大更改。第一次更改（在<code>ALS</code> ）是组件中唯一未标记为“ Alpha”或“实验”的组件。</p>

<ul>
  <li><em>（零钱）</em>在<a href="api/scala/index.html#org.apache.spark.mllib.recommendation.ALS"><code>ALS</code></a> ，无关的方法<code>solveLeastSquares</code>已被删除。的<code>DeveloperApi</code>方法<code>analyzeBlocks</code>也被删除了。</li>
  <li><em>（零钱）</em> <a href="api/scala/index.html#org.apache.spark.mllib.feature.StandardScalerModel"><code>StandardScalerModel</code></a>仍然是Alpha组件。在其中<code>variance</code>方法已被替换为<code>std</code>方法。计算原始返回的列方差值<code>variance</code>方法，只需平方由<code>std</code> 。</li>
  <li><em>（零钱）</em> <a href="api/scala/index.html#org.apache.spark.mllib.regression.StreamingLinearRegressionWithSGD"><code>StreamingLinearRegressionWithSGD</code></a>仍然是实验组件。其中有两个更改：<ul>
      <li>使用默认构造函数加参数setter方法的构造函数模式被删除了带有参数的构造函数。</li>
      <li>变量<code>model</code>不再公开。</li>
    </ul>
  </li>
  <li><em>（零钱）</em> <a href="api/scala/index.html#org.apache.spark.mllib.tree.DecisionTree"><code>DecisionTree</code></a>仍然是实验组件。在它及其关联的类中，进行了几处更改：<ul>
      <li>在<code>DecisionTree</code> ，不推荐使用的类方法<code>train</code>已被删除。（对象/静态<code>train</code>方法仍然存在。）</li>
      <li>在<code>Strategy</code> ， <code>checkpointDir</code>参数已删除。仍然支持检查点，但是必须在调用树和树集成训练之前设置检查点目录。</li>
    </ul>
  </li>
  <li><code>PythonMLlibAPI</code> （Scala / Java和MLlib的Python之间的接口）是公共API，但现在是私有的，已声明<code>private[python]</code> 。这绝不是供外部使用。</li>
  <li>在线性回归（包括套索和岭回归）中，平方损失现在除以2。因此，为了产生与1.2中相同的结果，正则化参数需要除以2，步长需要乘以2。</li>
</ul>

<p>在里面<code>spark.ml</code>包，主要的API更改来自Spark SQL。我们在这里列出最重要的更改：</p>

<ul>
  <li>旧的<a href="https://spark.apache.org/docs/1.2.1/api/scala/index.html#org.apache.spark.sql.SchemaRDD">SchemaRDD</a>已由带有经过一些修改的API的<a href="api/scala/index.html#org.apache.spark.sql.DataFrame">DataFrame</a>取代。中的所有算法<code>spark.ml</code>过去使用SchemaRDD的现在使用DataFrame。</li>
  <li>在Spark 1.2中，我们使用了隐式转换<code>RDD</code>的<code>LabeledPoint</code>进入<code>SchemaRDD</code>通过调用<code>import sqlContext._</code>哪里<code>sqlContext</code>是...的一个实例<code>SQLContext</code> 。这些隐式已被移动，因此我们现在称为<code>import sqlContext.implicits._</code> 。</li>
  <li>用于SQL的Java API也进行了相应更改。有关详细信息，请参见上面的示例和《 <a href="sql-programming-guide.html">Spark SQL编程指南</a> 》。</li>
</ul>

<p>其他变化在<code>LogisticRegression</code> ：</p>

<ul>
  <li>的<code>scoreCol</code>输出列（默认值为“分数”）已重命名为<code>probabilityCol</code> （默认值为“概率”）。该类型最初是<code>Double</code> （针对1.0类的概率），但现在<code>Vector</code> （针对每个类别的概率，以在将来支持多类别分类）。</li>
  <li>在Spark 1.2中， <code>LogisticRegressionModel</code>没有拦截。在Spark 1.3中，它包括一个拦截器；但是，它将始终为0.0，因为它使用<a href="api/scala/index.html#org.apache.spark.mllib.classification.LogisticRegressionWithLBFGS">spark.mllib的默认设置</a><a href="api/scala/index.html#org.apache.spark.mllib.classification.LogisticRegressionWithLBFGS">。LogisticRegressionWithLBFGS</a> 。将来会添加使用拦截的选项。</li>
</ul>

<h2 id="from-11-to-12">从1.1到1.2</h2>

<p>MLlib v1.2中唯一的API更改位于<a href="api/scala/index.html#org.apache.spark.mllib.tree.DecisionTree"><code>DecisionTree</code></a> ，它仍然是MLlib 1.2中的实验性API：</p>

<ol>
  <li>
    <p><em>（重大更改）</em>用于分类的Scala API带有一个指定参数，用于指定类的数量。在MLlib v1.1中，此参数称为<code>numClasses</code>在Python和<code>numClassesForClassification</code>在斯卡拉。在MLlib v1.2中，名称都设置为<code>numClasses</code> 。这个<code>numClasses</code>参数通过以下方式指定<a href="api/scala/index.html#org.apache.spark.mllib.tree.configuration.Strategy"><code>Strategy</code></a>或通过<a href="api/scala/index.html#org.apache.spark.mllib.tree.DecisionTree"><code>DecisionTree</code></a>静态的<code>trainClassifier</code>和<code>trainRegressor</code>方法。</p>
  </li>
  <li>
    <p><em>（重大更改）</em>用于<a href="api/scala/index.html#org.apache.spark.mllib.tree.model.Node"><code>Node</code></a>已经改变。通常，这应该不会影响用户代码，除非用户手动构造决策树（而不是使用<code>trainClassifier</code>要么<code>trainRegressor</code>方法）。那个树<code>Node</code>现在包括更多信息，包括预测标签的概率（用于分类）。</p>
  </li>
  <li>
    <p>打印方法的输出已更改。的<code>toString</code> （Scala / Java）和<code>__repr__</code> （Python）用于打印完整模型的方法；他们现在打印摘要。对于完整模型，请使用<code>toDebugString</code> 。</p>
  </li>
</ol>

<p>相应地更新了Spark发行版中的示例和《 <a href="mllib-decision-tree.html#examples">决策树指南》</a>中的示例。</p>

<h2 id="from-10-to-11">从1.0到1.1</h2>

<p>MLlib v1.1中唯一的API更改位于<a href="api/scala/index.html#org.apache.spark.mllib.tree.DecisionTree"><code>DecisionTree</code></a> ，它仍然是MLlib 1.1中的实验性API：</p>

<ol>
  <li>
    <p><em>（突破性更改）</em>为了与<a href="http://scikit-learn.org/stable/modules/classes.html#module-sklearn.tree">scikit-learn</a>和<a href="http://cran.r-project.org/web/packages/rpart/index.html">rpart中</a>的树实现相匹配，树深度的含义已更改为1。在MLlib v1.0中，深度1树有1个叶节点，深度2树有1个根节点和2个叶节点。在MLlib v1.1中，深度为0的树具有1个叶节点，深度为1的树具有1个根节点和2个叶节点。该深度由<code>maxDepth</code>输入参数<a href="api/scala/index.html#org.apache.spark.mllib.tree.configuration.Strategy"><code>Strategy</code></a>或通过<a href="api/scala/index.html#org.apache.spark.mllib.tree.DecisionTree"><code>DecisionTree</code></a>静态的<code>trainClassifier</code>和<code>trainRegressor</code>方法。</p>
  </li>
  <li>
    <p><em>（不间断的更改）</em>我们建议使用新添加的<code>trainClassifier</code>和<code>trainRegressor</code>建立一个方法<a href="api/scala/index.html#org.apache.spark.mllib.tree.DecisionTree"><code>DecisionTree</code></a> ，而不是使用旧的参数类<code>Strategy</code> 。这些新的训练方法明确地将分类和回归分开，并且用简单的方法替换了专门的参数类型<code>String</code>类型。</p>
  </li>
</ol>

<p>新推荐的例子<code>trainClassifier</code>和<code>trainRegressor</code>在“ <a href="mllib-decision-tree.html#examples">决策树指南”</a>中给出。</p>

<h2 id="from-09-to-10">从0.9到1.0</h2>

<p>在MLlib v1.0中，我们以统一的方式支持密集输入和稀疏输入，这引入了一些重大更改。如果您的数据稀疏，请以稀疏格式而不是密集格式存储，以利用存储和计算中的稀疏性。详细说明如下。</p>



                </div>
            
             <!-- /container -->
        </div>

        <script src="js/vendor/jquery-1.12.4.min.js"></script>
        <script src="js/vendor/bootstrap.min.js"></script>
        <script src="js/vendor/anchor.min.js"></script>
        <script src="js/main.js"></script>

        <!-- MathJax Section -->
        <script type="text/x-mathjax-config">
            MathJax.Hub.Config({
                TeX: { equationNumbers: { autoNumber: "AMS" } }
            });
        </script>
        <script>
            // Note that we load MathJax this way to work with local file (file://), HTTP and HTTPS.
            // We could use "//cdn.mathjax...", but that won't support "file://".
            (function(d, script) {
                script = d.createElement('script');
                script.type = 'text/javascript';
                script.async = true;
                script.onload = function(){
                    MathJax.Hub.Config({
                        tex2jax: {
                            inlineMath: [ ["$", "$"], ["\\\\(","\\\\)"] ],
                            displayMath: [ ["$$","$$"], ["\\[", "\\]"] ],
                            processEscapes: true,
                            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre']
                        }
                    });
                };
                script.src = ('https:' == document.location.protocol ? 'https://' : 'http://') +
                    'cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js' +
                    '?config=TeX-AMS-MML_HTMLorMML';
                d.getElementsByTagName('head')[0].appendChild(script);
            }(document));
        </script>
    

</body></html>