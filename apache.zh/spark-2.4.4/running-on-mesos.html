<html class="no-js" ><!--<![endif]--><head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
        <title>在Mesos上运行Spark-Spark 2.4.4文档</title>
        

        

        <link rel="stylesheet" href="css/bootstrap.min.css">
        <style>
            body {
                padding-top: 60px;
                padding-bottom: 40px;
            }
        </style>
        <meta name="viewport" content="width=device-width">
        <link rel="stylesheet" href="css/bootstrap-responsive.min.css">
        <link rel="stylesheet" href="css/main.css">

        <script src="js/vendor/modernizr-2.6.1-respond-1.1.0.min.js"></script>

        <link rel="stylesheet" href="css/pygments-default.css">

        
        <!-- Google analytics script -->
        <script type="text/javascript">
          var _gaq = _gaq || [];
          _gaq.push(['_setAccount', 'UA-32518208-2']);
          _gaq.push(['_trackPageview']);

          (function() {
            var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
            ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
            var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
          })();
        </script>
        

    </head>
    <body >
        <!--[if lt IE 7]>
            <p class="chromeframe">You are using an outdated browser. <a href="https://browsehappy.com/">Upgrade your browser today</a> or <a href="http://www.google.com/chromeframe/?redirect=true">install Google Chrome Frame</a> to better experience this site.</p>
        <![endif]-->

        <!-- This code is taken from http://twitter.github.com/bootstrap/examples/hero.html -->

        <div class="navbar navbar-fixed-top" id="topbar">
            <div class="navbar-inner">
                <div class="container">
                    <div class="brand"><a href="index.html"><img src="img/spark-logo-hd.png" style="height:50px"></a> <span class="version">2.4.4</span>
                    </div>
                    <ul class="nav">
                        <!--TODO(andyk): Add class="active" attribute to li some how.-->
                        <li><a href="index.html">总览</a></li>

                        <li class="dropdown">
                            <a href="#" class="dropdown-toggle" data-toggle="dropdown">编程指南<b class="caret"></b></a>
                            <ul class="dropdown-menu">
                                <li><a href="quick-start.html">快速开始</a></li>
                                <li><a href="rdd-programming-guide.html">RDD，累加器，广播变量</a></li>
                                <li><a href="sql-programming-guide.html">SQL，数据框和数据集</a></li>
                                <li><a href="structured-streaming-programming-guide.html">结构化流</a></li>
                                <li><a href="streaming-programming-guide.html">火花流（DStreams）</a></li>
                                <li><a href="ml-guide.html">MLlib（机器学习）</a></li>
                                <li><a href="graphx-programming-guide.html">GraphX（图形处理）</a></li>
                                <li><a href="sparkr.html">SparkR（Spark上的R）</a></li>
                            </ul>
                        </li>

                        <li class="dropdown">
                            <a href="#" class="dropdown-toggle" data-toggle="dropdown">API文件<b class="caret"></b></a>
                            <ul class="dropdown-menu">
                                <li><a href="api/scala/index.html#org.apache.spark.package">斯卡拉</a></li>
                                <li><a href="api/java/index.html">爪哇</a></li>
                                <li><a href="api/python/index.html">蟒蛇</a></li>
                                <li><a href="api/R/index.html">[R</a></li>
                                <li><a href="api/sql/index.html">SQL，内置函数</a></li>
                            </ul>
                        </li>

                        <li class="dropdown">
                            <a href="#" class="dropdown-toggle" data-toggle="dropdown">部署中<b class="caret"></b></a>
                            <ul class="dropdown-menu">
                                <li><a href="cluster-overview.html">总览</a></li>
                                <li><a href="submitting-applications.html">提交申请</a></li>
                                <li class="divider"></li>
                                <li><a href="spark-standalone.html">Spark独立</a></li>
                                <li><a href="running-on-mesos.html">梅索斯</a></li>
                                <li><a href="running-on-yarn.html">纱</a></li>
                                <li><a href="running-on-kubernetes.html">Kubernetes</a></li>
                            </ul>
                        </li>

                        <li class="dropdown">
                            <a href="api.html" class="dropdown-toggle" data-toggle="dropdown">更多<b class="caret"></b></a>
                            <ul class="dropdown-menu">
                                <li><a href="configuration.html">组态</a></li>
                                <li><a href="monitoring.html">监控方式</a></li>
                                <li><a href="tuning.html">调音指南</a></li>
                                <li><a href="job-scheduling.html">作业调度</a></li>
                                <li><a href="security.html">安全</a></li>
                                <li><a href="hardware-provisioning.html">硬件配置</a></li>
                                <li class="divider"></li>
                                <li><a href="building-spark.html">建筑火花</a></li>
                                <li><a href="https://spark.apache.org/contributing.html">为Spark贡献</a></li>
                                <li><a href="https://spark.apache.org/third-party-projects.html">第三方项目</a></li>
                            </ul>
                        </li>
                    </ul>
                    <!--<p class="navbar-text pull-right"><span class="version-text">v2.4.4</span></p>-->
                </div>
            </div>
        </div>

        <div class="container-wrapper">

            
                <div class="content" id="content">
                    
                        <h1 class="title">在Mesos上运行Spark</h1>
                    

                    <ul id="markdown-toc">
  <li><a href="#security" id="markdown-toc-security">安全</a></li>
  <li><a href="#how-it-works" id="markdown-toc-how-it-works">怎么运行的</a></li>
  <li><a href="#installing-mesos" id="markdown-toc-installing-mesos">安装Mesos</a>    <ul>
      <li><a href="#from-source" id="markdown-toc-from-source">从来源</a></li>
      <li><a href="#third-party-packages" id="markdown-toc-third-party-packages">第三方套餐</a></li>
      <li><a href="#verification" id="markdown-toc-verification">验证</a></li>
    </ul>
  </li>
  <li><a href="#connecting-spark-to-mesos" id="markdown-toc-connecting-spark-to-mesos">将Spark连接到Mesos</a>    <ul>
      <li><a href="#authenticating-to-mesos" id="markdown-toc-authenticating-to-mesos">向Mesos进行身份验证</a>        <ul>
          <li><a href="#credential-specification-preference-order" id="markdown-toc-credential-specification-preference-order">凭证规范首选项顺序</a></li>
        </ul>
      </li>
      <li><a href="#uploading-spark-package" id="markdown-toc-uploading-spark-package">上传Spark Package</a></li>
      <li><a href="#using-a-mesos-master-url" id="markdown-toc-using-a-mesos-master-url">使用Mesos主网址</a></li>
      <li><a href="#client-mode" id="markdown-toc-client-mode">客户端模式</a></li>
      <li><a href="#cluster-mode" id="markdown-toc-cluster-mode">集群模式</a></li>
    </ul>
  </li>
  <li><a href="#mesos-run-modes" id="markdown-toc-mesos-run-modes">Mesos运行模式</a>    <ul>
      <li><a href="#coarse-grained" id="markdown-toc-coarse-grained">粗粒</a></li>
      <li><a href="#fine-grained-deprecated" id="markdown-toc-fine-grained-deprecated">细粒度（已弃用）</a></li>
    </ul>
  </li>
  <li><a href="#mesos-docker-support" id="markdown-toc-mesos-docker-support">Mesos Docker支持</a></li>
  <li><a href="#running-alongside-hadoop" id="markdown-toc-running-alongside-hadoop">与Hadoop一起运行</a></li>
  <li><a href="#dynamic-resource-allocation-with-mesos" id="markdown-toc-dynamic-resource-allocation-with-mesos">使用Mesos进行动态资源分配</a></li>
  <li><a href="#configuration" id="markdown-toc-configuration">组态</a>    <ul>
      <li><a href="#spark-properties" id="markdown-toc-spark-properties">火花特性</a></li>
    </ul>
  </li>
  <li><a href="#troubleshooting-and-debugging" id="markdown-toc-troubleshooting-and-debugging">故障排除和调试</a></li>
</ul>

<p>Spark可以在<a href="http://mesos.apache.org/">Apache Mesos</a>管理的硬件群集上运行。</p>

<p>与Mesos一起部署Spark的优势包括：</p>

<ul>
  <li>Spark与其他<a href="https://mesos.apache.org/documentation/latest/frameworks/">框架</a>之间的动态分区</li>
  <li>Spark的多个实例之间的可扩展分区</li>
</ul>

<h1 id="security">安全</h1>

<p>默认情况下，Spark中的安全性处于关闭状态。这可能意味着您默认情况下容易受到攻击。在运行Spark之前，请参阅<a href="security.html">Spark安全性</a>和本文档中的特定安全性部分。</p>

<h1 id="how-it-works">怎么运行的</h1>

<p>在独立集群部署中，下图中的集群管理器是Spark主实例。使用Mesos时，Mesos主节点将Spark主节点替换为集群管理器。</p>

<p style="text-align:center">
  <img src="img/cluster-overview.png" title="Spark集群组件" alt="Spark集群组件">
</p>

<p>现在，当驱动程序创建作业并开始发布任务以进行调度时，Mesos将确定哪些计算机处理哪些任务。因为在计划这些短期任务时会考虑其他框架，所以多个框架可以共存于同一群集上，而无需求助于资源的静态分区。</p>

<p>首先，请按照以下步骤安装Mesos并通过Mesos部署Spark作业。</p>

<h1 id="installing-mesos">安装Mesos</h1>

<p>Spark 2.4.4专为与Mesos 1.0.0或更高版本一起使用而设计，不需要任何特殊的Mesos补丁。基于文件和环境的机密支持需要Mesos 1.3.0或更高版本。</p>

<p>如果您已经在运行Mesos集群，则可以跳过此Mesos安装步骤。</p>

<p>否则，安装Mesos for Spark与安装供其他框架使用的Mesos没什么不同。您可以从源代码或使用预构建的软件包安装Mesos。</p>

<h2 id="from-source">从来源</h2>

<p>要从源代码安装Apache Mesos，请执行以下步骤：</p>

<ol>
  <li>从<a href="http://www.apache.org/dyn/closer.lua/mesos/1.0.0/">镜像</a>下载Mesos版本</li>
  <li>遵循Mesos <a href="http://mesos.apache.org/getting-started">入门</a>页面来编译和安装Mesos</li>
</ol>

<p><strong>注意：</strong>如果要运行Mesos而不将其安装到系统的默认路径中（例如，如果您没有安装它的管理权限），请传递<code>--prefix</code>选择<code>configure</code>告诉它在哪里安装。例如，通过<code>--prefix=/home/me/mesos</code> 。默认情况下，前缀为<code>/usr/local</code> 。</p>

<h2 id="third-party-packages">第三方套餐</h2>

<p>Apache Mesos项目仅发布源版本，而不发布二进制软件包。但是其他第三方项目会发布二进制版本，这可能对设置Mesos有所帮助。</p>

<p>其中之一是中间层。要使用Mesosphere提供的二进制发行版安装Mesos，请执行以下操作：</p>

<ol>
  <li>从<a href="https://open.mesosphere.com/downloads/mesos/">下载页面</a>下载Mesos安装软件包</li>
  <li>按照他们的说明进行安装和配置</li>
</ol>

<p>Mesosphere安装文档建议设置ZooKeeper来处理Mesos主服务器故障转移，但是Mesos也可以在不使用单个主服务器的ZooKeeper的情况下运行。</p>

<h2 id="verification">验证</h2>

<p>要验证Mesos集群已准备好用于Spark，请在端口上导航到Mesos主Webui。 <code>:5050</code>确认从站选项卡中存在所有预期的计算机。</p>

<h1 id="connecting-spark-to-mesos">将Spark连接到Mesos</h1>

<p>要使用Spark中的Mesos，您需要一个在Mesos可访问的位置可用的Spark二进制软件包，以及一个配置为连接到Mesos的Spark驱动程序。</p>

<p>或者，您也可以将Spark安装在所有Mesos从站的相同位置，并进行配置<code>spark.mesos.executor.home</code> （默认为SPARK_HOME）指向该位置。</p>

<h2 id="authenticating-to-mesos">向Mesos进行身份验证</h2>

<p>启用Mesos Framework身份验证后，有必要提供一个主体和密码，用于通过此主体和密码对Mesos进行Spark身份验证。每个Spark作业都将在Mesos中注册为单独的框架。</p>

<p>根据您的部署环境，您可能希望创建在所有用户之间共享的一组框架凭据，或者为每个用户创建框架凭据。创建和管理框架凭据应遵循Mesos <a href="http://mesos.apache.org/documentation/latest/authentication/">身份验证文档进行</a> 。</p>

<p>可以根据部署环境和安全要求以多种方式指定框架凭据。最简单的方法是指定<code>spark.mesos.principal</code>和<code>spark.mesos.secret</code>值直接在您的Spark配置中。另外，您可以间接指定这些值，而不是指定<code>spark.mesos.principal.file</code>和<code>spark.mesos.secret.file</code> ，这些设置指向包含主体和密钥的文件。这些文件必须是UTF-8编码的纯文本文件。与适当的文件所有权和模式/ ACL结合使用，可以提供一种更安全的方式来指定这些凭据。</p>

<p>此外，如果您更喜欢使用环境变量，则可以通过环境变量来指定所有上述内容，环境变量名称只是配置设置中的大写字母，用<code>.</code>替换为<code>_</code>例如<code>SPARK_MESOS_PRINCIPAL</code> 。</p>

<h3 id="credential-specification-preference-order">凭证规范首选项顺序</h3>

<p>请注意，如果您指定了多种获取凭证的方式，则以下优先顺序适用。Spark将使用找到的第一个有效值，并忽略所有后续值：</p>

<ul>
  <li><code>spark.mesos.principal</code>配置设定</li>
  <li><code>SPARK_MESOS_PRINCIPAL</code>环境变量</li>
  <li><code>spark.mesos.principal.file</code>配置设定</li>
  <li><code>SPARK_MESOS_PRINCIPAL_FILE</code>环境变量</li>
</ul>

<p>同等命令适用于该机密。本质上，我们更喜欢直接由文件而不是文件间接指定配置，并且我们更喜欢使用配置设置而不是环境变量。</p>

<h2 id="uploading-spark-package">上传Spark Package</h2>

<p>当Mesos首次在Mesos从属服务器上运行任务时，该从属服务器必须具有Spark二进制软件包才能运行Spark Mesos执行器后端。可以将Spark软件包托管在任何Hadoop可访问的URI上，包括通过HTTP进行的HTTP访问。 <code>http://</code> ， <a href="http://aws.amazon.com/s3">Amazon Simple Storage Service</a>通过<code>s3n://</code>或HDFS通过<code>hdfs://</code> 。</p>

<p>要使用预编译的软件包：</p>

<ol>
  <li>从Spark <a href="https://spark.apache.org/downloads.html">下载页面</a>下载Spark二进制包</li>
  <li>上载到hdfs / http / s3</li>
</ol>

<p>要在HDFS上托管，请使用Hadoop fs put命令：<code>hadoop fs -put spark-2.4.4.tar.gz /path/to/spark-2.4.4.tar.gz</code></p>

<p>或者，如果您使用的是自定义编译的Spark版本，则需要使用<code>dev/make-distribution.sh</code> Spark源tarball /结帐中包含的脚本。</p>

<ol>
  <li>使用<a href="index.html">此处</a>的说明下载并构建Spark</li>
  <li>使用创建二进制包<code>./dev/make-distribution.sh --tgz</code> 。</li>
  <li>将档案上传到http / s3 / hdfs</li>
</ol>

<h2 id="using-a-mesos-master-url">使用Mesos主网址</h2>

<p>Mesos的主URL格式为<code>mesos://host:5050</code>对于单主Mesos集群，或<code>mesos://zk://host1:2181,host2:2181,host3:2181/mesos</code>使用ZooKeeper的多主Mesos集群。</p>

<h2 id="client-mode">客户端模式</h2>

<p>在客户端模式下，Spark Mesos框架直接在客户端计算机上启动，并等待驱动程序输出。</p>

<p>驱动程序需要一些配置<code>spark-env.sh</code>与Mesos正确交互：</p>

<ol>
  <li>在<code>spark-env.sh</code>设置一些环境变量：<ul>
      <li><code>export MESOS_NATIVE_JAVA_LIBRARY=<path to libmesos.so></code> 。该路径通常是<code><pre><code class="language-scala" data-lang="scala"><span></span><span class="k">val</span> <span class="n">conf</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SparkConf</span><span class="o">()</span>
  <span class="o">.</span><span class="n">setMaster</span><span class="o">(</span><span class="s">&quot;mesos://HOST:5050&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">setAppName</span><span class="o">(</span><span class="s">&quot;My app&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">set</span><span class="o">(</span><span class="s">&quot;spark.executor.uri&quot;</span><span class="o">,</span> <span class="s">&quot;&lt;path to spark-2.4.4.tar.gz uploaded above&gt;&quot;</span><span class="o">)</span>
<span class="k">val</span> <span class="n">sc</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SparkContext</span><span class="o">(</span><span class="n">conf</span><span class="o">)</span></code></pre></figure>

<p>（您也可以使用<a href="submitting-applications.html"><code>spark-submit</code></a>并配置<code>spark.executor.uri</code>在<a href="configuration.html#loading-default-configurations">conf / spark-defaults.conf</a>文件中。）</p>

<p>运行外壳时， <code>spark.executor.uri</code>参数继承自<code>SPARK_EXECUTOR_URI</code> ，因此不需要将其作为系统属性冗余传递。</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span></span>./bin/spark-shell --master mesos://host:5050</code></pre></figure>

<h2 id="cluster-mode">集群模式</h2>

<p>Mesos上的Spark还支持群集模式，该驱动程序在群集中启动，并且客户端可以从Mesos Web UI查找驱动程序的结果。</p>

<p>要使用群集模式，必须启动<code>MesosClusterDispatcher</code>通过<code>sbin/start-mesos-dispatcher.sh</code>脚本，传入Mesos主网址（例如：mesos：// host：5050）。这开始<code>MesosClusterDispatcher</code>作为在主机上运行的守护程序。请注意<code>MesosClusterDispatcher</code>不支持身份验证。您应确保对其的所有网络访问均受到保护（默认情况下，端口为7077）。</p>

<p>通过设置Mesos代理配置属性（需要mesos版本> = 1.4）， <code>--conf spark.mesos.proxy.baseURL=http://localhost:5050</code>启动调度程序时，每个驱动程序的mesos沙箱URI被添加到mesos调度程序UI中。</p>

<p>如果您想运行<code>MesosClusterDispatcher</code>在马拉松比赛中，您需要运行<code>MesosClusterDispatcher</code>在前台（即： <code>bin/spark-class org.apache.spark.deploy.mesos.MesosClusterDispatcher</code> ）。请注意<code>MesosClusterDispatcher</code>尚不支持HA的多个实例。</p>

<p>的<code>MesosClusterDispatcher</code>还支持将恢复状态写入Zookeeper。这将允许<code>MesosClusterDispatcher</code>以便能够在重新启动时恢复所有已提交并正在运行的容器。为了启用此恢复模式，您可以通过配置在spark-env中设置SPARK_DAEMON_JAVA_OPTS <code>spark.deploy.recoveryMode</code>以及相关的spark.deploy.zookeeper。*配置。有关这些配置的更多信息，请参考配置<a href="configuration.html#deploy">文档</a> 。</p>

<p>您还可以指定<code>MesosClusterDispatcher</code>通过在spark-env中设置环境变量SPARK_DAEMON_CLASSPATH来在类路径中进行设置。</p>

<p>您可以从客户端通过运行以下命令将作业提交到Mesos群集<code>spark-submit</code>并将主URL指定为<code>MesosClusterDispatcher</code> （例如：mesos：// dispatcher：7077）。您可以在Spark群集Web UI上查看驱动程序状态。</p>

<p>例如：</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span></span>./bin/spark-submit <span class="se">\</span>
  --class org.apache.spark.examples.SparkPi <span class="se">\</span>
  --master mesos://207.184.161.138:7077 <span class="se">\</span>
  --deploy-mode cluster <span class="se">\</span>
  --supervise <span class="se">\</span>
  --executor-memory 20G <span class="se">\</span>
  --total-executor-cores <span class="m">100</span> <span class="se">\</span>
  http://path/to/examples.jar <span class="se">\</span>
  <span class="m">1000</span></code></pre></figure>

<p>请注意，传递给spark-submit的jar或python文件应该是Mesos从属可访问的URI，因为Spark驱动程序不会自动上传本地jar。</p>

<h1 id="mesos-run-modes">Mesos运行模式</h1>

<p>Spark可以两种方式在Mesos上运行：“粗粒度”（默认）和“细粒度”（不建议使用）。</p>

<h2 id="coarse-grained">粗粒</h2>

<p>在“粗粒度”模式下，每个Spark执行程序都作为单个Mesos任务运行。Spark执行程序的大小取决于以下配置变量：</p>

<ul>
  <li>执行器内存：<code>spark.executor.memory</code></li>
  <li>执行器核心：<code>spark.executor.cores</code></li>
  <li>执行者人数： <code>spark.cores.max</code> /<code>spark.executor.cores</code></li>
</ul>

<p>请参阅“ <a href="configuration.html">Spark配置”</a>页面以获取详细信息和默认值。</p>

<p>执行程序启动时，执行人员会急切地长大，直到<code>spark.cores.max</code>到达了。如果你不设置<code>spark.cores.max</code> ，Spark应用程序将消耗Mesos提供给它的所有资源，因此，我们当然建议您在任何类型的多租户集群中设置此变量，包括运行多个并发Spark应用程序的集群。</p>

<p>调度程序将按Mesos所提供的要约开始执行程序循环，但没有价差保证，因为Mesos不在要约流上提供此类保证。</p>

<p>在这种模式下，Spark执行程序将遵守端口分配（如果用户提供的话）。具体来说，如果用户定义<code>spark.blockManager.port</code>在Spark配置中，mesos调度程序将检查包含端口号的有效端口范围的可用报价。如果没有可用的范围，它将不会启动任何任务。如果用户没有对端口号施加任何限制，则照常使用临时端口。如果用户定义端口，则此端口遵循的实现意味着每个主机执行一项任务。在将来的网络中，应支持隔离。</p>

<p>粗粒度模式的好处是启动开销要低得多，但是以在应用程序的整个过程中保留Mesos资源为代价。要将作业配置为动态调整以适应其资源需求，请查看“ <a href="#dynamic-resource-allocation-with-mesos">动态分配”</a> 。</p>

<h2 id="fine-grained-deprecated">细粒度（已弃用）</h2>

<p><strong>注意：</strong>从Spark 2.0.0开始不赞成使用细粒度模式。考虑使用<a href="#dynamic-resource-allocation-with-mesos">动态分配</a>以获得某些好处。有关完整说明，请参见<a href="https://issues.apache.org/jira/browse/SPARK-11857">SPARK-11857</a></p>

<p>在“细粒度”模式下，Spark执行器中的每个Spark任务都作为单独的Mesos任务运行。这允许Spark的多个实例（和其他框架）以非常精细的粒度共享内核，其中每个应用程序在上下扩展时将获得或多或少的内核，但是在启动每个任务时会带来额外的开销。此模式可能不适用于低延迟要求，例如交互式查询或服务Web请求。</p>

<p>请注意，尽管细粒度的Spark任务将在内核终止时放弃内核，但它们不会放弃内存，因为JVM不会将内存返还给操作系统。执行器空闲时也不会终止。</p>

<p>要以细粒度模式运行，请设置<code>spark.mesos.coarse</code>在您的<a href="configuration.html#spark-properties">SparkConf中将</a>属性设置为false：</p>

<figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span></span><span class="n">conf</span><span class="o">.</span><span class="n">set</span><span class="o">(</span><span class="s">&quot;spark.mesos.coarse&quot;</span><span class="o">,</span> <span class="s">&quot;false&quot;</span><span class="o">)</span></code></pre></figure>

<p>您也可以利用<code>spark.mesos.constraints</code>在Mesos资源商品上设置基于属性的约束。默认情况下，将接受所有资源报价。</p>

<figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span></span><span class="n">conf</span><span class="o">.</span><span class="n">set</span><span class="o">(</span><span class="s">&quot;spark.mesos.constraints&quot;</span><span class="o">,</span> <span class="s">&quot;os:centos7;us-east-1:false&quot;</span><span class="o">)</span></code></pre></figure>

<p>例如，假设<code>spark.mesos.constraints</code>被设定为<code>os:centos7;us-east-1:false</code> ，然后将检查资源报价，看它们是否满足这两个约束，然后才被接受以启动新的执行程序。</p>

<p>要限制驱动程序任务的运行位置，请使用<code>spark.mesos.driver.constraints</code></p>

<h1 id="mesos-docker-support">Mesos Docker支持</h1>

<p>通过设置属性，Spark可以利用Mesos Docker容器化器<code>spark.mesos.executor.docker.image</code>在您的<a href="configuration.html#spark-properties">SparkConf中</a> 。</p>

<p>所使用的Docker映像必须已在映像中包含适当版本的Spark，或者您可以让Mesos通过常规方法下载Spark。</p>

<p>需要Mesos版本0.20.1或更高版本。</p>

<p>请注意，默认情况下，如果Mesos代理上已存在该图像，则它不会提取该图像。如果您使用可变图像标签，则可以设置<code>spark.mesos.executor.docker.forcePullImage</code>至<code>true</code>为了强制代理始终在运行执行程序之前提取映像。强制拉取图像仅在Mesos 0.22及更高版本中可用。</p>

<h1 id="running-alongside-hadoop">与Hadoop一起运行</h1>

<p>您可以将Spark和Mesos与现有的Hadoop集群一起运行，只需将它们作为单独的服务在计算机上启动即可。要从Spark访问Hadoop数据，完整<code>hdfs://</code>网址为必填项（通常为<code>hdfs://<namenode>:9000/path</code> ，但是您可以在Hadoop Namenode Web UI上找到正确的URL）。</p>

<p>此外，还可以在Mesos上运行Hadoop MapReduce，以实现更好的资源隔离和两者之间的共享。在这种情况下，Mesos将充当将内核分配给Hadoop或Spark的统一调度程序，而不是让内核通过每个节点上的Linux调度程序共享资源。请参考<a href="https://github.com/mesos/hadoop">Mesos</a>上的<a href="https://github.com/mesos/hadoop">Hadoop</a> 。</p>

<p>无论哪种情况，HDFS都与Hadoop MapReduce分开运行，而无需通过Mesos进行调度。</p>

<h1 id="dynamic-resource-allocation-with-mesos">使用Mesos进行动态资源分配</h1>

<p>Mesos仅在粗粒度模式下支持动态分配，该模式可以根据应用程序的统计信息调整执行程序的数量。有关一般信息，请参见<a href="job-scheduling.html#dynamic-resource-allocation">动态资源分配</a> 。</p>

<p>要使用的外部随机播放服务是Mesos随机播放服务。由于Mesos尚不支持通知另一个框架的终止，因此它在Shuffle服务之上提供了shuffle数据清除功能。要启动它，运行<code>$SPARK_HOME/sbin/start-mesos-shuffle-service.sh</code>在所有从节点上， <code>spark.shuffle.service.enabled</code>调成<code>true</code> 。</p>

<p>这也可以通过Marathon使用唯一的主机约束和以下命令来实现： <code>bin/spark-class org.apache.spark.deploy.mesos.MesosExternalShuffleService</code> 。</p>

<h1 id="configuration">组态</h1>

<p>有关Spark配置的信息，请参阅<a href="configuration.html">配置页面</a> 。以下配置特定于Mesos上的Spark。</p>

<h4 id="spark-properties">火花特性</h4>

<table class="table">
<tbody><tr><th>物业名称</th><th>默认</th><th>含义</th></tr>
<tr>
  <td><code>spark.mesos.coarse</code></td>
  <td>真正</td>
  <td>如果设置为<code>true</code> ，以“粗粒度”共享模式在Mesos群集上运行，在该模式下，Spark在每台计算机上获取一个长期存在的Mesos任务。如果设置为<code>false</code> ，以“细粒度”共享模式在Mesos群集上运行，其中每个Spark任务创建一个Mesos任务。<a href="running-on-mesos.html#mesos-run-modes">“ Mesos运行模式”中的</a>详细信息。
  </td>
</tr>
<tr>
  <td><code>spark.mesos.extra.cores</code></td>
  <td><code>0</code></td>
  <td>设置供执行者播发的额外内核数。这不会导致分配更多的核心。相反，它意味着执行者将“假装”它具有更多的内核，以便驱动程序将向其发送更多的任务。使用它来增加并行度。此设置仅用于Mesos粗粒度模式。
  </td>
</tr>
<tr>
  <td><code>spark.mesos.mesosExecutor.cores</code></td>
  <td><code>1.0</code></td>
  <td>（仅限于细粒度模式）分配给每个Mesos执行程序的内核数。这不包括用于运行Spark任务的核心。换句话说，即使没有运行Spark任务，每个Mesos执行程序也将占用此处配置的内核数。该值可以是浮点数。
  </td>
</tr>
<tr>
  <td><code>spark.mesos.executor.docker.image</code></td>
  <td>（没有）</td>
  <td>设置Spark执行程序将在其中运行的Docker映像的名称。所选映像必须安装了Spark，以及兼容版本的Mesos库。可以使用以下命令指定映像中Spark的安装路径<code>spark.mesos.executor.home</code> ; Mesos库的安装路径可以用<code>spark.executorEnv.MESOS_NATIVE_JAVA_LIBRARY</code> 。
  </td>
</tr>
<tr>
  <td><code>spark.mesos.executor.docker.forcePullImage</code></td>
  <td>假</td>
  <td>强制Mesos代理拉取在中指定的图像<code>spark.mesos.executor.docker.image</code> 。默认情况下，Mesos代理将不会提取它们已经缓存的图像。
  </td>
</tr>
<tr>
  <td><code>spark.mesos.executor.docker.parameters</code></td>
  <td>（没有）</td>
  <td>设置自定义参数列表，该列表将传递到<code>docker run</code>使用docker容器化程序在Mesos上启动Spark执行程序时使用命令。此属性的格式是键/值对的逗号分隔列表。例：<pre>key1=val1,key2=val2,key3=val3</pre>
  </td>
</tr>
<tr>
  <td><code>spark.mesos.executor.docker.volumes</code></td>
  <td>（没有）</td>
  <td>设置将要安装到Docker映像中的卷的列表，该列表使用<code>spark.mesos.executor.docker.image</code> 。该属性的格式是以下形式的逗号分隔映射列表： <code>docker run -v</code> 。那就是他们的形式：<pre>[host_path:]container_path[:ro|:rw]</pre>
  </td>
</tr>
<tr>
  <td><code>spark.mesos.task.labels</code></td>
  <td>（没有）</td>
  <td>设置Mesos标签以添加到每个任务。标签是自由格式的键/值对。键值对应以冒号分隔，并且逗号用于列出多个。如果您的标签包含冒号或逗号，则可以使用反斜杠将其转义。例如键：值，键2：a \：b。
  </td>
</tr>
<tr>
  <td><code>spark.mesos.executor.home</code></td>
  <td>驾驶员侧<code>SPARK_HOME</code></td>
  <td>在Mesos的执行程序上设置安装Spark的目录。默认情况下，执行者将仅使用驱动程序的Spark主目录，这可能对他们不可见。请注意，这仅在未通过以下方式指定Spark二进制包的情况下才有意义<code>spark.executor.uri</code> 。
  </td>
</tr>
<tr>
  <td><code>spark.mesos.executor.memoryOverhead</code></td>
  <td>执行程序内存* 0.10，最小为384</td>
  <td>每个执行者要分配的额外内存量（以MB为单位）。默认情况下，间接费用将大于384或10％ <code>spark.executor.memory</code> 。如果设置，则最终开销将是该值。
  </td>
</tr>
<tr>
  <td><code>spark.mesos.uris</code></td>
  <td>（没有）</td>
  <td>当Mesos启动驱动程序或执行程序时，以逗号分隔的URI列表将下载到沙箱。这适用于粗粒度和细粒度模式。
  </td>
</tr>
<tr>
  <td><code>spark.mesos.principal</code></td>
  <td>（没有）</td>
  <td>设置Spark框架用于通过Mesos进行身份验证的主体。您也可以通过环境变量“ SPARK_MESOS_PRINCIPAL”来指定。
  </td>
</tr>
<tr>
  <td><code>spark.mesos.principal.file</code></td>
  <td>（没有）</td>
  <td>设置包含主体的文件，Spark框架将使用该主体通过Mesos进行身份验证。允许在更具安全意识的部署中间接指定主体。启动作业的用户必须可读该文件，并且该文件必须是UTF-8编码的纯文本。您也可以通过环境变量`SPARK_MESOS_PRINCIPAL_FILE`进行指定。
  </td>
</tr>
<tr>
  <td><code>spark.mesos.secret</code></td>
  <td>（没有）</td>
  <td>设置Spark框架用于通过Mesos进行身份验证的秘密。例如，在通过注册表进行身份验证时使用。您也可以通过环境变量“ SPARK_MESOS_SECRET”来指定。
  </td>
</tr>
<tr>
  <td><code>spark.mesos.secret.file</code></td>
  <td>（没有）</td>
  <td>设置包含机密的文件，Spark框架将使用该机密对Mesos进行身份验证。例如，在通过注册表进行身份验证时使用。允许在更具安全意识的部署中间接指定机密。启动作业的用户必须可读该文件，并且该文件必须是UTF-8编码的纯文本。您也可以通过环境变量“ SPARK_MESOS_SECRET_FILE”来指定。
  </td>
</tr>
<tr>
  <td><code>spark.mesos.role</code></td>
  <td><code>*</code></td>
  <td>为Mesos设置此Spark框架的角色。在Mesos中，角色用于保留和资源权重共享。
  </td>
</tr>
<tr>
  <td><code>spark.mesos.constraints</code></td>
  <td>（没有）</td>
  <td>Mesos资源提供的基于属性的约束。默认情况下，将接受所有资源报价。此设置仅适用于执行者。有关属性的更多信息，请参阅<a href="http://mesos.apache.org/documentation/attributes-resources/">Mesos属性和资源</a> 。
    <ul>
      <li>标量约束与“小于等于”语义匹配，即约束中的值必须小于或等于资源提供中的值。</li>
      <li>范围约束与“包含”语义匹配，即约束中的值必须在资源报价的值之内。</li>
      <li>集合约束与语义的“子集”匹配，即约束中的值必须是资源报价值的子集。</li>
      <li>文本约束与“平等”语义匹配，即约束中的值必须完全等于资源提供的值。</li>
      <li>如果没有价值作为约束的一部分，则将接受具有相应属性的任何要约（不进行价值检查）。</li>
    </ul>
  </td>
</tr>
<tr>
  <td><code>spark.mesos.driver.constraints</code></td>
  <td>（没有）</td>
  <td>和...一样<code>spark.mesos.constraints</code>除了适用于通过调度程序启动的驱动程序。默认情况下，将接受具有足够资源的所有报价。
  </td>
</tr>
<tr>
  <td><code>spark.mesos.containerizer</code></td>
  <td><code>docker</code></td>
  <td>这仅影响Docker容器，并且必须是“ docker”或“ mesos”之一。Mesos为docker支持两种类型的容器化程序：“ docker”容器化程序和首选的“ mesos”容器化程序。在此处阅读更多信息：http://mesos.apache.org/documentation/latest/container-image/</td>
</tr>
<tr>
  <td><code>spark.mesos.driver.webui.url</code></td>
  <td><code>(none)</code></td>
  <td>设置Spark Mesos驱动程序webui_url以与框架进行交互。如果未设置，它将指向Spark的内部Web UI。</td>
</tr>
<tr>
  <td><code>spark.mesos.driver.labels</code></td>
  <td><code>(none)</code></td>
  <td>Mesos标签添加到驱动程序。看到<code>spark.mesos.task.labels</code>用于格式化信息。
  </td>
</tr>

<tr>
  <td>
    <code>spark.mesos.driver.secret.values</code> ， <code>spark.mesos.driver.secret.names</code> ， <code>spark.mesos.executor.secret.values</code> ， <code>spark.mesos.executor.secret.names</code> ，</td>
  <td><code>(none)</code></td>
  <td>
    <p>机密由其内容和目的地指定。这些属性指定秘密的内容。要指定秘密的目的地，请参见下面的单元格。
    </p>
    <p>您可以通过值（1）或通过引用（2）来指定秘密的内容。
    </p>
    <p>（1）要通过值指定机密，请设置<code>spark.mesos.[driver|executor].secret.values</code>属性，以在驱动程序或执行程序中提供机密。例如，要将秘密密码“ guessme”提供给驱动程序，请设置：</p><pre>spark.mesos.driver.secret.values=guessme</pre>
    <p></p>
    <p>（2）要指定已通过引用放置在秘密存储区中的秘密，请通过设置以下内容在秘密存储区中指定其名称： <code>spark.mesos.[driver|executor].secret.names</code>属性。例如，要使秘密存储区中名为“ password”的秘密密码对驱动程序可用，请设置：</p><pre>spark.mesos.driver.secret.names=password</pre>
    <p></p>
    <p>注意：要使用秘密存储，请确保已通过自定义的<a href="http://mesos.apache.org/documentation/latest/secrets/">SecretResolver模块</a>将其与Mesos集成。
    </p>
    <p>要指定多个机密，请提供一个逗号分隔的列表：</p><pre>spark.mesos.driver.secret.values=guessme,passwd123</pre>要么<pre>spark.mesos.driver.secret.names=password1,password2</pre>
    <p></p>
  </td>
</tr>

<tr>
  <td>
    <code>spark.mesos.driver.secret.envkeys</code> ， <code>spark.mesos.driver.secret.filenames</code> ， <code>spark.mesos.executor.secret.envkeys</code> ， <code>spark.mesos.executor.secret.filenames</code> ，</td>
  <td><code>(none)</code></td>
  <td>
    <p>机密由其内容和目的地指定。这些属性指定机密的目的地。要指定机密内容，请参见上面的单元格。
    </p>
    <p>您可以在驱动程序或执行程序中将秘密的目的地指定为（1）环境变量或（2）作为文件。
    </p>
    <p>（1）要设置基于环境的秘密，请设置<code>spark.mesos.[driver|executor].secret.envkeys</code>属性。该机密将在驱动程序或执行程序中显示为具有给定名称的环境变量。例如，要将可用于驱动程序进程的秘密密码设置为$ PASSWORD，请设置：</p><pre>spark.mesos.driver.secret.envkeys=PASSWORD</pre>
    <p></p>
    <p>（2）要设置基于文件的机密，请设置<code>spark.mesos.[driver|executor].secret.filenames</code>属性。机密将在驱动程序或执行程序中以给定文件名出现在文件的内容中。例如，要在驱动程序进程中的“ pwdfile”文件中提供秘密密码，请设置：</p><pre>spark.mesos.driver.secret.filenames=pwdfile</pre>
    <p></p>
    <p>路径是相对于容器的工作目录的。绝对路径必须已经存在。注意：基于文件的机密需要自定义的<a href="http://mesos.apache.org/documentation/latest/secrets/">SecretResolver模块</a> 。
    </p>
    <p>要指定与多个机密相对应的环境变量或文件名，请提供一个用逗号分隔的列表：</p><pre>spark.mesos.driver.secret.envkeys=PASSWORD1,PASSWORD2</pre>要么<pre>spark.mesos.driver.secret.filenames=pwdfile1,pwdfile2</pre>
    <p></p>
  </td>
</tr>

<tr>
  <td><code>spark.mesos.driverEnv.[EnvironmentVariableName]</code></td>
  <td><code>(none)</code></td>
  <td>这仅影响以群集模式提交的驱动程序。将EnvironmentVariableName指定的环境变量添加到驱动程序进程中。用户可以指定多个以设置多个环境变量。
  </td>
</tr>
<tr>
  <td><code>spark.mesos.dispatcher.webui.url</code></td>
  <td><code>(none)</code></td>
  <td>设置Spark Mesos调度程序webui_url以与框架进行交互。如果未设置，它将指向Spark的内部Web UI。</td>
  </tr>
<tr>
  <td><code>spark.mesos.dispatcher.driverDefault.[PropertyName]</code></td>
  <td><code>(none)</code></td>
  <td>设置通过调度程序提交的驱动程序的默认属性。例如，spark.mesos.dispatcher.driverProperty.spark.executor.memory = 32g导致以群集模式提交的所有驱动程序的执行程序在32g容器中运行。
</td>
</tr>
<tr>
  <td><code>spark.mesos.dispatcher.historyServer.url</code></td>
  <td><code>(none)</code></td>
  <td>设置<a href="monitoring.html#viewing-after-the-fact">历史记录服务器</a>的URL。然后，调度程序会将每个驱动程序链接到其在历史记录服务器中的条目。
  </td>
</tr>
<tr>
  <td><code>spark.mesos.gpus.max</code></td>
  <td><code>0</code></td>
  <td>设置要为此任务获取的最大GPU资源数量。请注意，当找不到GPU资源时，执行程序仍会启动，因为此配置只是一个上限，而不是保证的数量。
  </td>
  </tr>
<tr>
  <td><code>spark.mesos.network.name</code></td>
  <td><code>(none)</code></td>
  <td>将容器连接到给定的命名网络。如果以群集模式启动此作业，则还要在给定的命名网络中启动驱动程序。有关更多详细信息，请参见<a href="http://mesos.apache.org/documentation/latest/cni/">Mesos CNI文档</a> 。
  </td>
</tr>
<tr>
  <td><code>spark.mesos.network.labels</code></td>
  <td><code>(none)</code></td>
  <td>将网络标签传递给CNI插件。这是键值对的逗号分隔列表，其中每个键值对的格式均为key：value。例：<pre>key1:val1,key2:val2</pre>有关更多详细信息，请参见<a href="http://mesos.apache.org/documentation/latest/cni/#mesos-meta-data-to-cni-plugins">Mesos CNI文档</a> 。
  </td>
</tr>
<tr>
  <td><code>spark.mesos.fetcherCache.enable</code></td>
  <td><code>false</code></td>
  <td>如果设置为true，则所有URI（例如：spark.executor.uri，spark.mesos.uris）都将由<a href="http://mesos.apache.org/documentation/latest/fetcher/">Mesos Fetcher缓存进行缓存。</a>
  </td>
</tr>
<tr>
  <td><code>spark.mesos.driver.failoverTimeout</code></td>
  <td><code>0.0</code></td>
  <td>主服务器在暂时断开连接之后，将通过杀死所有执行程序来破坏驱动程序框架之前，等待驱动程序重新连接的时间（以秒为单位）。默认值为零，表示没有超时：如果驱动程序断开连接，则主服务器立即拆除框架。
  </td>
</tr>
<tr>
  <td><code>spark.mesos.rejectOfferDuration</code></td>
  <td><code>120s</code></td>
  <td>考虑未使用资源被拒绝的时间，作为spark.mesos.rejectOfferDurationForUnmetConstraints，spark.mesos.rejectOfferDurationForReachedMaxCores的后备时间</td>
</tr>
<tr>
  <td><code>spark.mesos.rejectOfferDurationForUnmetConstraints</code></td>
  <td><code>spark.mesos.rejectOfferDuration</code></td>
  <td>是时候考虑未满足约束而拒绝使用的未使用资源了</td>
</tr>
<tr>
  <td><code>spark.mesos.rejectOfferDurationForReachedMaxCores</code></td>
  <td><code>spark.mesos.rejectOfferDuration</code></td>
  <td>当最大内核数时，考虑未使用资源的时间<code>spark.cores.max</code>到达了</td>
</tr>
<tr>
  <td><code>spark.mesos.appJar.local.resolution.mode</code></td>
  <td><code>host</code></td>
  <td>提供对“ local：///”方案的支持，以在集群模式下引用应用程序jar资源。如果用户使用本地资源（“ local：/// path / to / jar”）并且未使用config选项，则默认为“ host”。mesos fetcher尝试从主机的文件系统中获取资源。如果该值未知，它将在调度程序日志中显示警告消息，默认为“主机”。如果值是`container`，那么容器中的spark Submit将使用容器路径中的jar：`/ path / to / jar`。
  </td>
</tr>
</tbody></table>

<h1 id="troubleshooting-and-debugging">故障排除和调试</h1>

<p>调试期间需要注意的几个地方：</p>

<ul>
  <li>端口上的Mesos主站<code>:5050</code>
    <ul>
      <li>从站应该出现在“从站”选项卡中</li>
      <li>Spark应用程序应出现在“框架”选项卡中</li>
      <li>任务应该出现在框架的细节中</li>
      <li>检查失败任务沙箱的stdout和stderr</li>
    </ul>
  </li>
  <li>Mesos日志<ul>
      <li>主日志和从日志都在<code>/var/log/mesos</code>默认</li>
    </ul>
  </li>
</ul>

<p>常见的陷阱：</p>

<ul>
  <li>无法到达/访问火花组件<ul>
      <li>从站必须能够从以下地址下载Spark二进制包<code>http://</code> ， <code>hdfs://</code>要么<code>s3n://</code>您提供的网址</li>
    </ul>
  </li>
  <li>防火墙阻止通讯<ul>
      <li>检查有关连接失败的消息</li>
      <li>暂时禁用防火墙进行调试，然后戳出适当的漏洞</li>
    </ul>
  </li>
</ul>


                </div>
            
             <!-- /container -->
        </div>

        <script src="js/vendor/jquery-1.12.4.min.js"></script>
        <script src="js/vendor/bootstrap.min.js"></script>
        <script src="js/vendor/anchor.min.js"></script>
        <script src="js/main.js"></script>

        <!-- MathJax Section -->
        <script type="text/x-mathjax-config">
            MathJax.Hub.Config({
                TeX: { equationNumbers: { autoNumber: "AMS" } }
            });
        </script>
        <script>
            // Note that we load MathJax this way to work with local file (file://), HTTP and HTTPS.
            // We could use "//cdn.mathjax...", but that won't support "file://".
            (function(d, script) {
                script = d.createElement('script');
                script.type = 'text/javascript';
                script.async = true;
                script.onload = function(){
                    MathJax.Hub.Config({
                        tex2jax: {
                            inlineMath: [ ["$", "$"], ["\\\\(","\\\\)"] ],
                            displayMath: [ ["$$","$$"], ["\\[", "\\]"] ],
                            processEscapes: true,
                            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre']
                        }
                    });
                };
                script.src = ('https:' == document.location.protocol ? 'https://' : 'http://') +
                    'cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js' +
                    '?config=TeX-AMS-MML_HTMLorMML';
                d.getElementsByTagName('head')[0].appendChild(script);
            }(document));
        </script>
    

</body></html>